{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from scipy.sparse import csr_matrix,hstack\n",
    "import time\n",
    "'''from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD'''\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold,KFold\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('input/events.csv',index_col='event_id')\n",
    "label = pd.read_csv('input/label_categories.csv')\n",
    "app_event = pd.read_csv('input/app_events.csv')\n",
    "app_label = pd.read_csv('input/app_labels.csv')\n",
    "device = pd.read_csv('input/phone_brand_device_model.csv')\n",
    "device = device.drop_duplicates('device_id').set_index('device_id')\n",
    "gender_age_train = pd.read_csv('input/gender_age_train.csv',index_col = 'device_id')\n",
    "gender_age_test = pd.read_csv('input/gender_age_test.csv',index_col = 'device_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convinience of creating sparse matrix, we create another integer index for the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_age_train\n",
      "                      gender  age   group\n",
      "device_id                               \n",
      "-8076087639492063270      M   35  M32-38\n",
      "\n",
      "gender_age_test\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [1002079943728939269]\n",
      "\n",
      "device\n",
      "                      phone_brand device_model\n",
      "device_id                                    \n",
      "-8890648629457979026          小米           红米\n",
      "\n",
      "events\n",
      "                   device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
      "\n",
      "label\n",
      "    label_id category\n",
      "0         1      NaN\n",
      "\n",
      "app_event\n",
      "    event_id               app_id  is_installed  is_active\n",
      "0         2  5927333115845830913             1          1\n",
      "\n",
      "app_label\n",
      "                 app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print('gender_age_train\\n',gender_age_train.head(1))\n",
    "print('\\ngender_age_test\\n',gender_age_test.head(1))\n",
    "print('\\ndevice\\n',device.head(1))\n",
    "print('\\nevents\\n',events.head(1))\n",
    "print('\\nlabel\\n',label.head(1))\n",
    "print('\\napp_event\\n',app_event.head(1))\n",
    "print('\\napp_label\\n',app_label.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of two set of devices: with events and without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set without events:    51336\n",
      "Size of training set with events:       23309\n",
      "Total size of training set:             74645\n",
      "Size of testing set without events:     76877\n",
      "Size of training set with events:       35194\n",
      "Total size of training set:             112071\n"
     ]
    }
   ],
   "source": [
    "gender_age_train_with = gender_age_train.loc[gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_train_without = gender_age_train.loc[~gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_with = gender_age_test.loc[gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_without = gender_age_test.loc[~gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set without events:',gender_age_train_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_train_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_train.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of testing set without events:',gender_age_test_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_test_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_age_train_with['int_index'] = np.arange(gender_age_train_with.shape[0])\n",
    "gender_age_test_with['int_index'] = np.arange(gender_age_test_with.shape[0])\n",
    "gender_age_train_without['int_index'] = np.arange(gender_age_train_without.shape[0])\n",
    "gender_age_test_without['int_index'] = np.arange(gender_age_test_without.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering I: phone brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the phone brand, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(device.phone_brand)\n",
    "device['brand'] = encoder.transform(device.phone_brand)\n",
    "gender_age_train_with['brand'] = device['brand']\n",
    "gender_age_test_with['brand'] = device['brand']\n",
    "gender_age_train_without['brand'] = device['brand']\n",
    "gender_age_test_without['brand'] = device['brand']\n",
    "brandnumber = len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sparse matrix with each row representing one device and each column representing one brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 131)\n",
      "X_test_brand_with shape: (35194, 131)\n",
      "X_train_brand_without shape: (51336, 131)\n",
      "X_test_brand_without shape: (76877, 131)\n"
     ]
    }
   ],
   "source": [
    "X_train_brand_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                            (gender_age_train_with.int_index,gender_age_train_with.brand)),\n",
    "                               shape = (gender_age_train_with.shape[0],brandnumber))\n",
    "X_test_brand_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                           (gender_age_test_with.int_index,gender_age_test_with.brand)),\n",
    "                              shape = (gender_age_test_with.shape[0],brandnumber))\n",
    "print('X_train_brand_with shape:',X_train_brand_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_brand_with.shape)\n",
    "X_train_brand_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                            (gender_age_train_without.int_index,gender_age_train_without.brand)),\n",
    "                                  shape = (gender_age_train_without.shape[0],brandnumber))\n",
    "X_test_brand_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                           (gender_age_test_without.int_index,gender_age_test_without.brand)),\n",
    "                                 shape = (gender_age_test_without.shape[0],brandnumber))\n",
    "print('X_train_brand_without shape:',X_train_brand_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_brand_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering II: phone device model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brand_model = device.phone_brand.str.cat(device.device_model)\n",
    "encoder3 = LabelEncoder()\n",
    "encoder3.fit(brand_model)\n",
    "device['model'] = encoder3.transform(brand_model)\n",
    "gender_age_train_with['model'] = device['model']\n",
    "gender_age_test_with['model'] = device['model']\n",
    "gender_age_train_without['model'] = device['model']\n",
    "gender_age_test_without['model'] = device['model']\n",
    "modelnumber = len(encoder3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 1667)\n",
      "X_test_brand_with shape: (35194, 1667)\n",
      "X_train_brand_without shape: (51336, 1667)\n",
      "X_test_brand_without shape: (76877, 1667)\n"
     ]
    }
   ],
   "source": [
    "X_train_model_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                                 (gender_age_train_with.int_index,gender_age_train_with.model)),\n",
    "                               shape = (gender_age_train_with.shape[0],modelnumber))\n",
    "X_test_model_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                                (gender_age_test_with.int_index,gender_age_test_with.model)),\n",
    "                              shape = (gender_age_test_with.shape[0],modelnumber))\n",
    "X_train_model_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                                    (gender_age_train_without.int_index,gender_age_train_without.model)),\n",
    "                                  shape = (gender_age_train_without.shape[0],modelnumber))\n",
    "X_test_model_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                                   (gender_age_test_without.int_index,gender_age_test_without.model)),\n",
    "                                 shape = (gender_age_test_without.shape[0],modelnumber))\n",
    "\n",
    "print('X_train_brand_with shape:',X_train_model_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_model_with.shape)\n",
    "print('X_train_brand_without shape:',X_train_model_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_model_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering III: Installed app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the app_id and store it into app column, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = LabelEncoder()\n",
    "encoder2.fit(app_event.app_id)\n",
    "app_event['app'] = encoder2.transform(app_event.app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 19234, 19235, 19236], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(app_event.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   event_id               app_id  is_installed  is_active    app\n",
      "0         2  5927333115845830913             1          1  15408\n",
      "                  device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n"
     ]
    }
   ],
   "source": [
    "print(app_event.head(1))\n",
    "print(events.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  event_id    app  is_installed\n",
      "0 -6401643145415154744         2  15408             1\n",
      "1 -6401643145415154744         2   3384             1\n",
      "2 -6401643145415154744         2   7620             1\n",
      "3 -6401643145415154744         2   8902             1\n",
      "4 -6401643145415154744         2  18686             1\n"
     ]
    }
   ],
   "source": [
    "installed_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_installed']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "print(installed_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_app_train:\n",
      "                           size  int_index\n",
      "device_id            app                  \n",
      "-9222956879900151005 548     18       5145\n",
      "                     1096    18       5145\n",
      "                     1248    26       5145\n",
      "                     1545    12       5145\n",
      "                     1664    18       5145\n"
     ]
    }
   ],
   "source": [
    "installed_app_grouped = installed_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_app_train_with = pd.merge(installed_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_index=True)\n",
    "installed_app_test_with = pd.merge(installed_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_index=True)\n",
    "print('installed_app_train:')\n",
    "print(installed_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id   app  size  int_index\n",
      "0 -9222956879900151005   548    18       5145\n",
      "1 -9222956879900151005  1096    18       5145\n",
      "2 -9222956879900151005  1248    26       5145\n",
      "3 -9222956879900151005  1545    12       5145\n",
      "4 -9222956879900151005  1664    18       5145\n",
      "             device_id    app  size  int_index\n",
      "0 -9222661944218806987   1867     3       2851\n",
      "1 -9222661944218806987   7519     8       2851\n",
      "2 -9222661944218806987   7843     1       2851\n",
      "3 -9222661944218806987   8704     4       2851\n",
      "4 -9222661944218806987  10000     1       2851\n"
     ]
    }
   ],
   "source": [
    "installed_app_train_with = installed_app_train_with.reset_index()\n",
    "installed_app_test_with = installed_app_test_with.reset_index()\n",
    "installed_app_train_with = installed_app_train_with.dropna(subset=['int_index'])\n",
    "installed_app_test_with = installed_app_test_with.dropna(subset=['int_index'])\n",
    "print(installed_app_train_with.head())\n",
    "print(installed_app_test_with.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of unique app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35194\n",
      "915632\n"
     ]
    }
   ],
   "source": [
    "print(gender_age_test_with.shape[0])\n",
    "print(installed_app_train_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique apps:\n",
      "19237\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique apps:')\n",
    "print(np.size(installed_app.app.unique()))\n",
    "appnumber = np.size(installed_app.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ..., 19234 19235 19236]\n",
      "1387337\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(installed_app_train_with.app.unique()))\n",
    "print(installed_app_test_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed shape: (23309, 19237)\n",
      "X_test_installed shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "X_train_installed_with = csr_matrix((np.ones(installed_app_train_with.shape[0]),\n",
    "                                (installed_app_train_with.int_index,installed_app_train_with.app)), \n",
    "                               shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_installed_with = csr_matrix((np.ones(installed_app_test_with.shape[0]),\n",
    "                               (installed_app_test_with.int_index,installed_app_test_with.app)),\n",
    "                               shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_installed shape:',X_train_installed_with.shape)\n",
    "print('X_test_installed shape:',X_test_installed_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 35191, 35192, 35193], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(installed_app_test_with.int_index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering IV: app label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                app_id  event_id\n",
      "0  5927333115845830913         2\n",
      "                app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print(app_event[['app_id','event_id']].head(1))\n",
    "print(app_label[['app_id','label_id']].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_label_new:\n",
      "                app_id  label_id    app  label\n",
      "0  7324884708820027918       251  17355    207\n",
      "1 -4494216993218550286       251   4618    207\n",
      "2  6058196446775239644       406  15548    247\n",
      "3  6058196446775239644       407  15548    248\n",
      "4  8694625920731541625       406  18689    247\n"
     ]
    }
   ],
   "source": [
    "app_label_new = app_label.loc[app_label.app_id.isin(app_event.app_id.unique())].copy()\n",
    "app_label_new['app'] = encoder2.transform(app_label_new.app_id)\n",
    "encoder4 = LabelEncoder().fit(app_label_new.label_id)\n",
    "app_label_new['label'] = encoder4.transform(app_label_new.label_id)\n",
    "labelnumber = len(encoder4.classes_)\n",
    "print('app_label_new:')\n",
    "print(app_label_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919886\n",
      "129892268\n",
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_label_grouped:\n",
      "             device_id  label  size\n",
      "0 -9222956879900151005    117     1\n",
      "1 -9222956879900151005    120     1\n",
      "2 -9222956879900151005    126     1\n",
      "3 -9222956879900151005    138     2\n",
      "4 -9222956879900151005    147     2\n"
     ]
    }
   ],
   "source": [
    "print(app_label.size)\n",
    "print(installed_app.size)\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_label_grouped = (installed_app_grouped.reset_index()[['device_id','app']]\n",
    "                          .merge(app_label_new[['app','label']])\n",
    "                          .groupby(['device_id','label']))['app'].agg(['size']).reset_index()\n",
    "                          \n",
    "print('installed_label_grouped:')\n",
    "print(installed_label_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_app_train_with = pd.merge(installed_label_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_on='device_id')\n",
    "label_app_test_with = pd.merge(installed_label_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_on ='device_id' )\n",
    "label_app_train_with = label_app_train_with.dropna(subset= ['int_index','label'])\n",
    "label_app_test_with = label_app_test_with.dropna(subset= ['int_index','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed_with shape: (23309, 492)\n",
      "X_test_installed_with shape: (35194, 492)\n"
     ]
    }
   ],
   "source": [
    "X_train_label_with = csr_matrix((np.ones(label_app_train_with.shape[0]),\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((np.ones(label_app_test_with.shape[0]),(label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))\n",
    "print('X_train_installed_with shape:',X_train_label_with.shape)\n",
    "print('X_test_installed_with shape:',X_test_label_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering V: active app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  event_id    app  is_active\n",
      "0 -6401643145415154744         2  15408          1\n",
      "3 -6401643145415154744         2   8902          1\n",
      "4 -6401643145415154744         2  18686          1\n",
      "5 -6401643145415154744         2  14346          1\n",
      "9 -6401643145415154744         2  16908          1\n"
     ]
    }
   ],
   "source": [
    "active_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_active']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "active_app = active_app.loc[active_app.is_active==1]\n",
    "print(active_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548      4\n",
      "                     1248    15\n",
      "                     1545     2\n",
      "                     1848    31\n",
      "                     2236    17\n"
     ]
    }
   ],
   "source": [
    "active_app_grouped = active_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('active_app_grouped:')\n",
    "print(active_app_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_app_train_with:\n",
      "                           size  int_index\n",
      "device_id            app                  \n",
      "-9222956879900151005 548      4       5145\n",
      "                     1248    15       5145\n",
      "                     1545     2       5145\n",
      "                     1848    31       5145\n",
      "                     2236    17       5145\n"
     ]
    }
   ],
   "source": [
    "active_app_train_with = pd.merge(active_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'left',right_index=True,left_index=True)\n",
    "active_app_test_with = pd.merge(active_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'left',right_index=True,left_index=True)\n",
    "print('active_app_train_with:')\n",
    "print(active_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id   app  size  int_index\n",
      "0 -9222956879900151005   548     4       5145\n",
      "1 -9222956879900151005  1248    15       5145\n",
      "2 -9222956879900151005  1545     2       5145\n",
      "3 -9222956879900151005  1848    31       5145\n",
      "4 -9222956879900151005  2236    17       5145\n",
      "              device_id    app  size  int_index\n",
      "55 -9222661944218806987   1867     3       2851\n",
      "56 -9222661944218806987   7519     7       2851\n",
      "57 -9222661944218806987   7843     1       2851\n",
      "58 -9222661944218806987   8704     3       2851\n",
      "59 -9222661944218806987  10000     1       2851\n"
     ]
    }
   ],
   "source": [
    "active_app_train_with = active_app_train_with.reset_index()\n",
    "active_app_test_with = active_app_test_with.reset_index()\n",
    "active_app_train_with = active_app_train_with.dropna(subset=['int_index'])\n",
    "active_app_test_with = active_app_test_with.dropna(subset=['int_index'])\n",
    "print(active_app_train_with.head())\n",
    "print(active_app_test_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     5     6 ..., 19225 19228 19236]\n",
      "19237\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(active_app_train_with.app.unique()))\n",
    "print(appnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_active shape: (23309, 19237)\n",
      "X_test_active shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "# binary active map\n",
    "#X_train_active_with = csr_matrix((np.ones(active_app_train_with.shape[0]),\n",
    "#                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "#                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "#X_test_active = csr_matrix((np.ones(active_app_test_with.shape[0]),\n",
    "#                            (active_app_test.int_index,active_app_test_with.app)),\n",
    "#                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "# count the number of active app\n",
    "X_train_active_with = csr_matrix((np.log(np.log(active_app_train_with['size']+1)+1),\n",
    "                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_active_with = csr_matrix((np.log(np.log(active_app_test_with['size']+1)+1),\n",
    "                            (active_app_test_with.int_index,active_app_test_with.app)),\n",
    "                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_active shape:',X_train_active_with.shape)\n",
    "print('X_test_active shape:',X_test_active_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering VI: active time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29182687948017175</td>\n",
       "      <td>2016-05-01 00:55:25</td>\n",
       "      <td>121.38</td>\n",
       "      <td>31.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>2016-05-01 00:54:12</td>\n",
       "      <td>103.65</td>\n",
       "      <td>30.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4833982096941402721</td>\n",
       "      <td>2016-05-01 00:08:05</td>\n",
       "      <td>106.60</td>\n",
       "      <td>29.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6815121365017318426</td>\n",
       "      <td>2016-05-01 00:06:40</td>\n",
       "      <td>104.27</td>\n",
       "      <td>23.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5373797595892518570</td>\n",
       "      <td>2016-05-01 00:07:18</td>\n",
       "      <td>115.88</td>\n",
       "      <td>28.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    device_id            timestamp  longitude  latitude\n",
       "event_id                                                               \n",
       "1           29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
       "2        -6401643145415154744  2016-05-01 00:54:12     103.65     30.97\n",
       "3        -4833982096941402721  2016-05-01 00:08:05     106.60     29.70\n",
       "4        -6815121365017318426  2016-05-01 00:06:40     104.27     23.28\n",
       "5        -5373797595892518570  2016-05-01 00:07:18     115.88     28.66"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  time  times\n",
      "0 -9222956879900151005     7      2\n",
      "1 -9222956879900151005    11      7\n",
      "2 -9222956879900151005    12     13\n",
      "3 -9222956879900151005    13      3\n",
      "4 -9222956879900151005    14      5\n"
     ]
    }
   ],
   "source": [
    "events_time = events[['device_id','timestamp']].copy()\n",
    "events_time['time']  = events_time['timestamp'].str[11:13].astype(int)\n",
    "events_time.drop(['timestamp'],axis=1,inplace=True)\n",
    "events_time = events_time.groupby(['device_id','time'])['time'].agg({'times':'count'}).reset_index()\n",
    "print(events_time.head())\n",
    "timenumber= events_time.time.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_time_with shape: (23309, 24)\n",
      "X_test_time_with shape: (35194, 24)\n"
     ]
    }
   ],
   "source": [
    "time_train_with = pd.merge(events_time,gender_age_train_with[['int_index']],\n",
    "                               right_index=True,left_on='device_id')\n",
    "time_test_with = pd.merge(events_time,gender_age_test_with[['int_index']],\n",
    "                               right_index=True,left_on ='device_id' )\n",
    "#binary\n",
    "#X_train_time_with = csr_matrix((np.ones(time_train_with.shape[0]),\n",
    "#                            (time_train_with.int_index,time_train_with.time)), \n",
    "#                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "#X_test_time_with = csr_matrix((np.ones(time_test_with.shape[0]),\n",
    "#                            (time_test_with.int_index,time_test_with.time)),\n",
    "#                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "\n",
    "#number\n",
    "X_train_time_with = csr_matrix((np.log(np.log(time_train_with['times']+1)+1),\n",
    "                            (time_train_with.int_index,time_train_with.time)), \n",
    "                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "X_test_time_with = csr_matrix((np.log(np.log(time_test_with['times']+1)+1),\n",
    "                            (time_test_with.int_index,time_test_with.time)),\n",
    "                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "print('X_train_time_with shape:',X_train_time_with.shape)\n",
    "print('X_test_time_with shape:',X_test_time_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the time period count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler(with_mean=False)\\nX_train_time_with = scaler.fit_transform(X_train_time_with)\\nX_test_time_with = scaler.transform(X_test_time_with)'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_time_with = scaler.fit_transform(X_train_time_with)\n",
    "X_test_time_with = scaler.transform(X_test_time_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature join and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(51336, 1798)\n",
      "Testing shape:\n",
      "(76877, 1798)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_without = hstack((X_train_brand_without,X_train_model_without),format='csr')\n",
    "X_test_total_without = hstack((X_test_brand_without,X_test_model_without),format='csr')\n",
    "print('Training shape:')\n",
    "print(X_train_total_without.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device with events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(23309, 40788)\n",
      "Testing shape:\n",
      "(35194, 40788)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_with = hstack((X_train_brand_with,X_train_model_with,\n",
    "                             X_train_installed_with,X_train_label_with,\n",
    "                            X_train_active_with,X_train_time_with),format='csr')\n",
    "X_test_total_with = hstack((X_test_brand_with,X_test_model_with,\n",
    "                           X_test_installed_with,X_test_label_with,\n",
    "                            X_test_active_with,X_test_time_with),format='csr')\n",
    "print('Training shape:')\n",
    "print(X_train_total_with.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(74645, 15155)\n",
      "Testing shape:\n",
      "(112071, 15155)\n"
     ]
    }
   ],
   "source": [
    "#percentile selction\n",
    "#selector = SelectPercentile(f_classif, percentile=80)\n",
    "#selector.fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#X_val.shape\n",
    "\n",
    "# Selection using chi-square\n",
    "#selector = SelectKBest(chi2, k=15155).fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#print('Training shape:')\n",
    "#print(X_train_total.shape)\n",
    "#print('Testing shape:')\n",
    "#print(X_test_total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep learning model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator \n",
    "    #(https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(150, input_dim=X_train_total.shape[1], init='normal', activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(50, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## device with events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-663b282bed8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_with\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargetencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgender_age_train_with\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdummy_y_with\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_with\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "targetencoder = LabelEncoder().fit(gender_age_train_with.group)\n",
    "y_with = targetencoder.transform(gender_age_train_with.group)\n",
    "nclasses = len(targetencoder.classes_)\n",
    "dummy_y_with = np_utils.to_categorical(y_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "Epoch 1/10\n",
      "48s - loss: 2.4395 - acc: 0.1322 - val_loss: 2.4139 - val_acc: 0.1273\n",
      "Epoch 2/10\n",
      "44s - loss: 2.3681 - acc: 0.1542 - val_loss: 2.3843 - val_acc: 0.1434\n",
      "Epoch 3/10\n",
      "44s - loss: 2.3241 - acc: 0.1711 - val_loss: 2.3619 - val_acc: 0.1561\n",
      "Epoch 4/10\n",
      "43s - loss: 2.3024 - acc: 0.1805 - val_loss: 2.3495 - val_acc: 0.1627\n",
      "Epoch 5/10\n",
      "43s - loss: 2.2824 - acc: 0.1878 - val_loss: 2.3434 - val_acc: 0.1641\n",
      "Epoch 6/10\n",
      "46s - loss: 2.2728 - acc: 0.1913 - val_loss: 2.3385 - val_acc: 0.1677\n",
      "Epoch 7/10\n",
      "46s - loss: 2.2650 - acc: 0.1940 - val_loss: 2.3345 - val_acc: 0.1705\n",
      "Epoch 8/10\n",
      "48s - loss: 2.2562 - acc: 0.1990 - val_loss: 2.3314 - val_acc: 0.1695\n",
      "Epoch 9/10\n",
      "46s - loss: 2.2462 - acc: 0.2023 - val_loss: 2.3297 - val_acc: 0.1725\n",
      "Epoch 10/10\n",
      "47s - loss: 2.2437 - acc: 0.2034 - val_loss: 2.3254 - val_acc: 0.1756\n",
      "logloss val 2.3254444197794397\n",
      "*****************************************************\n",
      "Epoch 1/10\n",
      "53s - loss: 2.4362 - acc: 0.1328 - val_loss: 2.4182 - val_acc: 0.1301\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py:1403: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-7346ac89cc8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                          \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                          \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m69984\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                          )\n\u001b[1;32m     17\u001b[0m     scores_val = model.predict_generator(generator=batch_generatorp(X_val, 32, False), \n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                                         \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                                         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                                         max_q_size=max_q_size)\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1383\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1385\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 564\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 637\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m--> 628\u001b[0;31m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(len(y_train_total_with),n_folds = 10)\n",
    "scores_val_list_with=[]\n",
    "score_list_with=[]\n",
    "for train, test in kf:\n",
    "    X_train_with = X_train_total_with[train]\n",
    "    y_train_with = dummy_y_with[train]\n",
    "    X_val_with = X_train_total_with[test]\n",
    "    y_val_with = dummy_y_with[test]\n",
    "    #print(X_val.shape)\n",
    "    print('*****************************************************')\n",
    "    model=baseline_model()\n",
    "    fit= model.fit_generator(generator=batch_generator(X_train_with, y_train_with, 400, True),\n",
    "                         nb_epoch=10,\n",
    "                         samples_per_epoch=69984,\n",
    "                         validation_data=(X_val_with.todense(), y_val_with), verbose=2\n",
    "                         )\n",
    "    scores_val_with = model.predict_generator(generator=batch_generatorp(X_val_with, 32, False), \n",
    "                                         val_samples=X_val_with.shape[0])\n",
    "    scores_val_list_with.append(scores_val_with)\n",
    "    scores_with = model.predict_generator(generator=batch_generatorp(X_test_total_with, 32, False), \n",
    "                                     val_samples=X_test_total_with.shape[0])\n",
    "    score_list.append(scores_with)\n",
    "    print('logloss val {}'.format(log_loss(y_val_with, scores_val_with)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,i in enumerate(val_loss_list_with):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_with = sumi/len(val_loss_list_with)\n",
    "print('average logloss val {}'.format(val_loss_ave_with))\n",
    "for index,i in enumerate(score_list_with):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_with = sumi/len(score_list_with)\n",
    "pred_with = pd.DataFrame(score_ave_with, index = gender_age_test_with.index, columns=targetencoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-663b282bed8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_with\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargetencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgender_age_train_with\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdummy_y_with\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_with\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "targetencoder = LabelEncoder().fit(gender_age_train_without.group)\n",
    "y_without = targetencoder.transform(gender_age_train_without.group)\n",
    "nclasses = len(targetencoder.classes_)\n",
    "dummy_y_without = np_utils.to_categorical(y_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "Epoch 1/10\n",
      "48s - loss: 2.4395 - acc: 0.1322 - val_loss: 2.4139 - val_acc: 0.1273\n",
      "Epoch 2/10\n",
      "44s - loss: 2.3681 - acc: 0.1542 - val_loss: 2.3843 - val_acc: 0.1434\n",
      "Epoch 3/10\n",
      "44s - loss: 2.3241 - acc: 0.1711 - val_loss: 2.3619 - val_acc: 0.1561\n",
      "Epoch 4/10\n",
      "43s - loss: 2.3024 - acc: 0.1805 - val_loss: 2.3495 - val_acc: 0.1627\n",
      "Epoch 5/10\n",
      "43s - loss: 2.2824 - acc: 0.1878 - val_loss: 2.3434 - val_acc: 0.1641\n",
      "Epoch 6/10\n",
      "46s - loss: 2.2728 - acc: 0.1913 - val_loss: 2.3385 - val_acc: 0.1677\n",
      "Epoch 7/10\n",
      "46s - loss: 2.2650 - acc: 0.1940 - val_loss: 2.3345 - val_acc: 0.1705\n",
      "Epoch 8/10\n",
      "48s - loss: 2.2562 - acc: 0.1990 - val_loss: 2.3314 - val_acc: 0.1695\n",
      "Epoch 9/10\n",
      "46s - loss: 2.2462 - acc: 0.2023 - val_loss: 2.3297 - val_acc: 0.1725\n",
      "Epoch 10/10\n",
      "47s - loss: 2.2437 - acc: 0.2034 - val_loss: 2.3254 - val_acc: 0.1756\n",
      "logloss val 2.3254444197794397\n",
      "*****************************************************\n",
      "Epoch 1/10\n",
      "53s - loss: 2.4362 - acc: 0.1328 - val_loss: 2.4182 - val_acc: 0.1301\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py:1403: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-7346ac89cc8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                          \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                          \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m69984\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                          )\n\u001b[1;32m     17\u001b[0m     scores_val = model.predict_generator(generator=batch_generatorp(X_val, 32, False), \n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                                         \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                                         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                                         max_q_size=max_q_size)\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1383\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1385\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 564\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 637\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m--> 628\u001b[0;31m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(len(y_train_total_without),n_folds = 10)\n",
    "scores_val_list_without=[]\n",
    "score_list_without=[]\n",
    "for train, test in kf:\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = dummy_y_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = dummy_y_without[test]\n",
    "    #print(X_val.shape)\n",
    "    print('*****************************************************')\n",
    "    model=baseline_model()\n",
    "    fit= model.fit_generator(generator=batch_generator(X_train_without, y_train_without, 400, True),\n",
    "                         nb_epoch=10,\n",
    "                         samples_per_epoch=69984,\n",
    "                         validation_data=(X_val_without.todense(), y_val_without), verbose=2\n",
    "                         )\n",
    "    scores_val_without = model.predict_generator(generator=batch_generatorp(X_val_without, 32, False), \n",
    "                                         val_samples=X_val_without.shape[0])\n",
    "    scores_val_list_without.append(scores_val_without)\n",
    "    scores_without = model.predict_generator(generator=batch_generatorp(X_test_total_without, 32, False), \n",
    "                                     val_samples=X_test_total_without.shape[0])\n",
    "    score_list.append(scores_without)\n",
    "    print('logloss val {}'.format(log_loss(y_val_without, scores_val_without)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(val_loss_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## putting together and save into final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.concat(pred_with,pred_without)\n",
    "pred.to_csv('keras_v15.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and fitting: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "targetencoder = LabelEncoder()\n",
    "targetencoder.fit(gender_age_train.group)\n",
    "y_train_total = targetencoder.transform(gender_age_train.group)\n",
    "target_len = len(targetencoder.classes_)\n",
    "print(target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = cv.train_test_split(X_train_total,y_train_total,test_size=0.005, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.02, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.02,multi_class='multinomial',solver='newton-cg')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2749612582739513"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19901403922409175"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F23-</th>\n",
       "      <th>F24-26</th>\n",
       "      <th>F27-28</th>\n",
       "      <th>F29-32</th>\n",
       "      <th>F33-42</th>\n",
       "      <th>F43+</th>\n",
       "      <th>M22-</th>\n",
       "      <th>M23-26</th>\n",
       "      <th>M27-28</th>\n",
       "      <th>M29-31</th>\n",
       "      <th>M32-38</th>\n",
       "      <th>M39+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002079943728939269</th>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>0.033186</td>\n",
       "      <td>0.051509</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.031108</td>\n",
       "      <td>0.069016</td>\n",
       "      <td>0.108805</td>\n",
       "      <td>0.245644</td>\n",
       "      <td>0.416199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1547860181818787117</th>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>0.061730</td>\n",
       "      <td>0.070525</td>\n",
       "      <td>0.148762</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.118501</td>\n",
       "      <td>0.055331</td>\n",
       "      <td>0.067424</td>\n",
       "      <td>0.240890</td>\n",
       "      <td>0.177163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374582448058474277</th>\n",
       "      <td>0.022811</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.040158</td>\n",
       "      <td>0.136054</td>\n",
       "      <td>0.174151</td>\n",
       "      <td>0.077040</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>0.039140</td>\n",
       "      <td>0.101672</td>\n",
       "      <td>0.183772</td>\n",
       "      <td>0.147106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-6220210354783429585</th>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>0.046435</td>\n",
       "      <td>0.144354</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.174171</td>\n",
       "      <td>0.068642</td>\n",
       "      <td>0.121052</td>\n",
       "      <td>0.169799</td>\n",
       "      <td>0.154253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-5893464122623104785</th>\n",
       "      <td>0.047394</td>\n",
       "      <td>0.065124</td>\n",
       "      <td>0.042721</td>\n",
       "      <td>0.062585</td>\n",
       "      <td>0.056626</td>\n",
       "      <td>0.043316</td>\n",
       "      <td>0.092342</td>\n",
       "      <td>0.164602</td>\n",
       "      <td>0.097607</td>\n",
       "      <td>0.102084</td>\n",
       "      <td>0.132622</td>\n",
       "      <td>0.092977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F23-    F24-26    F27-28    F29-32    F33-42  \\\n",
       "device_id                                                                \n",
       " 1002079943728939269  0.001320  0.006996  0.013956  0.011760  0.033186   \n",
       "-1547860181818787117  0.009032  0.014880  0.029417  0.061730  0.070525   \n",
       " 7374582448058474277  0.022811  0.042062  0.040158  0.136054  0.174151   \n",
       "-6220210354783429585  0.003416  0.029785  0.009868  0.012436  0.046435   \n",
       "-5893464122623104785  0.047394  0.065124  0.042721  0.062585  0.056626   \n",
       "\n",
       "                          F43+      M22-    M23-26    M27-28    M29-31  \\\n",
       "device_id                                                                \n",
       " 1002079943728939269  0.051509  0.010501  0.031108  0.069016  0.108805   \n",
       "-1547860181818787117  0.148762  0.006344  0.118501  0.055331  0.067424   \n",
       " 7374582448058474277  0.077040  0.011671  0.024363  0.039140  0.101672   \n",
       "-6220210354783429585  0.144354  0.065789  0.174171  0.068642  0.121052   \n",
       "-5893464122623104785  0.043316  0.092342  0.164602  0.097607  0.102084   \n",
       "\n",
       "                        M32-38      M39+  \n",
       "device_id                                 \n",
       " 1002079943728939269  0.245644  0.416199  \n",
       "-1547860181818787117  0.240890  0.177163  \n",
       " 7374582448058474277  0.183772  0.147106  \n",
       "-6220210354783429585  0.169799  0.154253  \n",
       "-5893464122623104785  0.132622  0.092977  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.fit(X_train_total,y_train_total)\n",
    "pred = pd.DataFrame(model.predict_proba(X_test_total), index = gender_age_test.index, columns=targetencoder.classes_)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.to_csv('logreg_submission.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting :RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=1,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = rfc(n_estimators=300,verbose=1,n_jobs=-1)\n",
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2819344751732902"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test,y_pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
