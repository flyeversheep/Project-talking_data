{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from scipy.sparse import csr_matrix,hstack,vstack\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold,KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import os\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('input/events.csv',index_col='event_id')\n",
    "label = pd.read_csv('input/label_categories.csv')\n",
    "app_event = pd.read_csv('input/app_events.csv')\n",
    "app_label = pd.read_csv('input/app_labels.csv')\n",
    "device = pd.read_csv('input/phone_brand_device_model.csv')\n",
    "device = device.drop_duplicates('device_id').set_index('device_id')\n",
    "gender_age_train = pd.read_csv('input/gender_age_train.csv',index_col = 'device_id')\n",
    "gender_age_test = pd.read_csv('input/gender_age_test.csv',index_col = 'device_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convinience of creating sparse matrix, we create another integer index for the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_age_train\n",
      "                      gender  age   group\n",
      "device_id                               \n",
      "-8076087639492063270      M   35  M32-38\n",
      "\n",
      "gender_age_test\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [1002079943728939269]\n",
      "\n",
      "device\n",
      "                      phone_brand device_model\n",
      "device_id                                    \n",
      "-8890648629457979026          小米           红米\n",
      "\n",
      "events\n",
      "                   device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
      "\n",
      "label\n",
      "    label_id category\n",
      "0         1      NaN\n",
      "\n",
      "app_event\n",
      "    event_id               app_id  is_installed  is_active\n",
      "0         2  5927333115845830913             1          1\n",
      "\n",
      "app_label\n",
      "                 app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print('gender_age_train\\n',gender_age_train.head(1))\n",
    "print('\\ngender_age_test\\n',gender_age_test.head(1))\n",
    "print('\\ndevice\\n',device.head(1))\n",
    "print('\\nevents\\n',events.head(1))\n",
    "print('\\nlabel\\n',label.head(1))\n",
    "print('\\napp_event\\n',app_event.head(1))\n",
    "print('\\napp_label\\n',app_label.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of two set of devices: with events and without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set without events:    51336\n",
      "Size of training set with events:       23309\n",
      "Total size of training set:             74645\n",
      "Size of testing set without events:     76877\n",
      "Size of training set with events:       35194\n",
      "Total size of training set:             112071\n"
     ]
    }
   ],
   "source": [
    "gender_age_train_with = gender_age_train.loc[gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_train_without = gender_age_train.loc[~gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_with = gender_age_test.loc[gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_without = gender_age_test.loc[~gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set without events:',gender_age_train_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_train_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_train.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of testing set without events:',gender_age_test_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_test_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_age_train_with['int_index'] = np.arange(gender_age_train_with.shape[0])\n",
    "gender_age_test_with['int_index'] = np.arange(gender_age_test_with.shape[0])\n",
    "gender_age_train_without['int_index'] = np.arange(gender_age_train_without.shape[0])\n",
    "gender_age_test_without['int_index'] = np.arange(gender_age_test_without.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering I: phone brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the phone brand, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(device.phone_brand)\n",
    "device['brand'] = encoder.transform(device.phone_brand)\n",
    "gender_age_train_with['brand'] = device['brand']\n",
    "gender_age_test_with['brand'] = device['brand']\n",
    "gender_age_train_without['brand'] = device['brand']\n",
    "gender_age_test_without['brand'] = device['brand']\n",
    "brandnumber = len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sparse matrix with each row representing one device and each column representing one brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 131)\n",
      "X_test_brand_with shape: (35194, 131)\n",
      "X_train_brand_without shape: (51336, 131)\n",
      "X_test_brand_without shape: (76877, 131)\n"
     ]
    }
   ],
   "source": [
    "X_train_brand_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                            (gender_age_train_with.int_index,gender_age_train_with.brand)),\n",
    "                               shape = (gender_age_train_with.shape[0],brandnumber))\n",
    "X_test_brand_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                           (gender_age_test_with.int_index,gender_age_test_with.brand)),\n",
    "                              shape = (gender_age_test_with.shape[0],brandnumber))\n",
    "print('X_train_brand_with shape:',X_train_brand_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_brand_with.shape)\n",
    "X_train_brand_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                            (gender_age_train_without.int_index,gender_age_train_without.brand)),\n",
    "                                  shape = (gender_age_train_without.shape[0],brandnumber))\n",
    "X_test_brand_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                           (gender_age_test_without.int_index,gender_age_test_without.brand)),\n",
    "                                 shape = (gender_age_test_without.shape[0],brandnumber))\n",
    "print('X_train_brand_without shape:',X_train_brand_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_brand_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering II: phone device model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brand_model = device.phone_brand.str.cat(device.device_model)\n",
    "encoder3 = LabelEncoder()\n",
    "encoder3.fit(brand_model)\n",
    "device['model'] = encoder3.transform(brand_model)\n",
    "gender_age_train_with['model'] = device['model']\n",
    "gender_age_test_with['model'] = device['model']\n",
    "gender_age_train_without['model'] = device['model']\n",
    "gender_age_test_without['model'] = device['model']\n",
    "modelnumber = len(encoder3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 1667)\n",
      "X_test_brand_with shape: (35194, 1667)\n",
      "X_train_brand_without shape: (51336, 1667)\n",
      "X_test_brand_without shape: (76877, 1667)\n"
     ]
    }
   ],
   "source": [
    "X_train_model_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                                 (gender_age_train_with.int_index,gender_age_train_with.model)),\n",
    "                               shape = (gender_age_train_with.shape[0],modelnumber))\n",
    "X_test_model_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                                (gender_age_test_with.int_index,gender_age_test_with.model)),\n",
    "                              shape = (gender_age_test_with.shape[0],modelnumber))\n",
    "X_train_model_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                                    (gender_age_train_without.int_index,gender_age_train_without.model)),\n",
    "                                  shape = (gender_age_train_without.shape[0],modelnumber))\n",
    "X_test_model_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                                   (gender_age_test_without.int_index,gender_age_test_without.model)),\n",
    "                                 shape = (gender_age_test_without.shape[0],modelnumber))\n",
    "\n",
    "print('X_train_brand_with shape:',X_train_model_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_model_with.shape)\n",
    "print('X_train_brand_without shape:',X_train_model_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_model_without.shape)\n",
    "del device,brand_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering III: Installed app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the app_id and store it into app column, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = LabelEncoder()\n",
    "encoder2.fit(app_event.app_id)\n",
    "app_event['app'] = encoder2.transform(app_event.app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 19234, 19235, 19236])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(app_event.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   event_id               app_id  is_installed  is_active    app\n",
      "0         2  5927333115845830913             1          1  15408\n",
      "                  device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n"
     ]
    }
   ],
   "source": [
    "print(app_event.head(1))\n",
    "print(events.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  event_id    app  is_installed\n",
      "0 -6401643145415154744         2  15408             1\n",
      "1 -6401643145415154744         2   3384             1\n",
      "2 -6401643145415154744         2   7620             1\n",
      "3 -6401643145415154744         2   8902             1\n",
      "4 -6401643145415154744         2  18686             1\n"
     ]
    }
   ],
   "source": [
    "installed_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_installed']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "print(installed_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_app_train:\n",
      "                           size  int_index\n",
      "device_id            app                  \n",
      "-9222956879900151005 548     18       5145\n",
      "                     1096    18       5145\n",
      "                     1248    26       5145\n",
      "                     1545    12       5145\n",
      "                     1664    18       5145\n"
     ]
    }
   ],
   "source": [
    "installed_app_grouped = installed_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_app_train_with = pd.merge(installed_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_index=True)\n",
    "installed_app_test_with = pd.merge(installed_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_index=True)\n",
    "print('installed_app_train:')\n",
    "print(installed_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id   app  size  int_index\n",
      "0 -9222956879900151005   548    18       5145\n",
      "1 -9222956879900151005  1096    18       5145\n",
      "2 -9222956879900151005  1248    26       5145\n",
      "3 -9222956879900151005  1545    12       5145\n",
      "4 -9222956879900151005  1664    18       5145\n",
      "             device_id    app  size  int_index\n",
      "0 -9222661944218806987   1867     3       2851\n",
      "1 -9222661944218806987   7519     8       2851\n",
      "2 -9222661944218806987   7843     1       2851\n",
      "3 -9222661944218806987   8704     4       2851\n",
      "4 -9222661944218806987  10000     1       2851\n"
     ]
    }
   ],
   "source": [
    "installed_app_train_with = installed_app_train_with.reset_index()\n",
    "installed_app_test_with = installed_app_test_with.reset_index()\n",
    "installed_app_train_with = installed_app_train_with.dropna(subset=['int_index'])\n",
    "installed_app_test_with = installed_app_test_with.dropna(subset=['int_index'])\n",
    "print(installed_app_train_with.head())\n",
    "print(installed_app_test_with.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of unique app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35194\n",
      "915632\n"
     ]
    }
   ],
   "source": [
    "print(gender_age_test_with.shape[0])\n",
    "print(installed_app_train_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique apps:\n",
      "19237\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique apps:')\n",
    "print(np.size(installed_app.app.unique()))\n",
    "appnumber = np.size(installed_app.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ..., 19234 19235 19236]\n",
      "1387337\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(installed_app_train_with.app.unique()))\n",
    "print(installed_app_test_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed shape: (23309, 19237)\n",
      "X_test_installed shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "X_train_installed_with = csr_matrix((np.ones(installed_app_train_with.shape[0]),\n",
    "                                (installed_app_train_with.int_index,installed_app_train_with.app)), \n",
    "                               shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_installed_with = csr_matrix((np.ones(installed_app_test_with.shape[0]),\n",
    "                               (installed_app_test_with.int_index,installed_app_test_with.app)),\n",
    "                               shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_installed shape:',X_train_installed_with.shape)\n",
    "print('X_test_installed shape:',X_test_installed_with.shape)\n",
    "del installed_app_test_with,installed_app_train_with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering IV: app label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                app_id  event_id\n",
      "0  5927333115845830913         2\n",
      "                app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print(app_event[['app_id','event_id']].head(1))\n",
    "print(app_label[['app_id','label_id']].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_label_new:\n",
      "                app_id  label_id    app  label\n",
      "0  7324884708820027918       251  17355    207\n",
      "1 -4494216993218550286       251   4618    207\n",
      "2  6058196446775239644       406  15548    247\n",
      "3  6058196446775239644       407  15548    248\n",
      "4  8694625920731541625       406  18689    247\n"
     ]
    }
   ],
   "source": [
    "app_label_new = app_label.loc[app_label.app_id.isin(app_event.app_id.unique())].copy()\n",
    "app_label_new['app'] = encoder2.transform(app_label_new.app_id)\n",
    "encoder4 = LabelEncoder().fit(app_label_new.label_id)\n",
    "app_label_new['label'] = encoder4.transform(app_label_new.label_id)\n",
    "labelnumber = len(encoder4.classes_)\n",
    "print('app_label_new:')\n",
    "print(app_label_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919886\n",
      "129892268\n",
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_label_grouped:\n",
      "             device_id  label  size\n",
      "0 -9222956879900151005    117     1\n",
      "1 -9222956879900151005    120     1\n",
      "2 -9222956879900151005    126     1\n",
      "3 -9222956879900151005    138     2\n",
      "4 -9222956879900151005    147     2\n"
     ]
    }
   ],
   "source": [
    "print(app_label.size)\n",
    "print(installed_app.size)\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_label_grouped = (installed_app_grouped.reset_index()[['device_id','app']]\n",
    "                          .merge(app_label_new[['app','label']])\n",
    "                          .groupby(['device_id','label']))['app'].agg(['size']).reset_index()\n",
    "                          \n",
    "print('installed_label_grouped:')\n",
    "print(installed_label_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_app_train_with = pd.merge(installed_label_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_on='device_id')\n",
    "label_app_test_with = pd.merge(installed_label_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_on ='device_id' )\n",
    "label_app_train_with = label_app_train_with.dropna(subset= ['int_index','label'])\n",
    "label_app_test_with = label_app_test_with.dropna(subset= ['int_index','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed_with shape: (23309, 492)\n",
      "X_test_installed_with shape: (35194, 492)\n"
     ]
    }
   ],
   "source": [
    "#binary\n",
    "X_train_label_with = csr_matrix((np.ones(label_app_train_with.shape[0]),\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((np.ones(label_app_test_with.shape[0]),(label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))\n",
    "#count\n",
    "'''X_train_label_with = csr_matrix((label_app_train_with['size'],\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((label_app_test_with['size'],\n",
    "                                (label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))'''\n",
    "print('X_train_installed_with shape:',X_train_label_with.shape)\n",
    "print('X_test_installed_with shape:',X_test_label_with.shape)\n",
    "del installed_app_grouped,label,app_label,app_label_new,label_app_test_with,label_app_train_with,encoder4,installed_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering V: active app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_active']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "active_app = active_app.loc[active_app.is_active==1]\n",
    "print(active_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_grouped = active_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('active_app_grouped:')\n",
    "print(active_app_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_train_with = pd.merge(active_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'left',right_index=True,left_index=True)\n",
    "active_app_test_with = pd.merge(active_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'left',right_index=True,left_index=True)\n",
    "print('active_app_train_with:')\n",
    "print(active_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_train_with = active_app_train_with.reset_index()\n",
    "active_app_test_with = active_app_test_with.reset_index()\n",
    "active_app_train_with = active_app_train_with.dropna(subset=['int_index'])\n",
    "active_app_test_with = active_app_test_with.dropna(subset=['int_index'])\n",
    "print(active_app_train_with.head())\n",
    "print(active_app_test_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# binary active map\n",
    "#X_train_active_with = csr_matrix((np.ones(active_app_train_with.shape[0]),\n",
    "#                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "#                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "#X_test_active = csr_matrix((np.ones(active_app_test_with.shape[0]),\n",
    "#                            (active_app_test.int_index,active_app_test_with.app)),\n",
    "#                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "# count the number of active app\n",
    "X_train_active_with = csr_matrix((active_app_train_with['size'],\n",
    "                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_active_with = csr_matrix((active_app_test_with['size'],\n",
    "                            (active_app_test_with.int_index,active_app_test_with.app)),\n",
    "                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_active shape:',X_train_active_with.shape)\n",
    "print('X_test_active shape:',X_test_active_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_active_with = scaler.fit_transform(X_train_active_with)\n",
    "X_test_active_with = scaler.transform(X_test_active_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering VI: active time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  time  times\n",
      "0 -9222956879900151005     7      2\n",
      "1 -9222956879900151005    11      7\n",
      "2 -9222956879900151005    12     13\n",
      "3 -9222956879900151005    13      3\n",
      "4 -9222956879900151005    14      5\n"
     ]
    }
   ],
   "source": [
    "events_time = events[['device_id','timestamp']].copy()\n",
    "events_time['time']  = events_time['timestamp'].str[11:13].astype(int)\n",
    "events_time.drop(['timestamp'],axis=1,inplace=True)\n",
    "events_time = events_time.groupby(['device_id','time'])['time'].agg({'times':'count'}).reset_index()\n",
    "print(events_time.head())\n",
    "timenumber= events_time.time.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_time_with shape: (23309, 24)\n",
      "X_test_time_with shape: (35194, 24)\n"
     ]
    }
   ],
   "source": [
    "time_train_with = pd.merge(events_time,gender_age_train_with[['int_index']],\n",
    "                               right_index=True,left_on='device_id')\n",
    "time_test_with = pd.merge(events_time,gender_age_test_with[['int_index']],\n",
    "                               right_index=True,left_on ='device_id' )\n",
    "#binary\n",
    "X_train_time_with = csr_matrix((np.ones(time_train_with.shape[0]),\n",
    "                            (time_train_with.int_index,time_train_with.time)), \n",
    "                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "X_test_time_with = csr_matrix((np.ones(time_test_with.shape[0]),\n",
    "                            (time_test_with.int_index,time_test_with.time)),\n",
    "                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "\n",
    "#number\n",
    "#X_train_time_with = csr_matrix((time_train_with['times'],\n",
    "#                            (time_train_with.int_index,time_train_with.time)), \n",
    "#                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "#X_test_time_with = csr_matrix((time_test_with['times'],\n",
    "#                            (time_test_with.int_index,time_test_with.time)),\n",
    "#                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "print('X_train_time_with shape:',X_train_time_with.shape)\n",
    "print('X_test_time_with shape:',X_test_time_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the time period count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_time_with = scaler.fit_transform(X_train_time_with)\n",
    "X_test_time_with = scaler.transform(X_test_time_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature join and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(74645, 1798)\n",
      "Testing shape:\n",
      "(76877, 1798)\n",
      "y shape:\n",
      "(74645, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_without = hstack((X_train_brand_without,X_train_model_without),format='csr')\n",
    "temp_train = hstack((X_train_brand_with,X_train_model_with),format='csr')\n",
    "X_test_total_without = hstack((X_test_brand_without,X_test_model_without),format='csr')\n",
    "\n",
    "X_train_total_without= vstack((X_train_total_without,temp_train),format = 'csr')\n",
    "gender_age_train_without_temp = pd.concat((gender_age_train_without,gender_age_train_with))\n",
    "\n",
    "print('Training shape:')\n",
    "print(X_train_total_without.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_without.shape)\n",
    "print('y shape:')\n",
    "print(gender_age_train_without_temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device with events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(23309, 21527)\n",
      "Testing shape:\n",
      "(35194, 21527)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_with = hstack((X_train_brand_with,X_train_model_with,\n",
    "                             #X_train_active_with,\n",
    "                             #X_train_time_with,\n",
    "                             X_train_installed_with,X_train_label_with),format='csr')\n",
    "X_test_total_with = hstack((X_test_brand_with,X_test_model_with,\n",
    "                            #X_test_active_with,\n",
    "                            #X_test_time_with,\n",
    "                           X_test_installed_with,X_test_label_with),format='csr')\n",
    "print('Training shape:')\n",
    "print(X_train_total_with.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentile selction\n",
    "#selector = SelectPercentile(f_classif, percentile=80)\n",
    "#selector.fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#X_val.shape\n",
    "\n",
    "# Selection using chi-square\n",
    "#selector = SelectKBest(chi2, k=15155).fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#print('Training shape:')\n",
    "#print(X_train_total.shape)\n",
    "#print('Testing shape:')\n",
    "#print(X_test_total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear the memory before we do the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del app_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Start training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetencoder = LabelEncoder().fit(gender_age_train_with.group)\n",
    "nclasses = len(targetencoder.classes_)\n",
    "y_train_total_with = targetencoder.transform(gender_age_train_with.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset I: device with events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator \n",
    "    #(https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3409 - acc: 0.1686 - val_loss: 2.2428 - val_acc: 0.1969\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1057 - acc: 0.2552 - val_loss: 2.1580 - val_acc: 0.2419\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0186 - acc: 0.2842 - val_loss: 2.1418 - val_acc: 0.2509\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9772 - acc: 0.3003 - val_loss: 2.1395 - val_acc: 0.2483\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9413 - acc: 0.3142 - val_loss: 2.1319 - val_acc: 0.2560\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9172 - acc: 0.3231 - val_loss: 2.1313 - val_acc: 0.2603\n",
      "Epoch 7/15\n",
      "20s - loss: 1.8970 - acc: 0.3305 - val_loss: 2.1285 - val_acc: 0.2547\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8801 - acc: 0.3347 - val_loss: 2.1275 - val_acc: 0.2594\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8586 - acc: 0.3400 - val_loss: 2.1416 - val_acc: 0.2551\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8469 - acc: 0.3475 - val_loss: 2.1390 - val_acc: 0.2551\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8346 - acc: 0.3507 - val_loss: 2.1359 - val_acc: 0.2547\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8184 - acc: 0.3575 - val_loss: 2.1362 - val_acc: 0.2526\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8038 - acc: 0.3610 - val_loss: 2.1383 - val_acc: 0.2487\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7880 - acc: 0.3663 - val_loss: 2.1418 - val_acc: 0.2611\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7779 - acc: 0.3701 - val_loss: 2.1563 - val_acc: 0.2603\n",
      "logloss val 2.8185404014206243\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3366 - acc: 0.1680 - val_loss: 2.1890 - val_acc: 0.2362\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1040 - acc: 0.2560 - val_loss: 2.0711 - val_acc: 0.2572\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0245 - acc: 0.2845 - val_loss: 2.0367 - val_acc: 0.2868\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9864 - acc: 0.2975 - val_loss: 2.0274 - val_acc: 0.2799\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9547 - acc: 0.3085 - val_loss: 2.0082 - val_acc: 0.2958\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9291 - acc: 0.3174 - val_loss: 2.0046 - val_acc: 0.2953\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9078 - acc: 0.3271 - val_loss: 2.0020 - val_acc: 0.3078\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8895 - acc: 0.3302 - val_loss: 1.9892 - val_acc: 0.3116\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8731 - acc: 0.3375 - val_loss: 1.9873 - val_acc: 0.3120\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8536 - acc: 0.3443 - val_loss: 1.9913 - val_acc: 0.3150\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8417 - acc: 0.3472 - val_loss: 1.9971 - val_acc: 0.3146\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8274 - acc: 0.3542 - val_loss: 1.9968 - val_acc: 0.3112\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8093 - acc: 0.3573 - val_loss: 2.0102 - val_acc: 0.3095\n",
      "Epoch 14/15\n",
      "19s - loss: 1.7954 - acc: 0.3642 - val_loss: 2.0090 - val_acc: 0.3086\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7878 - acc: 0.3662 - val_loss: 2.0116 - val_acc: 0.3052\n",
      "logloss val 2.0115566791839754\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3477 - acc: 0.1598 - val_loss: 2.2140 - val_acc: 0.2195\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1067 - acc: 0.2534 - val_loss: 2.1092 - val_acc: 0.2546\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0267 - acc: 0.2798 - val_loss: 2.0779 - val_acc: 0.2730\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9824 - acc: 0.3000 - val_loss: 2.0463 - val_acc: 0.2829\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9451 - acc: 0.3094 - val_loss: 2.0441 - val_acc: 0.2923\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9204 - acc: 0.3226 - val_loss: 2.0455 - val_acc: 0.2816\n",
      "Epoch 7/15\n",
      "19s - loss: 1.8966 - acc: 0.3300 - val_loss: 2.0385 - val_acc: 0.2928\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8828 - acc: 0.3314 - val_loss: 2.0582 - val_acc: 0.2893\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8652 - acc: 0.3374 - val_loss: 2.0411 - val_acc: 0.2928\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8483 - acc: 0.3444 - val_loss: 2.0541 - val_acc: 0.2975\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8394 - acc: 0.3478 - val_loss: 2.0522 - val_acc: 0.2898\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8190 - acc: 0.3515 - val_loss: 2.0507 - val_acc: 0.2885\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8069 - acc: 0.3574 - val_loss: 2.0704 - val_acc: 0.2833\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7887 - acc: 0.3653 - val_loss: 2.0666 - val_acc: 0.2863\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7813 - acc: 0.3642 - val_loss: 2.0769 - val_acc: 0.2790\n",
      "logloss val 2.07690589148084\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3326 - acc: 0.1732 - val_loss: 2.1382 - val_acc: 0.2543\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1034 - acc: 0.2526 - val_loss: 2.0385 - val_acc: 0.2800\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0271 - acc: 0.2813 - val_loss: 2.0007 - val_acc: 0.2955\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9763 - acc: 0.2984 - val_loss: 1.9917 - val_acc: 0.3045\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9512 - acc: 0.3105 - val_loss: 1.9827 - val_acc: 0.3126\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9288 - acc: 0.3194 - val_loss: 1.9862 - val_acc: 0.3070\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9087 - acc: 0.3244 - val_loss: 1.9756 - val_acc: 0.3092\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8867 - acc: 0.3306 - val_loss: 1.9886 - val_acc: 0.3019\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8725 - acc: 0.3363 - val_loss: 1.9810 - val_acc: 0.3079\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8604 - acc: 0.3427 - val_loss: 1.9753 - val_acc: 0.3092\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8379 - acc: 0.3477 - val_loss: 1.9839 - val_acc: 0.3109\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8291 - acc: 0.3509 - val_loss: 1.9807 - val_acc: 0.3079\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8125 - acc: 0.3595 - val_loss: 1.9899 - val_acc: 0.3023\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8006 - acc: 0.3605 - val_loss: 2.0049 - val_acc: 0.3049\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7856 - acc: 0.3648 - val_loss: 1.9968 - val_acc: 0.3062\n",
      "logloss val 1.9967585300076969\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "20s - loss: 2.3446 - acc: 0.1673 - val_loss: 2.1563 - val_acc: 0.2616\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1244 - acc: 0.2475 - val_loss: 2.0114 - val_acc: 0.2903\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0395 - acc: 0.2766 - val_loss: 1.9592 - val_acc: 0.3023\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9974 - acc: 0.2954 - val_loss: 1.9352 - val_acc: 0.3203\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9608 - acc: 0.3094 - val_loss: 1.9264 - val_acc: 0.3255\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9341 - acc: 0.3186 - val_loss: 1.9218 - val_acc: 0.3340\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9165 - acc: 0.3198 - val_loss: 1.9143 - val_acc: 0.3315\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8969 - acc: 0.3324 - val_loss: 1.9216 - val_acc: 0.3298\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8779 - acc: 0.3369 - val_loss: 1.9167 - val_acc: 0.3315\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8602 - acc: 0.3441 - val_loss: 1.9168 - val_acc: 0.3332\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8445 - acc: 0.3469 - val_loss: 1.9252 - val_acc: 0.3246\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8322 - acc: 0.3520 - val_loss: 1.9230 - val_acc: 0.3276\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8186 - acc: 0.3567 - val_loss: 1.9326 - val_acc: 0.3302\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8056 - acc: 0.3593 - val_loss: 1.9474 - val_acc: 0.3293\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7952 - acc: 0.3619 - val_loss: 1.9442 - val_acc: 0.3328\n",
      "logloss val 1.944222394943397\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3517 - acc: 0.1613 - val_loss: 2.1662 - val_acc: 0.2364\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1254 - acc: 0.2458 - val_loss: 2.0136 - val_acc: 0.2831\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0432 - acc: 0.2758 - val_loss: 1.9776 - val_acc: 0.2943\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9904 - acc: 0.2994 - val_loss: 1.9515 - val_acc: 0.3067\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9629 - acc: 0.3049 - val_loss: 1.9381 - val_acc: 0.3115\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9349 - acc: 0.3171 - val_loss: 1.9409 - val_acc: 0.3157\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9207 - acc: 0.3225 - val_loss: 1.9243 - val_acc: 0.3119\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8934 - acc: 0.3288 - val_loss: 1.9370 - val_acc: 0.3166\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8800 - acc: 0.3352 - val_loss: 1.9270 - val_acc: 0.3140\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8519 - acc: 0.3458 - val_loss: 1.9336 - val_acc: 0.3089\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8513 - acc: 0.3446 - val_loss: 1.9339 - val_acc: 0.3136\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8302 - acc: 0.3500 - val_loss: 1.9335 - val_acc: 0.3106\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8181 - acc: 0.3584 - val_loss: 1.9411 - val_acc: 0.3063\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8025 - acc: 0.3612 - val_loss: 1.9429 - val_acc: 0.3127\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7911 - acc: 0.3667 - val_loss: 1.9485 - val_acc: 0.3046\n",
      "logloss val 1.948535798374989\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "20s - loss: 2.3512 - acc: 0.1618 - val_loss: 2.1667 - val_acc: 0.2589\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1401 - acc: 0.2435 - val_loss: 1.9644 - val_acc: 0.3044\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0472 - acc: 0.2732 - val_loss: 1.9228 - val_acc: 0.3122\n",
      "Epoch 4/15\n",
      "19s - loss: 2.0042 - acc: 0.2922 - val_loss: 1.8952 - val_acc: 0.3280\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9671 - acc: 0.3037 - val_loss: 1.8710 - val_acc: 0.3349\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9426 - acc: 0.3135 - val_loss: 1.8653 - val_acc: 0.3379\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9252 - acc: 0.3219 - val_loss: 1.8633 - val_acc: 0.3422\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8987 - acc: 0.3313 - val_loss: 1.8590 - val_acc: 0.3439\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8814 - acc: 0.3336 - val_loss: 1.8591 - val_acc: 0.3448\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8697 - acc: 0.3390 - val_loss: 1.8553 - val_acc: 0.3478\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8537 - acc: 0.3434 - val_loss: 1.8583 - val_acc: 0.3388\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8341 - acc: 0.3499 - val_loss: 1.8652 - val_acc: 0.3456\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8227 - acc: 0.3524 - val_loss: 1.8677 - val_acc: 0.3336\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8101 - acc: 0.3619 - val_loss: 1.8704 - val_acc: 0.3456\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7995 - acc: 0.3631 - val_loss: 1.8738 - val_acc: 0.3383\n",
      "logloss val 1.873810533090742\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3557 - acc: 0.1620 - val_loss: 2.1322 - val_acc: 0.2688\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1226 - acc: 0.2501 - val_loss: 1.9597 - val_acc: 0.2997\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0443 - acc: 0.2782 - val_loss: 1.9196 - val_acc: 0.3160\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9963 - acc: 0.2971 - val_loss: 1.8851 - val_acc: 0.3285\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9699 - acc: 0.3047 - val_loss: 1.8775 - val_acc: 0.3250\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9401 - acc: 0.3160 - val_loss: 1.8610 - val_acc: 0.3310\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9176 - acc: 0.3218 - val_loss: 1.8627 - val_acc: 0.3310\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8998 - acc: 0.3264 - val_loss: 1.8507 - val_acc: 0.3409\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8799 - acc: 0.3377 - val_loss: 1.8495 - val_acc: 0.3375\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8682 - acc: 0.3414 - val_loss: 1.8502 - val_acc: 0.3332\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8470 - acc: 0.3472 - val_loss: 1.8551 - val_acc: 0.3362\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8389 - acc: 0.3485 - val_loss: 1.8533 - val_acc: 0.3375\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8224 - acc: 0.3549 - val_loss: 1.8607 - val_acc: 0.3366\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8060 - acc: 0.3574 - val_loss: 1.8589 - val_acc: 0.3392\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7996 - acc: 0.3617 - val_loss: 1.8617 - val_acc: 0.3383\n",
      "logloss val 1.8616983961620264\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3485 - acc: 0.1603 - val_loss: 2.1479 - val_acc: 0.2423\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1198 - acc: 0.2498 - val_loss: 1.9990 - val_acc: 0.2930\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0427 - acc: 0.2748 - val_loss: 1.9530 - val_acc: 0.3110\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9977 - acc: 0.2917 - val_loss: 1.9160 - val_acc: 0.3222\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9736 - acc: 0.3027 - val_loss: 1.9130 - val_acc: 0.3179\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9415 - acc: 0.3143 - val_loss: 1.9018 - val_acc: 0.3256\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9178 - acc: 0.3215 - val_loss: 1.8987 - val_acc: 0.3303\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9124 - acc: 0.3244 - val_loss: 1.8912 - val_acc: 0.3338\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8894 - acc: 0.3321 - val_loss: 1.8972 - val_acc: 0.3286\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8744 - acc: 0.3384 - val_loss: 1.8902 - val_acc: 0.3346\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8517 - acc: 0.3453 - val_loss: 1.8987 - val_acc: 0.3320\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8436 - acc: 0.3487 - val_loss: 1.8915 - val_acc: 0.3398\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8296 - acc: 0.3547 - val_loss: 1.9133 - val_acc: 0.3273\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8135 - acc: 0.3578 - val_loss: 1.9088 - val_acc: 0.3351\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7991 - acc: 0.3595 - val_loss: 1.9155 - val_acc: 0.3359\n",
      "logloss val 1.915454947532942\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "20s - loss: 2.3234 - acc: 0.1781 - val_loss: 2.1116 - val_acc: 0.2627\n",
      "Epoch 2/15\n",
      "19s - loss: 2.0937 - acc: 0.2616 - val_loss: 2.0144 - val_acc: 0.2984\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0223 - acc: 0.2821 - val_loss: 2.0025 - val_acc: 0.2936\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9830 - acc: 0.3005 - val_loss: 1.9716 - val_acc: 0.3087\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9469 - acc: 0.3113 - val_loss: 1.9659 - val_acc: 0.3104\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9318 - acc: 0.3192 - val_loss: 1.9391 - val_acc: 0.3147\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9077 - acc: 0.3264 - val_loss: 1.9422 - val_acc: 0.3177\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8864 - acc: 0.3332 - val_loss: 1.9472 - val_acc: 0.3138\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8701 - acc: 0.3366 - val_loss: 1.9454 - val_acc: 0.3181\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8582 - acc: 0.3406 - val_loss: 1.9513 - val_acc: 0.3156\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8410 - acc: 0.3496 - val_loss: 1.9732 - val_acc: 0.3143\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8266 - acc: 0.3561 - val_loss: 1.9533 - val_acc: 0.3164\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8147 - acc: 0.3601 - val_loss: 1.9877 - val_acc: 0.3113\n",
      "Epoch 14/15\n",
      "19s - loss: 1.7997 - acc: 0.3643 - val_loss: 1.9828 - val_acc: 0.3130\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7878 - acc: 0.3667 - val_loss: 1.9967 - val_acc: 0.3113\n",
      "logloss val 1.9967056688090108\n",
      "average logloss val 2.0444189241006248\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3449 - acc: 0.1648 - val_loss: 2.2609 - val_acc: 0.1931\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1090 - acc: 0.2535 - val_loss: 2.1816 - val_acc: 0.2290\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0211 - acc: 0.2830 - val_loss: 2.1521 - val_acc: 0.2453\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9793 - acc: 0.2997 - val_loss: 2.1430 - val_acc: 0.2551\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9478 - acc: 0.3084 - val_loss: 2.1337 - val_acc: 0.2598\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9205 - acc: 0.3186 - val_loss: 2.1360 - val_acc: 0.2551\n",
      "Epoch 7/15\n",
      "19s - loss: 1.8950 - acc: 0.3310 - val_loss: 2.1395 - val_acc: 0.2573\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8735 - acc: 0.3378 - val_loss: 2.1390 - val_acc: 0.2509\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8672 - acc: 0.3369 - val_loss: 2.1386 - val_acc: 0.2577\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8503 - acc: 0.3483 - val_loss: 2.1292 - val_acc: 0.2560\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8300 - acc: 0.3533 - val_loss: 2.1441 - val_acc: 0.2564\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8172 - acc: 0.3560 - val_loss: 2.1341 - val_acc: 0.2624\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8031 - acc: 0.3613 - val_loss: 2.1391 - val_acc: 0.2509\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7916 - acc: 0.3637 - val_loss: 2.1536 - val_acc: 0.2564\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7752 - acc: 0.3689 - val_loss: 2.1617 - val_acc: 0.2547\n",
      "logloss val 2.8190559441410272\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3384 - acc: 0.1658 - val_loss: 2.1921 - val_acc: 0.2400\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1036 - acc: 0.2533 - val_loss: 2.0710 - val_acc: 0.2675\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0274 - acc: 0.2827 - val_loss: 2.0420 - val_acc: 0.2765\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9805 - acc: 0.3029 - val_loss: 2.0194 - val_acc: 0.2932\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9548 - acc: 0.3091 - val_loss: 1.9972 - val_acc: 0.2992\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9260 - acc: 0.3209 - val_loss: 1.9949 - val_acc: 0.2953\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9031 - acc: 0.3271 - val_loss: 1.9899 - val_acc: 0.3043\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8869 - acc: 0.3315 - val_loss: 1.9903 - val_acc: 0.3009\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8755 - acc: 0.3369 - val_loss: 1.9867 - val_acc: 0.3090\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8562 - acc: 0.3451 - val_loss: 1.9884 - val_acc: 0.3086\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8435 - acc: 0.3490 - val_loss: 1.9827 - val_acc: 0.3090\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8261 - acc: 0.3533 - val_loss: 1.9887 - val_acc: 0.3073\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8059 - acc: 0.3599 - val_loss: 1.9982 - val_acc: 0.3073\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7995 - acc: 0.3621 - val_loss: 2.0070 - val_acc: 0.3056\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7872 - acc: 0.3677 - val_loss: 2.0017 - val_acc: 0.3060\n",
      "logloss val 2.0017484768380482\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "20s - loss: 2.3456 - acc: 0.1669 - val_loss: 2.2017 - val_acc: 0.2276\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1065 - acc: 0.2518 - val_loss: 2.1025 - val_acc: 0.2529\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0327 - acc: 0.2772 - val_loss: 2.0769 - val_acc: 0.2743\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9808 - acc: 0.2976 - val_loss: 2.0627 - val_acc: 0.2799\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9517 - acc: 0.3092 - val_loss: 2.0481 - val_acc: 0.2850\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9207 - acc: 0.3198 - val_loss: 2.0526 - val_acc: 0.2838\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9036 - acc: 0.3248 - val_loss: 2.0552 - val_acc: 0.2739\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8818 - acc: 0.3356 - val_loss: 2.0504 - val_acc: 0.2790\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8685 - acc: 0.3397 - val_loss: 2.0539 - val_acc: 0.2778\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8521 - acc: 0.3433 - val_loss: 2.0578 - val_acc: 0.2825\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8361 - acc: 0.3469 - val_loss: 2.0594 - val_acc: 0.2825\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8198 - acc: 0.3543 - val_loss: 2.0544 - val_acc: 0.2868\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8085 - acc: 0.3582 - val_loss: 2.0703 - val_acc: 0.2765\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7951 - acc: 0.3613 - val_loss: 2.0743 - val_acc: 0.2816\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7775 - acc: 0.3671 - val_loss: 2.0749 - val_acc: 0.2850\n",
      "logloss val 2.074859388835117\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3500 - acc: 0.1595 - val_loss: 2.1804 - val_acc: 0.2277\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1212 - acc: 0.2487 - val_loss: 2.0463 - val_acc: 0.2697\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0310 - acc: 0.2801 - val_loss: 2.0110 - val_acc: 0.2937\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9874 - acc: 0.2967 - val_loss: 1.9895 - val_acc: 0.3109\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9628 - acc: 0.3060 - val_loss: 1.9894 - val_acc: 0.3096\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9268 - acc: 0.3194 - val_loss: 1.9856 - val_acc: 0.3027\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9115 - acc: 0.3258 - val_loss: 1.9766 - val_acc: 0.3079\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8931 - acc: 0.3272 - val_loss: 1.9696 - val_acc: 0.3152\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8707 - acc: 0.3363 - val_loss: 1.9823 - val_acc: 0.3062\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8604 - acc: 0.3434 - val_loss: 1.9749 - val_acc: 0.3032\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8421 - acc: 0.3495 - val_loss: 1.9814 - val_acc: 0.3036\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8284 - acc: 0.3527 - val_loss: 1.9866 - val_acc: 0.3083\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8133 - acc: 0.3575 - val_loss: 1.9874 - val_acc: 0.3117\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8014 - acc: 0.3586 - val_loss: 1.9915 - val_acc: 0.3062\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7856 - acc: 0.3684 - val_loss: 1.9965 - val_acc: 0.3096\n",
      "logloss val 1.996539902617727\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3560 - acc: 0.1558 - val_loss: 2.1732 - val_acc: 0.2496\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1312 - acc: 0.2443 - val_loss: 2.0025 - val_acc: 0.2826\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0511 - acc: 0.2738 - val_loss: 1.9802 - val_acc: 0.2946\n",
      "Epoch 4/15\n",
      "19s - loss: 2.0049 - acc: 0.2891 - val_loss: 1.9709 - val_acc: 0.2963\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9711 - acc: 0.3029 - val_loss: 1.9355 - val_acc: 0.3199\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9439 - acc: 0.3112 - val_loss: 1.9329 - val_acc: 0.3182\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9203 - acc: 0.3226 - val_loss: 1.9255 - val_acc: 0.3238\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8945 - acc: 0.3283 - val_loss: 1.9282 - val_acc: 0.3293\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8819 - acc: 0.3313 - val_loss: 1.9434 - val_acc: 0.3199\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8694 - acc: 0.3384 - val_loss: 1.9317 - val_acc: 0.3263\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8529 - acc: 0.3441 - val_loss: 1.9344 - val_acc: 0.3268\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8421 - acc: 0.3473 - val_loss: 1.9380 - val_acc: 0.3255\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8246 - acc: 0.3537 - val_loss: 1.9446 - val_acc: 0.3263\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8093 - acc: 0.3583 - val_loss: 1.9487 - val_acc: 0.3225\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7972 - acc: 0.3627 - val_loss: 1.9594 - val_acc: 0.3263\n",
      "logloss val 1.95935504160323\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3413 - acc: 0.1636 - val_loss: 2.1240 - val_acc: 0.2557\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1049 - acc: 0.2534 - val_loss: 2.0101 - val_acc: 0.2909\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0325 - acc: 0.2794 - val_loss: 1.9801 - val_acc: 0.2921\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9967 - acc: 0.2913 - val_loss: 1.9532 - val_acc: 0.3076\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9570 - acc: 0.3071 - val_loss: 1.9440 - val_acc: 0.3162\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9373 - acc: 0.3156 - val_loss: 1.9444 - val_acc: 0.3153\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9087 - acc: 0.3237 - val_loss: 1.9390 - val_acc: 0.3153\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8965 - acc: 0.3260 - val_loss: 1.9309 - val_acc: 0.3230\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8758 - acc: 0.3379 - val_loss: 1.9382 - val_acc: 0.3145\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8591 - acc: 0.3418 - val_loss: 1.9369 - val_acc: 0.3063\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8429 - acc: 0.3458 - val_loss: 1.9413 - val_acc: 0.3059\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8335 - acc: 0.3482 - val_loss: 1.9425 - val_acc: 0.2999\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8163 - acc: 0.3537 - val_loss: 1.9472 - val_acc: 0.3067\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8073 - acc: 0.3561 - val_loss: 1.9478 - val_acc: 0.3102\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7934 - acc: 0.3619 - val_loss: 1.9550 - val_acc: 0.3072\n",
      "logloss val 1.955024066538359\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3400 - acc: 0.1687 - val_loss: 2.1104 - val_acc: 0.2602\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1187 - acc: 0.2465 - val_loss: 1.9655 - val_acc: 0.3018\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0448 - acc: 0.2748 - val_loss: 1.9202 - val_acc: 0.3122\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0047 - acc: 0.2936 - val_loss: 1.8965 - val_acc: 0.3212\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9721 - acc: 0.3010 - val_loss: 1.8754 - val_acc: 0.3255\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9442 - acc: 0.3084 - val_loss: 1.8669 - val_acc: 0.3375\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9236 - acc: 0.3196 - val_loss: 1.8677 - val_acc: 0.3310\n",
      "Epoch 8/15\n",
      "19s - loss: 1.9089 - acc: 0.3235 - val_loss: 1.8573 - val_acc: 0.3444\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8854 - acc: 0.3313 - val_loss: 1.8572 - val_acc: 0.3465\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8722 - acc: 0.3398 - val_loss: 1.8563 - val_acc: 0.3431\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8553 - acc: 0.3436 - val_loss: 1.8602 - val_acc: 0.3461\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8422 - acc: 0.3457 - val_loss: 1.8586 - val_acc: 0.3474\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8285 - acc: 0.3508 - val_loss: 1.8643 - val_acc: 0.3461\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8127 - acc: 0.3560 - val_loss: 1.8704 - val_acc: 0.3396\n",
      "Epoch 15/15\n",
      "19s - loss: 1.8044 - acc: 0.3602 - val_loss: 1.8733 - val_acc: 0.3392\n",
      "logloss val 1.8732837231788595\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3564 - acc: 0.1601 - val_loss: 2.1382 - val_acc: 0.2533\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1307 - acc: 0.2463 - val_loss: 1.9586 - val_acc: 0.2993\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0483 - acc: 0.2758 - val_loss: 1.9272 - val_acc: 0.3066\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0078 - acc: 0.2893 - val_loss: 1.8981 - val_acc: 0.3220\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9688 - acc: 0.3045 - val_loss: 1.8783 - val_acc: 0.3263\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9526 - acc: 0.3117 - val_loss: 1.8688 - val_acc: 0.3298\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9235 - acc: 0.3209 - val_loss: 1.8683 - val_acc: 0.3255\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9070 - acc: 0.3258 - val_loss: 1.8586 - val_acc: 0.3285\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8943 - acc: 0.3293 - val_loss: 1.8588 - val_acc: 0.3358\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8748 - acc: 0.3369 - val_loss: 1.8572 - val_acc: 0.3280\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8591 - acc: 0.3398 - val_loss: 1.8572 - val_acc: 0.3323\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8459 - acc: 0.3478 - val_loss: 1.8665 - val_acc: 0.3323\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8308 - acc: 0.3538 - val_loss: 1.8665 - val_acc: 0.3366\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8207 - acc: 0.3570 - val_loss: 1.8667 - val_acc: 0.3358\n",
      "Epoch 15/15\n",
      "19s - loss: 1.8030 - acc: 0.3624 - val_loss: 1.8731 - val_acc: 0.3362\n",
      "logloss val 1.873071629351196\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3513 - acc: 0.1655 - val_loss: 2.1466 - val_acc: 0.2569\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1239 - acc: 0.2484 - val_loss: 1.9834 - val_acc: 0.2917\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0429 - acc: 0.2783 - val_loss: 1.9480 - val_acc: 0.3097\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9955 - acc: 0.2952 - val_loss: 1.9164 - val_acc: 0.3200\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9621 - acc: 0.3068 - val_loss: 1.9042 - val_acc: 0.3260\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9422 - acc: 0.3142 - val_loss: 1.9038 - val_acc: 0.3252\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9126 - acc: 0.3272 - val_loss: 1.8992 - val_acc: 0.3243\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8981 - acc: 0.3269 - val_loss: 1.8884 - val_acc: 0.3290\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8815 - acc: 0.3332 - val_loss: 1.8815 - val_acc: 0.3303\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8647 - acc: 0.3414 - val_loss: 1.8915 - val_acc: 0.3333\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8536 - acc: 0.3435 - val_loss: 1.8962 - val_acc: 0.3338\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8344 - acc: 0.3477 - val_loss: 1.8920 - val_acc: 0.3295\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8204 - acc: 0.3551 - val_loss: 1.8961 - val_acc: 0.3273\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8048 - acc: 0.3592 - val_loss: 1.9050 - val_acc: 0.3286\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7919 - acc: 0.3617 - val_loss: 1.9131 - val_acc: 0.3204\n",
      "logloss val 1.9130681506443281\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3524 - acc: 0.1594 - val_loss: 2.1882 - val_acc: 0.2438\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1260 - acc: 0.2461 - val_loss: 2.0366 - val_acc: 0.2855\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0392 - acc: 0.2771 - val_loss: 1.9979 - val_acc: 0.2954\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9950 - acc: 0.2958 - val_loss: 1.9813 - val_acc: 0.3027\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9634 - acc: 0.3068 - val_loss: 1.9707 - val_acc: 0.3031\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9343 - acc: 0.3175 - val_loss: 1.9603 - val_acc: 0.3018\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9106 - acc: 0.3254 - val_loss: 1.9520 - val_acc: 0.3078\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8959 - acc: 0.3303 - val_loss: 1.9573 - val_acc: 0.3151\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8781 - acc: 0.3366 - val_loss: 1.9532 - val_acc: 0.3160\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8627 - acc: 0.3400 - val_loss: 1.9707 - val_acc: 0.3035\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8447 - acc: 0.3483 - val_loss: 1.9686 - val_acc: 0.3100\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8292 - acc: 0.3527 - val_loss: 1.9902 - val_acc: 0.3070\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8203 - acc: 0.3565 - val_loss: 1.9767 - val_acc: 0.3113\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8031 - acc: 0.3600 - val_loss: 1.9727 - val_acc: 0.3117\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7899 - acc: 0.3677 - val_loss: 1.9944 - val_acc: 0.3057\n",
      "logloss val 1.9943711127776773\n",
      "average logloss val 2.046037743652557\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3201 - acc: 0.1775 - val_loss: 2.2301 - val_acc: 0.2115\n",
      "Epoch 2/15\n",
      "20s - loss: 2.0969 - acc: 0.2566 - val_loss: 2.1677 - val_acc: 0.2346\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0217 - acc: 0.2800 - val_loss: 2.1415 - val_acc: 0.2543\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9728 - acc: 0.2999 - val_loss: 2.1449 - val_acc: 0.2496\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9432 - acc: 0.3140 - val_loss: 2.1318 - val_acc: 0.2551\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9130 - acc: 0.3266 - val_loss: 2.1265 - val_acc: 0.2560\n",
      "Epoch 7/15\n",
      "20s - loss: 1.8952 - acc: 0.3286 - val_loss: 2.1194 - val_acc: 0.2560\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8738 - acc: 0.3358 - val_loss: 2.1293 - val_acc: 0.2573\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8578 - acc: 0.3423 - val_loss: 2.1352 - val_acc: 0.2616\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8423 - acc: 0.3514 - val_loss: 2.1385 - val_acc: 0.2641\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8288 - acc: 0.3507 - val_loss: 2.1301 - val_acc: 0.2633\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8165 - acc: 0.3531 - val_loss: 2.1355 - val_acc: 0.2586\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8022 - acc: 0.3611 - val_loss: 2.1386 - val_acc: 0.2598\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7886 - acc: 0.3676 - val_loss: 2.1451 - val_acc: 0.2628\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7756 - acc: 0.3712 - val_loss: 2.1479 - val_acc: 0.2633\n",
      "logloss val 2.807067915196748\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3544 - acc: 0.1633 - val_loss: 2.2149 - val_acc: 0.2323\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1335 - acc: 0.2450 - val_loss: 2.0908 - val_acc: 0.2623\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0428 - acc: 0.2767 - val_loss: 2.0582 - val_acc: 0.2752\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9949 - acc: 0.2921 - val_loss: 2.0205 - val_acc: 0.2880\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9539 - acc: 0.3106 - val_loss: 2.0034 - val_acc: 0.2958\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9319 - acc: 0.3172 - val_loss: 1.9988 - val_acc: 0.2966\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9120 - acc: 0.3235 - val_loss: 1.9983 - val_acc: 0.2975\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8951 - acc: 0.3304 - val_loss: 1.9885 - val_acc: 0.2983\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8792 - acc: 0.3355 - val_loss: 1.9841 - val_acc: 0.2983\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8589 - acc: 0.3434 - val_loss: 2.0004 - val_acc: 0.3005\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8440 - acc: 0.3486 - val_loss: 1.9916 - val_acc: 0.3048\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8268 - acc: 0.3524 - val_loss: 1.9932 - val_acc: 0.3052\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8160 - acc: 0.3559 - val_loss: 1.9937 - val_acc: 0.3060\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8019 - acc: 0.3636 - val_loss: 2.0092 - val_acc: 0.3065\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7907 - acc: 0.3649 - val_loss: 1.9953 - val_acc: 0.3065\n",
      "logloss val 1.9953097130808592\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3322 - acc: 0.1676 - val_loss: 2.1958 - val_acc: 0.2250\n",
      "Epoch 2/15\n",
      "19s - loss: 2.0935 - acc: 0.2569 - val_loss: 2.0913 - val_acc: 0.2670\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0229 - acc: 0.2832 - val_loss: 2.0656 - val_acc: 0.2773\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9803 - acc: 0.3002 - val_loss: 2.0563 - val_acc: 0.2876\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9442 - acc: 0.3139 - val_loss: 2.0398 - val_acc: 0.2910\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9198 - acc: 0.3203 - val_loss: 2.0368 - val_acc: 0.2928\n",
      "Epoch 7/15\n",
      "19s - loss: 1.8988 - acc: 0.3300 - val_loss: 2.0345 - val_acc: 0.2932\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8816 - acc: 0.3314 - val_loss: 2.0535 - val_acc: 0.2820\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8635 - acc: 0.3373 - val_loss: 2.0362 - val_acc: 0.2958\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8475 - acc: 0.3463 - val_loss: 2.0500 - val_acc: 0.2880\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8320 - acc: 0.3495 - val_loss: 2.0346 - val_acc: 0.3009\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8199 - acc: 0.3534 - val_loss: 2.0500 - val_acc: 0.2966\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8078 - acc: 0.3607 - val_loss: 2.0529 - val_acc: 0.3009\n",
      "Epoch 14/15\n",
      "19s - loss: 1.7913 - acc: 0.3643 - val_loss: 2.0647 - val_acc: 0.2988\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7755 - acc: 0.3695 - val_loss: 2.0714 - val_acc: 0.2962\n",
      "logloss val 2.0714195600509964\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3534 - acc: 0.1618 - val_loss: 2.1850 - val_acc: 0.2380\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1274 - acc: 0.2479 - val_loss: 2.0482 - val_acc: 0.2723\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0315 - acc: 0.2784 - val_loss: 2.0003 - val_acc: 0.3083\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9883 - acc: 0.2966 - val_loss: 1.9887 - val_acc: 0.3040\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9562 - acc: 0.3090 - val_loss: 1.9820 - val_acc: 0.3105\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9250 - acc: 0.3179 - val_loss: 1.9725 - val_acc: 0.3139\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9060 - acc: 0.3262 - val_loss: 1.9807 - val_acc: 0.3105\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8846 - acc: 0.3327 - val_loss: 1.9793 - val_acc: 0.3053\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8696 - acc: 0.3386 - val_loss: 1.9753 - val_acc: 0.3156\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8522 - acc: 0.3428 - val_loss: 1.9748 - val_acc: 0.3066\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8403 - acc: 0.3470 - val_loss: 1.9761 - val_acc: 0.3087\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8291 - acc: 0.3515 - val_loss: 1.9877 - val_acc: 0.3079\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8122 - acc: 0.3583 - val_loss: 1.9883 - val_acc: 0.3113\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8016 - acc: 0.3621 - val_loss: 1.9988 - val_acc: 0.3100\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7853 - acc: 0.3676 - val_loss: 2.0049 - val_acc: 0.3062\n",
      "logloss val 2.004860614229799\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3285 - acc: 0.1709 - val_loss: 2.1144 - val_acc: 0.2663\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1021 - acc: 0.2538 - val_loss: 2.0080 - val_acc: 0.2779\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0314 - acc: 0.2809 - val_loss: 1.9535 - val_acc: 0.3079\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9900 - acc: 0.2981 - val_loss: 1.9395 - val_acc: 0.3186\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9474 - acc: 0.3128 - val_loss: 1.9308 - val_acc: 0.3130\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9381 - acc: 0.3149 - val_loss: 1.9332 - val_acc: 0.3229\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9122 - acc: 0.3255 - val_loss: 1.9283 - val_acc: 0.3178\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8970 - acc: 0.3293 - val_loss: 1.9227 - val_acc: 0.3255\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8737 - acc: 0.3383 - val_loss: 1.9260 - val_acc: 0.3272\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8637 - acc: 0.3415 - val_loss: 1.9305 - val_acc: 0.3319\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8456 - acc: 0.3483 - val_loss: 1.9316 - val_acc: 0.3220\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8309 - acc: 0.3519 - val_loss: 1.9440 - val_acc: 0.3152\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8161 - acc: 0.3568 - val_loss: 1.9488 - val_acc: 0.3255\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8070 - acc: 0.3596 - val_loss: 1.9467 - val_acc: 0.3203\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7843 - acc: 0.3669 - val_loss: 1.9527 - val_acc: 0.3186\n",
      "logloss val 1.9526881915396943\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3496 - acc: 0.1656 - val_loss: 2.1535 - val_acc: 0.2471\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1213 - acc: 0.2499 - val_loss: 2.0180 - val_acc: 0.2947\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0390 - acc: 0.2785 - val_loss: 1.9726 - val_acc: 0.3054\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9933 - acc: 0.2962 - val_loss: 1.9508 - val_acc: 0.3153\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9618 - acc: 0.3077 - val_loss: 1.9341 - val_acc: 0.3132\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9353 - acc: 0.3170 - val_loss: 1.9341 - val_acc: 0.3179\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9091 - acc: 0.3244 - val_loss: 1.9299 - val_acc: 0.3123\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8947 - acc: 0.3330 - val_loss: 1.9286 - val_acc: 0.3175\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8791 - acc: 0.3383 - val_loss: 1.9316 - val_acc: 0.3157\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8589 - acc: 0.3410 - val_loss: 1.9376 - val_acc: 0.3093\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8467 - acc: 0.3505 - val_loss: 1.9309 - val_acc: 0.3149\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8324 - acc: 0.3532 - val_loss: 1.9416 - val_acc: 0.3136\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8171 - acc: 0.3597 - val_loss: 1.9439 - val_acc: 0.3093\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8034 - acc: 0.3597 - val_loss: 1.9444 - val_acc: 0.3089\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7949 - acc: 0.3653 - val_loss: 1.9558 - val_acc: 0.3080\n",
      "logloss val 1.9557634344078936\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3514 - acc: 0.1603 - val_loss: 2.1342 - val_acc: 0.2598\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1277 - acc: 0.2449 - val_loss: 1.9689 - val_acc: 0.3036\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0536 - acc: 0.2695 - val_loss: 1.9245 - val_acc: 0.3160\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0027 - acc: 0.2926 - val_loss: 1.8953 - val_acc: 0.3280\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9706 - acc: 0.3017 - val_loss: 1.8890 - val_acc: 0.3263\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9503 - acc: 0.3091 - val_loss: 1.8684 - val_acc: 0.3328\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9185 - acc: 0.3225 - val_loss: 1.8603 - val_acc: 0.3371\n",
      "Epoch 8/15\n",
      "19s - loss: 1.9057 - acc: 0.3236 - val_loss: 1.8614 - val_acc: 0.3422\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8891 - acc: 0.3335 - val_loss: 1.8588 - val_acc: 0.3353\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8686 - acc: 0.3389 - val_loss: 1.8533 - val_acc: 0.3392\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8562 - acc: 0.3416 - val_loss: 1.8640 - val_acc: 0.3366\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8392 - acc: 0.3489 - val_loss: 1.8613 - val_acc: 0.3371\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8265 - acc: 0.3536 - val_loss: 1.8689 - val_acc: 0.3340\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8124 - acc: 0.3575 - val_loss: 1.8688 - val_acc: 0.3383\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7996 - acc: 0.3586 - val_loss: 1.8709 - val_acc: 0.3349\n",
      "logloss val 1.8709147137187603\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3359 - acc: 0.1675 - val_loss: 2.1043 - val_acc: 0.2653\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1195 - acc: 0.2481 - val_loss: 1.9621 - val_acc: 0.2945\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0453 - acc: 0.2763 - val_loss: 1.9182 - val_acc: 0.3100\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9979 - acc: 0.2909 - val_loss: 1.8977 - val_acc: 0.3195\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9693 - acc: 0.3053 - val_loss: 1.8809 - val_acc: 0.3323\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9423 - acc: 0.3131 - val_loss: 1.8619 - val_acc: 0.3349\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9209 - acc: 0.3235 - val_loss: 1.8565 - val_acc: 0.3323\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8980 - acc: 0.3279 - val_loss: 1.8550 - val_acc: 0.3353\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8892 - acc: 0.3301 - val_loss: 1.8511 - val_acc: 0.3375\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8654 - acc: 0.3401 - val_loss: 1.8486 - val_acc: 0.3358\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8548 - acc: 0.3441 - val_loss: 1.8476 - val_acc: 0.3323\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8421 - acc: 0.3465 - val_loss: 1.8530 - val_acc: 0.3379\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8230 - acc: 0.3527 - val_loss: 1.8543 - val_acc: 0.3392\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8168 - acc: 0.3565 - val_loss: 1.8561 - val_acc: 0.3375\n",
      "Epoch 15/15\n",
      "20s - loss: 1.8030 - acc: 0.3614 - val_loss: 1.8687 - val_acc: 0.3439\n",
      "logloss val 1.86867808262597\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3537 - acc: 0.1586 - val_loss: 2.1734 - val_acc: 0.2328\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1312 - acc: 0.2442 - val_loss: 1.9848 - val_acc: 0.2857\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0428 - acc: 0.2804 - val_loss: 1.9331 - val_acc: 0.3123\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9923 - acc: 0.2983 - val_loss: 1.9142 - val_acc: 0.3265\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9631 - acc: 0.3068 - val_loss: 1.9042 - val_acc: 0.3222\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9412 - acc: 0.3175 - val_loss: 1.8915 - val_acc: 0.3290\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9169 - acc: 0.3226 - val_loss: 1.8865 - val_acc: 0.3338\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8963 - acc: 0.3298 - val_loss: 1.8856 - val_acc: 0.3273\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8776 - acc: 0.3373 - val_loss: 1.8873 - val_acc: 0.3286\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8652 - acc: 0.3391 - val_loss: 1.8823 - val_acc: 0.3355\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8472 - acc: 0.3438 - val_loss: 1.8876 - val_acc: 0.3376\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8374 - acc: 0.3499 - val_loss: 1.8889 - val_acc: 0.3342\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8189 - acc: 0.3542 - val_loss: 1.9089 - val_acc: 0.3312\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8047 - acc: 0.3587 - val_loss: 1.8938 - val_acc: 0.3363\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7895 - acc: 0.3657 - val_loss: 1.9361 - val_acc: 0.3381\n",
      "logloss val 1.9361258756520174\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "21s - loss: 2.3463 - acc: 0.1599 - val_loss: 2.1774 - val_acc: 0.2326\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1255 - acc: 0.2460 - val_loss: 2.0297 - val_acc: 0.2648\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0400 - acc: 0.2743 - val_loss: 2.0096 - val_acc: 0.2786\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9972 - acc: 0.2939 - val_loss: 1.9647 - val_acc: 0.2962\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9645 - acc: 0.3043 - val_loss: 1.9479 - val_acc: 0.3031\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9385 - acc: 0.3132 - val_loss: 1.9490 - val_acc: 0.2992\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9163 - acc: 0.3211 - val_loss: 1.9509 - val_acc: 0.3014\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8927 - acc: 0.3276 - val_loss: 1.9495 - val_acc: 0.3087\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8757 - acc: 0.3373 - val_loss: 1.9483 - val_acc: 0.3104\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8602 - acc: 0.3380 - val_loss: 1.9653 - val_acc: 0.3065\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8477 - acc: 0.3422 - val_loss: 1.9428 - val_acc: 0.3143\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8308 - acc: 0.3506 - val_loss: 1.9488 - val_acc: 0.3126\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8177 - acc: 0.3542 - val_loss: 1.9636 - val_acc: 0.3147\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8125 - acc: 0.3540 - val_loss: 1.9809 - val_acc: 0.3083\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7846 - acc: 0.3624 - val_loss: 1.9879 - val_acc: 0.3113\n",
      "logloss val 1.9879472045216453\n",
      "average logloss val 2.0450775305024385\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3517 - acc: 0.1576 - val_loss: 2.2514 - val_acc: 0.2076\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1115 - acc: 0.2525 - val_loss: 2.1625 - val_acc: 0.2324\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0226 - acc: 0.2848 - val_loss: 2.1417 - val_acc: 0.2483\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9748 - acc: 0.3004 - val_loss: 2.1332 - val_acc: 0.2534\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9440 - acc: 0.3129 - val_loss: 2.1194 - val_acc: 0.2547\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9119 - acc: 0.3230 - val_loss: 2.1158 - val_acc: 0.2573\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9009 - acc: 0.3277 - val_loss: 2.1220 - val_acc: 0.2577\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8849 - acc: 0.3320 - val_loss: 2.1203 - val_acc: 0.2590\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8604 - acc: 0.3394 - val_loss: 2.1138 - val_acc: 0.2586\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8452 - acc: 0.3466 - val_loss: 2.1174 - val_acc: 0.2598\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8328 - acc: 0.3517 - val_loss: 2.1192 - val_acc: 0.2603\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8180 - acc: 0.3538 - val_loss: 2.1179 - val_acc: 0.2637\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8038 - acc: 0.3595 - val_loss: 2.1262 - val_acc: 0.2564\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7826 - acc: 0.3694 - val_loss: 2.1353 - val_acc: 0.2581\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7738 - acc: 0.3700 - val_loss: 2.1523 - val_acc: 0.2637\n",
      "logloss val 2.8265773546831747\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3408 - acc: 0.1646 - val_loss: 2.1897 - val_acc: 0.2233\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1106 - acc: 0.2467 - val_loss: 2.0979 - val_acc: 0.2555\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0310 - acc: 0.2804 - val_loss: 2.0587 - val_acc: 0.2765\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9927 - acc: 0.2971 - val_loss: 2.0207 - val_acc: 0.2902\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9545 - acc: 0.3100 - val_loss: 2.0098 - val_acc: 0.3065\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9335 - acc: 0.3192 - val_loss: 1.9934 - val_acc: 0.3035\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9108 - acc: 0.3242 - val_loss: 1.9921 - val_acc: 0.3035\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8946 - acc: 0.3289 - val_loss: 1.9872 - val_acc: 0.3026\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8765 - acc: 0.3362 - val_loss: 1.9957 - val_acc: 0.3090\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8574 - acc: 0.3410 - val_loss: 1.9963 - val_acc: 0.3086\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8446 - acc: 0.3473 - val_loss: 1.9875 - val_acc: 0.3086\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8333 - acc: 0.3515 - val_loss: 1.9894 - val_acc: 0.3129\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8165 - acc: 0.3592 - val_loss: 1.9980 - val_acc: 0.3052\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8005 - acc: 0.3608 - val_loss: 2.0113 - val_acc: 0.3099\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7900 - acc: 0.3648 - val_loss: 2.0177 - val_acc: 0.3039\n",
      "logloss val 2.0176905612355487\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3356 - acc: 0.1656 - val_loss: 2.1928 - val_acc: 0.2319\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1065 - acc: 0.2536 - val_loss: 2.0934 - val_acc: 0.2628\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0219 - acc: 0.2846 - val_loss: 2.0826 - val_acc: 0.2748\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9792 - acc: 0.3028 - val_loss: 2.0565 - val_acc: 0.2808\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9444 - acc: 0.3118 - val_loss: 2.0572 - val_acc: 0.2855\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9218 - acc: 0.3216 - val_loss: 2.0466 - val_acc: 0.2868\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9000 - acc: 0.3304 - val_loss: 2.0430 - val_acc: 0.2923\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8845 - acc: 0.3317 - val_loss: 2.0511 - val_acc: 0.2898\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8632 - acc: 0.3392 - val_loss: 2.0564 - val_acc: 0.2808\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8533 - acc: 0.3431 - val_loss: 2.0425 - val_acc: 0.2919\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8379 - acc: 0.3496 - val_loss: 2.0490 - val_acc: 0.2906\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8224 - acc: 0.3550 - val_loss: 2.0512 - val_acc: 0.2902\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8074 - acc: 0.3572 - val_loss: 2.0558 - val_acc: 0.2940\n",
      "Epoch 14/15\n",
      "19s - loss: 1.7936 - acc: 0.3630 - val_loss: 2.0680 - val_acc: 0.2932\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7777 - acc: 0.3674 - val_loss: 2.0664 - val_acc: 0.2975\n",
      "logloss val 2.066444740767546\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3467 - acc: 0.1617 - val_loss: 2.1665 - val_acc: 0.2341\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1134 - acc: 0.2514 - val_loss: 2.0353 - val_acc: 0.2792\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0293 - acc: 0.2813 - val_loss: 2.0067 - val_acc: 0.2925\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9842 - acc: 0.2965 - val_loss: 1.9863 - val_acc: 0.2985\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9482 - acc: 0.3103 - val_loss: 1.9808 - val_acc: 0.3045\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9297 - acc: 0.3167 - val_loss: 1.9799 - val_acc: 0.3049\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9077 - acc: 0.3237 - val_loss: 1.9745 - val_acc: 0.3079\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8839 - acc: 0.3309 - val_loss: 1.9787 - val_acc: 0.3032\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8747 - acc: 0.3359 - val_loss: 1.9813 - val_acc: 0.3066\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8536 - acc: 0.3426 - val_loss: 1.9840 - val_acc: 0.3113\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8378 - acc: 0.3453 - val_loss: 1.9808 - val_acc: 0.3045\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8246 - acc: 0.3527 - val_loss: 1.9849 - val_acc: 0.3075\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8116 - acc: 0.3549 - val_loss: 1.9904 - val_acc: 0.3070\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7993 - acc: 0.3601 - val_loss: 2.0054 - val_acc: 0.3023\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7896 - acc: 0.3638 - val_loss: 2.0022 - val_acc: 0.3010\n",
      "logloss val 2.0021913736497985\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3533 - acc: 0.1626 - val_loss: 2.1355 - val_acc: 0.2539\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1177 - acc: 0.2510 - val_loss: 2.0067 - val_acc: 0.2890\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0370 - acc: 0.2809 - val_loss: 1.9501 - val_acc: 0.3130\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9924 - acc: 0.2972 - val_loss: 1.9455 - val_acc: 0.3087\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9603 - acc: 0.3081 - val_loss: 1.9380 - val_acc: 0.3105\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9315 - acc: 0.3180 - val_loss: 1.9241 - val_acc: 0.3276\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9114 - acc: 0.3242 - val_loss: 1.9247 - val_acc: 0.3268\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9003 - acc: 0.3286 - val_loss: 1.9301 - val_acc: 0.3280\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8784 - acc: 0.3354 - val_loss: 1.9256 - val_acc: 0.3315\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8584 - acc: 0.3437 - val_loss: 1.9315 - val_acc: 0.3353\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8450 - acc: 0.3491 - val_loss: 1.9368 - val_acc: 0.3319\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8308 - acc: 0.3537 - val_loss: 1.9390 - val_acc: 0.3315\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8133 - acc: 0.3573 - val_loss: 1.9426 - val_acc: 0.3289\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8036 - acc: 0.3622 - val_loss: 1.9538 - val_acc: 0.3233\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7905 - acc: 0.3633 - val_loss: 1.9574 - val_acc: 0.3306\n",
      "logloss val 1.957429175821471\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3314 - acc: 0.1724 - val_loss: 2.1380 - val_acc: 0.2544\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1042 - acc: 0.2523 - val_loss: 2.0106 - val_acc: 0.2866\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0366 - acc: 0.2790 - val_loss: 1.9723 - val_acc: 0.3042\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9928 - acc: 0.2985 - val_loss: 1.9471 - val_acc: 0.3110\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9621 - acc: 0.3071 - val_loss: 1.9404 - val_acc: 0.3140\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9285 - acc: 0.3196 - val_loss: 1.9366 - val_acc: 0.3153\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9125 - acc: 0.3247 - val_loss: 1.9364 - val_acc: 0.3162\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8975 - acc: 0.3296 - val_loss: 1.9358 - val_acc: 0.3110\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8778 - acc: 0.3363 - val_loss: 1.9345 - val_acc: 0.3097\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8605 - acc: 0.3425 - val_loss: 1.9324 - val_acc: 0.3102\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8446 - acc: 0.3489 - val_loss: 1.9376 - val_acc: 0.3085\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8340 - acc: 0.3510 - val_loss: 1.9391 - val_acc: 0.3085\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8162 - acc: 0.3552 - val_loss: 1.9389 - val_acc: 0.3063\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8089 - acc: 0.3584 - val_loss: 1.9522 - val_acc: 0.3033\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7899 - acc: 0.3641 - val_loss: 1.9562 - val_acc: 0.3093\n",
      "logloss val 1.9561609404501017\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3394 - acc: 0.1681 - val_loss: 2.1112 - val_acc: 0.2679\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1169 - acc: 0.2507 - val_loss: 1.9819 - val_acc: 0.2885\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0409 - acc: 0.2792 - val_loss: 1.9253 - val_acc: 0.3143\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9977 - acc: 0.2958 - val_loss: 1.8936 - val_acc: 0.3233\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9659 - acc: 0.3051 - val_loss: 1.8844 - val_acc: 0.3263\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9410 - acc: 0.3122 - val_loss: 1.8791 - val_acc: 0.3285\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9168 - acc: 0.3219 - val_loss: 1.8687 - val_acc: 0.3349\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9035 - acc: 0.3279 - val_loss: 1.8662 - val_acc: 0.3388\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8828 - acc: 0.3332 - val_loss: 1.8667 - val_acc: 0.3345\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8649 - acc: 0.3394 - val_loss: 1.8661 - val_acc: 0.3358\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8513 - acc: 0.3418 - val_loss: 1.8688 - val_acc: 0.3293\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8380 - acc: 0.3490 - val_loss: 1.8715 - val_acc: 0.3332\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8256 - acc: 0.3524 - val_loss: 1.8751 - val_acc: 0.3362\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8106 - acc: 0.3563 - val_loss: 1.8799 - val_acc: 0.3315\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7961 - acc: 0.3646 - val_loss: 1.8840 - val_acc: 0.3366\n",
      "logloss val 1.8839722946733388\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3506 - acc: 0.1654 - val_loss: 2.1325 - val_acc: 0.2649\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1273 - acc: 0.2450 - val_loss: 1.9562 - val_acc: 0.3126\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0461 - acc: 0.2778 - val_loss: 1.9149 - val_acc: 0.3195\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9926 - acc: 0.2955 - val_loss: 1.8924 - val_acc: 0.3263\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9653 - acc: 0.3063 - val_loss: 1.8832 - val_acc: 0.3164\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9384 - acc: 0.3163 - val_loss: 1.8711 - val_acc: 0.3272\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9224 - acc: 0.3217 - val_loss: 1.8700 - val_acc: 0.3280\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9003 - acc: 0.3284 - val_loss: 1.8648 - val_acc: 0.3237\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8884 - acc: 0.3348 - val_loss: 1.8599 - val_acc: 0.3315\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8672 - acc: 0.3381 - val_loss: 1.8600 - val_acc: 0.3310\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8518 - acc: 0.3428 - val_loss: 1.8600 - val_acc: 0.3315\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8363 - acc: 0.3509 - val_loss: 1.8637 - val_acc: 0.3362\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8245 - acc: 0.3564 - val_loss: 1.8665 - val_acc: 0.3267\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8141 - acc: 0.3589 - val_loss: 1.8687 - val_acc: 0.3388\n",
      "Epoch 15/15\n",
      "20s - loss: 1.8047 - acc: 0.3629 - val_loss: 1.8706 - val_acc: 0.3332\n",
      "logloss val 1.870633560088295\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3522 - acc: 0.1621 - val_loss: 2.1709 - val_acc: 0.2384\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1323 - acc: 0.2443 - val_loss: 1.9934 - val_acc: 0.2908\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0400 - acc: 0.2768 - val_loss: 1.9422 - val_acc: 0.3179\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0013 - acc: 0.2952 - val_loss: 1.9099 - val_acc: 0.3273\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9629 - acc: 0.3078 - val_loss: 1.8968 - val_acc: 0.3265\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9388 - acc: 0.3145 - val_loss: 1.8891 - val_acc: 0.3247\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9171 - acc: 0.3234 - val_loss: 1.8941 - val_acc: 0.3209\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8967 - acc: 0.3294 - val_loss: 1.8826 - val_acc: 0.3359\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8829 - acc: 0.3338 - val_loss: 1.8815 - val_acc: 0.3355\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8666 - acc: 0.3387 - val_loss: 1.8954 - val_acc: 0.3325\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8479 - acc: 0.3438 - val_loss: 1.8943 - val_acc: 0.3312\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8341 - acc: 0.3486 - val_loss: 1.8942 - val_acc: 0.3303\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8248 - acc: 0.3543 - val_loss: 1.8985 - val_acc: 0.3338\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8126 - acc: 0.3565 - val_loss: 1.9024 - val_acc: 0.3316\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7911 - acc: 0.3630 - val_loss: 1.9139 - val_acc: 0.3295\n",
      "logloss val 1.9139031213037532\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3440 - acc: 0.1632 - val_loss: 2.1664 - val_acc: 0.2382\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1202 - acc: 0.2473 - val_loss: 2.0239 - val_acc: 0.2941\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0304 - acc: 0.2797 - val_loss: 2.0187 - val_acc: 0.2825\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9891 - acc: 0.2978 - val_loss: 1.9786 - val_acc: 0.2906\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9610 - acc: 0.3041 - val_loss: 1.9649 - val_acc: 0.2971\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9316 - acc: 0.3177 - val_loss: 1.9585 - val_acc: 0.2979\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9145 - acc: 0.3221 - val_loss: 1.9624 - val_acc: 0.2962\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8917 - acc: 0.3328 - val_loss: 1.9639 - val_acc: 0.2962\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8802 - acc: 0.3363 - val_loss: 1.9472 - val_acc: 0.3065\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8584 - acc: 0.3428 - val_loss: 1.9677 - val_acc: 0.3035\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8483 - acc: 0.3431 - val_loss: 1.9857 - val_acc: 0.3031\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8284 - acc: 0.3535 - val_loss: 1.9648 - val_acc: 0.3091\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8139 - acc: 0.3570 - val_loss: 1.9872 - val_acc: 0.3083\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8047 - acc: 0.3627 - val_loss: 1.9911 - val_acc: 0.3014\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7846 - acc: 0.3688 - val_loss: 1.9891 - val_acc: 0.3035\n",
      "logloss val 1.9891486560183533\n",
      "average logloss val 2.0484151778691384\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3391 - acc: 0.1647 - val_loss: 2.2497 - val_acc: 0.2055\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1013 - acc: 0.2538 - val_loss: 2.1611 - val_acc: 0.2384\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0146 - acc: 0.2859 - val_loss: 2.1455 - val_acc: 0.2496\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9712 - acc: 0.3019 - val_loss: 2.1401 - val_acc: 0.2560\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9465 - acc: 0.3096 - val_loss: 2.1279 - val_acc: 0.2603\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9166 - acc: 0.3242 - val_loss: 2.1393 - val_acc: 0.2479\n",
      "Epoch 7/15\n",
      "20s - loss: 1.8946 - acc: 0.3295 - val_loss: 2.1306 - val_acc: 0.2633\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8821 - acc: 0.3371 - val_loss: 2.1184 - val_acc: 0.2603\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8571 - acc: 0.3439 - val_loss: 2.1306 - val_acc: 0.2564\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8434 - acc: 0.3480 - val_loss: 2.1384 - val_acc: 0.2654\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8261 - acc: 0.3531 - val_loss: 2.1516 - val_acc: 0.2573\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8127 - acc: 0.3594 - val_loss: 2.1355 - val_acc: 0.2590\n",
      "Epoch 13/15\n",
      "20s - loss: 1.7994 - acc: 0.3652 - val_loss: 2.1350 - val_acc: 0.2517\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7877 - acc: 0.3678 - val_loss: 2.1395 - val_acc: 0.2551\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7682 - acc: 0.3757 - val_loss: 2.1469 - val_acc: 0.2607\n",
      "logloss val 2.800812850083466\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3443 - acc: 0.1629 - val_loss: 2.2016 - val_acc: 0.2259\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1087 - acc: 0.2544 - val_loss: 2.0566 - val_acc: 0.2700\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0252 - acc: 0.2869 - val_loss: 2.0306 - val_acc: 0.2829\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9829 - acc: 0.3006 - val_loss: 2.0103 - val_acc: 0.2910\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9502 - acc: 0.3138 - val_loss: 1.9951 - val_acc: 0.2923\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9241 - acc: 0.3210 - val_loss: 1.9969 - val_acc: 0.2923\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9020 - acc: 0.3269 - val_loss: 2.0104 - val_acc: 0.2923\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8861 - acc: 0.3335 - val_loss: 1.9897 - val_acc: 0.2970\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8728 - acc: 0.3392 - val_loss: 1.9949 - val_acc: 0.3078\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8572 - acc: 0.3431 - val_loss: 1.9905 - val_acc: 0.3048\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8465 - acc: 0.3467 - val_loss: 2.0058 - val_acc: 0.2992\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8261 - acc: 0.3532 - val_loss: 1.9927 - val_acc: 0.3018\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8152 - acc: 0.3589 - val_loss: 1.9982 - val_acc: 0.3035\n",
      "Epoch 14/15\n",
      "19s - loss: 1.7984 - acc: 0.3634 - val_loss: 1.9917 - val_acc: 0.3060\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7889 - acc: 0.3663 - val_loss: 2.0128 - val_acc: 0.2996\n",
      "logloss val 2.0128338584250396\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3401 - acc: 0.1651 - val_loss: 2.2124 - val_acc: 0.2255\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1059 - acc: 0.2545 - val_loss: 2.1039 - val_acc: 0.2546\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0236 - acc: 0.2856 - val_loss: 2.0738 - val_acc: 0.2730\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9781 - acc: 0.3007 - val_loss: 2.0587 - val_acc: 0.2846\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9413 - acc: 0.3142 - val_loss: 2.0549 - val_acc: 0.2838\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9246 - acc: 0.3198 - val_loss: 2.0525 - val_acc: 0.2838\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9030 - acc: 0.3271 - val_loss: 2.0472 - val_acc: 0.2906\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8842 - acc: 0.3309 - val_loss: 2.0512 - val_acc: 0.2876\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8655 - acc: 0.3416 - val_loss: 2.0509 - val_acc: 0.2872\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8499 - acc: 0.3440 - val_loss: 2.0586 - val_acc: 0.2846\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8318 - acc: 0.3480 - val_loss: 2.0673 - val_acc: 0.2850\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8194 - acc: 0.3532 - val_loss: 2.0734 - val_acc: 0.2842\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8079 - acc: 0.3608 - val_loss: 2.0699 - val_acc: 0.2863\n",
      "Epoch 14/15\n",
      "19s - loss: 1.7950 - acc: 0.3621 - val_loss: 2.0745 - val_acc: 0.2880\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7790 - acc: 0.3680 - val_loss: 2.0782 - val_acc: 0.2842\n",
      "logloss val 2.078198076090598\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3398 - acc: 0.1669 - val_loss: 2.1573 - val_acc: 0.2414\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1162 - acc: 0.2480 - val_loss: 2.0447 - val_acc: 0.2693\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0312 - acc: 0.2794 - val_loss: 2.0023 - val_acc: 0.2933\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9799 - acc: 0.2972 - val_loss: 1.9901 - val_acc: 0.3066\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9558 - acc: 0.3070 - val_loss: 1.9806 - val_acc: 0.3117\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9334 - acc: 0.3165 - val_loss: 1.9774 - val_acc: 0.3160\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9044 - acc: 0.3293 - val_loss: 1.9824 - val_acc: 0.3057\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8957 - acc: 0.3271 - val_loss: 1.9769 - val_acc: 0.3160\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8709 - acc: 0.3370 - val_loss: 1.9866 - val_acc: 0.3032\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8557 - acc: 0.3433 - val_loss: 1.9809 - val_acc: 0.3143\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8438 - acc: 0.3474 - val_loss: 1.9834 - val_acc: 0.3027\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8275 - acc: 0.3553 - val_loss: 1.9967 - val_acc: 0.3092\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8163 - acc: 0.3553 - val_loss: 1.9934 - val_acc: 0.3096\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7977 - acc: 0.3650 - val_loss: 1.9964 - val_acc: 0.3079\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7887 - acc: 0.3670 - val_loss: 2.0020 - val_acc: 0.3087\n",
      "logloss val 2.0019514600406834\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3360 - acc: 0.1686 - val_loss: 2.1210 - val_acc: 0.2667\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1091 - acc: 0.2495 - val_loss: 1.9957 - val_acc: 0.2886\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0380 - acc: 0.2778 - val_loss: 1.9589 - val_acc: 0.3126\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9946 - acc: 0.2957 - val_loss: 1.9405 - val_acc: 0.3255\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9598 - acc: 0.3094 - val_loss: 1.9293 - val_acc: 0.3250\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9430 - acc: 0.3132 - val_loss: 1.9272 - val_acc: 0.3276\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9115 - acc: 0.3236 - val_loss: 1.9266 - val_acc: 0.3349\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9013 - acc: 0.3285 - val_loss: 1.9227 - val_acc: 0.3328\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8764 - acc: 0.3356 - val_loss: 1.9317 - val_acc: 0.3259\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8661 - acc: 0.3406 - val_loss: 1.9342 - val_acc: 0.3306\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8473 - acc: 0.3460 - val_loss: 1.9381 - val_acc: 0.3280\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8312 - acc: 0.3517 - val_loss: 1.9383 - val_acc: 0.3315\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8176 - acc: 0.3564 - val_loss: 1.9497 - val_acc: 0.3250\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8010 - acc: 0.3607 - val_loss: 1.9509 - val_acc: 0.3250\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7938 - acc: 0.3622 - val_loss: 1.9560 - val_acc: 0.3289\n",
      "logloss val 1.9559645778157435\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3439 - acc: 0.1651 - val_loss: 2.1560 - val_acc: 0.2462\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1235 - acc: 0.2493 - val_loss: 2.0270 - val_acc: 0.2789\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0373 - acc: 0.2784 - val_loss: 1.9810 - val_acc: 0.2943\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9974 - acc: 0.2981 - val_loss: 1.9627 - val_acc: 0.3037\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9682 - acc: 0.3031 - val_loss: 1.9470 - val_acc: 0.3024\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9320 - acc: 0.3188 - val_loss: 1.9367 - val_acc: 0.3102\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9160 - acc: 0.3235 - val_loss: 1.9395 - val_acc: 0.3037\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8948 - acc: 0.3306 - val_loss: 1.9384 - val_acc: 0.3145\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8738 - acc: 0.3342 - val_loss: 1.9395 - val_acc: 0.3166\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8557 - acc: 0.3408 - val_loss: 1.9381 - val_acc: 0.3145\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8465 - acc: 0.3464 - val_loss: 1.9436 - val_acc: 0.3003\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8322 - acc: 0.3545 - val_loss: 1.9500 - val_acc: 0.3115\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8189 - acc: 0.3545 - val_loss: 1.9520 - val_acc: 0.3085\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8044 - acc: 0.3615 - val_loss: 1.9554 - val_acc: 0.3067\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7885 - acc: 0.3649 - val_loss: 1.9640 - val_acc: 0.3080\n",
      "logloss val 1.9639571540390355\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3579 - acc: 0.1569 - val_loss: 2.1580 - val_acc: 0.2623\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1304 - acc: 0.2488 - val_loss: 1.9691 - val_acc: 0.3010\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0471 - acc: 0.2758 - val_loss: 1.9166 - val_acc: 0.3195\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0020 - acc: 0.2968 - val_loss: 1.8881 - val_acc: 0.3255\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9704 - acc: 0.3049 - val_loss: 1.8721 - val_acc: 0.3319\n",
      "Epoch 6/15\n",
      "21s - loss: 1.9390 - acc: 0.3143 - val_loss: 1.8648 - val_acc: 0.3336\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9214 - acc: 0.3219 - val_loss: 1.8610 - val_acc: 0.3396\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9029 - acc: 0.3293 - val_loss: 1.8674 - val_acc: 0.3388\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8846 - acc: 0.3325 - val_loss: 1.8603 - val_acc: 0.3426\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8727 - acc: 0.3396 - val_loss: 1.8564 - val_acc: 0.3435\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8546 - acc: 0.3440 - val_loss: 1.8589 - val_acc: 0.3426\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8395 - acc: 0.3480 - val_loss: 1.8668 - val_acc: 0.3396\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8284 - acc: 0.3537 - val_loss: 1.8643 - val_acc: 0.3383\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8107 - acc: 0.3575 - val_loss: 1.8729 - val_acc: 0.3362\n",
      "Epoch 15/15\n",
      "19s - loss: 1.8041 - acc: 0.3593 - val_loss: 1.8745 - val_acc: 0.3465\n",
      "logloss val 1.8745496535909303\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3575 - acc: 0.1549 - val_loss: 2.1571 - val_acc: 0.2589\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1357 - acc: 0.2481 - val_loss: 1.9600 - val_acc: 0.2988\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0428 - acc: 0.2772 - val_loss: 1.9198 - val_acc: 0.3233\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9974 - acc: 0.2953 - val_loss: 1.9028 - val_acc: 0.3263\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9674 - acc: 0.3079 - val_loss: 1.8763 - val_acc: 0.3345\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9401 - acc: 0.3178 - val_loss: 1.8700 - val_acc: 0.3396\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9177 - acc: 0.3235 - val_loss: 1.8627 - val_acc: 0.3409\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9055 - acc: 0.3306 - val_loss: 1.8577 - val_acc: 0.3375\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8833 - acc: 0.3380 - val_loss: 1.8555 - val_acc: 0.3319\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8639 - acc: 0.3404 - val_loss: 1.8572 - val_acc: 0.3323\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8562 - acc: 0.3462 - val_loss: 1.8585 - val_acc: 0.3353\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8371 - acc: 0.3513 - val_loss: 1.8569 - val_acc: 0.3401\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8257 - acc: 0.3539 - val_loss: 1.8618 - val_acc: 0.3379\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8096 - acc: 0.3594 - val_loss: 1.8676 - val_acc: 0.3379\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7960 - acc: 0.3675 - val_loss: 1.8672 - val_acc: 0.3418\n",
      "logloss val 1.8671933908087135\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3598 - acc: 0.1581 - val_loss: 2.1729 - val_acc: 0.2367\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1299 - acc: 0.2463 - val_loss: 1.9931 - val_acc: 0.2912\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0405 - acc: 0.2780 - val_loss: 1.9512 - val_acc: 0.3046\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9940 - acc: 0.2956 - val_loss: 1.9187 - val_acc: 0.3196\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9665 - acc: 0.3039 - val_loss: 1.8975 - val_acc: 0.3247\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9409 - acc: 0.3109 - val_loss: 1.8953 - val_acc: 0.3256\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9158 - acc: 0.3233 - val_loss: 1.8884 - val_acc: 0.3308\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8968 - acc: 0.3275 - val_loss: 1.8812 - val_acc: 0.3312\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8839 - acc: 0.3304 - val_loss: 1.8804 - val_acc: 0.3372\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8596 - acc: 0.3426 - val_loss: 1.8816 - val_acc: 0.3351\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8516 - acc: 0.3422 - val_loss: 1.8966 - val_acc: 0.3385\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8339 - acc: 0.3496 - val_loss: 1.8991 - val_acc: 0.3376\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8231 - acc: 0.3520 - val_loss: 1.8981 - val_acc: 0.3363\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8099 - acc: 0.3567 - val_loss: 1.9024 - val_acc: 0.3415\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7928 - acc: 0.3649 - val_loss: 1.9094 - val_acc: 0.3385\n",
      "logloss val 1.9093675095852345\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3519 - acc: 0.1633 - val_loss: 2.1584 - val_acc: 0.2356\n",
      "Epoch 2/15\n",
      "21s - loss: 2.1223 - acc: 0.2468 - val_loss: 2.0339 - val_acc: 0.2859\n",
      "Epoch 3/15\n",
      "21s - loss: 2.0352 - acc: 0.2762 - val_loss: 2.0027 - val_acc: 0.2928\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9951 - acc: 0.2965 - val_loss: 1.9884 - val_acc: 0.3001\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9557 - acc: 0.3123 - val_loss: 1.9692 - val_acc: 0.3091\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9344 - acc: 0.3192 - val_loss: 1.9653 - val_acc: 0.3070\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9148 - acc: 0.3255 - val_loss: 1.9633 - val_acc: 0.3117\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8915 - acc: 0.3333 - val_loss: 1.9626 - val_acc: 0.3009\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8752 - acc: 0.3380 - val_loss: 1.9526 - val_acc: 0.3147\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8590 - acc: 0.3425 - val_loss: 1.9483 - val_acc: 0.3138\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8464 - acc: 0.3450 - val_loss: 1.9477 - val_acc: 0.3194\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8276 - acc: 0.3529 - val_loss: 1.9696 - val_acc: 0.3164\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8145 - acc: 0.3575 - val_loss: 1.9688 - val_acc: 0.3138\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8043 - acc: 0.3629 - val_loss: 1.9714 - val_acc: 0.3087\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7857 - acc: 0.3667 - val_loss: 1.9793 - val_acc: 0.3147\n",
      "logloss val 1.9793465153933802\n",
      "average logloss val 2.0444175045872823\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3511 - acc: 0.1607 - val_loss: 2.2648 - val_acc: 0.1961\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1169 - acc: 0.2515 - val_loss: 2.1622 - val_acc: 0.2427\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0187 - acc: 0.2863 - val_loss: 2.1378 - val_acc: 0.2607\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9779 - acc: 0.3021 - val_loss: 2.1243 - val_acc: 0.2646\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9417 - acc: 0.3143 - val_loss: 2.1213 - val_acc: 0.2654\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9189 - acc: 0.3227 - val_loss: 2.1140 - val_acc: 0.2676\n",
      "Epoch 7/15\n",
      "20s - loss: 1.8899 - acc: 0.3340 - val_loss: 2.1188 - val_acc: 0.2646\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8782 - acc: 0.3405 - val_loss: 2.1150 - val_acc: 0.2684\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8543 - acc: 0.3458 - val_loss: 2.1144 - val_acc: 0.2641\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8405 - acc: 0.3484 - val_loss: 2.1078 - val_acc: 0.2641\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8241 - acc: 0.3559 - val_loss: 2.1153 - val_acc: 0.2586\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8105 - acc: 0.3591 - val_loss: 2.1170 - val_acc: 0.2633\n",
      "Epoch 13/15\n",
      "19s - loss: 1.7985 - acc: 0.3603 - val_loss: 2.1232 - val_acc: 0.2637\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7850 - acc: 0.3696 - val_loss: 2.1280 - val_acc: 0.2577\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7723 - acc: 0.3750 - val_loss: 2.1312 - val_acc: 0.2654\n",
      "logloss val 2.7877364644084746\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.3537 - acc: 0.1605 - val_loss: 2.2257 - val_acc: 0.2152\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1297 - acc: 0.2502 - val_loss: 2.0775 - val_acc: 0.2662\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0293 - acc: 0.2827 - val_loss: 2.0506 - val_acc: 0.2812\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9899 - acc: 0.3012 - val_loss: 2.0121 - val_acc: 0.2889\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9563 - acc: 0.3117 - val_loss: 1.9986 - val_acc: 0.2949\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9314 - acc: 0.3187 - val_loss: 1.9971 - val_acc: 0.2988\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9113 - acc: 0.3268 - val_loss: 1.9874 - val_acc: 0.3009\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8877 - acc: 0.3327 - val_loss: 1.9909 - val_acc: 0.3018\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8734 - acc: 0.3406 - val_loss: 1.9865 - val_acc: 0.3035\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8627 - acc: 0.3417 - val_loss: 1.9860 - val_acc: 0.3069\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8404 - acc: 0.3462 - val_loss: 1.9906 - val_acc: 0.3048\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8278 - acc: 0.3551 - val_loss: 1.9899 - val_acc: 0.3086\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8141 - acc: 0.3597 - val_loss: 1.9884 - val_acc: 0.3108\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8042 - acc: 0.3615 - val_loss: 2.0029 - val_acc: 0.3065\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7917 - acc: 0.3639 - val_loss: 1.9981 - val_acc: 0.3078\n",
      "logloss val 1.9981210709175836\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3406 - acc: 0.1635 - val_loss: 2.1940 - val_acc: 0.2362\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1108 - acc: 0.2500 - val_loss: 2.1069 - val_acc: 0.2580\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0366 - acc: 0.2741 - val_loss: 2.0925 - val_acc: 0.2585\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9900 - acc: 0.2917 - val_loss: 2.0952 - val_acc: 0.2636\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9571 - acc: 0.3069 - val_loss: 2.0518 - val_acc: 0.2889\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9336 - acc: 0.3138 - val_loss: 2.0556 - val_acc: 0.2880\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9068 - acc: 0.3221 - val_loss: 2.0458 - val_acc: 0.2915\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8973 - acc: 0.3284 - val_loss: 2.0381 - val_acc: 0.2910\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8731 - acc: 0.3389 - val_loss: 2.0380 - val_acc: 0.2910\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8581 - acc: 0.3423 - val_loss: 2.0427 - val_acc: 0.2893\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8424 - acc: 0.3433 - val_loss: 2.0528 - val_acc: 0.2898\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8309 - acc: 0.3508 - val_loss: 2.0538 - val_acc: 0.2859\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8111 - acc: 0.3591 - val_loss: 2.0614 - val_acc: 0.2932\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8022 - acc: 0.3616 - val_loss: 2.0720 - val_acc: 0.2893\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7897 - acc: 0.3660 - val_loss: 2.0642 - val_acc: 0.2940\n",
      "logloss val 2.0641797130663555\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3503 - acc: 0.1606 - val_loss: 2.1686 - val_acc: 0.2376\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1161 - acc: 0.2501 - val_loss: 2.0383 - val_acc: 0.2736\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0356 - acc: 0.2765 - val_loss: 2.0257 - val_acc: 0.2826\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9942 - acc: 0.2931 - val_loss: 1.9916 - val_acc: 0.2942\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9578 - acc: 0.3070 - val_loss: 1.9805 - val_acc: 0.3019\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9370 - acc: 0.3126 - val_loss: 1.9802 - val_acc: 0.2937\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9096 - acc: 0.3241 - val_loss: 1.9687 - val_acc: 0.3096\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8906 - acc: 0.3293 - val_loss: 1.9694 - val_acc: 0.3109\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8739 - acc: 0.3356 - val_loss: 1.9755 - val_acc: 0.3092\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8568 - acc: 0.3409 - val_loss: 1.9744 - val_acc: 0.3096\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8405 - acc: 0.3442 - val_loss: 1.9885 - val_acc: 0.3049\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8285 - acc: 0.3490 - val_loss: 1.9820 - val_acc: 0.3057\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8128 - acc: 0.3563 - val_loss: 1.9848 - val_acc: 0.3087\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8000 - acc: 0.3620 - val_loss: 1.9839 - val_acc: 0.3135\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7873 - acc: 0.3665 - val_loss: 2.0144 - val_acc: 0.3036\n",
      "logloss val 2.0144304034758536\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3520 - acc: 0.1598 - val_loss: 2.1570 - val_acc: 0.2517\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1272 - acc: 0.2473 - val_loss: 1.9949 - val_acc: 0.2817\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0412 - acc: 0.2748 - val_loss: 1.9528 - val_acc: 0.3075\n",
      "Epoch 4/15\n",
      "21s - loss: 1.9954 - acc: 0.2940 - val_loss: 1.9434 - val_acc: 0.3109\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9641 - acc: 0.3048 - val_loss: 1.9263 - val_acc: 0.3208\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9349 - acc: 0.3165 - val_loss: 1.9203 - val_acc: 0.3229\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9149 - acc: 0.3208 - val_loss: 1.9172 - val_acc: 0.3336\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8936 - acc: 0.3301 - val_loss: 1.9167 - val_acc: 0.3293\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8789 - acc: 0.3378 - val_loss: 1.9189 - val_acc: 0.3358\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8584 - acc: 0.3414 - val_loss: 1.9237 - val_acc: 0.3306\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8514 - acc: 0.3467 - val_loss: 1.9245 - val_acc: 0.3306\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8290 - acc: 0.3529 - val_loss: 1.9308 - val_acc: 0.3268\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8199 - acc: 0.3547 - val_loss: 1.9323 - val_acc: 0.3315\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8085 - acc: 0.3579 - val_loss: 1.9375 - val_acc: 0.3276\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7930 - acc: 0.3642 - val_loss: 1.9550 - val_acc: 0.3190\n",
      "logloss val 1.9550438861892943\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3315 - acc: 0.1727 - val_loss: 2.1406 - val_acc: 0.2518\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1141 - acc: 0.2498 - val_loss: 2.0327 - val_acc: 0.2711\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0448 - acc: 0.2756 - val_loss: 1.9950 - val_acc: 0.2823\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0058 - acc: 0.2909 - val_loss: 1.9649 - val_acc: 0.2982\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9683 - acc: 0.3057 - val_loss: 1.9502 - val_acc: 0.3003\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9418 - acc: 0.3119 - val_loss: 1.9394 - val_acc: 0.3037\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9179 - acc: 0.3214 - val_loss: 1.9360 - val_acc: 0.3020\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8990 - acc: 0.3270 - val_loss: 1.9342 - val_acc: 0.3046\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8835 - acc: 0.3347 - val_loss: 1.9281 - val_acc: 0.3085\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8684 - acc: 0.3411 - val_loss: 1.9318 - val_acc: 0.3016\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8530 - acc: 0.3434 - val_loss: 1.9350 - val_acc: 0.3076\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8389 - acc: 0.3491 - val_loss: 1.9390 - val_acc: 0.3076\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8233 - acc: 0.3516 - val_loss: 1.9420 - val_acc: 0.3012\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8115 - acc: 0.3590 - val_loss: 1.9431 - val_acc: 0.3072\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7979 - acc: 0.3624 - val_loss: 1.9449 - val_acc: 0.3080\n",
      "logloss val 1.944922906322785\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3550 - acc: 0.1590 - val_loss: 2.1520 - val_acc: 0.2641\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1300 - acc: 0.2425 - val_loss: 1.9856 - val_acc: 0.2937\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0463 - acc: 0.2739 - val_loss: 1.9119 - val_acc: 0.3173\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9989 - acc: 0.2925 - val_loss: 1.8863 - val_acc: 0.3276\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9740 - acc: 0.3029 - val_loss: 1.8734 - val_acc: 0.3306\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9457 - acc: 0.3123 - val_loss: 1.8720 - val_acc: 0.3298\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9228 - acc: 0.3217 - val_loss: 1.8658 - val_acc: 0.3401\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9024 - acc: 0.3302 - val_loss: 1.8554 - val_acc: 0.3401\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8912 - acc: 0.3304 - val_loss: 1.8561 - val_acc: 0.3435\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8719 - acc: 0.3369 - val_loss: 1.8527 - val_acc: 0.3353\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8564 - acc: 0.3436 - val_loss: 1.8554 - val_acc: 0.3375\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8410 - acc: 0.3482 - val_loss: 1.8590 - val_acc: 0.3383\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8257 - acc: 0.3541 - val_loss: 1.8619 - val_acc: 0.3405\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8183 - acc: 0.3574 - val_loss: 1.8639 - val_acc: 0.3383\n",
      "Epoch 15/15\n",
      "20s - loss: 1.8008 - acc: 0.3618 - val_loss: 1.8702 - val_acc: 0.3366\n",
      "logloss val 1.8702213616746899\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3519 - acc: 0.1630 - val_loss: 2.1373 - val_acc: 0.2636\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1320 - acc: 0.2448 - val_loss: 1.9707 - val_acc: 0.2997\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0514 - acc: 0.2716 - val_loss: 1.9267 - val_acc: 0.3173\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0075 - acc: 0.2919 - val_loss: 1.8958 - val_acc: 0.3250\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9704 - acc: 0.3014 - val_loss: 1.8792 - val_acc: 0.3246\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9450 - acc: 0.3124 - val_loss: 1.8669 - val_acc: 0.3272\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9286 - acc: 0.3206 - val_loss: 1.8641 - val_acc: 0.3298\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9043 - acc: 0.3248 - val_loss: 1.8756 - val_acc: 0.3242\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8909 - acc: 0.3341 - val_loss: 1.8571 - val_acc: 0.3336\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8739 - acc: 0.3387 - val_loss: 1.8632 - val_acc: 0.3302\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8581 - acc: 0.3436 - val_loss: 1.8590 - val_acc: 0.3426\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8420 - acc: 0.3504 - val_loss: 1.8633 - val_acc: 0.3371\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8277 - acc: 0.3525 - val_loss: 1.8620 - val_acc: 0.3362\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8158 - acc: 0.3577 - val_loss: 1.8608 - val_acc: 0.3366\n",
      "Epoch 15/15\n",
      "20s - loss: 1.8023 - acc: 0.3621 - val_loss: 1.8673 - val_acc: 0.3405\n",
      "logloss val 1.8672796794053643\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3466 - acc: 0.1634 - val_loss: 2.1334 - val_acc: 0.2582\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1237 - acc: 0.2482 - val_loss: 1.9826 - val_acc: 0.3037\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0375 - acc: 0.2804 - val_loss: 1.9416 - val_acc: 0.3157\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9933 - acc: 0.2984 - val_loss: 1.9097 - val_acc: 0.3252\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9649 - acc: 0.3058 - val_loss: 1.8979 - val_acc: 0.3308\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9363 - acc: 0.3164 - val_loss: 1.8903 - val_acc: 0.3419\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9135 - acc: 0.3258 - val_loss: 1.8956 - val_acc: 0.3368\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9018 - acc: 0.3280 - val_loss: 1.8951 - val_acc: 0.3325\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8835 - acc: 0.3339 - val_loss: 1.8974 - val_acc: 0.3338\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8636 - acc: 0.3390 - val_loss: 1.8897 - val_acc: 0.3415\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8466 - acc: 0.3483 - val_loss: 1.8970 - val_acc: 0.3415\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8308 - acc: 0.3513 - val_loss: 1.9123 - val_acc: 0.3325\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8203 - acc: 0.3548 - val_loss: 1.9046 - val_acc: 0.3342\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8073 - acc: 0.3595 - val_loss: 1.9139 - val_acc: 0.3342\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7954 - acc: 0.3640 - val_loss: 1.9210 - val_acc: 0.3376\n",
      "logloss val 1.9210234632872702\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3397 - acc: 0.1691 - val_loss: 2.1486 - val_acc: 0.2438\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1160 - acc: 0.2500 - val_loss: 2.0319 - val_acc: 0.2764\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0358 - acc: 0.2791 - val_loss: 1.9852 - val_acc: 0.2919\n",
      "Epoch 4/15\n",
      "21s - loss: 1.9944 - acc: 0.2976 - val_loss: 1.9652 - val_acc: 0.3001\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9593 - acc: 0.3115 - val_loss: 1.9578 - val_acc: 0.2941\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9324 - acc: 0.3172 - val_loss: 1.9629 - val_acc: 0.3014\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9102 - acc: 0.3252 - val_loss: 1.9595 - val_acc: 0.3027\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8950 - acc: 0.3336 - val_loss: 1.9538 - val_acc: 0.3078\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8717 - acc: 0.3396 - val_loss: 1.9747 - val_acc: 0.3009\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8551 - acc: 0.3450 - val_loss: 1.9648 - val_acc: 0.3113\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8441 - acc: 0.3479 - val_loss: 1.9701 - val_acc: 0.3057\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8312 - acc: 0.3509 - val_loss: 1.9695 - val_acc: 0.3083\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8156 - acc: 0.3554 - val_loss: 1.9765 - val_acc: 0.3104\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7986 - acc: 0.3631 - val_loss: 1.9890 - val_acc: 0.3113\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7889 - acc: 0.3643 - val_loss: 1.9824 - val_acc: 0.3113\n",
      "logloss val 1.982442934277324\n",
      "average logloss val 2.0405401883024994\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3386 - acc: 0.1688 - val_loss: 2.2441 - val_acc: 0.2089\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1042 - acc: 0.2529 - val_loss: 2.1727 - val_acc: 0.2273\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0209 - acc: 0.2853 - val_loss: 2.1430 - val_acc: 0.2504\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9777 - acc: 0.2998 - val_loss: 2.1347 - val_acc: 0.2577\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9418 - acc: 0.3166 - val_loss: 2.1258 - val_acc: 0.2598\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9172 - acc: 0.3227 - val_loss: 2.1240 - val_acc: 0.2658\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9020 - acc: 0.3276 - val_loss: 2.1158 - val_acc: 0.2616\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8813 - acc: 0.3356 - val_loss: 2.1244 - val_acc: 0.2598\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8633 - acc: 0.3390 - val_loss: 2.1209 - val_acc: 0.2530\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8522 - acc: 0.3437 - val_loss: 2.1312 - val_acc: 0.2650\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8326 - acc: 0.3525 - val_loss: 2.1269 - val_acc: 0.2637\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8156 - acc: 0.3531 - val_loss: 2.1263 - val_acc: 0.2637\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8022 - acc: 0.3616 - val_loss: 2.1378 - val_acc: 0.2539\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7875 - acc: 0.3672 - val_loss: 2.1419 - val_acc: 0.2590\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7730 - acc: 0.3704 - val_loss: 2.1528 - val_acc: 0.2607\n",
      "logloss val 2.8348628198355086\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3546 - acc: 0.1624 - val_loss: 2.2166 - val_acc: 0.2345\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1278 - acc: 0.2450 - val_loss: 2.0869 - val_acc: 0.2559\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0370 - acc: 0.2750 - val_loss: 2.0638 - val_acc: 0.2726\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9964 - acc: 0.2940 - val_loss: 2.0355 - val_acc: 0.2829\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9609 - acc: 0.3074 - val_loss: 2.0081 - val_acc: 0.2872\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9381 - acc: 0.3138 - val_loss: 2.0041 - val_acc: 0.2962\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9164 - acc: 0.3212 - val_loss: 1.9911 - val_acc: 0.3069\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8909 - acc: 0.3350 - val_loss: 1.9857 - val_acc: 0.3086\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8800 - acc: 0.3348 - val_loss: 1.9884 - val_acc: 0.3056\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8583 - acc: 0.3438 - val_loss: 1.9783 - val_acc: 0.3133\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8468 - acc: 0.3497 - val_loss: 1.9821 - val_acc: 0.3095\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8291 - acc: 0.3510 - val_loss: 1.9855 - val_acc: 0.3168\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8160 - acc: 0.3594 - val_loss: 1.9921 - val_acc: 0.3060\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8031 - acc: 0.3606 - val_loss: 1.9971 - val_acc: 0.3116\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7887 - acc: 0.3695 - val_loss: 2.0159 - val_acc: 0.3103\n",
      "logloss val 2.0158715523441098\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3530 - acc: 0.1576 - val_loss: 2.2526 - val_acc: 0.2057\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1262 - acc: 0.2417 - val_loss: 2.1042 - val_acc: 0.2610\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0290 - acc: 0.2833 - val_loss: 2.0846 - val_acc: 0.2696\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9847 - acc: 0.2967 - val_loss: 2.0680 - val_acc: 0.2910\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9443 - acc: 0.3108 - val_loss: 2.0496 - val_acc: 0.2906\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9226 - acc: 0.3208 - val_loss: 2.0425 - val_acc: 0.3022\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9005 - acc: 0.3259 - val_loss: 2.0513 - val_acc: 0.2906\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8858 - acc: 0.3327 - val_loss: 2.0419 - val_acc: 0.2953\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8694 - acc: 0.3356 - val_loss: 2.0436 - val_acc: 0.2889\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8471 - acc: 0.3438 - val_loss: 2.0502 - val_acc: 0.2928\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8357 - acc: 0.3464 - val_loss: 2.0521 - val_acc: 0.2962\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8255 - acc: 0.3545 - val_loss: 2.0597 - val_acc: 0.2919\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8059 - acc: 0.3586 - val_loss: 2.0611 - val_acc: 0.2928\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7974 - acc: 0.3614 - val_loss: 2.0927 - val_acc: 0.2842\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7792 - acc: 0.3665 - val_loss: 2.0779 - val_acc: 0.2876\n",
      "logloss val 2.0778561454111384\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3366 - acc: 0.1712 - val_loss: 2.1454 - val_acc: 0.2487\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1095 - acc: 0.2554 - val_loss: 2.0311 - val_acc: 0.2860\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0228 - acc: 0.2856 - val_loss: 1.9989 - val_acc: 0.2989\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9772 - acc: 0.2988 - val_loss: 1.9878 - val_acc: 0.3045\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9543 - acc: 0.3089 - val_loss: 1.9761 - val_acc: 0.3057\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9273 - acc: 0.3169 - val_loss: 1.9761 - val_acc: 0.3113\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9079 - acc: 0.3286 - val_loss: 1.9728 - val_acc: 0.3096\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8817 - acc: 0.3324 - val_loss: 1.9770 - val_acc: 0.3083\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8709 - acc: 0.3397 - val_loss: 1.9797 - val_acc: 0.3083\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8495 - acc: 0.3468 - val_loss: 1.9795 - val_acc: 0.3122\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8368 - acc: 0.3507 - val_loss: 1.9930 - val_acc: 0.3117\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8266 - acc: 0.3493 - val_loss: 1.9847 - val_acc: 0.3083\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8111 - acc: 0.3587 - val_loss: 1.9888 - val_acc: 0.3109\n",
      "Epoch 14/15\n",
      "19s - loss: 1.7947 - acc: 0.3615 - val_loss: 1.9961 - val_acc: 0.3148\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7829 - acc: 0.3664 - val_loss: 2.0063 - val_acc: 0.3075\n",
      "logloss val 2.0063005445994144\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3281 - acc: 0.1740 - val_loss: 2.1071 - val_acc: 0.2672\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1052 - acc: 0.2519 - val_loss: 1.9942 - val_acc: 0.2895\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0294 - acc: 0.2817 - val_loss: 1.9644 - val_acc: 0.3087\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9835 - acc: 0.2986 - val_loss: 1.9563 - val_acc: 0.3075\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9516 - acc: 0.3107 - val_loss: 1.9335 - val_acc: 0.3178\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9333 - acc: 0.3174 - val_loss: 1.9280 - val_acc: 0.3216\n",
      "Epoch 7/15\n",
      "20s - loss: 1.8972 - acc: 0.3278 - val_loss: 1.9265 - val_acc: 0.3225\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8907 - acc: 0.3331 - val_loss: 1.9267 - val_acc: 0.3328\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8757 - acc: 0.3358 - val_loss: 1.9278 - val_acc: 0.3212\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8527 - acc: 0.3441 - val_loss: 1.9292 - val_acc: 0.3280\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8493 - acc: 0.3473 - val_loss: 1.9333 - val_acc: 0.3302\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8303 - acc: 0.3498 - val_loss: 1.9430 - val_acc: 0.3199\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8179 - acc: 0.3546 - val_loss: 1.9455 - val_acc: 0.3225\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7969 - acc: 0.3639 - val_loss: 1.9550 - val_acc: 0.3148\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7911 - acc: 0.3648 - val_loss: 1.9530 - val_acc: 0.3238\n",
      "logloss val 1.9529573646955962\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3412 - acc: 0.1629 - val_loss: 2.1461 - val_acc: 0.2471\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1102 - acc: 0.2517 - val_loss: 2.0050 - val_acc: 0.2754\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0334 - acc: 0.2818 - val_loss: 1.9658 - val_acc: 0.3046\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9904 - acc: 0.2972 - val_loss: 1.9504 - val_acc: 0.3042\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9587 - acc: 0.3050 - val_loss: 1.9403 - val_acc: 0.3063\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9325 - acc: 0.3166 - val_loss: 1.9317 - val_acc: 0.3136\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9141 - acc: 0.3207 - val_loss: 1.9282 - val_acc: 0.3162\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8915 - acc: 0.3275 - val_loss: 1.9275 - val_acc: 0.3157\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8775 - acc: 0.3337 - val_loss: 1.9291 - val_acc: 0.3119\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8630 - acc: 0.3429 - val_loss: 1.9322 - val_acc: 0.3076\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8436 - acc: 0.3462 - val_loss: 1.9322 - val_acc: 0.3085\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8355 - acc: 0.3517 - val_loss: 1.9361 - val_acc: 0.3076\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8134 - acc: 0.3574 - val_loss: 1.9371 - val_acc: 0.3076\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8043 - acc: 0.3579 - val_loss: 1.9428 - val_acc: 0.3063\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7905 - acc: 0.3649 - val_loss: 1.9534 - val_acc: 0.3046\n",
      "logloss val 1.9534357056971616\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3412 - acc: 0.1674 - val_loss: 2.1405 - val_acc: 0.2718\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1193 - acc: 0.2516 - val_loss: 1.9694 - val_acc: 0.3044\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0455 - acc: 0.2759 - val_loss: 1.9188 - val_acc: 0.3199\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9989 - acc: 0.2919 - val_loss: 1.8929 - val_acc: 0.3259\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9727 - acc: 0.3052 - val_loss: 1.8803 - val_acc: 0.3332\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9473 - acc: 0.3106 - val_loss: 1.8719 - val_acc: 0.3358\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9211 - acc: 0.3221 - val_loss: 1.8688 - val_acc: 0.3340\n",
      "Epoch 8/15\n",
      "19s - loss: 1.9020 - acc: 0.3251 - val_loss: 1.8621 - val_acc: 0.3375\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8880 - acc: 0.3343 - val_loss: 1.8648 - val_acc: 0.3379\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8683 - acc: 0.3399 - val_loss: 1.8678 - val_acc: 0.3353\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8548 - acc: 0.3443 - val_loss: 1.8589 - val_acc: 0.3409\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8425 - acc: 0.3499 - val_loss: 1.8624 - val_acc: 0.3392\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8244 - acc: 0.3543 - val_loss: 1.8612 - val_acc: 0.3405\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8171 - acc: 0.3561 - val_loss: 1.8666 - val_acc: 0.3388\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7995 - acc: 0.3589 - val_loss: 1.8735 - val_acc: 0.3418\n",
      "logloss val 1.873460914751667\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3432 - acc: 0.1722 - val_loss: 2.1101 - val_acc: 0.2714\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1090 - acc: 0.2540 - val_loss: 1.9546 - val_acc: 0.3091\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0396 - acc: 0.2803 - val_loss: 1.9116 - val_acc: 0.3199\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9962 - acc: 0.2963 - val_loss: 1.8878 - val_acc: 0.3216\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9658 - acc: 0.3079 - val_loss: 1.8794 - val_acc: 0.3220\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9431 - acc: 0.3143 - val_loss: 1.8670 - val_acc: 0.3272\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9173 - acc: 0.3239 - val_loss: 1.8622 - val_acc: 0.3319\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9085 - acc: 0.3258 - val_loss: 1.8576 - val_acc: 0.3345\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8807 - acc: 0.3377 - val_loss: 1.8644 - val_acc: 0.3366\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8709 - acc: 0.3389 - val_loss: 1.8570 - val_acc: 0.3306\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8547 - acc: 0.3454 - val_loss: 1.8592 - val_acc: 0.3392\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8479 - acc: 0.3468 - val_loss: 1.8570 - val_acc: 0.3401\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8291 - acc: 0.3531 - val_loss: 1.8591 - val_acc: 0.3358\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8151 - acc: 0.3593 - val_loss: 1.8627 - val_acc: 0.3340\n",
      "Epoch 15/15\n",
      "20s - loss: 1.8068 - acc: 0.3608 - val_loss: 1.8650 - val_acc: 0.3328\n",
      "logloss val 1.8649522780559529\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3564 - acc: 0.1581 - val_loss: 2.1491 - val_acc: 0.2564\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1289 - acc: 0.2457 - val_loss: 2.0020 - val_acc: 0.2762\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0506 - acc: 0.2738 - val_loss: 1.9525 - val_acc: 0.3037\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0020 - acc: 0.2922 - val_loss: 1.9410 - val_acc: 0.3123\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9772 - acc: 0.3018 - val_loss: 1.9172 - val_acc: 0.3179\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9467 - acc: 0.3104 - val_loss: 1.8972 - val_acc: 0.3282\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9238 - acc: 0.3184 - val_loss: 1.9025 - val_acc: 0.3342\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9028 - acc: 0.3277 - val_loss: 1.8914 - val_acc: 0.3402\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8909 - acc: 0.3325 - val_loss: 1.8923 - val_acc: 0.3411\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8710 - acc: 0.3383 - val_loss: 1.9010 - val_acc: 0.3325\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8585 - acc: 0.3444 - val_loss: 1.8954 - val_acc: 0.3376\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8434 - acc: 0.3489 - val_loss: 1.8950 - val_acc: 0.3385\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8307 - acc: 0.3523 - val_loss: 1.9123 - val_acc: 0.3359\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8144 - acc: 0.3586 - val_loss: 1.9166 - val_acc: 0.3351\n",
      "Epoch 15/15\n",
      "20s - loss: 1.8017 - acc: 0.3609 - val_loss: 1.9171 - val_acc: 0.3320\n",
      "logloss val 1.9171361225964372\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3502 - acc: 0.1596 - val_loss: 2.1583 - val_acc: 0.2481\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1211 - acc: 0.2470 - val_loss: 2.0504 - val_acc: 0.2846\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0345 - acc: 0.2808 - val_loss: 1.9716 - val_acc: 0.3057\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9875 - acc: 0.2993 - val_loss: 1.9668 - val_acc: 0.3095\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9536 - acc: 0.3113 - val_loss: 1.9773 - val_acc: 0.2945\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9320 - acc: 0.3173 - val_loss: 1.9525 - val_acc: 0.3022\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9104 - acc: 0.3255 - val_loss: 1.9532 - val_acc: 0.3083\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8925 - acc: 0.3332 - val_loss: 1.9343 - val_acc: 0.3151\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8761 - acc: 0.3327 - val_loss: 1.9415 - val_acc: 0.3078\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8593 - acc: 0.3400 - val_loss: 1.9497 - val_acc: 0.3100\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8423 - acc: 0.3498 - val_loss: 1.9509 - val_acc: 0.3151\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8310 - acc: 0.3489 - val_loss: 1.9587 - val_acc: 0.3095\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8091 - acc: 0.3559 - val_loss: 1.9554 - val_acc: 0.3156\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7978 - acc: 0.3634 - val_loss: 1.9883 - val_acc: 0.3143\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7874 - acc: 0.3655 - val_loss: 1.9791 - val_acc: 0.3121\n",
      "logloss val 1.9791302628777778\n",
      "average logloss val 2.0475963710864766\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3295 - acc: 0.1726 - val_loss: 2.2287 - val_acc: 0.2063\n",
      "Epoch 2/15\n",
      "20s - loss: 2.0930 - acc: 0.2591 - val_loss: 2.1836 - val_acc: 0.2342\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0173 - acc: 0.2850 - val_loss: 2.1417 - val_acc: 0.2419\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9717 - acc: 0.3013 - val_loss: 2.1347 - val_acc: 0.2590\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9447 - acc: 0.3115 - val_loss: 2.1273 - val_acc: 0.2560\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9123 - acc: 0.3266 - val_loss: 2.1284 - val_acc: 0.2594\n",
      "Epoch 7/15\n",
      "20s - loss: 1.8957 - acc: 0.3284 - val_loss: 2.1241 - val_acc: 0.2620\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8767 - acc: 0.3362 - val_loss: 2.1174 - val_acc: 0.2663\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8570 - acc: 0.3416 - val_loss: 2.1180 - val_acc: 0.2663\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8444 - acc: 0.3438 - val_loss: 2.1127 - val_acc: 0.2667\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8284 - acc: 0.3511 - val_loss: 2.1283 - val_acc: 0.2646\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8190 - acc: 0.3550 - val_loss: 2.1194 - val_acc: 0.2693\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8037 - acc: 0.3598 - val_loss: 2.1308 - val_acc: 0.2624\n",
      "Epoch 14/15\n",
      "20s - loss: 1.7905 - acc: 0.3646 - val_loss: 2.1339 - val_acc: 0.2688\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7748 - acc: 0.3675 - val_loss: 2.1327 - val_acc: 0.2697\n",
      "logloss val 2.7978449241526944\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3557 - acc: 0.1623 - val_loss: 2.2240 - val_acc: 0.2225\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1258 - acc: 0.2485 - val_loss: 2.0754 - val_acc: 0.2585\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0415 - acc: 0.2745 - val_loss: 2.0553 - val_acc: 0.2705\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9931 - acc: 0.2962 - val_loss: 2.0294 - val_acc: 0.2838\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9604 - acc: 0.3040 - val_loss: 2.0173 - val_acc: 0.2902\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9386 - acc: 0.3105 - val_loss: 2.0064 - val_acc: 0.2996\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9121 - acc: 0.3254 - val_loss: 2.0084 - val_acc: 0.2958\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8960 - acc: 0.3255 - val_loss: 1.9954 - val_acc: 0.3056\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8756 - acc: 0.3352 - val_loss: 1.9923 - val_acc: 0.3043\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8610 - acc: 0.3416 - val_loss: 1.9888 - val_acc: 0.3030\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8451 - acc: 0.3449 - val_loss: 1.9929 - val_acc: 0.2996\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8290 - acc: 0.3518 - val_loss: 2.0016 - val_acc: 0.3013\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8162 - acc: 0.3542 - val_loss: 2.0142 - val_acc: 0.2975\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8006 - acc: 0.3587 - val_loss: 2.0020 - val_acc: 0.3026\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7857 - acc: 0.3638 - val_loss: 2.0144 - val_acc: 0.3056\n",
      "logloss val 2.0144094372059276\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3422 - acc: 0.1679 - val_loss: 2.2069 - val_acc: 0.2276\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1105 - acc: 0.2504 - val_loss: 2.1027 - val_acc: 0.2589\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0277 - acc: 0.2793 - val_loss: 2.0795 - val_acc: 0.2636\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9853 - acc: 0.2951 - val_loss: 2.0685 - val_acc: 0.2739\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9550 - acc: 0.3068 - val_loss: 2.0558 - val_acc: 0.2778\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9276 - acc: 0.3196 - val_loss: 2.0471 - val_acc: 0.2872\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9020 - acc: 0.3256 - val_loss: 2.0547 - val_acc: 0.2786\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8811 - acc: 0.3316 - val_loss: 2.0540 - val_acc: 0.2782\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8710 - acc: 0.3398 - val_loss: 2.0425 - val_acc: 0.2889\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8541 - acc: 0.3430 - val_loss: 2.0545 - val_acc: 0.2850\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8389 - acc: 0.3450 - val_loss: 2.0594 - val_acc: 0.2833\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8213 - acc: 0.3539 - val_loss: 2.0563 - val_acc: 0.2906\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8071 - acc: 0.3569 - val_loss: 2.0657 - val_acc: 0.2889\n",
      "Epoch 14/15\n",
      "19s - loss: 1.7960 - acc: 0.3634 - val_loss: 2.0671 - val_acc: 0.2868\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7829 - acc: 0.3667 - val_loss: 2.0817 - val_acc: 0.2872\n",
      "logloss val 2.0816842662838417\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3452 - acc: 0.1658 - val_loss: 2.1635 - val_acc: 0.2371\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1139 - acc: 0.2505 - val_loss: 2.0454 - val_acc: 0.2813\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0336 - acc: 0.2798 - val_loss: 2.0035 - val_acc: 0.2985\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9877 - acc: 0.2963 - val_loss: 1.9849 - val_acc: 0.3117\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9613 - acc: 0.3078 - val_loss: 1.9876 - val_acc: 0.3002\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9274 - acc: 0.3205 - val_loss: 1.9795 - val_acc: 0.3105\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9086 - acc: 0.3238 - val_loss: 1.9741 - val_acc: 0.3122\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8926 - acc: 0.3299 - val_loss: 1.9723 - val_acc: 0.3156\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8705 - acc: 0.3399 - val_loss: 1.9806 - val_acc: 0.3113\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8588 - acc: 0.3421 - val_loss: 1.9778 - val_acc: 0.3083\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8380 - acc: 0.3498 - val_loss: 1.9875 - val_acc: 0.3040\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8248 - acc: 0.3542 - val_loss: 1.9903 - val_acc: 0.3122\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8149 - acc: 0.3561 - val_loss: 1.9924 - val_acc: 0.3100\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8025 - acc: 0.3599 - val_loss: 1.9983 - val_acc: 0.3057\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7903 - acc: 0.3662 - val_loss: 1.9993 - val_acc: 0.3045\n",
      "logloss val 1.9993219873346373\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3544 - acc: 0.1623 - val_loss: 2.1700 - val_acc: 0.2616\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1279 - acc: 0.2486 - val_loss: 1.9944 - val_acc: 0.2895\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0436 - acc: 0.2776 - val_loss: 1.9476 - val_acc: 0.3083\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9921 - acc: 0.2973 - val_loss: 1.9330 - val_acc: 0.3169\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9667 - acc: 0.3081 - val_loss: 1.9192 - val_acc: 0.3182\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9314 - acc: 0.3210 - val_loss: 1.9140 - val_acc: 0.3293\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9160 - acc: 0.3261 - val_loss: 1.9142 - val_acc: 0.3246\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8914 - acc: 0.3314 - val_loss: 1.9159 - val_acc: 0.3276\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8781 - acc: 0.3371 - val_loss: 1.9141 - val_acc: 0.3349\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8615 - acc: 0.3421 - val_loss: 1.9182 - val_acc: 0.3293\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8436 - acc: 0.3493 - val_loss: 1.9240 - val_acc: 0.3229\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8351 - acc: 0.3505 - val_loss: 1.9279 - val_acc: 0.3220\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8187 - acc: 0.3564 - val_loss: 1.9288 - val_acc: 0.3319\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8006 - acc: 0.3618 - val_loss: 1.9365 - val_acc: 0.3250\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7919 - acc: 0.3642 - val_loss: 1.9389 - val_acc: 0.3298\n",
      "logloss val 1.9388977730560675\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3509 - acc: 0.1623 - val_loss: 2.1462 - val_acc: 0.2411\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1187 - acc: 0.2500 - val_loss: 2.0053 - val_acc: 0.2853\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0386 - acc: 0.2819 - val_loss: 1.9641 - val_acc: 0.3054\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9879 - acc: 0.2957 - val_loss: 1.9454 - val_acc: 0.3115\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9631 - acc: 0.3065 - val_loss: 1.9391 - val_acc: 0.3200\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9261 - acc: 0.3218 - val_loss: 1.9395 - val_acc: 0.3097\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9101 - acc: 0.3293 - val_loss: 1.9365 - val_acc: 0.3153\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8953 - acc: 0.3314 - val_loss: 1.9336 - val_acc: 0.3089\n",
      "Epoch 9/15\n",
      "19s - loss: 1.8715 - acc: 0.3400 - val_loss: 1.9370 - val_acc: 0.3145\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8592 - acc: 0.3433 - val_loss: 1.9345 - val_acc: 0.3076\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8461 - acc: 0.3488 - val_loss: 1.9420 - val_acc: 0.3054\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8363 - acc: 0.3502 - val_loss: 1.9400 - val_acc: 0.3016\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8140 - acc: 0.3565 - val_loss: 1.9504 - val_acc: 0.3067\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8010 - acc: 0.3603 - val_loss: 1.9479 - val_acc: 0.3016\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7936 - acc: 0.3655 - val_loss: 1.9572 - val_acc: 0.3080\n",
      "logloss val 1.9572334951334562\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3416 - acc: 0.1677 - val_loss: 2.1106 - val_acc: 0.2692\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1158 - acc: 0.2500 - val_loss: 1.9562 - val_acc: 0.3049\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0425 - acc: 0.2747 - val_loss: 1.9132 - val_acc: 0.3169\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0037 - acc: 0.2913 - val_loss: 1.8857 - val_acc: 0.3302\n",
      "Epoch 5/15\n",
      "19s - loss: 1.9633 - acc: 0.3064 - val_loss: 1.8801 - val_acc: 0.3358\n",
      "Epoch 6/15\n",
      "19s - loss: 1.9464 - acc: 0.3121 - val_loss: 1.8684 - val_acc: 0.3392\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9181 - acc: 0.3197 - val_loss: 1.8566 - val_acc: 0.3375\n",
      "Epoch 8/15\n",
      "19s - loss: 1.8991 - acc: 0.3273 - val_loss: 1.8568 - val_acc: 0.3379\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8888 - acc: 0.3301 - val_loss: 1.8570 - val_acc: 0.3418\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8664 - acc: 0.3383 - val_loss: 1.8660 - val_acc: 0.3358\n",
      "Epoch 11/15\n",
      "19s - loss: 1.8572 - acc: 0.3400 - val_loss: 1.8566 - val_acc: 0.3349\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8416 - acc: 0.3445 - val_loss: 1.8603 - val_acc: 0.3358\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8253 - acc: 0.3533 - val_loss: 1.8586 - val_acc: 0.3431\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8096 - acc: 0.3584 - val_loss: 1.8693 - val_acc: 0.3409\n",
      "Epoch 15/15\n",
      "20s - loss: 1.8004 - acc: 0.3600 - val_loss: 1.8736 - val_acc: 0.3392\n",
      "logloss val 1.8736062197774022\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3529 - acc: 0.1612 - val_loss: 2.1437 - val_acc: 0.2598\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1228 - acc: 0.2478 - val_loss: 1.9571 - val_acc: 0.2993\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0475 - acc: 0.2730 - val_loss: 1.9100 - val_acc: 0.3216\n",
      "Epoch 4/15\n",
      "20s - loss: 2.0009 - acc: 0.2932 - val_loss: 1.8895 - val_acc: 0.3259\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9665 - acc: 0.3094 - val_loss: 1.8728 - val_acc: 0.3323\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9422 - acc: 0.3149 - val_loss: 1.8617 - val_acc: 0.3396\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9243 - acc: 0.3220 - val_loss: 1.8585 - val_acc: 0.3323\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8981 - acc: 0.3311 - val_loss: 1.8532 - val_acc: 0.3413\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8859 - acc: 0.3310 - val_loss: 1.8590 - val_acc: 0.3409\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8707 - acc: 0.3372 - val_loss: 1.8531 - val_acc: 0.3345\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8534 - acc: 0.3435 - val_loss: 1.8574 - val_acc: 0.3336\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8400 - acc: 0.3505 - val_loss: 1.8543 - val_acc: 0.3358\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8295 - acc: 0.3536 - val_loss: 1.8572 - val_acc: 0.3375\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8122 - acc: 0.3595 - val_loss: 1.8644 - val_acc: 0.3319\n",
      "Epoch 15/15\n",
      "20s - loss: 1.8036 - acc: 0.3642 - val_loss: 1.8668 - val_acc: 0.3345\n",
      "logloss val 1.8667653348284772\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3488 - acc: 0.1661 - val_loss: 2.1292 - val_acc: 0.2487\n",
      "Epoch 2/15\n",
      "19s - loss: 2.1151 - acc: 0.2471 - val_loss: 1.9753 - val_acc: 0.3015\n",
      "Epoch 3/15\n",
      "20s - loss: 2.0383 - acc: 0.2780 - val_loss: 1.9476 - val_acc: 0.3187\n",
      "Epoch 4/15\n",
      "20s - loss: 1.9929 - acc: 0.2977 - val_loss: 1.9045 - val_acc: 0.3299\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9663 - acc: 0.3062 - val_loss: 1.9083 - val_acc: 0.3217\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9420 - acc: 0.3146 - val_loss: 1.8860 - val_acc: 0.3316\n",
      "Epoch 7/15\n",
      "20s - loss: 1.9204 - acc: 0.3215 - val_loss: 1.9010 - val_acc: 0.3260\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9026 - acc: 0.3268 - val_loss: 1.8797 - val_acc: 0.3320\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8837 - acc: 0.3335 - val_loss: 1.8781 - val_acc: 0.3346\n",
      "Epoch 10/15\n",
      "19s - loss: 1.8627 - acc: 0.3362 - val_loss: 1.8967 - val_acc: 0.3252\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8558 - acc: 0.3396 - val_loss: 1.8869 - val_acc: 0.3320\n",
      "Epoch 12/15\n",
      "20s - loss: 1.8357 - acc: 0.3453 - val_loss: 1.8833 - val_acc: 0.3342\n",
      "Epoch 13/15\n",
      "19s - loss: 1.8256 - acc: 0.3511 - val_loss: 1.8900 - val_acc: 0.3368\n",
      "Epoch 14/15\n",
      "20s - loss: 1.8087 - acc: 0.3573 - val_loss: 1.9007 - val_acc: 0.3320\n",
      "Epoch 15/15\n",
      "19s - loss: 1.7940 - acc: 0.3584 - val_loss: 1.9054 - val_acc: 0.3419\n",
      "logloss val 1.9054482386737177\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "24s - loss: 2.3389 - acc: 0.1713 - val_loss: 2.1415 - val_acc: 0.2502\n",
      "Epoch 2/15\n",
      "20s - loss: 2.1100 - acc: 0.2517 - val_loss: 2.0301 - val_acc: 0.2846\n",
      "Epoch 3/15\n",
      "19s - loss: 2.0368 - acc: 0.2784 - val_loss: 1.9793 - val_acc: 0.2936\n",
      "Epoch 4/15\n",
      "19s - loss: 1.9879 - acc: 0.2951 - val_loss: 1.9753 - val_acc: 0.2949\n",
      "Epoch 5/15\n",
      "20s - loss: 1.9606 - acc: 0.3065 - val_loss: 1.9824 - val_acc: 0.2954\n",
      "Epoch 6/15\n",
      "20s - loss: 1.9371 - acc: 0.3140 - val_loss: 1.9619 - val_acc: 0.3061\n",
      "Epoch 7/15\n",
      "19s - loss: 1.9137 - acc: 0.3239 - val_loss: 1.9556 - val_acc: 0.3121\n",
      "Epoch 8/15\n",
      "20s - loss: 1.8956 - acc: 0.3301 - val_loss: 1.9522 - val_acc: 0.3048\n",
      "Epoch 9/15\n",
      "20s - loss: 1.8778 - acc: 0.3356 - val_loss: 1.9420 - val_acc: 0.3074\n",
      "Epoch 10/15\n",
      "20s - loss: 1.8601 - acc: 0.3427 - val_loss: 1.9772 - val_acc: 0.3035\n",
      "Epoch 11/15\n",
      "20s - loss: 1.8436 - acc: 0.3483 - val_loss: 1.9633 - val_acc: 0.3083\n",
      "Epoch 12/15\n",
      "19s - loss: 1.8324 - acc: 0.3514 - val_loss: 1.9791 - val_acc: 0.3014\n",
      "Epoch 13/15\n",
      "20s - loss: 1.8228 - acc: 0.3566 - val_loss: 1.9593 - val_acc: 0.3121\n",
      "Epoch 14/15\n",
      "19s - loss: 1.8014 - acc: 0.3631 - val_loss: 1.9911 - val_acc: 0.3087\n",
      "Epoch 15/15\n",
      "20s - loss: 1.7965 - acc: 0.3629 - val_loss: 1.9860 - val_acc: 0.3087\n",
      "logloss val 1.9859629007358632\n",
      "average logloss val 2.0421174577182084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py:1403: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    }
   ],
   "source": [
    "def with_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, input_dim=X_dim_input, init='normal', activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(150, input_dim=X_dim_input, init='normal', activation='tanh'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "\n",
    "dummy_y_with = np_utils.to_categorical(y_train_total_with)\n",
    "for i in range(8):\n",
    "    kf = StratifiedKFold(y_train_total_with,n_folds = 10,random_state = i)\n",
    "    score_list_with=[]\n",
    "    val_loss_list_with = []\n",
    "    for index,(train, test) in enumerate(kf):\n",
    "        X_train_with = X_train_total_with[train]\n",
    "        y_train_with = dummy_y_with[train]\n",
    "        X_val_with = X_train_total_with[test]\n",
    "        y_val_with = dummy_y_with[test]\n",
    "        #print(X_val.shape)\n",
    "        print('*****************************************************')\n",
    "        print('{}_fold'.format(index))\n",
    "        model=with_model(X_train_total_with.shape[1])\n",
    "        fit= model.fit_generator(generator=batch_generator(X_train_with, y_train_with, 256, True),\n",
    "                             nb_epoch=15,\n",
    "                             samples_per_epoch=40000,\n",
    "                             validation_data=(X_val_with.todense(), y_val_with), verbose=2\n",
    "                             )\n",
    "        scores_val_with = model.predict_generator(generator=batch_generatorp(X_val_with, 32, False), \n",
    "                                             val_samples=X_val_with.shape[0])\n",
    "        scores_with = model.predict_generator(generator=batch_generatorp(X_test_total_with, 32, False), \n",
    "                                         val_samples=X_test_total_with.shape[0])\n",
    "        score_list_with.append(scores_with)\n",
    "        val_loss = log_loss(y_val_with, scores_val_with)\n",
    "        val_loss_list_with.append(val_loss)\n",
    "        print('logloss val {}'.format(val_loss))\n",
    "\n",
    "    for index,i in enumerate(val_loss_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    val_loss_ave_with = sumi/len(val_loss_list_with)\n",
    "    print('average logloss val {}'.format(val_loss_ave_with))\n",
    "    for index,i in enumerate(score_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    score_ave_with = sumi/len(score_list_with)\n",
    "    pred_with = pd.DataFrame(score_ave_with, index = gender_age_test_with.index, columns=targetencoder.classes_)\n",
    "    pred_with.to_csv('nnet_with_50tanh_150tanh_100relu_softmax{}.csv'.format(val_loss_ave_with))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.43406\ttest-mlogloss:2.46504\n",
      "[1]\ttrain-mlogloss:2.38551\ttest-mlogloss:2.4472\n",
      "[2]\ttrain-mlogloss:2.33908\ttest-mlogloss:2.43083\n",
      "[3]\ttrain-mlogloss:2.29459\ttest-mlogloss:2.41487\n",
      "[4]\ttrain-mlogloss:2.25142\ttest-mlogloss:2.40019\n",
      "[5]\ttrain-mlogloss:2.21016\ttest-mlogloss:2.38692\n",
      "[6]\ttrain-mlogloss:2.17004\ttest-mlogloss:2.3736\n",
      "[7]\ttrain-mlogloss:2.13185\ttest-mlogloss:2.36154\n",
      "[8]\ttrain-mlogloss:2.09429\ttest-mlogloss:2.35047\n",
      "[9]\ttrain-mlogloss:2.05819\ttest-mlogloss:2.33931\n",
      "[10]\ttrain-mlogloss:2.02275\ttest-mlogloss:2.32907\n",
      "[11]\ttrain-mlogloss:1.98903\ttest-mlogloss:2.31983\n",
      "[12]\ttrain-mlogloss:1.95605\ttest-mlogloss:2.31087\n",
      "[13]\ttrain-mlogloss:1.9236\ttest-mlogloss:2.30211\n",
      "[14]\ttrain-mlogloss:1.89199\ttest-mlogloss:2.29334\n",
      "[15]\ttrain-mlogloss:1.86148\ttest-mlogloss:2.28565\n",
      "[16]\ttrain-mlogloss:1.83177\ttest-mlogloss:2.27869\n",
      "[17]\ttrain-mlogloss:1.80266\ttest-mlogloss:2.2718\n",
      "[18]\ttrain-mlogloss:1.77412\ttest-mlogloss:2.2645\n",
      "[19]\ttrain-mlogloss:1.74637\ttest-mlogloss:2.25779\n",
      "[20]\ttrain-mlogloss:1.71946\ttest-mlogloss:2.25144\n",
      "[21]\ttrain-mlogloss:1.69316\ttest-mlogloss:2.24532\n",
      "[22]\ttrain-mlogloss:1.66705\ttest-mlogloss:2.23913\n",
      "[23]\ttrain-mlogloss:1.64166\ttest-mlogloss:2.23339\n",
      "[24]\ttrain-mlogloss:1.61656\ttest-mlogloss:2.22772\n",
      "[25]\ttrain-mlogloss:1.59249\ttest-mlogloss:2.22269\n",
      "[26]\ttrain-mlogloss:1.56881\ttest-mlogloss:2.21775\n",
      "[27]\ttrain-mlogloss:1.54563\ttest-mlogloss:2.21296\n",
      "[28]\ttrain-mlogloss:1.52288\ttest-mlogloss:2.20816\n",
      "[29]\ttrain-mlogloss:1.50076\ttest-mlogloss:2.20343\n",
      "[30]\ttrain-mlogloss:1.47887\ttest-mlogloss:2.19898\n",
      "[31]\ttrain-mlogloss:1.45761\ttest-mlogloss:2.19476\n",
      "[32]\ttrain-mlogloss:1.43691\ttest-mlogloss:2.19123\n",
      "[33]\ttrain-mlogloss:1.41675\ttest-mlogloss:2.18745\n",
      "[34]\ttrain-mlogloss:1.39689\ttest-mlogloss:2.18388\n",
      "[35]\ttrain-mlogloss:1.37728\ttest-mlogloss:2.18086\n",
      "[36]\ttrain-mlogloss:1.35774\ttest-mlogloss:2.17724\n",
      "[37]\ttrain-mlogloss:1.33881\ttest-mlogloss:2.1738\n",
      "[38]\ttrain-mlogloss:1.3199\ttest-mlogloss:2.17017\n",
      "[39]\ttrain-mlogloss:1.3015\ttest-mlogloss:2.16668\n",
      "[40]\ttrain-mlogloss:1.28355\ttest-mlogloss:2.16356\n",
      "[41]\ttrain-mlogloss:1.26587\ttest-mlogloss:2.16074\n",
      "[42]\ttrain-mlogloss:1.24863\ttest-mlogloss:2.15816\n",
      "[43]\ttrain-mlogloss:1.23164\ttest-mlogloss:2.1553\n",
      "[44]\ttrain-mlogloss:1.2148\ttest-mlogloss:2.15223\n",
      "[45]\ttrain-mlogloss:1.19846\ttest-mlogloss:2.14918\n",
      "[46]\ttrain-mlogloss:1.18221\ttest-mlogloss:2.14708\n",
      "[47]\ttrain-mlogloss:1.16635\ttest-mlogloss:2.14463\n",
      "[48]\ttrain-mlogloss:1.15088\ttest-mlogloss:2.14234\n",
      "[49]\ttrain-mlogloss:1.13571\ttest-mlogloss:2.14032\n",
      "[50]\ttrain-mlogloss:1.12074\ttest-mlogloss:2.13831\n",
      "[51]\ttrain-mlogloss:1.10598\ttest-mlogloss:2.1362\n",
      "[52]\ttrain-mlogloss:1.09155\ttest-mlogloss:2.13416\n",
      "[53]\ttrain-mlogloss:1.07737\ttest-mlogloss:2.13234\n",
      "[54]\ttrain-mlogloss:1.06341\ttest-mlogloss:2.13022\n",
      "[55]\ttrain-mlogloss:1.0498\ttest-mlogloss:2.12821\n",
      "[56]\ttrain-mlogloss:1.0363\ttest-mlogloss:2.12649\n",
      "[57]\ttrain-mlogloss:1.02314\ttest-mlogloss:2.12489\n",
      "[58]\ttrain-mlogloss:1.01008\ttest-mlogloss:2.12322\n",
      "[59]\ttrain-mlogloss:0.997277\ttest-mlogloss:2.1218\n",
      "[60]\ttrain-mlogloss:0.984693\ttest-mlogloss:2.12011\n",
      "[61]\ttrain-mlogloss:0.972358\ttest-mlogloss:2.11874\n",
      "[62]\ttrain-mlogloss:0.960269\ttest-mlogloss:2.11716\n",
      "[63]\ttrain-mlogloss:0.948314\ttest-mlogloss:2.11586\n",
      "[64]\ttrain-mlogloss:0.936614\ttest-mlogloss:2.11393\n",
      "[65]\ttrain-mlogloss:0.924983\ttest-mlogloss:2.11262\n",
      "[66]\ttrain-mlogloss:0.913555\ttest-mlogloss:2.11116\n",
      "[67]\ttrain-mlogloss:0.902406\ttest-mlogloss:2.10958\n",
      "[68]\ttrain-mlogloss:0.891439\ttest-mlogloss:2.10818\n",
      "[69]\ttrain-mlogloss:0.880831\ttest-mlogloss:2.10672\n",
      "[70]\ttrain-mlogloss:0.870209\ttest-mlogloss:2.10525\n",
      "[71]\ttrain-mlogloss:0.859805\ttest-mlogloss:2.10403\n",
      "[72]\ttrain-mlogloss:0.849599\ttest-mlogloss:2.10284\n",
      "[73]\ttrain-mlogloss:0.839562\ttest-mlogloss:2.10181\n",
      "[74]\ttrain-mlogloss:0.8297\ttest-mlogloss:2.10072\n",
      "[75]\ttrain-mlogloss:0.81988\ttest-mlogloss:2.09978\n",
      "[76]\ttrain-mlogloss:0.810225\ttest-mlogloss:2.09862\n",
      "[77]\ttrain-mlogloss:0.800748\ttest-mlogloss:2.09787\n",
      "[78]\ttrain-mlogloss:0.791536\ttest-mlogloss:2.09696\n",
      "[79]\ttrain-mlogloss:0.782433\ttest-mlogloss:2.09612\n",
      "[80]\ttrain-mlogloss:0.773493\ttest-mlogloss:2.0954\n",
      "[81]\ttrain-mlogloss:0.764664\ttest-mlogloss:2.09441\n",
      "[82]\ttrain-mlogloss:0.756008\ttest-mlogloss:2.09354\n",
      "[83]\ttrain-mlogloss:0.747516\ttest-mlogloss:2.09296\n",
      "[84]\ttrain-mlogloss:0.73909\ttest-mlogloss:2.09208\n",
      "[85]\ttrain-mlogloss:0.73096\ttest-mlogloss:2.09105\n",
      "[86]\ttrain-mlogloss:0.722787\ttest-mlogloss:2.09002\n",
      "[87]\ttrain-mlogloss:0.714805\ttest-mlogloss:2.08899\n",
      "[88]\ttrain-mlogloss:0.706949\ttest-mlogloss:2.08816\n",
      "[89]\ttrain-mlogloss:0.69924\ttest-mlogloss:2.08702\n",
      "[90]\ttrain-mlogloss:0.691511\ttest-mlogloss:2.08623\n",
      "[91]\ttrain-mlogloss:0.684002\ttest-mlogloss:2.08568\n",
      "[92]\ttrain-mlogloss:0.676539\ttest-mlogloss:2.08507\n",
      "[93]\ttrain-mlogloss:0.669244\ttest-mlogloss:2.08446\n",
      "[94]\ttrain-mlogloss:0.662094\ttest-mlogloss:2.0838\n",
      "[95]\ttrain-mlogloss:0.65505\ttest-mlogloss:2.08301\n",
      "[96]\ttrain-mlogloss:0.648153\ttest-mlogloss:2.08237\n",
      "[97]\ttrain-mlogloss:0.641409\ttest-mlogloss:2.08175\n",
      "[98]\ttrain-mlogloss:0.634628\ttest-mlogloss:2.08096\n",
      "[99]\ttrain-mlogloss:0.628068\ttest-mlogloss:2.08033\n",
      "[100]\ttrain-mlogloss:0.621566\ttest-mlogloss:2.07969\n",
      "[101]\ttrain-mlogloss:0.615098\ttest-mlogloss:2.07916\n",
      "[102]\ttrain-mlogloss:0.608778\ttest-mlogloss:2.07864\n",
      "[103]\ttrain-mlogloss:0.602553\ttest-mlogloss:2.07801\n",
      "[104]\ttrain-mlogloss:0.596422\ttest-mlogloss:2.07735\n",
      "[105]\ttrain-mlogloss:0.590451\ttest-mlogloss:2.07677\n",
      "[106]\ttrain-mlogloss:0.584524\ttest-mlogloss:2.07615\n",
      "[107]\ttrain-mlogloss:0.578677\ttest-mlogloss:2.07573\n",
      "[108]\ttrain-mlogloss:0.572874\ttest-mlogloss:2.07541\n",
      "[109]\ttrain-mlogloss:0.567188\ttest-mlogloss:2.07495\n",
      "[110]\ttrain-mlogloss:0.561501\ttest-mlogloss:2.07438\n",
      "[111]\ttrain-mlogloss:0.55603\ttest-mlogloss:2.07405\n",
      "[112]\ttrain-mlogloss:0.55065\ttest-mlogloss:2.07337\n",
      "[113]\ttrain-mlogloss:0.545285\ttest-mlogloss:2.07293\n",
      "[114]\ttrain-mlogloss:0.540012\ttest-mlogloss:2.07253\n",
      "[115]\ttrain-mlogloss:0.534826\ttest-mlogloss:2.07226\n",
      "[116]\ttrain-mlogloss:0.52976\ttest-mlogloss:2.07204\n",
      "[117]\ttrain-mlogloss:0.524734\ttest-mlogloss:2.07163\n",
      "[118]\ttrain-mlogloss:0.519772\ttest-mlogloss:2.07102\n",
      "[119]\ttrain-mlogloss:0.51476\ttest-mlogloss:2.07051\n",
      "[120]\ttrain-mlogloss:0.510043\ttest-mlogloss:2.07025\n",
      "[121]\ttrain-mlogloss:0.50528\ttest-mlogloss:2.07007\n",
      "[122]\ttrain-mlogloss:0.500652\ttest-mlogloss:2.0697\n",
      "[123]\ttrain-mlogloss:0.496015\ttest-mlogloss:2.06935\n",
      "[124]\ttrain-mlogloss:0.49152\ttest-mlogloss:2.06928\n",
      "[125]\ttrain-mlogloss:0.487095\ttest-mlogloss:2.06896\n",
      "[126]\ttrain-mlogloss:0.482646\ttest-mlogloss:2.06872\n",
      "[127]\ttrain-mlogloss:0.478309\ttest-mlogloss:2.06845\n",
      "[128]\ttrain-mlogloss:0.474046\ttest-mlogloss:2.06821\n",
      "[129]\ttrain-mlogloss:0.469837\ttest-mlogloss:2.06808\n",
      "[130]\ttrain-mlogloss:0.46571\ttest-mlogloss:2.0679\n",
      "[131]\ttrain-mlogloss:0.46162\ttest-mlogloss:2.06778\n",
      "[132]\ttrain-mlogloss:0.457545\ttest-mlogloss:2.0677\n",
      "[133]\ttrain-mlogloss:0.453573\ttest-mlogloss:2.06743\n",
      "[134]\ttrain-mlogloss:0.449652\ttest-mlogloss:2.06727\n",
      "[135]\ttrain-mlogloss:0.445795\ttest-mlogloss:2.06718\n",
      "[136]\ttrain-mlogloss:0.441994\ttest-mlogloss:2.06702\n",
      "[137]\ttrain-mlogloss:0.438302\ttest-mlogloss:2.06694\n",
      "[138]\ttrain-mlogloss:0.434532\ttest-mlogloss:2.06685\n",
      "[139]\ttrain-mlogloss:0.430824\ttest-mlogloss:2.06681\n",
      "[140]\ttrain-mlogloss:0.427187\ttest-mlogloss:2.06677\n",
      "[141]\ttrain-mlogloss:0.423674\ttest-mlogloss:2.06659\n",
      "[142]\ttrain-mlogloss:0.420169\ttest-mlogloss:2.06656\n",
      "[143]\ttrain-mlogloss:0.416722\ttest-mlogloss:2.06626\n",
      "[144]\ttrain-mlogloss:0.413323\ttest-mlogloss:2.06618\n",
      "[145]\ttrain-mlogloss:0.40996\ttest-mlogloss:2.06611\n",
      "[146]\ttrain-mlogloss:0.406596\ttest-mlogloss:2.06597\n",
      "[147]\ttrain-mlogloss:0.403329\ttest-mlogloss:2.06575\n",
      "[148]\ttrain-mlogloss:0.400084\ttest-mlogloss:2.06546\n",
      "[149]\ttrain-mlogloss:0.39692\ttest-mlogloss:2.06532\n",
      "[150]\ttrain-mlogloss:0.393813\ttest-mlogloss:2.06502\n",
      "[151]\ttrain-mlogloss:0.390773\ttest-mlogloss:2.06488\n",
      "[152]\ttrain-mlogloss:0.387718\ttest-mlogloss:2.0649\n",
      "[153]\ttrain-mlogloss:0.384682\ttest-mlogloss:2.06456\n",
      "[154]\ttrain-mlogloss:0.381744\ttest-mlogloss:2.06459\n",
      "[155]\ttrain-mlogloss:0.378859\ttest-mlogloss:2.06447\n",
      "[156]\ttrain-mlogloss:0.375913\ttest-mlogloss:2.06425\n",
      "[157]\ttrain-mlogloss:0.37307\ttest-mlogloss:2.06399\n",
      "[158]\ttrain-mlogloss:0.37026\ttest-mlogloss:2.06391\n",
      "[159]\ttrain-mlogloss:0.367492\ttest-mlogloss:2.06375\n",
      "[160]\ttrain-mlogloss:0.364768\ttest-mlogloss:2.06348\n",
      "[161]\ttrain-mlogloss:0.362109\ttest-mlogloss:2.06345\n",
      "[162]\ttrain-mlogloss:0.359474\ttest-mlogloss:2.0634\n",
      "[163]\ttrain-mlogloss:0.356869\ttest-mlogloss:2.06336\n",
      "[164]\ttrain-mlogloss:0.354227\ttest-mlogloss:2.06301\n",
      "[165]\ttrain-mlogloss:0.351641\ttest-mlogloss:2.06287\n",
      "[166]\ttrain-mlogloss:0.349111\ttest-mlogloss:2.06281\n",
      "[167]\ttrain-mlogloss:0.346648\ttest-mlogloss:2.06279\n",
      "[168]\ttrain-mlogloss:0.344204\ttest-mlogloss:2.06273\n",
      "[169]\ttrain-mlogloss:0.341724\ttest-mlogloss:2.06268\n",
      "[170]\ttrain-mlogloss:0.339289\ttest-mlogloss:2.06281\n",
      "[171]\ttrain-mlogloss:0.336902\ttest-mlogloss:2.06266\n",
      "[172]\ttrain-mlogloss:0.334523\ttest-mlogloss:2.06268\n",
      "[173]\ttrain-mlogloss:0.332175\ttest-mlogloss:2.06254\n",
      "[174]\ttrain-mlogloss:0.329889\ttest-mlogloss:2.06251\n",
      "[175]\ttrain-mlogloss:0.32761\ttest-mlogloss:2.06254\n",
      "[176]\ttrain-mlogloss:0.325377\ttest-mlogloss:2.06266\n",
      "[177]\ttrain-mlogloss:0.323166\ttest-mlogloss:2.06257\n",
      "[178]\ttrain-mlogloss:0.320974\ttest-mlogloss:2.06268\n",
      "[179]\ttrain-mlogloss:0.318808\ttest-mlogloss:2.0627\n",
      "[180]\ttrain-mlogloss:0.316672\ttest-mlogloss:2.063\n",
      "[181]\ttrain-mlogloss:0.314586\ttest-mlogloss:2.06299\n",
      "[182]\ttrain-mlogloss:0.312499\ttest-mlogloss:2.0631\n",
      "[183]\ttrain-mlogloss:0.310468\ttest-mlogloss:2.06331\n",
      "[184]\ttrain-mlogloss:0.30845\ttest-mlogloss:2.06324\n",
      "[185]\ttrain-mlogloss:0.306466\ttest-mlogloss:2.06326\n",
      "[186]\ttrain-mlogloss:0.304503\ttest-mlogloss:2.06327\n",
      "[187]\ttrain-mlogloss:0.302544\ttest-mlogloss:2.06317\n",
      "[188]\ttrain-mlogloss:0.300619\ttest-mlogloss:2.06339\n",
      "[189]\ttrain-mlogloss:0.298702\ttest-mlogloss:2.06342\n",
      "[190]\ttrain-mlogloss:0.296832\ttest-mlogloss:2.06344\n",
      "[191]\ttrain-mlogloss:0.294959\ttest-mlogloss:2.06332\n",
      "[192]\ttrain-mlogloss:0.293156\ttest-mlogloss:2.06348\n",
      "[193]\ttrain-mlogloss:0.291319\ttest-mlogloss:2.06346\n",
      "[194]\ttrain-mlogloss:0.289521\ttest-mlogloss:2.06351\n",
      "[195]\ttrain-mlogloss:0.287751\ttest-mlogloss:2.06351\n",
      "[196]\ttrain-mlogloss:0.285992\ttest-mlogloss:2.06366\n",
      "[197]\ttrain-mlogloss:0.284273\ttest-mlogloss:2.06376\n",
      "[198]\ttrain-mlogloss:0.282548\ttest-mlogloss:2.06379\n",
      "[199]\ttrain-mlogloss:0.280839\ttest-mlogloss:2.0637\n",
      "logloss val 2.0636953264339026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_with)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':2000,\n",
    "         'eta':0.05,\n",
    "         'silent':0,\n",
    "         'objective':'multi:softprob',\n",
    "         'nthread':2,\n",
    "         'num_class':12,\n",
    "         'eval_metric':'mlogloss',\n",
    "        'lambda':5,\n",
    "        'lambda_bias':0,\n",
    "        'alpha':2}\n",
    "num_round = 200\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training with all data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(X_train_total_with,label = y_train_total_with)\n",
    "xg_test = xgb.DMatrix(X_test_total_with)\n",
    "bst = xgb.train(param,xg_train,num_round)\n",
    "yprob = bst.predict(xg_test).reshape(X_test_total_with.shape[0],12)\n",
    "pred_with_xgb = pd.DataFrame(yprob, \n",
    "                            index = gender_age_test_with.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_with_xgb.to_csv('xgb_with_result{}.csv'.format(val_loss))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0180472176683\n",
      "newton-cg\n",
      "1.99455721395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_with)\n",
    "#lr grid search\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['newton-cg']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_without= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.0180472176683,multi_class='multinomial',solver='newton-cg')\n",
    "lr.fit(X_train_total_with,y_train_total_with)\n",
    "score_ave_with_lr = lr.predict_proba(X_test_total_with)\n",
    "pred_with_lr = pd.DataFrame(score_ave_with_lr, \n",
    "                            index = gender_age_test_with.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_with_lr.to_csv('lr_with_result{}.csv'.format(val_loss_ave_with))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset II: device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_total_without = targetencoder.transform(gender_age_train_without_temp.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Device without eventsI: Naive Bayes, Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204.50354026\n",
      "2.42330723892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#NB grid search\n",
    "nbc = MultinomialNB()\n",
    "alpha_value = np.logspace(-3,4,100)\n",
    "clf = GridSearchCV(estimator=nbc,param_grid = dict(alpha=alpha_value),scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.alpha)\n",
    "print(-clf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0744380301325\n",
      "lbfgs\n",
      "2.39019928895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#lr grid search\n",
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_without)\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['lbfgs']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_without= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_without)\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(C=0.02,multi_class='multinomial',solver='newton-cg')\n",
    "lr = LogisticRegression(C=0.0744380301325,multi_class='multinomial',solver='lbfgs')\n",
    "lr.fit(X_train_total_without,y_train_total_without)\n",
    "score_ave_without_lr = lr.predict_proba(X_test_total_without)\n",
    "pred_without_lr = pd.DataFrame(score_ave_without_lr, \n",
    "                            index = gender_age_test_without.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_without_lr.to_csv('lr_without_result{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\\nscore_list_without=[]\\nval_loss_list_without = []\\nfor index,(train, test) in enumerate(kf):\\n    X_train_without = X_train_total_without[train]\\n    y_train_without = y_train_total_without[train]\\n    X_val_without = X_train_total_without[test]\\n    y_val_without = y_train_total_without[test]\\n    print('*****************************************************')\\n    print('{}_fold'.format(index))\\n    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\\n    lr.fit(X_train_without,y_train_without)\\n    scores_val_without = lr.predict_proba(X_val_without)\\n    val_loss = log_loss(y_val_without, scores_val_without)\\n    val_loss_list_without.append(val_loss)\\n    print('logloss val {}'.format(val_loss))\\n    \\n    scores_without = lr.predict_proba(X_test_total_without)\\n    score_list_without.append(scores_without)\\n    \\nfor index,i in enumerate(val_loss_list_without):\\n    if(index==0):\\n        sumi = i\\n    else:\\n        sumi = i+sumi\\nval_loss_ave_without = sumi/len(score_list_without)\\nprint('average logloss val {}'.format(val_loss_ave_without))\\nfor index,i in enumerate(score_list_without):\\n    if(index==0):\\n        sumi = i\\n    else:\\n        sumi = i+sumi\\nscore_ave_without = sumi/len(score_list_without)\\npred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\n",
    "score_list_without=[]\n",
    "val_loss_list_without = []\n",
    "for index,(train, test) in enumerate(kf):\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = y_train_total_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = y_train_total_without[test]\n",
    "    print('*****************************************************')\n",
    "    print('{}_fold'.format(index))\n",
    "    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\n",
    "    lr.fit(X_train_without,y_train_without)\n",
    "    scores_val_without = lr.predict_proba(X_val_without)\n",
    "    val_loss = log_loss(y_val_without, scores_val_without)\n",
    "    val_loss_list_without.append(val_loss)\n",
    "    print('logloss val {}'.format(val_loss))\n",
    "    \n",
    "    scores_without = lr.predict_proba(X_test_total_without)\n",
    "    score_list_without.append(scores_without)\n",
    "    \n",
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(score_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without eventsII: Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/keras/engine/training.py:1460: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 2.4629 - acc: 0.1261 - val_loss: 2.4279 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4256 - acc: 0.1298 - val_loss: 2.4264 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4268 - acc: 0.1271 - val_loss: 2.4253 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4219 - acc: 0.1285 - val_loss: 2.4250 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4209 - acc: 0.1289 - val_loss: 2.4248 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4194 - acc: 0.1308 - val_loss: 2.4247 - val_acc: 0.1293\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4163 - acc: 0.1341 - val_loss: 2.4246 - val_acc: 0.1342\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4120 - acc: 0.1401 - val_loss: 2.4236 - val_acc: 0.1407\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4066 - acc: 0.1465 - val_loss: 2.4183 - val_acc: 0.1399\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4017 - acc: 0.1440 - val_loss: 2.4161 - val_acc: 0.1390\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3980 - acc: 0.1443 - val_loss: 2.4128 - val_acc: 0.1402\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3968 - acc: 0.1431 - val_loss: 2.4130 - val_acc: 0.1431\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3945 - acc: 0.1450 - val_loss: 2.4107 - val_acc: 0.1453\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3915 - acc: 0.1491 - val_loss: 2.4097 - val_acc: 0.1513\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3920 - acc: 0.1489 - val_loss: 2.4081 - val_acc: 0.1512\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3887 - acc: 0.1519 - val_loss: 2.4084 - val_acc: 0.1494\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3877 - acc: 0.1501 - val_loss: 2.4071 - val_acc: 0.1504\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3863 - acc: 0.1521 - val_loss: 2.4079 - val_acc: 0.1512\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3848 - acc: 0.1529 - val_loss: 2.4072 - val_acc: 0.1474\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3841 - acc: 0.1529 - val_loss: 2.4065 - val_acc: 0.1505\n",
      "logloss val 2.406513364236188\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4639 - acc: 0.1261 - val_loss: 2.4276 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4269 - acc: 0.1280 - val_loss: 2.4253 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4235 - acc: 0.1282 - val_loss: 2.4235 - val_acc: 0.1294\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4233 - acc: 0.1288 - val_loss: 2.4219 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4215 - acc: 0.1292 - val_loss: 2.4213 - val_acc: 0.1284\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4191 - acc: 0.1310 - val_loss: 2.4207 - val_acc: 0.1307\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4194 - acc: 0.1319 - val_loss: 2.4199 - val_acc: 0.1291\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4168 - acc: 0.1325 - val_loss: 2.4193 - val_acc: 0.1288\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4157 - acc: 0.1368 - val_loss: 2.4172 - val_acc: 0.1390\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4109 - acc: 0.1394 - val_loss: 2.4134 - val_acc: 0.1433\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4066 - acc: 0.1433 - val_loss: 2.4080 - val_acc: 0.1409\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4021 - acc: 0.1423 - val_loss: 2.4046 - val_acc: 0.1404\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3983 - acc: 0.1427 - val_loss: 2.4025 - val_acc: 0.1430\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3971 - acc: 0.1440 - val_loss: 2.4006 - val_acc: 0.1422\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3950 - acc: 0.1449 - val_loss: 2.3994 - val_acc: 0.1450\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3940 - acc: 0.1443 - val_loss: 2.3985 - val_acc: 0.1466\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3909 - acc: 0.1476 - val_loss: 2.3975 - val_acc: 0.1476\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3900 - acc: 0.1493 - val_loss: 2.3972 - val_acc: 0.1466\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3893 - acc: 0.1504 - val_loss: 2.3964 - val_acc: 0.1487\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3877 - acc: 0.1511 - val_loss: 2.3967 - val_acc: 0.1503\n",
      "logloss val 2.39665597203874\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4605 - acc: 0.1268 - val_loss: 2.4274 - val_acc: 0.1288\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4270 - acc: 0.1277 - val_loss: 2.4252 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4254 - acc: 0.1285 - val_loss: 2.4232 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4227 - acc: 0.1284 - val_loss: 2.4213 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4207 - acc: 0.1298 - val_loss: 2.4198 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4200 - acc: 0.1318 - val_loss: 2.4190 - val_acc: 0.1303\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4186 - acc: 0.1370 - val_loss: 2.4176 - val_acc: 0.1375\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4135 - acc: 0.1423 - val_loss: 2.4145 - val_acc: 0.1420\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4095 - acc: 0.1416 - val_loss: 2.4083 - val_acc: 0.1405\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4025 - acc: 0.1427 - val_loss: 2.4046 - val_acc: 0.1442\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3983 - acc: 0.1449 - val_loss: 2.4027 - val_acc: 0.1428\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3971 - acc: 0.1445 - val_loss: 2.4010 - val_acc: 0.1445\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3941 - acc: 0.1463 - val_loss: 2.3999 - val_acc: 0.1469\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3943 - acc: 0.1479 - val_loss: 2.3990 - val_acc: 0.1493\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3914 - acc: 0.1476 - val_loss: 2.3987 - val_acc: 0.1537\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3908 - acc: 0.1482 - val_loss: 2.3983 - val_acc: 0.1568\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3881 - acc: 0.1507 - val_loss: 2.3975 - val_acc: 0.1578\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3862 - acc: 0.1529 - val_loss: 2.3976 - val_acc: 0.1578\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3870 - acc: 0.1520 - val_loss: 2.3976 - val_acc: 0.1537\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3850 - acc: 0.1533 - val_loss: 2.3979 - val_acc: 0.1543\n",
      "logloss val 2.3978786770719847\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "3s - loss: 2.4695 - acc: 0.1253 - val_loss: 2.4306 - val_acc: 0.1298\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4272 - acc: 0.1294 - val_loss: 2.4265 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4256 - acc: 0.1278 - val_loss: 2.4249 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4236 - acc: 0.1291 - val_loss: 2.4235 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4209 - acc: 0.1278 - val_loss: 2.4225 - val_acc: 0.1354\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4202 - acc: 0.1300 - val_loss: 2.4214 - val_acc: 0.1302\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4191 - acc: 0.1320 - val_loss: 2.4209 - val_acc: 0.1302\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4157 - acc: 0.1355 - val_loss: 2.4198 - val_acc: 0.1343\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4154 - acc: 0.1396 - val_loss: 2.4179 - val_acc: 0.1382\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4121 - acc: 0.1412 - val_loss: 2.4136 - val_acc: 0.1433\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4045 - acc: 0.1431 - val_loss: 2.4093 - val_acc: 0.1370\n",
      "Epoch 12/20\n",
      "2s - loss: 2.3978 - acc: 0.1443 - val_loss: 2.4081 - val_acc: 0.1323\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3973 - acc: 0.1463 - val_loss: 2.4082 - val_acc: 0.1275\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3944 - acc: 0.1471 - val_loss: 2.4067 - val_acc: 0.1342\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3922 - acc: 0.1485 - val_loss: 2.4059 - val_acc: 0.1347\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3910 - acc: 0.1495 - val_loss: 2.4057 - val_acc: 0.1355\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3887 - acc: 0.1518 - val_loss: 2.4058 - val_acc: 0.1382\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3887 - acc: 0.1526 - val_loss: 2.4057 - val_acc: 0.1397\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3845 - acc: 0.1545 - val_loss: 2.4056 - val_acc: 0.1383\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3865 - acc: 0.1538 - val_loss: 2.4058 - val_acc: 0.1410\n",
      "logloss val 2.405777173219826\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4660 - acc: 0.1281 - val_loss: 2.4280 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4262 - acc: 0.1278 - val_loss: 2.4261 - val_acc: 0.1270\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4251 - acc: 0.1281 - val_loss: 2.4245 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4228 - acc: 0.1299 - val_loss: 2.4232 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4211 - acc: 0.1281 - val_loss: 2.4222 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4194 - acc: 0.1286 - val_loss: 2.4213 - val_acc: 0.1364\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4178 - acc: 0.1333 - val_loss: 2.4198 - val_acc: 0.1369\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4164 - acc: 0.1384 - val_loss: 2.4167 - val_acc: 0.1406\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4099 - acc: 0.1414 - val_loss: 2.4104 - val_acc: 0.1424\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4027 - acc: 0.1438 - val_loss: 2.4057 - val_acc: 0.1467\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3989 - acc: 0.1431 - val_loss: 2.4043 - val_acc: 0.1501\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3962 - acc: 0.1471 - val_loss: 2.4031 - val_acc: 0.1477\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3942 - acc: 0.1477 - val_loss: 2.4019 - val_acc: 0.1460\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3923 - acc: 0.1501 - val_loss: 2.4016 - val_acc: 0.1449\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3907 - acc: 0.1509 - val_loss: 2.4010 - val_acc: 0.1408\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3876 - acc: 0.1527 - val_loss: 2.4011 - val_acc: 0.1436\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3891 - acc: 0.1512 - val_loss: 2.4011 - val_acc: 0.1447\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3846 - acc: 0.1537 - val_loss: 2.4009 - val_acc: 0.1428\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3855 - acc: 0.1526 - val_loss: 2.4004 - val_acc: 0.1426\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3835 - acc: 0.1537 - val_loss: 2.4002 - val_acc: 0.1449\n",
      "logloss val 2.400220066269058\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4627 - acc: 0.1263 - val_loss: 2.4280 - val_acc: 0.1286\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4262 - acc: 0.1278 - val_loss: 2.4265 - val_acc: 0.1330\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4259 - acc: 0.1300 - val_loss: 2.4254 - val_acc: 0.1286\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4224 - acc: 0.1282 - val_loss: 2.4244 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4203 - acc: 0.1295 - val_loss: 2.4234 - val_acc: 0.1286\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4202 - acc: 0.1296 - val_loss: 2.4226 - val_acc: 0.1326\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4182 - acc: 0.1319 - val_loss: 2.4216 - val_acc: 0.1316\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4166 - acc: 0.1331 - val_loss: 2.4200 - val_acc: 0.1332\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4145 - acc: 0.1366 - val_loss: 2.4177 - val_acc: 0.1353\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4126 - acc: 0.1401 - val_loss: 2.4124 - val_acc: 0.1416\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4049 - acc: 0.1425 - val_loss: 2.4045 - val_acc: 0.1462\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4004 - acc: 0.1436 - val_loss: 2.4011 - val_acc: 0.1454\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3983 - acc: 0.1440 - val_loss: 2.4000 - val_acc: 0.1448\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3951 - acc: 0.1456 - val_loss: 2.3995 - val_acc: 0.1456\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3935 - acc: 0.1477 - val_loss: 2.3990 - val_acc: 0.1459\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3922 - acc: 0.1485 - val_loss: 2.3986 - val_acc: 0.1509\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3908 - acc: 0.1492 - val_loss: 2.3987 - val_acc: 0.1515\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3884 - acc: 0.1523 - val_loss: 2.3984 - val_acc: 0.1521\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3886 - acc: 0.1518 - val_loss: 2.3983 - val_acc: 0.1530\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3856 - acc: 0.1518 - val_loss: 2.3984 - val_acc: 0.1530\n",
      "logloss val 2.398418695389394\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4667 - acc: 0.1260 - val_loss: 2.4284 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4274 - acc: 0.1279 - val_loss: 2.4257 - val_acc: 0.1286\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4252 - acc: 0.1268 - val_loss: 2.4237 - val_acc: 0.1306\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4236 - acc: 0.1300 - val_loss: 2.4215 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4221 - acc: 0.1296 - val_loss: 2.4205 - val_acc: 0.1286\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4199 - acc: 0.1297 - val_loss: 2.4180 - val_acc: 0.1316\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4187 - acc: 0.1373 - val_loss: 2.4152 - val_acc: 0.1428\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4139 - acc: 0.1413 - val_loss: 2.4084 - val_acc: 0.1411\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4050 - acc: 0.1428 - val_loss: 2.4012 - val_acc: 0.1439\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4014 - acc: 0.1430 - val_loss: 2.3986 - val_acc: 0.1444\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3983 - acc: 0.1446 - val_loss: 2.3979 - val_acc: 0.1451\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3944 - acc: 0.1460 - val_loss: 2.3972 - val_acc: 0.1473\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3931 - acc: 0.1475 - val_loss: 2.3967 - val_acc: 0.1490\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3922 - acc: 0.1478 - val_loss: 2.3970 - val_acc: 0.1502\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3903 - acc: 0.1515 - val_loss: 2.3964 - val_acc: 0.1487\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3884 - acc: 0.1521 - val_loss: 2.3967 - val_acc: 0.1501\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3868 - acc: 0.1529 - val_loss: 2.3961 - val_acc: 0.1473\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3853 - acc: 0.1533 - val_loss: 2.3963 - val_acc: 0.1485\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3850 - acc: 0.1534 - val_loss: 2.3960 - val_acc: 0.1481\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3846 - acc: 0.1529 - val_loss: 2.3963 - val_acc: 0.1491\n",
      "logloss val 2.3963135852101947\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4646 - acc: 0.1268 - val_loss: 2.4273 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4274 - acc: 0.1288 - val_loss: 2.4244 - val_acc: 0.1286\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4250 - acc: 0.1272 - val_loss: 2.4221 - val_acc: 0.1286\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4218 - acc: 0.1303 - val_loss: 2.4198 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4205 - acc: 0.1352 - val_loss: 2.4166 - val_acc: 0.1372\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4164 - acc: 0.1422 - val_loss: 2.4102 - val_acc: 0.1359\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4077 - acc: 0.1419 - val_loss: 2.4014 - val_acc: 0.1367\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4040 - acc: 0.1425 - val_loss: 2.3988 - val_acc: 0.1403\n",
      "Epoch 9/20\n",
      "2s - loss: 2.3994 - acc: 0.1455 - val_loss: 2.3967 - val_acc: 0.1406\n",
      "Epoch 10/20\n",
      "2s - loss: 2.3976 - acc: 0.1469 - val_loss: 2.3962 - val_acc: 0.1431\n",
      "Epoch 11/20\n",
      "2s - loss: 2.3957 - acc: 0.1463 - val_loss: 2.3952 - val_acc: 0.1404\n",
      "Epoch 12/20\n",
      "2s - loss: 2.3943 - acc: 0.1479 - val_loss: 2.3951 - val_acc: 0.1446\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3921 - acc: 0.1511 - val_loss: 2.3952 - val_acc: 0.1448\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3904 - acc: 0.1505 - val_loss: 2.3947 - val_acc: 0.1442\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3895 - acc: 0.1510 - val_loss: 2.3943 - val_acc: 0.1446\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3883 - acc: 0.1522 - val_loss: 2.3943 - val_acc: 0.1463\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3858 - acc: 0.1547 - val_loss: 2.3939 - val_acc: 0.1467\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3852 - acc: 0.1534 - val_loss: 2.3948 - val_acc: 0.1481\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3830 - acc: 0.1559 - val_loss: 2.3949 - val_acc: 0.1471\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3830 - acc: 0.1543 - val_loss: 2.3949 - val_acc: 0.1475\n",
      "logloss val 2.3949207724634225\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4654 - acc: 0.1257 - val_loss: 2.4283 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4258 - acc: 0.1290 - val_loss: 2.4266 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4268 - acc: 0.1284 - val_loss: 2.4251 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4225 - acc: 0.1292 - val_loss: 2.4240 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4223 - acc: 0.1281 - val_loss: 2.4225 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4212 - acc: 0.1283 - val_loss: 2.4218 - val_acc: 0.1287\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4190 - acc: 0.1306 - val_loss: 2.4202 - val_acc: 0.1308\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4178 - acc: 0.1309 - val_loss: 2.4186 - val_acc: 0.1304\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4170 - acc: 0.1327 - val_loss: 2.4160 - val_acc: 0.1371\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4110 - acc: 0.1419 - val_loss: 2.4107 - val_acc: 0.1446\n",
      "Epoch 11/20\n",
      "1s - loss: 2.4054 - acc: 0.1434 - val_loss: 2.4059 - val_acc: 0.1414\n",
      "Epoch 12/20\n",
      "1s - loss: 2.4018 - acc: 0.1428 - val_loss: 2.4030 - val_acc: 0.1416\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3993 - acc: 0.1439 - val_loss: 2.4019 - val_acc: 0.1405\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3954 - acc: 0.1453 - val_loss: 2.4019 - val_acc: 0.1410\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3956 - acc: 0.1453 - val_loss: 2.4006 - val_acc: 0.1420\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3932 - acc: 0.1473 - val_loss: 2.4004 - val_acc: 0.1424\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3913 - acc: 0.1480 - val_loss: 2.4000 - val_acc: 0.1436\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3889 - acc: 0.1502 - val_loss: 2.3986 - val_acc: 0.1445\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3893 - acc: 0.1502 - val_loss: 2.3987 - val_acc: 0.1444\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3866 - acc: 0.1522 - val_loss: 2.3976 - val_acc: 0.1424\n",
      "logloss val 2.397624038275701\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4651 - acc: 0.1247 - val_loss: 2.4280 - val_acc: 0.1270\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4280 - acc: 0.1284 - val_loss: 2.4263 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4248 - acc: 0.1292 - val_loss: 2.4249 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4241 - acc: 0.1270 - val_loss: 2.4235 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4218 - acc: 0.1293 - val_loss: 2.4223 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4205 - acc: 0.1286 - val_loss: 2.4211 - val_acc: 0.1287\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4206 - acc: 0.1272 - val_loss: 2.4201 - val_acc: 0.1278\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4179 - acc: 0.1278 - val_loss: 2.4190 - val_acc: 0.1287\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4178 - acc: 0.1280 - val_loss: 2.4176 - val_acc: 0.1327\n",
      "Epoch 10/20\n",
      "3s - loss: 2.4161 - acc: 0.1289 - val_loss: 2.4160 - val_acc: 0.1358\n",
      "Epoch 11/20\n",
      "1s - loss: 2.4132 - acc: 0.1364 - val_loss: 2.4123 - val_acc: 0.1468\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4085 - acc: 0.1420 - val_loss: 2.4044 - val_acc: 0.1476\n",
      "Epoch 13/20\n",
      "2s - loss: 2.4018 - acc: 0.1433 - val_loss: 2.3984 - val_acc: 0.1471\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3971 - acc: 0.1451 - val_loss: 2.3963 - val_acc: 0.1471\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3946 - acc: 0.1455 - val_loss: 2.3953 - val_acc: 0.1473\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3926 - acc: 0.1484 - val_loss: 2.3941 - val_acc: 0.1499\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3913 - acc: 0.1501 - val_loss: 2.3935 - val_acc: 0.1460\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3894 - acc: 0.1513 - val_loss: 2.3930 - val_acc: 0.1496\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3878 - acc: 0.1528 - val_loss: 2.3932 - val_acc: 0.1489\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3862 - acc: 0.1520 - val_loss: 2.3923 - val_acc: 0.1493\n",
      "logloss val 2.392325430377301\n",
      "average logloss val 2.3986647774551813\n"
     ]
    }
   ],
   "source": [
    "# define baseline model\n",
    "def without_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "dummy_y_without = np_utils.to_categorical(y_train_total_without)\n",
    "kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\n",
    "score_list_without=[]\n",
    "val_loss_list_without = []\n",
    "for index,(train, test) in enumerate(kf):\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = dummy_y_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = dummy_y_without[test]\n",
    "    print('*****************************************************')\n",
    "    print('{}_fold'.format(index))\n",
    "    model=without_model(X_train_total_without.shape[1])\n",
    "    fit= model.fit_generator(generator=batch_generator(X_train_without, y_train_without, 512, True),\n",
    "                         nb_epoch=20,\n",
    "                         samples_per_epoch=80000,\n",
    "                         validation_data=(X_val_without.todense(), y_val_without), verbose=2\n",
    "                         )\n",
    "    scores_val_without = model.predict_generator(generator=batch_generatorp(X_val_without, 512, False), \n",
    "                                         val_samples=X_val_without.shape[0])\n",
    "    scores_without = model.predict_generator(generator=batch_generatorp(X_test_total_without, 512, False), \n",
    "                                     val_samples=X_test_total_without.shape[0])\n",
    "    score_list_without.append(scores_without)\n",
    "    \n",
    "    val_loss = log_loss(y_val_without, scores_val_without)\n",
    "    val_loss_list_without.append(val_loss)\n",
    "    print('logloss val {}'.format(val_loss))\n",
    "\n",
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(score_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_without.to_csv('nnt_without_result{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_ensemble = (score_ave_without+score_ave_without_lr)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without eventsIII: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.48238\ttest-mlogloss:2.48264\n",
      "[1]\ttrain-mlogloss:2.47991\ttest-mlogloss:2.48043\n",
      "[2]\ttrain-mlogloss:2.4775\ttest-mlogloss:2.47829\n",
      "[3]\ttrain-mlogloss:2.47515\ttest-mlogloss:2.47621\n",
      "[4]\ttrain-mlogloss:2.47286\ttest-mlogloss:2.47417\n",
      "[5]\ttrain-mlogloss:2.47063\ttest-mlogloss:2.47218\n",
      "[6]\ttrain-mlogloss:2.46844\ttest-mlogloss:2.47024\n",
      "[7]\ttrain-mlogloss:2.46631\ttest-mlogloss:2.46836\n",
      "[8]\ttrain-mlogloss:2.46423\ttest-mlogloss:2.46652\n",
      "[9]\ttrain-mlogloss:2.46219\ttest-mlogloss:2.46473\n",
      "[10]\ttrain-mlogloss:2.4602\ttest-mlogloss:2.46298\n",
      "[11]\ttrain-mlogloss:2.45826\ttest-mlogloss:2.46127\n",
      "[12]\ttrain-mlogloss:2.45636\ttest-mlogloss:2.4596\n",
      "[13]\ttrain-mlogloss:2.4545\ttest-mlogloss:2.45797\n",
      "[14]\ttrain-mlogloss:2.45268\ttest-mlogloss:2.45636\n",
      "[15]\ttrain-mlogloss:2.45091\ttest-mlogloss:2.45481\n",
      "[16]\ttrain-mlogloss:2.44918\ttest-mlogloss:2.45328\n",
      "[17]\ttrain-mlogloss:2.44747\ttest-mlogloss:2.45183\n",
      "[18]\ttrain-mlogloss:2.44582\ttest-mlogloss:2.45041\n",
      "[19]\ttrain-mlogloss:2.44419\ttest-mlogloss:2.449\n",
      "[20]\ttrain-mlogloss:2.44259\ttest-mlogloss:2.44764\n",
      "[21]\ttrain-mlogloss:2.44104\ttest-mlogloss:2.44628\n",
      "[22]\ttrain-mlogloss:2.43953\ttest-mlogloss:2.44497\n",
      "[23]\ttrain-mlogloss:2.43806\ttest-mlogloss:2.44368\n",
      "[24]\ttrain-mlogloss:2.43661\ttest-mlogloss:2.44241\n",
      "[25]\ttrain-mlogloss:2.4352\ttest-mlogloss:2.4412\n",
      "[26]\ttrain-mlogloss:2.43381\ttest-mlogloss:2.44\n",
      "[27]\ttrain-mlogloss:2.43245\ttest-mlogloss:2.43882\n",
      "[28]\ttrain-mlogloss:2.43112\ttest-mlogloss:2.43768\n",
      "[29]\ttrain-mlogloss:2.42982\ttest-mlogloss:2.43657\n",
      "[30]\ttrain-mlogloss:2.42853\ttest-mlogloss:2.43547\n",
      "[31]\ttrain-mlogloss:2.42728\ttest-mlogloss:2.4344\n",
      "[32]\ttrain-mlogloss:2.42605\ttest-mlogloss:2.43335\n",
      "[33]\ttrain-mlogloss:2.42486\ttest-mlogloss:2.43236\n",
      "[34]\ttrain-mlogloss:2.42368\ttest-mlogloss:2.43137\n",
      "[35]\ttrain-mlogloss:2.42253\ttest-mlogloss:2.43038\n",
      "[36]\ttrain-mlogloss:2.42141\ttest-mlogloss:2.42947\n",
      "[37]\ttrain-mlogloss:2.4203\ttest-mlogloss:2.42853\n",
      "[38]\ttrain-mlogloss:2.41921\ttest-mlogloss:2.4276\n",
      "[39]\ttrain-mlogloss:2.41815\ttest-mlogloss:2.42673\n",
      "[40]\ttrain-mlogloss:2.41711\ttest-mlogloss:2.42585\n",
      "[41]\ttrain-mlogloss:2.41608\ttest-mlogloss:2.42499\n",
      "[42]\ttrain-mlogloss:2.41508\ttest-mlogloss:2.42417\n",
      "[43]\ttrain-mlogloss:2.4141\ttest-mlogloss:2.42335\n",
      "[44]\ttrain-mlogloss:2.41313\ttest-mlogloss:2.42257\n",
      "[45]\ttrain-mlogloss:2.41217\ttest-mlogloss:2.42179\n",
      "[46]\ttrain-mlogloss:2.41125\ttest-mlogloss:2.42105\n",
      "[47]\ttrain-mlogloss:2.41033\ttest-mlogloss:2.42028\n",
      "[48]\ttrain-mlogloss:2.40943\ttest-mlogloss:2.41952\n",
      "[49]\ttrain-mlogloss:2.40855\ttest-mlogloss:2.41884\n",
      "[50]\ttrain-mlogloss:2.4077\ttest-mlogloss:2.41816\n",
      "[51]\ttrain-mlogloss:2.40687\ttest-mlogloss:2.4175\n",
      "[52]\ttrain-mlogloss:2.40604\ttest-mlogloss:2.41682\n",
      "[53]\ttrain-mlogloss:2.40523\ttest-mlogloss:2.41616\n",
      "[54]\ttrain-mlogloss:2.40443\ttest-mlogloss:2.41553\n",
      "[55]\ttrain-mlogloss:2.40364\ttest-mlogloss:2.41491\n",
      "[56]\ttrain-mlogloss:2.40287\ttest-mlogloss:2.41431\n",
      "[57]\ttrain-mlogloss:2.40212\ttest-mlogloss:2.41372\n",
      "[58]\ttrain-mlogloss:2.40137\ttest-mlogloss:2.41313\n",
      "[59]\ttrain-mlogloss:2.40064\ttest-mlogloss:2.41256\n",
      "[60]\ttrain-mlogloss:2.39993\ttest-mlogloss:2.41196\n",
      "[61]\ttrain-mlogloss:2.39923\ttest-mlogloss:2.41146\n",
      "[62]\ttrain-mlogloss:2.39854\ttest-mlogloss:2.4109\n",
      "[63]\ttrain-mlogloss:2.39786\ttest-mlogloss:2.4104\n",
      "[64]\ttrain-mlogloss:2.39721\ttest-mlogloss:2.40991\n",
      "[65]\ttrain-mlogloss:2.39655\ttest-mlogloss:2.40939\n",
      "[66]\ttrain-mlogloss:2.3959\ttest-mlogloss:2.40888\n",
      "[67]\ttrain-mlogloss:2.39526\ttest-mlogloss:2.40841\n",
      "[68]\ttrain-mlogloss:2.39465\ttest-mlogloss:2.40797\n",
      "[69]\ttrain-mlogloss:2.39404\ttest-mlogloss:2.40753\n",
      "[70]\ttrain-mlogloss:2.39342\ttest-mlogloss:2.40707\n",
      "[71]\ttrain-mlogloss:2.39282\ttest-mlogloss:2.40663\n",
      "[72]\ttrain-mlogloss:2.39223\ttest-mlogloss:2.40619\n",
      "[73]\ttrain-mlogloss:2.39164\ttest-mlogloss:2.40579\n",
      "[74]\ttrain-mlogloss:2.39107\ttest-mlogloss:2.40541\n",
      "[75]\ttrain-mlogloss:2.39052\ttest-mlogloss:2.40499\n",
      "[76]\ttrain-mlogloss:2.38996\ttest-mlogloss:2.40462\n",
      "[77]\ttrain-mlogloss:2.38942\ttest-mlogloss:2.40426\n",
      "[78]\ttrain-mlogloss:2.38889\ttest-mlogloss:2.4039\n",
      "[79]\ttrain-mlogloss:2.38836\ttest-mlogloss:2.40352\n",
      "[80]\ttrain-mlogloss:2.38784\ttest-mlogloss:2.40318\n",
      "[81]\ttrain-mlogloss:2.38733\ttest-mlogloss:2.40282\n",
      "[82]\ttrain-mlogloss:2.38683\ttest-mlogloss:2.4025\n",
      "[83]\ttrain-mlogloss:2.38635\ttest-mlogloss:2.40217\n",
      "[84]\ttrain-mlogloss:2.38587\ttest-mlogloss:2.40184\n",
      "[85]\ttrain-mlogloss:2.3854\ttest-mlogloss:2.40156\n",
      "[86]\ttrain-mlogloss:2.38494\ttest-mlogloss:2.40124\n",
      "[87]\ttrain-mlogloss:2.38449\ttest-mlogloss:2.40095\n",
      "[88]\ttrain-mlogloss:2.38404\ttest-mlogloss:2.40068\n",
      "[89]\ttrain-mlogloss:2.38361\ttest-mlogloss:2.4004\n",
      "[90]\ttrain-mlogloss:2.38317\ttest-mlogloss:2.40012\n",
      "[91]\ttrain-mlogloss:2.38274\ttest-mlogloss:2.39987\n",
      "[92]\ttrain-mlogloss:2.38232\ttest-mlogloss:2.39962\n",
      "[93]\ttrain-mlogloss:2.38191\ttest-mlogloss:2.39935\n",
      "[94]\ttrain-mlogloss:2.38151\ttest-mlogloss:2.3991\n",
      "[95]\ttrain-mlogloss:2.38112\ttest-mlogloss:2.39886\n",
      "[96]\ttrain-mlogloss:2.38074\ttest-mlogloss:2.39861\n",
      "[97]\ttrain-mlogloss:2.38036\ttest-mlogloss:2.39839\n",
      "[98]\ttrain-mlogloss:2.38\ttest-mlogloss:2.39817\n",
      "[99]\ttrain-mlogloss:2.37963\ttest-mlogloss:2.39793\n",
      "[100]\ttrain-mlogloss:2.37927\ttest-mlogloss:2.39772\n",
      "[101]\ttrain-mlogloss:2.3789\ttest-mlogloss:2.3975\n",
      "[102]\ttrain-mlogloss:2.37856\ttest-mlogloss:2.39729\n",
      "[103]\ttrain-mlogloss:2.37821\ttest-mlogloss:2.39708\n",
      "[104]\ttrain-mlogloss:2.37787\ttest-mlogloss:2.39687\n",
      "[105]\ttrain-mlogloss:2.37753\ttest-mlogloss:2.39667\n",
      "[106]\ttrain-mlogloss:2.37721\ttest-mlogloss:2.3965\n",
      "[107]\ttrain-mlogloss:2.37687\ttest-mlogloss:2.39631\n",
      "[108]\ttrain-mlogloss:2.37656\ttest-mlogloss:2.39614\n",
      "[109]\ttrain-mlogloss:2.37624\ttest-mlogloss:2.39595\n",
      "[110]\ttrain-mlogloss:2.37594\ttest-mlogloss:2.39581\n",
      "[111]\ttrain-mlogloss:2.37563\ttest-mlogloss:2.39562\n",
      "[112]\ttrain-mlogloss:2.37534\ttest-mlogloss:2.39547\n",
      "[113]\ttrain-mlogloss:2.37505\ttest-mlogloss:2.3953\n",
      "[114]\ttrain-mlogloss:2.37474\ttest-mlogloss:2.39513\n",
      "[115]\ttrain-mlogloss:2.37446\ttest-mlogloss:2.39496\n",
      "[116]\ttrain-mlogloss:2.37417\ttest-mlogloss:2.39479\n",
      "[117]\ttrain-mlogloss:2.37389\ttest-mlogloss:2.39462\n",
      "[118]\ttrain-mlogloss:2.3736\ttest-mlogloss:2.39446\n",
      "[119]\ttrain-mlogloss:2.37333\ttest-mlogloss:2.3943\n",
      "[120]\ttrain-mlogloss:2.37306\ttest-mlogloss:2.39413\n",
      "[121]\ttrain-mlogloss:2.37279\ttest-mlogloss:2.39399\n",
      "[122]\ttrain-mlogloss:2.37252\ttest-mlogloss:2.39383\n",
      "[123]\ttrain-mlogloss:2.37226\ttest-mlogloss:2.39367\n",
      "[124]\ttrain-mlogloss:2.372\ttest-mlogloss:2.39353\n",
      "[125]\ttrain-mlogloss:2.37176\ttest-mlogloss:2.39338\n",
      "[126]\ttrain-mlogloss:2.3715\ttest-mlogloss:2.39324\n",
      "[127]\ttrain-mlogloss:2.37126\ttest-mlogloss:2.3931\n",
      "[128]\ttrain-mlogloss:2.37102\ttest-mlogloss:2.39297\n",
      "[129]\ttrain-mlogloss:2.37079\ttest-mlogloss:2.39286\n",
      "[130]\ttrain-mlogloss:2.37054\ttest-mlogloss:2.39274\n",
      "[131]\ttrain-mlogloss:2.37031\ttest-mlogloss:2.39261\n",
      "[132]\ttrain-mlogloss:2.3701\ttest-mlogloss:2.39248\n",
      "[133]\ttrain-mlogloss:2.36989\ttest-mlogloss:2.39239\n",
      "[134]\ttrain-mlogloss:2.36967\ttest-mlogloss:2.39226\n",
      "[135]\ttrain-mlogloss:2.36946\ttest-mlogloss:2.39215\n",
      "[136]\ttrain-mlogloss:2.36926\ttest-mlogloss:2.39205\n",
      "[137]\ttrain-mlogloss:2.36906\ttest-mlogloss:2.39194\n",
      "[138]\ttrain-mlogloss:2.36886\ttest-mlogloss:2.39182\n",
      "[139]\ttrain-mlogloss:2.36866\ttest-mlogloss:2.39168\n",
      "[140]\ttrain-mlogloss:2.36847\ttest-mlogloss:2.39155\n",
      "[141]\ttrain-mlogloss:2.36828\ttest-mlogloss:2.39145\n",
      "[142]\ttrain-mlogloss:2.3681\ttest-mlogloss:2.39134\n",
      "[143]\ttrain-mlogloss:2.36791\ttest-mlogloss:2.39124\n",
      "[144]\ttrain-mlogloss:2.36772\ttest-mlogloss:2.39113\n",
      "[145]\ttrain-mlogloss:2.36754\ttest-mlogloss:2.39101\n",
      "[146]\ttrain-mlogloss:2.36736\ttest-mlogloss:2.39093\n",
      "[147]\ttrain-mlogloss:2.36718\ttest-mlogloss:2.39084\n",
      "[148]\ttrain-mlogloss:2.367\ttest-mlogloss:2.39074\n",
      "[149]\ttrain-mlogloss:2.36683\ttest-mlogloss:2.39065\n",
      "[150]\ttrain-mlogloss:2.36666\ttest-mlogloss:2.39056\n",
      "[151]\ttrain-mlogloss:2.36649\ttest-mlogloss:2.39045\n",
      "[152]\ttrain-mlogloss:2.36632\ttest-mlogloss:2.39039\n",
      "[153]\ttrain-mlogloss:2.36615\ttest-mlogloss:2.39029\n",
      "[154]\ttrain-mlogloss:2.36598\ttest-mlogloss:2.39021\n",
      "[155]\ttrain-mlogloss:2.36582\ttest-mlogloss:2.39015\n",
      "[156]\ttrain-mlogloss:2.36566\ttest-mlogloss:2.39009\n",
      "[157]\ttrain-mlogloss:2.3655\ttest-mlogloss:2.39\n",
      "[158]\ttrain-mlogloss:2.36534\ttest-mlogloss:2.38993\n",
      "[159]\ttrain-mlogloss:2.36518\ttest-mlogloss:2.38987\n",
      "[160]\ttrain-mlogloss:2.36503\ttest-mlogloss:2.38981\n",
      "[161]\ttrain-mlogloss:2.36487\ttest-mlogloss:2.38974\n",
      "[162]\ttrain-mlogloss:2.36471\ttest-mlogloss:2.38968\n",
      "[163]\ttrain-mlogloss:2.36457\ttest-mlogloss:2.38962\n",
      "[164]\ttrain-mlogloss:2.36442\ttest-mlogloss:2.38954\n",
      "[165]\ttrain-mlogloss:2.36426\ttest-mlogloss:2.38949\n",
      "[166]\ttrain-mlogloss:2.36412\ttest-mlogloss:2.38944\n",
      "[167]\ttrain-mlogloss:2.36398\ttest-mlogloss:2.3894\n",
      "[168]\ttrain-mlogloss:2.36383\ttest-mlogloss:2.38936\n",
      "[169]\ttrain-mlogloss:2.36369\ttest-mlogloss:2.38931\n",
      "[170]\ttrain-mlogloss:2.36356\ttest-mlogloss:2.38929\n",
      "[171]\ttrain-mlogloss:2.36342\ttest-mlogloss:2.38924\n",
      "[172]\ttrain-mlogloss:2.36328\ttest-mlogloss:2.3892\n",
      "[173]\ttrain-mlogloss:2.36315\ttest-mlogloss:2.38917\n",
      "[174]\ttrain-mlogloss:2.36303\ttest-mlogloss:2.38915\n",
      "[175]\ttrain-mlogloss:2.3629\ttest-mlogloss:2.3891\n",
      "[176]\ttrain-mlogloss:2.36278\ttest-mlogloss:2.38906\n",
      "[177]\ttrain-mlogloss:2.36266\ttest-mlogloss:2.38902\n",
      "[178]\ttrain-mlogloss:2.36254\ttest-mlogloss:2.38897\n",
      "[179]\ttrain-mlogloss:2.36242\ttest-mlogloss:2.38894\n",
      "[180]\ttrain-mlogloss:2.36231\ttest-mlogloss:2.3889\n",
      "[181]\ttrain-mlogloss:2.36218\ttest-mlogloss:2.38884\n",
      "[182]\ttrain-mlogloss:2.36206\ttest-mlogloss:2.38882\n",
      "[183]\ttrain-mlogloss:2.36195\ttest-mlogloss:2.38877\n",
      "[184]\ttrain-mlogloss:2.36184\ttest-mlogloss:2.38873\n",
      "[185]\ttrain-mlogloss:2.36173\ttest-mlogloss:2.3887\n",
      "[186]\ttrain-mlogloss:2.36162\ttest-mlogloss:2.38868\n",
      "[187]\ttrain-mlogloss:2.36151\ttest-mlogloss:2.38866\n",
      "[188]\ttrain-mlogloss:2.36141\ttest-mlogloss:2.38863\n",
      "[189]\ttrain-mlogloss:2.3613\ttest-mlogloss:2.3886\n",
      "[190]\ttrain-mlogloss:2.3612\ttest-mlogloss:2.38857\n",
      "[191]\ttrain-mlogloss:2.36111\ttest-mlogloss:2.38857\n",
      "[192]\ttrain-mlogloss:2.361\ttest-mlogloss:2.38856\n",
      "[193]\ttrain-mlogloss:2.3609\ttest-mlogloss:2.38851\n",
      "[194]\ttrain-mlogloss:2.3608\ttest-mlogloss:2.38851\n",
      "[195]\ttrain-mlogloss:2.3607\ttest-mlogloss:2.38849\n",
      "[196]\ttrain-mlogloss:2.36061\ttest-mlogloss:2.38847\n",
      "[197]\ttrain-mlogloss:2.36051\ttest-mlogloss:2.38844\n",
      "[198]\ttrain-mlogloss:2.36041\ttest-mlogloss:2.38841\n",
      "[199]\ttrain-mlogloss:2.36032\ttest-mlogloss:2.38839\n",
      "[200]\ttrain-mlogloss:2.36023\ttest-mlogloss:2.38836\n",
      "[201]\ttrain-mlogloss:2.36014\ttest-mlogloss:2.38835\n",
      "[202]\ttrain-mlogloss:2.36004\ttest-mlogloss:2.38833\n",
      "[203]\ttrain-mlogloss:2.35996\ttest-mlogloss:2.38833\n",
      "[204]\ttrain-mlogloss:2.35987\ttest-mlogloss:2.38832\n",
      "[205]\ttrain-mlogloss:2.35978\ttest-mlogloss:2.3883\n",
      "[206]\ttrain-mlogloss:2.35969\ttest-mlogloss:2.3883\n",
      "[207]\ttrain-mlogloss:2.3596\ttest-mlogloss:2.38827\n",
      "[208]\ttrain-mlogloss:2.35952\ttest-mlogloss:2.38826\n",
      "[209]\ttrain-mlogloss:2.35943\ttest-mlogloss:2.38825\n",
      "[210]\ttrain-mlogloss:2.35935\ttest-mlogloss:2.38823\n",
      "[211]\ttrain-mlogloss:2.35927\ttest-mlogloss:2.38825\n",
      "[212]\ttrain-mlogloss:2.35918\ttest-mlogloss:2.38824\n",
      "[213]\ttrain-mlogloss:2.3591\ttest-mlogloss:2.38824\n",
      "[214]\ttrain-mlogloss:2.35902\ttest-mlogloss:2.38823\n",
      "[215]\ttrain-mlogloss:2.35894\ttest-mlogloss:2.38822\n",
      "[216]\ttrain-mlogloss:2.35886\ttest-mlogloss:2.38822\n",
      "[217]\ttrain-mlogloss:2.35878\ttest-mlogloss:2.38822\n",
      "[218]\ttrain-mlogloss:2.35871\ttest-mlogloss:2.3882\n",
      "[219]\ttrain-mlogloss:2.35864\ttest-mlogloss:2.3882\n",
      "[220]\ttrain-mlogloss:2.35856\ttest-mlogloss:2.38817\n",
      "[221]\ttrain-mlogloss:2.35849\ttest-mlogloss:2.38816\n",
      "[222]\ttrain-mlogloss:2.35842\ttest-mlogloss:2.38816\n",
      "[223]\ttrain-mlogloss:2.35835\ttest-mlogloss:2.38814\n",
      "[224]\ttrain-mlogloss:2.35828\ttest-mlogloss:2.38814\n",
      "[225]\ttrain-mlogloss:2.35821\ttest-mlogloss:2.38813\n",
      "[226]\ttrain-mlogloss:2.35814\ttest-mlogloss:2.38814\n",
      "[227]\ttrain-mlogloss:2.35807\ttest-mlogloss:2.38813\n",
      "[228]\ttrain-mlogloss:2.358\ttest-mlogloss:2.38813\n",
      "[229]\ttrain-mlogloss:2.35794\ttest-mlogloss:2.38812\n",
      "[230]\ttrain-mlogloss:2.35786\ttest-mlogloss:2.38812\n",
      "[231]\ttrain-mlogloss:2.3578\ttest-mlogloss:2.38811\n",
      "[232]\ttrain-mlogloss:2.35773\ttest-mlogloss:2.3881\n",
      "[233]\ttrain-mlogloss:2.35767\ttest-mlogloss:2.38809\n",
      "[234]\ttrain-mlogloss:2.3576\ttest-mlogloss:2.38808\n",
      "[235]\ttrain-mlogloss:2.35754\ttest-mlogloss:2.38808\n",
      "[236]\ttrain-mlogloss:2.35748\ttest-mlogloss:2.38806\n",
      "[237]\ttrain-mlogloss:2.35741\ttest-mlogloss:2.38804\n",
      "[238]\ttrain-mlogloss:2.35735\ttest-mlogloss:2.38804\n",
      "[239]\ttrain-mlogloss:2.3573\ttest-mlogloss:2.38806\n",
      "[240]\ttrain-mlogloss:2.35724\ttest-mlogloss:2.38804\n",
      "[241]\ttrain-mlogloss:2.35718\ttest-mlogloss:2.38804\n",
      "[242]\ttrain-mlogloss:2.35712\ttest-mlogloss:2.38806\n",
      "[243]\ttrain-mlogloss:2.35706\ttest-mlogloss:2.38806\n",
      "[244]\ttrain-mlogloss:2.357\ttest-mlogloss:2.38807\n",
      "[245]\ttrain-mlogloss:2.35695\ttest-mlogloss:2.38807\n",
      "[246]\ttrain-mlogloss:2.35689\ttest-mlogloss:2.38809\n",
      "[247]\ttrain-mlogloss:2.35684\ttest-mlogloss:2.38809\n",
      "[248]\ttrain-mlogloss:2.35678\ttest-mlogloss:2.38809\n",
      "[249]\ttrain-mlogloss:2.35673\ttest-mlogloss:2.38809\n",
      "[250]\ttrain-mlogloss:2.35668\ttest-mlogloss:2.38809\n",
      "[251]\ttrain-mlogloss:2.35662\ttest-mlogloss:2.38809\n",
      "[252]\ttrain-mlogloss:2.35656\ttest-mlogloss:2.38812\n",
      "[253]\ttrain-mlogloss:2.35651\ttest-mlogloss:2.38811\n",
      "[254]\ttrain-mlogloss:2.35645\ttest-mlogloss:2.3881\n",
      "[255]\ttrain-mlogloss:2.3564\ttest-mlogloss:2.38811\n",
      "[256]\ttrain-mlogloss:2.35635\ttest-mlogloss:2.38811\n",
      "[257]\ttrain-mlogloss:2.35629\ttest-mlogloss:2.38811\n",
      "[258]\ttrain-mlogloss:2.35623\ttest-mlogloss:2.38811\n",
      "[259]\ttrain-mlogloss:2.35618\ttest-mlogloss:2.38811\n",
      "[260]\ttrain-mlogloss:2.35613\ttest-mlogloss:2.38811\n",
      "[261]\ttrain-mlogloss:2.35608\ttest-mlogloss:2.38811\n",
      "[262]\ttrain-mlogloss:2.35603\ttest-mlogloss:2.3881\n",
      "[263]\ttrain-mlogloss:2.35598\ttest-mlogloss:2.38811\n",
      "[264]\ttrain-mlogloss:2.35593\ttest-mlogloss:2.38812\n",
      "[265]\ttrain-mlogloss:2.35588\ttest-mlogloss:2.38813\n",
      "[266]\ttrain-mlogloss:2.35582\ttest-mlogloss:2.38814\n",
      "[267]\ttrain-mlogloss:2.35577\ttest-mlogloss:2.38815\n",
      "[268]\ttrain-mlogloss:2.35573\ttest-mlogloss:2.38815\n",
      "[269]\ttrain-mlogloss:2.35568\ttest-mlogloss:2.38816\n",
      "[270]\ttrain-mlogloss:2.35563\ttest-mlogloss:2.38816\n",
      "[271]\ttrain-mlogloss:2.35559\ttest-mlogloss:2.38817\n",
      "[272]\ttrain-mlogloss:2.35554\ttest-mlogloss:2.38819\n",
      "[273]\ttrain-mlogloss:2.3555\ttest-mlogloss:2.38819\n",
      "[274]\ttrain-mlogloss:2.35545\ttest-mlogloss:2.3882\n",
      "[275]\ttrain-mlogloss:2.3554\ttest-mlogloss:2.38821\n",
      "[276]\ttrain-mlogloss:2.35535\ttest-mlogloss:2.38822\n",
      "[277]\ttrain-mlogloss:2.35531\ttest-mlogloss:2.38822\n",
      "[278]\ttrain-mlogloss:2.35527\ttest-mlogloss:2.38824\n",
      "[279]\ttrain-mlogloss:2.35523\ttest-mlogloss:2.38824\n",
      "[280]\ttrain-mlogloss:2.35518\ttest-mlogloss:2.38825\n",
      "[281]\ttrain-mlogloss:2.35514\ttest-mlogloss:2.38826\n",
      "[282]\ttrain-mlogloss:2.35509\ttest-mlogloss:2.38829\n",
      "[283]\ttrain-mlogloss:2.35505\ttest-mlogloss:2.3883\n",
      "[284]\ttrain-mlogloss:2.35501\ttest-mlogloss:2.3883\n",
      "[285]\ttrain-mlogloss:2.35496\ttest-mlogloss:2.38831\n",
      "[286]\ttrain-mlogloss:2.35493\ttest-mlogloss:2.38832\n",
      "[287]\ttrain-mlogloss:2.35489\ttest-mlogloss:2.38833\n",
      "[288]\ttrain-mlogloss:2.35485\ttest-mlogloss:2.38833\n",
      "[289]\ttrain-mlogloss:2.35481\ttest-mlogloss:2.38834\n",
      "[290]\ttrain-mlogloss:2.35477\ttest-mlogloss:2.38833\n",
      "[291]\ttrain-mlogloss:2.35474\ttest-mlogloss:2.38833\n",
      "[292]\ttrain-mlogloss:2.3547\ttest-mlogloss:2.38833\n",
      "[293]\ttrain-mlogloss:2.35467\ttest-mlogloss:2.38834\n",
      "[294]\ttrain-mlogloss:2.35463\ttest-mlogloss:2.38834\n",
      "[295]\ttrain-mlogloss:2.35459\ttest-mlogloss:2.38835\n",
      "[296]\ttrain-mlogloss:2.35456\ttest-mlogloss:2.38835\n",
      "[297]\ttrain-mlogloss:2.35453\ttest-mlogloss:2.38835\n",
      "[298]\ttrain-mlogloss:2.35449\ttest-mlogloss:2.38836\n",
      "[299]\ttrain-mlogloss:2.35446\ttest-mlogloss:2.38837\n",
      "logloss val 2.388368128214176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.02,\n",
    "                                                    stratify=y_train_total_without)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':40,\n",
    "         'eta':0.02,\n",
    "         'silent':0,\n",
    "         'objective':'multi:softprob',\n",
    "         'nthread':2,\n",
    "         'num_class':12,\n",
    "         'eval_metric':'mlogloss',\n",
    "        'lambda':4,\n",
    "        'lambda_bias':0,\n",
    "        'alpha':2}\n",
    "num_round = 300\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train_total_without,label = y_train_total_without)\n",
    "xg_test = xgb.DMatrix(X_test_total_without)\n",
    "bst = xgb.train(param,xg_train,num_round)\n",
    "yprob = bst.predict(xg_test).reshape(X_test_total_without.shape[0],12)\n",
    "pred_without_xgb = pd.DataFrame(yprob, \n",
    "                            index = gender_age_test_without.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_without_xgb.to_csv('xgb_without_result{}.csv'.format(val_loss))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# putting together and save into final file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final score based on the percentage of testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with score:1.9392115926279074\n",
      "without score:2.3931157227003554\n",
      "final validation score:2.2505748160093315\n"
     ]
    }
   ],
   "source": [
    "#val_score_final = val_loss_ave_without*76877/112071+val_loss_ave_with*35194/112071\n",
    "val_score_final = (val_loss_ave_without*X_test_total_without.shape[0]+\n",
    "                   val_loss_ave_with*X_test_total_with.shape[0])/(X_test_total_without.shape[0]+X_test_total_with.shape[0])\n",
    "print('with score:{}'.format(val_loss_ave_with))\n",
    "print('without score:{}'.format(val_loss_ave_without))\n",
    "print('final validation score:{}'.format(val_score_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pd.concat((pred_with,pred_without))\n",
    "pred.to_csv('doublemodel_v6.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
