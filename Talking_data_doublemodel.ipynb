{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yuyang/anaconda/lib/python3.5/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from scipy.sparse import csr_matrix,hstack,vstack\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold,KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import os\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('input/events.csv',index_col='event_id')\n",
    "label = pd.read_csv('input/label_categories.csv')\n",
    "app_event = pd.read_csv('input/app_events.csv')\n",
    "app_label = pd.read_csv('input/app_labels.csv')\n",
    "device = pd.read_csv('input/phone_brand_device_model.csv')\n",
    "device = device.drop_duplicates('device_id').set_index('device_id')\n",
    "gender_age_train = pd.read_csv('input/gender_age_train.csv',index_col = 'device_id')\n",
    "gender_age_test = pd.read_csv('input/gender_age_test.csv',index_col = 'device_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convinience of creating sparse matrix, we create another integer index for the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_age_train\n",
      "                      gender  age   group\n",
      "device_id                               \n",
      "-8076087639492063270      M   35  M32-38\n",
      "\n",
      "gender_age_test\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [1002079943728939269]\n",
      "\n",
      "device\n",
      "                      phone_brand device_model\n",
      "device_id                                    \n",
      "-8890648629457979026          小米           红米\n",
      "\n",
      "events\n",
      "                   device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
      "\n",
      "label\n",
      "    label_id category\n",
      "0         1      NaN\n",
      "\n",
      "app_event\n",
      "    event_id               app_id  is_installed  is_active\n",
      "0         2  5927333115845830913             1          1\n",
      "\n",
      "app_label\n",
      "                 app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print('gender_age_train\\n',gender_age_train.head(1))\n",
    "print('\\ngender_age_test\\n',gender_age_test.head(1))\n",
    "print('\\ndevice\\n',device.head(1))\n",
    "print('\\nevents\\n',events.head(1))\n",
    "print('\\nlabel\\n',label.head(1))\n",
    "print('\\napp_event\\n',app_event.head(1))\n",
    "print('\\napp_label\\n',app_label.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of two set of devices: with events and without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set without events:    51336\n",
      "Size of training set with events:       23309\n",
      "Total size of training set:             74645\n",
      "Size of testing set without events:     76877\n",
      "Size of training set with events:       35194\n",
      "Total size of training set:             112071\n"
     ]
    }
   ],
   "source": [
    "gender_age_train_with = gender_age_train.loc[gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_train_without = gender_age_train.loc[~gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_with = gender_age_test.loc[gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_without = gender_age_test.loc[~gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set without events:',gender_age_train_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_train_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_train.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of testing set without events:',gender_age_test_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_test_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_age_train_with['int_index'] = np.arange(gender_age_train_with.shape[0])\n",
    "gender_age_test_with['int_index'] = np.arange(gender_age_test_with.shape[0])\n",
    "gender_age_train_without['int_index'] = np.arange(gender_age_train_without.shape[0])\n",
    "gender_age_test_without['int_index'] = np.arange(gender_age_test_without.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering I: phone brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the phone brand, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(device.phone_brand)\n",
    "device['brand'] = encoder.transform(device.phone_brand)\n",
    "gender_age_train_with['brand'] = device['brand']\n",
    "gender_age_test_with['brand'] = device['brand']\n",
    "gender_age_train_without['brand'] = device['brand']\n",
    "gender_age_test_without['brand'] = device['brand']\n",
    "brandnumber = len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sparse matrix with each row representing one device and each column representing one brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 131)\n",
      "X_test_brand_with shape: (35194, 131)\n",
      "X_train_brand_without shape: (51336, 131)\n",
      "X_test_brand_without shape: (76877, 131)\n"
     ]
    }
   ],
   "source": [
    "X_train_brand_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                            (gender_age_train_with.int_index,gender_age_train_with.brand)),\n",
    "                               shape = (gender_age_train_with.shape[0],brandnumber))\n",
    "X_test_brand_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                           (gender_age_test_with.int_index,gender_age_test_with.brand)),\n",
    "                              shape = (gender_age_test_with.shape[0],brandnumber))\n",
    "print('X_train_brand_with shape:',X_train_brand_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_brand_with.shape)\n",
    "X_train_brand_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                            (gender_age_train_without.int_index,gender_age_train_without.brand)),\n",
    "                                  shape = (gender_age_train_without.shape[0],brandnumber))\n",
    "X_test_brand_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                           (gender_age_test_without.int_index,gender_age_test_without.brand)),\n",
    "                                 shape = (gender_age_test_without.shape[0],brandnumber))\n",
    "print('X_train_brand_without shape:',X_train_brand_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_brand_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering II: phone device model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brand_model = device.phone_brand.str.cat(device.device_model)\n",
    "encoder3 = LabelEncoder()\n",
    "encoder3.fit(brand_model)\n",
    "device['model'] = encoder3.transform(brand_model)\n",
    "gender_age_train_with['model'] = device['model']\n",
    "gender_age_test_with['model'] = device['model']\n",
    "gender_age_train_without['model'] = device['model']\n",
    "gender_age_test_without['model'] = device['model']\n",
    "modelnumber = len(encoder3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 1667)\n",
      "X_test_brand_with shape: (35194, 1667)\n",
      "X_train_brand_without shape: (51336, 1667)\n",
      "X_test_brand_without shape: (76877, 1667)\n"
     ]
    }
   ],
   "source": [
    "X_train_model_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                                 (gender_age_train_with.int_index,gender_age_train_with.model)),\n",
    "                               shape = (gender_age_train_with.shape[0],modelnumber))\n",
    "X_test_model_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                                (gender_age_test_with.int_index,gender_age_test_with.model)),\n",
    "                              shape = (gender_age_test_with.shape[0],modelnumber))\n",
    "X_train_model_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                                    (gender_age_train_without.int_index,gender_age_train_without.model)),\n",
    "                                  shape = (gender_age_train_without.shape[0],modelnumber))\n",
    "X_test_model_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                                   (gender_age_test_without.int_index,gender_age_test_without.model)),\n",
    "                                 shape = (gender_age_test_without.shape[0],modelnumber))\n",
    "\n",
    "print('X_train_brand_with shape:',X_train_model_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_model_with.shape)\n",
    "print('X_train_brand_without shape:',X_train_model_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_model_without.shape)\n",
    "del device,brand_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering III: Installed app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the app_id and store it into app column, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = LabelEncoder()\n",
    "encoder2.fit(app_event.app_id)\n",
    "app_event['app'] = encoder2.transform(app_event.app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 19234, 19235, 19236])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(app_event.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   event_id               app_id  is_installed  is_active    app\n",
      "0         2  5927333115845830913             1          1  15408\n",
      "                  device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n"
     ]
    }
   ],
   "source": [
    "print(app_event.head(1))\n",
    "print(events.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  event_id    app  is_installed\n",
      "0 -6401643145415154744         2  15408             1\n",
      "1 -6401643145415154744         2   3384             1\n",
      "2 -6401643145415154744         2   7620             1\n",
      "3 -6401643145415154744         2   8902             1\n",
      "4 -6401643145415154744         2  18686             1\n"
     ]
    }
   ],
   "source": [
    "installed_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_installed']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "print(installed_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_app_train:\n",
      "                           size  int_index\n",
      "device_id            app                  \n",
      "-9222956879900151005 548     18       5145\n",
      "                     1096    18       5145\n",
      "                     1248    26       5145\n",
      "                     1545    12       5145\n",
      "                     1664    18       5145\n"
     ]
    }
   ],
   "source": [
    "installed_app_grouped = installed_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_app_train_with = pd.merge(installed_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_index=True)\n",
    "installed_app_test_with = pd.merge(installed_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_index=True)\n",
    "print('installed_app_train:')\n",
    "print(installed_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id   app  size  int_index\n",
      "0 -9222956879900151005   548    18       5145\n",
      "1 -9222956879900151005  1096    18       5145\n",
      "2 -9222956879900151005  1248    26       5145\n",
      "3 -9222956879900151005  1545    12       5145\n",
      "4 -9222956879900151005  1664    18       5145\n",
      "             device_id    app  size  int_index\n",
      "0 -9222661944218806987   1867     3       2851\n",
      "1 -9222661944218806987   7519     8       2851\n",
      "2 -9222661944218806987   7843     1       2851\n",
      "3 -9222661944218806987   8704     4       2851\n",
      "4 -9222661944218806987  10000     1       2851\n"
     ]
    }
   ],
   "source": [
    "installed_app_train_with = installed_app_train_with.reset_index()\n",
    "installed_app_test_with = installed_app_test_with.reset_index()\n",
    "installed_app_train_with = installed_app_train_with.dropna(subset=['int_index'])\n",
    "installed_app_test_with = installed_app_test_with.dropna(subset=['int_index'])\n",
    "print(installed_app_train_with.head())\n",
    "print(installed_app_test_with.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of unique app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35194\n",
      "915632\n"
     ]
    }
   ],
   "source": [
    "print(gender_age_test_with.shape[0])\n",
    "print(installed_app_train_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique apps:\n",
      "19237\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique apps:')\n",
    "print(np.size(installed_app.app.unique()))\n",
    "appnumber = np.size(installed_app.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ..., 19234 19235 19236]\n",
      "1387337\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(installed_app_train_with.app.unique()))\n",
    "print(installed_app_test_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed shape: (23309, 19237)\n",
      "X_test_installed shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "X_train_installed_with = csr_matrix((np.ones(installed_app_train_with.shape[0]),\n",
    "                                (installed_app_train_with.int_index,installed_app_train_with.app)), \n",
    "                               shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_installed_with = csr_matrix((np.ones(installed_app_test_with.shape[0]),\n",
    "                               (installed_app_test_with.int_index,installed_app_test_with.app)),\n",
    "                               shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_installed shape:',X_train_installed_with.shape)\n",
    "print('X_test_installed shape:',X_test_installed_with.shape)\n",
    "del installed_app_test_with,installed_app_train_with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering IV: app label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                app_id  event_id\n",
      "0  5927333115845830913         2\n",
      "                app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print(app_event[['app_id','event_id']].head(1))\n",
    "print(app_label[['app_id','label_id']].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_label_new:\n",
      "                app_id  label_id    app  label\n",
      "0  7324884708820027918       251  17355    207\n",
      "1 -4494216993218550286       251   4618    207\n",
      "2  6058196446775239644       406  15548    247\n",
      "3  6058196446775239644       407  15548    248\n",
      "4  8694625920731541625       406  18689    247\n"
     ]
    }
   ],
   "source": [
    "app_label_new = app_label.loc[app_label.app_id.isin(app_event.app_id.unique())].copy()\n",
    "app_label_new['app'] = encoder2.transform(app_label_new.app_id)\n",
    "encoder4 = LabelEncoder().fit(app_label_new.label_id)\n",
    "app_label_new['label'] = encoder4.transform(app_label_new.label_id)\n",
    "labelnumber = len(encoder4.classes_)\n",
    "print('app_label_new:')\n",
    "print(app_label_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919886\n",
      "129892268\n",
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_label_grouped:\n",
      "             device_id  label  size\n",
      "0 -9222956879900151005    117     1\n",
      "1 -9222956879900151005    120     1\n",
      "2 -9222956879900151005    126     1\n",
      "3 -9222956879900151005    138     2\n",
      "4 -9222956879900151005    147     2\n"
     ]
    }
   ],
   "source": [
    "print(app_label.size)\n",
    "print(installed_app.size)\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_label_grouped = (installed_app_grouped.reset_index()[['device_id','app']]\n",
    "                          .merge(app_label_new[['app','label']])\n",
    "                          .groupby(['device_id','label']))['app'].agg(['size']).reset_index()\n",
    "                          \n",
    "print('installed_label_grouped:')\n",
    "print(installed_label_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_app_train_with = pd.merge(installed_label_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_on='device_id')\n",
    "label_app_test_with = pd.merge(installed_label_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_on ='device_id' )\n",
    "label_app_train_with = label_app_train_with.dropna(subset= ['int_index','label'])\n",
    "label_app_test_with = label_app_test_with.dropna(subset= ['int_index','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed_with shape: (23309, 492)\n",
      "X_test_installed_with shape: (35194, 492)\n"
     ]
    }
   ],
   "source": [
    "#binary\n",
    "X_train_label_with = csr_matrix((np.ones(label_app_train_with.shape[0]),\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((np.ones(label_app_test_with.shape[0]),(label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))\n",
    "#count\n",
    "'''X_train_label_with = csr_matrix((label_app_train_with['size'],\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((label_app_test_with['size'],\n",
    "                                (label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))'''\n",
    "print('X_train_installed_with shape:',X_train_label_with.shape)\n",
    "print('X_test_installed_with shape:',X_test_label_with.shape)\n",
    "del installed_app_grouped,label,app_label,app_label_new,label_app_test_with,label_app_train_with,encoder4,installed_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering V: active app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  event_id    app  is_active\n",
      "0 -6401643145415154744         2  15408          1\n",
      "3 -6401643145415154744         2   8902          1\n",
      "4 -6401643145415154744         2  18686          1\n",
      "5 -6401643145415154744         2  14346          1\n",
      "9 -6401643145415154744         2  16908          1\n"
     ]
    }
   ],
   "source": [
    "active_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_active']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "active_app = active_app.loc[active_app.is_active==1]\n",
    "print(active_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548      4\n",
      "                     1248    15\n",
      "                     1545     2\n",
      "                     1848    31\n",
      "                     2236    17\n"
     ]
    }
   ],
   "source": [
    "active_app_grouped = active_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('active_app_grouped:')\n",
    "print(active_app_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_app_train_with:\n",
      "                           size  int_index\n",
      "device_id            app                  \n",
      "-9222956879900151005 548      4     5145.0\n",
      "                     1248    15     5145.0\n",
      "                     1545     2     5145.0\n",
      "                     1848    31     5145.0\n",
      "                     2236    17     5145.0\n"
     ]
    }
   ],
   "source": [
    "active_app_train_with = pd.merge(active_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'left',right_index=True,left_index=True)\n",
    "active_app_test_with = pd.merge(active_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'left',right_index=True,left_index=True)\n",
    "print('active_app_train_with:')\n",
    "print(active_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id   app  size  int_index\n",
      "0 -9222956879900151005   548     4     5145.0\n",
      "1 -9222956879900151005  1248    15     5145.0\n",
      "2 -9222956879900151005  1545     2     5145.0\n",
      "3 -9222956879900151005  1848    31     5145.0\n",
      "4 -9222956879900151005  2236    17     5145.0\n",
      "              device_id    app  size  int_index\n",
      "55 -9222661944218806987   1867     3     2851.0\n",
      "56 -9222661944218806987   7519     7     2851.0\n",
      "57 -9222661944218806987   7843     1     2851.0\n",
      "58 -9222661944218806987   8704     3     2851.0\n",
      "59 -9222661944218806987  10000     1     2851.0\n"
     ]
    }
   ],
   "source": [
    "active_app_train_with = active_app_train_with.reset_index()\n",
    "active_app_test_with = active_app_test_with.reset_index()\n",
    "active_app_train_with = active_app_train_with.dropna(subset=['int_index'])\n",
    "active_app_test_with = active_app_test_with.dropna(subset=['int_index'])\n",
    "print(active_app_train_with.head())\n",
    "print(active_app_test_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_active shape: (23309, 19237)\n",
      "X_test_active shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "# binary active map\n",
    "#X_train_active_with = csr_matrix((np.ones(active_app_train_with.shape[0]),\n",
    "#                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "#                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "#X_test_active = csr_matrix((np.ones(active_app_test_with.shape[0]),\n",
    "#                            (active_app_test.int_index,active_app_test_with.app)),\n",
    "#                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "# count the number of active app\n",
    "X_train_active_with = csr_matrix((active_app_train_with['size'],\n",
    "                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_active_with = csr_matrix((active_app_test_with['size'],\n",
    "                            (active_app_test_with.int_index,active_app_test_with.app)),\n",
    "                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_active shape:',X_train_active_with.shape)\n",
    "print('X_test_active shape:',X_test_active_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler(with_mean=False)\\nX_train_active_with = scaler.fit_transform(X_train_active_with)\\nX_test_active_with = scaler.transform(X_test_active_with)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_active_with = scaler.fit_transform(X_train_active_with)\n",
    "X_test_active_with = scaler.transform(X_test_active_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering VI: active time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  time  times\n",
      "0 -9222956879900151005     7      2\n",
      "1 -9222956879900151005    11      7\n",
      "2 -9222956879900151005    12     13\n",
      "3 -9222956879900151005    13      3\n",
      "4 -9222956879900151005    14      5\n"
     ]
    }
   ],
   "source": [
    "events_time = events[['device_id','timestamp']].copy()\n",
    "events_time['time']  = events_time['timestamp'].str[11:13].astype(int)\n",
    "events_time.drop(['timestamp'],axis=1,inplace=True)\n",
    "events_time = events_time.groupby(['device_id','time'])['time'].agg({'times':'count'}).reset_index()\n",
    "print(events_time.head())\n",
    "timenumber= events_time.time.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_time_with shape: (23309, 24)\n",
      "X_test_time_with shape: (35194, 24)\n"
     ]
    }
   ],
   "source": [
    "time_train_with = pd.merge(events_time,gender_age_train_with[['int_index']],\n",
    "                               right_index=True,left_on='device_id')\n",
    "time_test_with = pd.merge(events_time,gender_age_test_with[['int_index']],\n",
    "                               right_index=True,left_on ='device_id' )\n",
    "#binary\n",
    "X_train_time_with = csr_matrix((np.ones(time_train_with.shape[0]),\n",
    "                            (time_train_with.int_index,time_train_with.time)), \n",
    "                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "X_test_time_with = csr_matrix((np.ones(time_test_with.shape[0]),\n",
    "                            (time_test_with.int_index,time_test_with.time)),\n",
    "                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "\n",
    "#number\n",
    "#X_train_time_with = csr_matrix((time_train_with['times'],\n",
    "#                            (time_train_with.int_index,time_train_with.time)), \n",
    "#                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "#X_test_time_with = csr_matrix((time_test_with['times'],\n",
    "#                            (time_test_with.int_index,time_test_with.time)),\n",
    "#                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "print('X_train_time_with shape:',X_train_time_with.shape)\n",
    "print('X_test_time_with shape:',X_test_time_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the time period count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler(with_mean=False)\\nX_train_time_with = scaler.fit_transform(X_train_time_with)\\nX_test_time_with = scaler.transform(X_test_time_with)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_time_with = scaler.fit_transform(X_train_time_with)\n",
    "X_test_time_with = scaler.transform(X_test_time_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature join and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(74645, 1798)\n",
      "Testing shape:\n",
      "(76877, 1798)\n",
      "y shape:\n",
      "(74645, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_without = hstack((X_train_brand_without,X_train_model_without),format='csr')\n",
    "temp_train = hstack((X_train_brand_with,X_train_model_with),format='csr')\n",
    "X_test_total_without = hstack((X_test_brand_without,X_test_model_without),format='csr')\n",
    "\n",
    "X_train_total_without= vstack((X_train_total_without,temp_train),format = 'csr')\n",
    "gender_age_train_without_temp = pd.concat((gender_age_train_without,gender_age_train_with))\n",
    "\n",
    "print('Training shape:')\n",
    "print(X_train_total_without.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_without.shape)\n",
    "print('y shape:')\n",
    "print(gender_age_train_without_temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device with events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(23309, 40788)\n",
      "Testing shape:\n",
      "(35194, 40788)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_with = hstack((X_train_brand_with,X_train_model_with,\n",
    "                             X_train_active_with,\n",
    "                             X_train_time_with,\n",
    "                             X_train_installed_with,X_train_label_with),format='csr')\n",
    "X_test_total_with = hstack((X_test_brand_with,X_test_model_with,\n",
    "                            X_test_active_with,\n",
    "                            X_test_time_with,\n",
    "                           X_test_installed_with,X_test_label_with),format='csr')\n",
    "print('Training shape:')\n",
    "print(X_train_total_with.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentile selction\n",
    "#selector = SelectPercentile(f_classif, percentile=80)\n",
    "#selector.fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#X_val.shape\n",
    "\n",
    "# Selection using chi-square\n",
    "#selector = SelectKBest(chi2, k=15155).fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#print('Training shape:')\n",
    "#print(X_train_total.shape)\n",
    "#print('Testing shape:')\n",
    "#print(X_test_total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear the memory before we do the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del app_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Start training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetencoder = LabelEncoder().fit(gender_age_train_with.group)\n",
    "nclasses = len(targetencoder.classes_)\n",
    "y_train_total_with = targetencoder.transform(gender_age_train_with.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset I: device with events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator \n",
    "    #(https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15"
     ]
    }
   ],
   "source": [
    "def with_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(50, input_dim=X_dim_input, init='normal', activation='tanh'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    model.add(Dense(50, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    #model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "\n",
    "dummy_y_with = np_utils.to_categorical(y_train_total_with)\n",
    "for i in range(8):\n",
    "    kf = StratifiedKFold(y_train_total_with,n_folds = 10,random_state = i)\n",
    "    score_list_with=[]\n",
    "    val_loss_list_with = []\n",
    "    for index,(train, test) in enumerate(kf):\n",
    "        X_train_with = X_train_total_with[train]\n",
    "        y_train_with = dummy_y_with[train]\n",
    "        X_val_with = X_train_total_with[test]\n",
    "        y_val_with = dummy_y_with[test]\n",
    "        #print(X_val.shape)\n",
    "        print('*****************************************************')\n",
    "        print('{}_fold'.format(index))\n",
    "        model=with_model(X_train_total_with.shape[1])\n",
    "        fit= model.fit_generator(generator=batch_generator(X_train_with, y_train_with, 32, True),\n",
    "                             nb_epoch=15,\n",
    "                             samples_per_epoch=30000,\n",
    "                             validation_data=(X_val_with.todense(), y_val_with), verbose=2\n",
    "                             )\n",
    "        scores_val_with = model.predict_generator(generator=batch_generatorp(X_val_with, 32, False), \n",
    "                                             val_samples=X_val_with.shape[0])\n",
    "        scores_with = model.predict_generator(generator=batch_generatorp(X_test_total_with, 32, False), \n",
    "                                         val_samples=X_test_total_with.shape[0])\n",
    "        score_list_with.append(scores_with)\n",
    "        val_loss = log_loss(y_val_with, scores_val_with)\n",
    "        val_loss_list_with.append(val_loss)\n",
    "        print('logloss val {}'.format(val_loss))\n",
    "\n",
    "    for index,i in enumerate(val_loss_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    val_loss_ave_with = sumi/len(val_loss_list_with)\n",
    "    print('average logloss val {}'.format(val_loss_ave_with))\n",
    "    for index,i in enumerate(score_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    score_ave_with = sumi/len(score_list_with)\n",
    "    pred_with = pd.DataFrame(score_ave_with, index = gender_age_test_with.index, columns=targetencoder.classes_)\n",
    "    pred_with.to_csv('nnet_with_all_feature_100relu_softmax{}.csv'.format(val_loss_ave_with))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=1 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=1, score=-2.064379 - 1.6min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=1 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=1, score=-2.065589 - 1.7min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=1 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=1, score=-2.061330 - 1.7min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=2 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=2, score=-2.054633 - 1.6min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:  1.6min\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:  6.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=2 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=2, score=-2.054962 - 1.7min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=2 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=2, score=-2.060082 - 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=3 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=3, score=-2.049457 - 1.6min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=3 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=3, score=-2.050009 - 1.6min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=3 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=3, score=-2.049425 - 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=4 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=4, score=-2.046652 - 1.9min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=4 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=4, score=-2.052939 - 1.7min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=4 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=4, score=-2.049513 - 1.6min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed: 11.4min\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed: 19.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=5 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=5, score=-2.039756 - 1.8min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=5 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=5, score=-2.045774 - 1.6min\n",
      "[CV] learning_rate=0.2, max_depth=7, reg_lambda=5 ....................\n",
      "[CV]  learning_rate=0.2, max_depth=7, reg_lambda=5, score=-2.047903 - 1.7min\n",
      "max_depth7\n",
      "n_estimators100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 24.7min finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'eta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-251e5c1908d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_depth{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_estimators{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eta{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mval_loss_ave_with\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_ave_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'eta'"
     ]
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.02,\n",
    "                                                    stratify=y_train_total_with)\n",
    "#grid search cv\n",
    "xgbclassifier = xgb.XGBClassifier(objective=\"multi:softprob\", nthread=1)\n",
    "\n",
    "clf = GridSearchCV(estimator=xgbclassifier,param_grid={\n",
    "        'max_depth': [ 6,7,8],\n",
    "        'learning_rate': [0.15,0.2,0.25],\n",
    "        'reg_lambda':[4,5],\n",
    "        'reg_alpha':[2,3,4]\n",
    "    },verbose=10,scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_estimator_\n",
    "val_loss_ave_with= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_with)\n",
    "del X_train,X_val,y_train,y_val\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=5,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.44207\ttest-mlogloss:2.45153\n",
      "[1]\ttrain-mlogloss:2.40474\ttest-mlogloss:2.42287\n",
      "[2]\ttrain-mlogloss:2.37107\ttest-mlogloss:2.39937\n",
      "[3]\ttrain-mlogloss:2.34069\ttest-mlogloss:2.37796\n",
      "[4]\ttrain-mlogloss:2.31321\ttest-mlogloss:2.35911\n",
      "[5]\ttrain-mlogloss:2.28735\ttest-mlogloss:2.3429\n",
      "[6]\ttrain-mlogloss:2.26327\ttest-mlogloss:2.32773\n",
      "[7]\ttrain-mlogloss:2.24098\ttest-mlogloss:2.31305\n",
      "[8]\ttrain-mlogloss:2.22053\ttest-mlogloss:2.30016\n",
      "[9]\ttrain-mlogloss:2.20115\ttest-mlogloss:2.28747\n",
      "[10]\ttrain-mlogloss:2.18315\ttest-mlogloss:2.27648\n",
      "[11]\ttrain-mlogloss:2.16617\ttest-mlogloss:2.26617\n",
      "[12]\ttrain-mlogloss:2.14979\ttest-mlogloss:2.25555\n",
      "[13]\ttrain-mlogloss:2.13418\ttest-mlogloss:2.2456\n",
      "[14]\ttrain-mlogloss:2.11917\ttest-mlogloss:2.23704\n",
      "[15]\ttrain-mlogloss:2.10498\ttest-mlogloss:2.23063\n",
      "[16]\ttrain-mlogloss:2.09125\ttest-mlogloss:2.22385\n",
      "[17]\ttrain-mlogloss:2.07768\ttest-mlogloss:2.21584\n",
      "[18]\ttrain-mlogloss:2.06511\ttest-mlogloss:2.21058\n",
      "[19]\ttrain-mlogloss:2.05267\ttest-mlogloss:2.20525\n",
      "[20]\ttrain-mlogloss:2.04125\ttest-mlogloss:2.1995\n",
      "[21]\ttrain-mlogloss:2.03004\ttest-mlogloss:2.19423\n",
      "[22]\ttrain-mlogloss:2.01926\ttest-mlogloss:2.18866\n",
      "[23]\ttrain-mlogloss:2.00834\ttest-mlogloss:2.18315\n",
      "[24]\ttrain-mlogloss:1.99783\ttest-mlogloss:2.18004\n",
      "[25]\ttrain-mlogloss:1.98782\ttest-mlogloss:2.17645\n",
      "[26]\ttrain-mlogloss:1.97831\ttest-mlogloss:2.17265\n",
      "[27]\ttrain-mlogloss:1.96864\ttest-mlogloss:2.16725\n",
      "[28]\ttrain-mlogloss:1.95983\ttest-mlogloss:2.16334\n",
      "[29]\ttrain-mlogloss:1.95132\ttest-mlogloss:2.15795\n",
      "[30]\ttrain-mlogloss:1.94264\ttest-mlogloss:2.15509\n",
      "[31]\ttrain-mlogloss:1.93416\ttest-mlogloss:2.15132\n",
      "[32]\ttrain-mlogloss:1.9261\ttest-mlogloss:2.15008\n",
      "[33]\ttrain-mlogloss:1.91889\ttest-mlogloss:2.14681\n",
      "[34]\ttrain-mlogloss:1.91149\ttest-mlogloss:2.14358\n",
      "[35]\ttrain-mlogloss:1.90428\ttest-mlogloss:2.14127\n",
      "[36]\ttrain-mlogloss:1.89734\ttest-mlogloss:2.13944\n",
      "[37]\ttrain-mlogloss:1.89038\ttest-mlogloss:2.13765\n",
      "[38]\ttrain-mlogloss:1.88339\ttest-mlogloss:2.13474\n",
      "[39]\ttrain-mlogloss:1.87645\ttest-mlogloss:2.13257\n",
      "[40]\ttrain-mlogloss:1.87015\ttest-mlogloss:2.13099\n",
      "[41]\ttrain-mlogloss:1.86326\ttest-mlogloss:2.12843\n",
      "[42]\ttrain-mlogloss:1.857\ttest-mlogloss:2.12663\n",
      "[43]\ttrain-mlogloss:1.85062\ttest-mlogloss:2.12458\n",
      "[44]\ttrain-mlogloss:1.8446\ttest-mlogloss:2.12296\n",
      "[45]\ttrain-mlogloss:1.8384\ttest-mlogloss:2.1216\n",
      "[46]\ttrain-mlogloss:1.83267\ttest-mlogloss:2.11933\n",
      "[47]\ttrain-mlogloss:1.82708\ttest-mlogloss:2.11754\n",
      "[48]\ttrain-mlogloss:1.8213\ttest-mlogloss:2.11758\n",
      "[49]\ttrain-mlogloss:1.81564\ttest-mlogloss:2.11498\n",
      "[50]\ttrain-mlogloss:1.8097\ttest-mlogloss:2.11375\n",
      "[51]\ttrain-mlogloss:1.80421\ttest-mlogloss:2.11261\n",
      "[52]\ttrain-mlogloss:1.79874\ttest-mlogloss:2.11244\n",
      "[53]\ttrain-mlogloss:1.79348\ttest-mlogloss:2.11177\n",
      "[54]\ttrain-mlogloss:1.78811\ttest-mlogloss:2.11111\n",
      "[55]\ttrain-mlogloss:1.78344\ttest-mlogloss:2.11018\n",
      "[56]\ttrain-mlogloss:1.77836\ttest-mlogloss:2.1092\n",
      "[57]\ttrain-mlogloss:1.77345\ttest-mlogloss:2.10857\n",
      "[58]\ttrain-mlogloss:1.76849\ttest-mlogloss:2.10783\n",
      "[59]\ttrain-mlogloss:1.76447\ttest-mlogloss:2.10758\n",
      "[60]\ttrain-mlogloss:1.75965\ttest-mlogloss:2.10612\n",
      "[61]\ttrain-mlogloss:1.75517\ttest-mlogloss:2.10413\n",
      "[62]\ttrain-mlogloss:1.75075\ttest-mlogloss:2.10259\n",
      "[63]\ttrain-mlogloss:1.74644\ttest-mlogloss:2.10198\n",
      "[64]\ttrain-mlogloss:1.74175\ttest-mlogloss:2.1\n",
      "[65]\ttrain-mlogloss:1.73785\ttest-mlogloss:2.09942\n",
      "[66]\ttrain-mlogloss:1.73392\ttest-mlogloss:2.0986\n",
      "[67]\ttrain-mlogloss:1.73005\ttest-mlogloss:2.09777\n",
      "[68]\ttrain-mlogloss:1.72606\ttest-mlogloss:2.09682\n",
      "[69]\ttrain-mlogloss:1.72212\ttest-mlogloss:2.0962\n",
      "[70]\ttrain-mlogloss:1.71777\ttest-mlogloss:2.09602\n",
      "[71]\ttrain-mlogloss:1.71356\ttest-mlogloss:2.09564\n",
      "[72]\ttrain-mlogloss:1.70972\ttest-mlogloss:2.09526\n",
      "[73]\ttrain-mlogloss:1.706\ttest-mlogloss:2.0954\n",
      "[74]\ttrain-mlogloss:1.70241\ttest-mlogloss:2.09298\n",
      "[75]\ttrain-mlogloss:1.69834\ttest-mlogloss:2.09339\n",
      "[76]\ttrain-mlogloss:1.6945\ttest-mlogloss:2.09299\n",
      "[77]\ttrain-mlogloss:1.69052\ttest-mlogloss:2.09179\n",
      "[78]\ttrain-mlogloss:1.68684\ttest-mlogloss:2.09099\n",
      "[79]\ttrain-mlogloss:1.68334\ttest-mlogloss:2.09016\n",
      "[80]\ttrain-mlogloss:1.67967\ttest-mlogloss:2.09009\n",
      "[81]\ttrain-mlogloss:1.67647\ttest-mlogloss:2.09072\n",
      "[82]\ttrain-mlogloss:1.67328\ttest-mlogloss:2.08946\n",
      "[83]\ttrain-mlogloss:1.66963\ttest-mlogloss:2.08777\n",
      "[84]\ttrain-mlogloss:1.66642\ttest-mlogloss:2.08752\n",
      "[85]\ttrain-mlogloss:1.66296\ttest-mlogloss:2.08705\n",
      "[86]\ttrain-mlogloss:1.65927\ttest-mlogloss:2.08625\n",
      "[87]\ttrain-mlogloss:1.65607\ttest-mlogloss:2.08535\n",
      "[88]\ttrain-mlogloss:1.65288\ttest-mlogloss:2.08533\n",
      "[89]\ttrain-mlogloss:1.64973\ttest-mlogloss:2.08473\n",
      "[90]\ttrain-mlogloss:1.64658\ttest-mlogloss:2.08347\n",
      "[91]\ttrain-mlogloss:1.64321\ttest-mlogloss:2.08193\n",
      "[92]\ttrain-mlogloss:1.64017\ttest-mlogloss:2.08217\n",
      "[93]\ttrain-mlogloss:1.63705\ttest-mlogloss:2.0803\n",
      "[94]\ttrain-mlogloss:1.63385\ttest-mlogloss:2.08056\n",
      "[95]\ttrain-mlogloss:1.63096\ttest-mlogloss:2.07937\n",
      "[96]\ttrain-mlogloss:1.6277\ttest-mlogloss:2.0786\n",
      "[97]\ttrain-mlogloss:1.62483\ttest-mlogloss:2.07817\n",
      "[98]\ttrain-mlogloss:1.62196\ttest-mlogloss:2.07754\n",
      "[99]\ttrain-mlogloss:1.61916\ttest-mlogloss:2.07667\n",
      "[100]\ttrain-mlogloss:1.61614\ttest-mlogloss:2.07659\n",
      "[101]\ttrain-mlogloss:1.61329\ttest-mlogloss:2.07594\n",
      "[102]\ttrain-mlogloss:1.61031\ttest-mlogloss:2.07575\n",
      "[103]\ttrain-mlogloss:1.60731\ttest-mlogloss:2.07509\n",
      "[104]\ttrain-mlogloss:1.60445\ttest-mlogloss:2.07487\n",
      "[105]\ttrain-mlogloss:1.60182\ttest-mlogloss:2.07538\n",
      "[106]\ttrain-mlogloss:1.59931\ttest-mlogloss:2.07477\n",
      "[107]\ttrain-mlogloss:1.59652\ttest-mlogloss:2.0744\n",
      "[108]\ttrain-mlogloss:1.59388\ttest-mlogloss:2.07408\n",
      "[109]\ttrain-mlogloss:1.59095\ttest-mlogloss:2.07284\n",
      "[110]\ttrain-mlogloss:1.58808\ttest-mlogloss:2.07245\n",
      "[111]\ttrain-mlogloss:1.58565\ttest-mlogloss:2.07154\n",
      "[112]\ttrain-mlogloss:1.58315\ttest-mlogloss:2.07074\n",
      "[113]\ttrain-mlogloss:1.57982\ttest-mlogloss:2.07023\n",
      "[114]\ttrain-mlogloss:1.57702\ttest-mlogloss:2.0704\n",
      "[115]\ttrain-mlogloss:1.57464\ttest-mlogloss:2.07023\n",
      "[116]\ttrain-mlogloss:1.57234\ttest-mlogloss:2.0699\n",
      "[117]\ttrain-mlogloss:1.56998\ttest-mlogloss:2.0696\n",
      "[118]\ttrain-mlogloss:1.56689\ttest-mlogloss:2.06956\n",
      "[119]\ttrain-mlogloss:1.56464\ttest-mlogloss:2.06984\n",
      "[120]\ttrain-mlogloss:1.56216\ttest-mlogloss:2.06936\n",
      "[121]\ttrain-mlogloss:1.55966\ttest-mlogloss:2.0681\n",
      "[122]\ttrain-mlogloss:1.55735\ttest-mlogloss:2.06821\n",
      "[123]\ttrain-mlogloss:1.55494\ttest-mlogloss:2.06851\n",
      "[124]\ttrain-mlogloss:1.55228\ttest-mlogloss:2.06857\n",
      "[125]\ttrain-mlogloss:1.54944\ttest-mlogloss:2.06833\n",
      "[126]\ttrain-mlogloss:1.54735\ttest-mlogloss:2.06875\n",
      "[127]\ttrain-mlogloss:1.5451\ttest-mlogloss:2.06792\n",
      "[128]\ttrain-mlogloss:1.54258\ttest-mlogloss:2.06756\n",
      "[129]\ttrain-mlogloss:1.54049\ttest-mlogloss:2.067\n",
      "[130]\ttrain-mlogloss:1.53824\ttest-mlogloss:2.0664\n",
      "[131]\ttrain-mlogloss:1.53608\ttest-mlogloss:2.06637\n",
      "[132]\ttrain-mlogloss:1.53378\ttest-mlogloss:2.06623\n",
      "[133]\ttrain-mlogloss:1.5315\ttest-mlogloss:2.06609\n",
      "[134]\ttrain-mlogloss:1.52949\ttest-mlogloss:2.06561\n",
      "[135]\ttrain-mlogloss:1.5271\ttest-mlogloss:2.06481\n",
      "[136]\ttrain-mlogloss:1.52496\ttest-mlogloss:2.0644\n",
      "[137]\ttrain-mlogloss:1.52266\ttest-mlogloss:2.06432\n",
      "[138]\ttrain-mlogloss:1.52042\ttest-mlogloss:2.0639\n",
      "[139]\ttrain-mlogloss:1.51808\ttest-mlogloss:2.06372\n",
      "[140]\ttrain-mlogloss:1.51563\ttest-mlogloss:2.06306\n",
      "[141]\ttrain-mlogloss:1.51343\ttest-mlogloss:2.06265\n",
      "[142]\ttrain-mlogloss:1.5115\ttest-mlogloss:2.06323\n",
      "[143]\ttrain-mlogloss:1.50952\ttest-mlogloss:2.06304\n",
      "[144]\ttrain-mlogloss:1.5073\ttest-mlogloss:2.06255\n",
      "[145]\ttrain-mlogloss:1.50493\ttest-mlogloss:2.06244\n",
      "[146]\ttrain-mlogloss:1.503\ttest-mlogloss:2.06273\n",
      "[147]\ttrain-mlogloss:1.50081\ttest-mlogloss:2.06198\n",
      "[148]\ttrain-mlogloss:1.4989\ttest-mlogloss:2.06175\n",
      "[149]\ttrain-mlogloss:1.49652\ttest-mlogloss:2.06164\n",
      "[150]\ttrain-mlogloss:1.49437\ttest-mlogloss:2.06052\n",
      "[151]\ttrain-mlogloss:1.4921\ttest-mlogloss:2.05998\n",
      "[152]\ttrain-mlogloss:1.48994\ttest-mlogloss:2.05993\n",
      "[153]\ttrain-mlogloss:1.48787\ttest-mlogloss:2.05966\n",
      "[154]\ttrain-mlogloss:1.48589\ttest-mlogloss:2.05957\n",
      "[155]\ttrain-mlogloss:1.48416\ttest-mlogloss:2.05897\n",
      "[156]\ttrain-mlogloss:1.48226\ttest-mlogloss:2.05813\n",
      "[157]\ttrain-mlogloss:1.4803\ttest-mlogloss:2.05846\n",
      "[158]\ttrain-mlogloss:1.47851\ttest-mlogloss:2.05792\n",
      "[159]\ttrain-mlogloss:1.47649\ttest-mlogloss:2.05784\n",
      "[160]\ttrain-mlogloss:1.47435\ttest-mlogloss:2.05716\n",
      "[161]\ttrain-mlogloss:1.47248\ttest-mlogloss:2.05724\n",
      "[162]\ttrain-mlogloss:1.47043\ttest-mlogloss:2.05703\n",
      "[163]\ttrain-mlogloss:1.46852\ttest-mlogloss:2.05705\n",
      "[164]\ttrain-mlogloss:1.46661\ttest-mlogloss:2.05739\n",
      "[165]\ttrain-mlogloss:1.46485\ttest-mlogloss:2.05688\n",
      "[166]\ttrain-mlogloss:1.46314\ttest-mlogloss:2.05659\n",
      "[167]\ttrain-mlogloss:1.46116\ttest-mlogloss:2.05651\n",
      "[168]\ttrain-mlogloss:1.45876\ttest-mlogloss:2.05671\n",
      "[169]\ttrain-mlogloss:1.45683\ttest-mlogloss:2.05635\n",
      "[170]\ttrain-mlogloss:1.45536\ttest-mlogloss:2.05581\n",
      "[171]\ttrain-mlogloss:1.45334\ttest-mlogloss:2.05599\n",
      "[172]\ttrain-mlogloss:1.45156\ttest-mlogloss:2.05541\n",
      "[173]\ttrain-mlogloss:1.44954\ttest-mlogloss:2.05523\n",
      "[174]\ttrain-mlogloss:1.44729\ttest-mlogloss:2.05478\n",
      "[175]\ttrain-mlogloss:1.44541\ttest-mlogloss:2.05458\n",
      "[176]\ttrain-mlogloss:1.44373\ttest-mlogloss:2.05416\n",
      "[177]\ttrain-mlogloss:1.44191\ttest-mlogloss:2.05405\n",
      "[178]\ttrain-mlogloss:1.44015\ttest-mlogloss:2.05453\n",
      "[179]\ttrain-mlogloss:1.43809\ttest-mlogloss:2.05421\n",
      "[180]\ttrain-mlogloss:1.43638\ttest-mlogloss:2.05379\n",
      "[181]\ttrain-mlogloss:1.43459\ttest-mlogloss:2.05377\n",
      "[182]\ttrain-mlogloss:1.43286\ttest-mlogloss:2.05342\n",
      "[183]\ttrain-mlogloss:1.43141\ttest-mlogloss:2.05321\n",
      "[184]\ttrain-mlogloss:1.42958\ttest-mlogloss:2.05302\n",
      "[185]\ttrain-mlogloss:1.4279\ttest-mlogloss:2.05352\n",
      "[186]\ttrain-mlogloss:1.42603\ttest-mlogloss:2.05299\n",
      "[187]\ttrain-mlogloss:1.42437\ttest-mlogloss:2.0528\n",
      "[188]\ttrain-mlogloss:1.42257\ttest-mlogloss:2.05257\n",
      "[189]\ttrain-mlogloss:1.42099\ttest-mlogloss:2.05266\n",
      "[190]\ttrain-mlogloss:1.41925\ttest-mlogloss:2.05311\n",
      "[191]\ttrain-mlogloss:1.41758\ttest-mlogloss:2.05289\n",
      "[192]\ttrain-mlogloss:1.41594\ttest-mlogloss:2.05274\n",
      "[193]\ttrain-mlogloss:1.4142\ttest-mlogloss:2.053\n",
      "[194]\ttrain-mlogloss:1.41229\ttest-mlogloss:2.05256\n",
      "[195]\ttrain-mlogloss:1.4105\ttest-mlogloss:2.05228\n",
      "[196]\ttrain-mlogloss:1.40888\ttest-mlogloss:2.05238\n",
      "[197]\ttrain-mlogloss:1.40679\ttest-mlogloss:2.05216\n",
      "[198]\ttrain-mlogloss:1.40551\ttest-mlogloss:2.05195\n",
      "[199]\ttrain-mlogloss:1.40416\ttest-mlogloss:2.0519\n",
      "[200]\ttrain-mlogloss:1.40254\ttest-mlogloss:2.05235\n",
      "[201]\ttrain-mlogloss:1.40087\ttest-mlogloss:2.05214\n",
      "[202]\ttrain-mlogloss:1.39917\ttest-mlogloss:2.05201\n",
      "[203]\ttrain-mlogloss:1.39749\ttest-mlogloss:2.05223\n",
      "[204]\ttrain-mlogloss:1.39569\ttest-mlogloss:2.05166\n",
      "[205]\ttrain-mlogloss:1.3943\ttest-mlogloss:2.05158\n",
      "[206]\ttrain-mlogloss:1.39263\ttest-mlogloss:2.05093\n",
      "[207]\ttrain-mlogloss:1.39117\ttest-mlogloss:2.05111\n",
      "[208]\ttrain-mlogloss:1.38972\ttest-mlogloss:2.05153\n",
      "[209]\ttrain-mlogloss:1.38816\ttest-mlogloss:2.05155\n",
      "[210]\ttrain-mlogloss:1.38624\ttest-mlogloss:2.05167\n",
      "[211]\ttrain-mlogloss:1.38486\ttest-mlogloss:2.05145\n",
      "[212]\ttrain-mlogloss:1.3834\ttest-mlogloss:2.05088\n",
      "[213]\ttrain-mlogloss:1.38197\ttest-mlogloss:2.05077\n",
      "[214]\ttrain-mlogloss:1.38037\ttest-mlogloss:2.05034\n",
      "[215]\ttrain-mlogloss:1.37878\ttest-mlogloss:2.05034\n",
      "[216]\ttrain-mlogloss:1.37717\ttest-mlogloss:2.05077\n",
      "[217]\ttrain-mlogloss:1.37561\ttest-mlogloss:2.05049\n",
      "[218]\ttrain-mlogloss:1.37404\ttest-mlogloss:2.05019\n",
      "[219]\ttrain-mlogloss:1.37279\ttest-mlogloss:2.0497\n",
      "[220]\ttrain-mlogloss:1.37143\ttest-mlogloss:2.04988\n",
      "[221]\ttrain-mlogloss:1.36988\ttest-mlogloss:2.05039\n",
      "[222]\ttrain-mlogloss:1.36855\ttest-mlogloss:2.05073\n",
      "[223]\ttrain-mlogloss:1.36702\ttest-mlogloss:2.05069\n",
      "[224]\ttrain-mlogloss:1.36565\ttest-mlogloss:2.05042\n",
      "[225]\ttrain-mlogloss:1.36424\ttest-mlogloss:2.05002\n",
      "[226]\ttrain-mlogloss:1.36294\ttest-mlogloss:2.04992\n",
      "[227]\ttrain-mlogloss:1.36155\ttest-mlogloss:2.04939\n",
      "[228]\ttrain-mlogloss:1.36\ttest-mlogloss:2.04956\n",
      "[229]\ttrain-mlogloss:1.35866\ttest-mlogloss:2.04906\n",
      "[230]\ttrain-mlogloss:1.35718\ttest-mlogloss:2.04876\n",
      "[231]\ttrain-mlogloss:1.35594\ttest-mlogloss:2.04898\n",
      "[232]\ttrain-mlogloss:1.35436\ttest-mlogloss:2.0491\n",
      "[233]\ttrain-mlogloss:1.35287\ttest-mlogloss:2.04918\n",
      "[234]\ttrain-mlogloss:1.35128\ttest-mlogloss:2.0492\n",
      "[235]\ttrain-mlogloss:1.34975\ttest-mlogloss:2.04879\n",
      "[236]\ttrain-mlogloss:1.34827\ttest-mlogloss:2.04876\n",
      "[237]\ttrain-mlogloss:1.34701\ttest-mlogloss:2.04872\n",
      "[238]\ttrain-mlogloss:1.34564\ttest-mlogloss:2.04847\n",
      "[239]\ttrain-mlogloss:1.34442\ttest-mlogloss:2.04876\n",
      "[240]\ttrain-mlogloss:1.34296\ttest-mlogloss:2.04841\n",
      "[241]\ttrain-mlogloss:1.34156\ttest-mlogloss:2.04867\n",
      "[242]\ttrain-mlogloss:1.34029\ttest-mlogloss:2.0489\n",
      "[243]\ttrain-mlogloss:1.33883\ttest-mlogloss:2.04902\n",
      "[244]\ttrain-mlogloss:1.33767\ttest-mlogloss:2.04878\n",
      "[245]\ttrain-mlogloss:1.33638\ttest-mlogloss:2.04926\n",
      "[246]\ttrain-mlogloss:1.33505\ttest-mlogloss:2.04901\n",
      "[247]\ttrain-mlogloss:1.33374\ttest-mlogloss:2.04825\n",
      "[248]\ttrain-mlogloss:1.33244\ttest-mlogloss:2.04809\n",
      "[249]\ttrain-mlogloss:1.3311\ttest-mlogloss:2.04816\n",
      "[250]\ttrain-mlogloss:1.32996\ttest-mlogloss:2.04818\n",
      "[251]\ttrain-mlogloss:1.32865\ttest-mlogloss:2.04807\n",
      "[252]\ttrain-mlogloss:1.32731\ttest-mlogloss:2.04798\n",
      "[253]\ttrain-mlogloss:1.32594\ttest-mlogloss:2.04774\n",
      "[254]\ttrain-mlogloss:1.32452\ttest-mlogloss:2.04748\n",
      "[255]\ttrain-mlogloss:1.3233\ttest-mlogloss:2.04771\n",
      "[256]\ttrain-mlogloss:1.32216\ttest-mlogloss:2.04794\n",
      "[257]\ttrain-mlogloss:1.32082\ttest-mlogloss:2.0479\n",
      "[258]\ttrain-mlogloss:1.31931\ttest-mlogloss:2.04786\n",
      "[259]\ttrain-mlogloss:1.31802\ttest-mlogloss:2.04732\n",
      "[260]\ttrain-mlogloss:1.31658\ttest-mlogloss:2.04788\n",
      "[261]\ttrain-mlogloss:1.31488\ttest-mlogloss:2.04805\n",
      "[262]\ttrain-mlogloss:1.31366\ttest-mlogloss:2.04842\n",
      "[263]\ttrain-mlogloss:1.31228\ttest-mlogloss:2.04824\n",
      "[264]\ttrain-mlogloss:1.31108\ttest-mlogloss:2.04817\n",
      "[265]\ttrain-mlogloss:1.30992\ttest-mlogloss:2.04776\n",
      "[266]\ttrain-mlogloss:1.3087\ttest-mlogloss:2.04774\n",
      "[267]\ttrain-mlogloss:1.30738\ttest-mlogloss:2.04751\n",
      "[268]\ttrain-mlogloss:1.30585\ttest-mlogloss:2.04708\n",
      "[269]\ttrain-mlogloss:1.30426\ttest-mlogloss:2.04657\n",
      "[270]\ttrain-mlogloss:1.30291\ttest-mlogloss:2.04631\n",
      "[271]\ttrain-mlogloss:1.30182\ttest-mlogloss:2.04631\n",
      "[272]\ttrain-mlogloss:1.30045\ttest-mlogloss:2.04631\n",
      "[273]\ttrain-mlogloss:1.29903\ttest-mlogloss:2.04603\n",
      "[274]\ttrain-mlogloss:1.29769\ttest-mlogloss:2.04621\n",
      "[275]\ttrain-mlogloss:1.29657\ttest-mlogloss:2.0463\n",
      "[276]\ttrain-mlogloss:1.29533\ttest-mlogloss:2.0463\n",
      "[277]\ttrain-mlogloss:1.29405\ttest-mlogloss:2.04608\n",
      "[278]\ttrain-mlogloss:1.29289\ttest-mlogloss:2.04595\n",
      "[279]\ttrain-mlogloss:1.29165\ttest-mlogloss:2.04635\n",
      "[280]\ttrain-mlogloss:1.29033\ttest-mlogloss:2.04666\n",
      "[281]\ttrain-mlogloss:1.28918\ttest-mlogloss:2.047\n",
      "[282]\ttrain-mlogloss:1.28777\ttest-mlogloss:2.04797\n",
      "[283]\ttrain-mlogloss:1.28664\ttest-mlogloss:2.04789\n",
      "[284]\ttrain-mlogloss:1.28544\ttest-mlogloss:2.04779\n",
      "[285]\ttrain-mlogloss:1.28404\ttest-mlogloss:2.04725\n",
      "[286]\ttrain-mlogloss:1.28292\ttest-mlogloss:2.04739\n",
      "[287]\ttrain-mlogloss:1.28177\ttest-mlogloss:2.04828\n",
      "[288]\ttrain-mlogloss:1.28051\ttest-mlogloss:2.04811\n",
      "[289]\ttrain-mlogloss:1.27937\ttest-mlogloss:2.04804\n",
      "[290]\ttrain-mlogloss:1.27824\ttest-mlogloss:2.04797\n",
      "[291]\ttrain-mlogloss:1.27731\ttest-mlogloss:2.0478\n",
      "[292]\ttrain-mlogloss:1.27612\ttest-mlogloss:2.04773\n",
      "[293]\ttrain-mlogloss:1.27498\ttest-mlogloss:2.04761\n",
      "[294]\ttrain-mlogloss:1.27384\ttest-mlogloss:2.04747\n",
      "[295]\ttrain-mlogloss:1.27257\ttest-mlogloss:2.04769\n",
      "[296]\ttrain-mlogloss:1.27145\ttest-mlogloss:2.04776\n",
      "[297]\ttrain-mlogloss:1.27017\ttest-mlogloss:2.04794\n",
      "[298]\ttrain-mlogloss:1.269\ttest-mlogloss:2.04773\n",
      "[299]\ttrain-mlogloss:1.26767\ttest-mlogloss:2.04743\n",
      "logloss val 2.047430712538652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.02,\n",
    "                                                    stratify=y_train_total_with,random_state=1)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':6,\n",
    "         'eta':0.1,\n",
    "         'silent':0,\n",
    "         'objective':'multi:softprob',\n",
    "         'nthread':2,\n",
    "         'num_class':12,\n",
    "         'eval_metric':'mlogloss',\n",
    "        'lambda':5,\n",
    "        'lambda_bias':0,\n",
    "        'alpha':1}\n",
    "num_round = 300\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training with all data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train_total_with,label = y_train_total_with)\n",
    "xg_test = xgb.DMatrix(X_test_total_with)\n",
    "bst = xgb.train(param,xg_train,num_round)\n",
    "yprob = bst.predict(xg_test).reshape(X_test_total_with.shape[0],12)\n",
    "pred_with_xgb = pd.DataFrame(yprob, \n",
    "                            index = gender_age_test_with.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_with_xgb.to_csv('xgb_with_result{}.csv'.format(val_loss))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0180472176683\n",
      "lbfgs\n",
      "1.98424599635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yuyang/anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_with)\n",
    "#lr grid search\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['lbfgs']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_with= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_with)\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.0180472176683,multi_class='multinomial',solver='lbfgs')\n",
    "lr.fit(X_train_total_with,y_train_total_with)\n",
    "score_ave_with_lr = lr.predict_proba(X_test_total_with)\n",
    "pred_with_lr = pd.DataFrame(score_ave_with_lr, \n",
    "                            index = gender_age_test_with.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_with_lr.to_csv('lr_with_result{}.csv'.format(val_loss_ave_with))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset II: device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_total_without = targetencoder.transform(gender_age_train_without_temp.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Device without eventsI: Naive Bayes, Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204.50354026\n",
      "2.42330723892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#NB grid search\n",
    "nbc = MultinomialNB()\n",
    "alpha_value = np.logspace(-3,4,100)\n",
    "clf = GridSearchCV(estimator=nbc,param_grid = dict(alpha=alpha_value),scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.alpha)\n",
    "print(-clf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-65573d0eebbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#lr grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m (X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.2,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                     stratify=y_train_total_without)\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msolver_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "#lr grid search\n",
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.2,\n",
    "                                                    stratify=y_train_total_without)\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['lbfgs']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_without= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_without)\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(C=0.02,multi_class='multinomial',solver='newton-cg')\n",
    "lr = LogisticRegression(C=0.0744380301325,multi_class='multinomial',solver='lbfgs')\n",
    "lr.fit(X_train_total_without,y_train_total_without)\n",
    "score_ave_without_lr = lr.predict_proba(X_test_total_without)\n",
    "pred_without_lr = pd.DataFrame(score_ave_without_lr, \n",
    "                            index = gender_age_test_without.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_without_lr.to_csv('lr_without_result{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\\nscore_list_without=[]\\nval_loss_list_without = []\\nfor index,(train, test) in enumerate(kf):\\n    X_train_without = X_train_total_without[train]\\n    y_train_without = y_train_total_without[train]\\n    X_val_without = X_train_total_without[test]\\n    y_val_without = y_train_total_without[test]\\n    print('*****************************************************')\\n    print('{}_fold'.format(index))\\n    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\\n    lr.fit(X_train_without,y_train_without)\\n    scores_val_without = lr.predict_proba(X_val_without)\\n    val_loss = log_loss(y_val_without, scores_val_without)\\n    val_loss_list_without.append(val_loss)\\n    print('logloss val {}'.format(val_loss))\\n    \\n    scores_without = lr.predict_proba(X_test_total_without)\\n    score_list_without.append(scores_without)\\n    \\nfor index,i in enumerate(val_loss_list_without):\\n    if(index==0):\\n        sumi = i\\n    else:\\n        sumi = i+sumi\\nval_loss_ave_without = sumi/len(score_list_without)\\nprint('average logloss val {}'.format(val_loss_ave_without))\\nfor index,i in enumerate(score_list_without):\\n    if(index==0):\\n        sumi = i\\n    else:\\n        sumi = i+sumi\\nscore_ave_without = sumi/len(score_list_without)\\npred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\n",
    "score_list_without=[]\n",
    "val_loss_list_without = []\n",
    "for index,(train, test) in enumerate(kf):\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = y_train_total_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = y_train_total_without[test]\n",
    "    print('*****************************************************')\n",
    "    print('{}_fold'.format(index))\n",
    "    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\n",
    "    lr.fit(X_train_without,y_train_without)\n",
    "    scores_val_without = lr.predict_proba(X_val_without)\n",
    "    val_loss = log_loss(y_val_without, scores_val_without)\n",
    "    val_loss_list_without.append(val_loss)\n",
    "    print('logloss val {}'.format(val_loss))\n",
    "    \n",
    "    scores_without = lr.predict_proba(X_test_total_without)\n",
    "    score_list_without.append(scores_without)\n",
    "    \n",
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(score_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without eventsII: Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4464 - acc: 0.1318 - val_loss: 2.4206 - val_acc: 0.1419\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4102 - acc: 0.1441 - val_loss: 2.4120 - val_acc: 0.1411\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4013 - acc: 0.1476 - val_loss: 2.4095 - val_acc: 0.1367\n",
      "Epoch 4/20\n",
      "6s - loss: 2.3972 - acc: 0.1513 - val_loss: 2.4085 - val_acc: 0.1391\n",
      "Epoch 5/20\n",
      "7s - loss: 2.3945 - acc: 0.1538 - val_loss: 2.4078 - val_acc: 0.1394\n",
      "Epoch 6/20\n",
      "6s - loss: 2.3913 - acc: 0.1542 - val_loss: 2.4073 - val_acc: 0.1379\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3913 - acc: 0.1564 - val_loss: 2.4065 - val_acc: 0.1410\n",
      "Epoch 8/20\n",
      "6s - loss: 2.3871 - acc: 0.1591 - val_loss: 2.4065 - val_acc: 0.1441\n",
      "Epoch 9/20\n",
      "6s - loss: 2.3855 - acc: 0.1595 - val_loss: 2.4064 - val_acc: 0.1419\n",
      "Epoch 10/20\n",
      "6s - loss: 2.3854 - acc: 0.1595 - val_loss: 2.4065 - val_acc: 0.1429\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3828 - acc: 0.1615 - val_loss: 2.4058 - val_acc: 0.1429\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3807 - acc: 0.1622 - val_loss: 2.4062 - val_acc: 0.1437\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3790 - acc: 0.1628 - val_loss: 2.4061 - val_acc: 0.1445\n",
      "Epoch 14/20\n",
      "6s - loss: 2.3799 - acc: 0.1621 - val_loss: 2.4062 - val_acc: 0.1422\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3756 - acc: 0.1637 - val_loss: 2.4059 - val_acc: 0.1426\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3757 - acc: 0.1638 - val_loss: 2.4063 - val_acc: 0.1426\n",
      "Epoch 17/20\n",
      "6s - loss: 2.3740 - acc: 0.1648 - val_loss: 2.4064 - val_acc: 0.1443\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3713 - acc: 0.1665 - val_loss: 2.4064 - val_acc: 0.1435\n",
      "Epoch 19/20\n",
      "6s - loss: 2.3722 - acc: 0.1669 - val_loss: 2.4070 - val_acc: 0.1422\n",
      "Epoch 20/20\n",
      "6s - loss: 2.3689 - acc: 0.1668 - val_loss: 2.4075 - val_acc: 0.1437\n",
      "logloss val 2.4075005667229594\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4460 - acc: 0.1332 - val_loss: 2.4181 - val_acc: 0.1445\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4104 - acc: 0.1449 - val_loss: 2.4072 - val_acc: 0.1457\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4020 - acc: 0.1474 - val_loss: 2.4027 - val_acc: 0.1513\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3984 - acc: 0.1479 - val_loss: 2.4002 - val_acc: 0.1525\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3971 - acc: 0.1514 - val_loss: 2.3986 - val_acc: 0.1516\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3928 - acc: 0.1552 - val_loss: 2.3972 - val_acc: 0.1519\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3910 - acc: 0.1555 - val_loss: 2.3966 - val_acc: 0.1558\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3917 - acc: 0.1547 - val_loss: 2.3958 - val_acc: 0.1549\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3882 - acc: 0.1573 - val_loss: 2.3950 - val_acc: 0.1537\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3863 - acc: 0.1584 - val_loss: 2.3943 - val_acc: 0.1540\n",
      "Epoch 11/20\n",
      "6s - loss: 2.3849 - acc: 0.1587 - val_loss: 2.3939 - val_acc: 0.1560\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3831 - acc: 0.1608 - val_loss: 2.3933 - val_acc: 0.1562\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3820 - acc: 0.1599 - val_loss: 2.3929 - val_acc: 0.1556\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3802 - acc: 0.1613 - val_loss: 2.3928 - val_acc: 0.1552\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3793 - acc: 0.1623 - val_loss: 2.3923 - val_acc: 0.1556\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3774 - acc: 0.1633 - val_loss: 2.3926 - val_acc: 0.1594\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3757 - acc: 0.1643 - val_loss: 2.3921 - val_acc: 0.1578\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3759 - acc: 0.1637 - val_loss: 2.3920 - val_acc: 0.1584\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3739 - acc: 0.1642 - val_loss: 2.3916 - val_acc: 0.1584\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3712 - acc: 0.1670 - val_loss: 2.3917 - val_acc: 0.1584\n",
      "logloss val 2.3917190370668013\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4452 - acc: 0.1309 - val_loss: 2.4208 - val_acc: 0.1395\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4120 - acc: 0.1428 - val_loss: 2.4098 - val_acc: 0.1412\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4047 - acc: 0.1458 - val_loss: 2.4045 - val_acc: 0.1433\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3978 - acc: 0.1496 - val_loss: 2.4019 - val_acc: 0.1513\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3954 - acc: 0.1525 - val_loss: 2.4001 - val_acc: 0.1560\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3925 - acc: 0.1549 - val_loss: 2.3986 - val_acc: 0.1539\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3921 - acc: 0.1539 - val_loss: 2.3975 - val_acc: 0.1547\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3900 - acc: 0.1571 - val_loss: 2.3966 - val_acc: 0.1533\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3882 - acc: 0.1576 - val_loss: 2.3961 - val_acc: 0.1568\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3865 - acc: 0.1579 - val_loss: 2.3952 - val_acc: 0.1575\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3837 - acc: 0.1599 - val_loss: 2.3948 - val_acc: 0.1596\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3839 - acc: 0.1599 - val_loss: 2.3945 - val_acc: 0.1594\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3814 - acc: 0.1602 - val_loss: 2.3941 - val_acc: 0.1602\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3807 - acc: 0.1618 - val_loss: 2.3937 - val_acc: 0.1616\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3781 - acc: 0.1621 - val_loss: 2.3935 - val_acc: 0.1616\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3768 - acc: 0.1640 - val_loss: 2.3934 - val_acc: 0.1612\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3744 - acc: 0.1646 - val_loss: 2.3935 - val_acc: 0.1635\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3754 - acc: 0.1643 - val_loss: 2.3932 - val_acc: 0.1603\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3737 - acc: 0.1649 - val_loss: 2.3933 - val_acc: 0.1633\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3714 - acc: 0.1664 - val_loss: 2.3934 - val_acc: 0.1622\n",
      "logloss val 2.3933663555021427\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4441 - acc: 0.1286 - val_loss: 2.4199 - val_acc: 0.1412\n",
      "Epoch 2/20\n",
      "6s - loss: 2.4097 - acc: 0.1456 - val_loss: 2.4109 - val_acc: 0.1393\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4035 - acc: 0.1473 - val_loss: 2.4083 - val_acc: 0.1437\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3973 - acc: 0.1530 - val_loss: 2.4071 - val_acc: 0.1465\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3945 - acc: 0.1532 - val_loss: 2.4062 - val_acc: 0.1446\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3911 - acc: 0.1556 - val_loss: 2.4053 - val_acc: 0.1445\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3915 - acc: 0.1547 - val_loss: 2.4050 - val_acc: 0.1424\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3875 - acc: 0.1584 - val_loss: 2.4043 - val_acc: 0.1442\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3871 - acc: 0.1587 - val_loss: 2.4042 - val_acc: 0.1461\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3849 - acc: 0.1579 - val_loss: 2.4039 - val_acc: 0.1479\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3838 - acc: 0.1597 - val_loss: 2.4035 - val_acc: 0.1489\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3818 - acc: 0.1617 - val_loss: 2.4036 - val_acc: 0.1495\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3798 - acc: 0.1617 - val_loss: 2.4034 - val_acc: 0.1487\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3790 - acc: 0.1615 - val_loss: 2.4035 - val_acc: 0.1489\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3774 - acc: 0.1627 - val_loss: 2.4035 - val_acc: 0.1508\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3744 - acc: 0.1642 - val_loss: 2.4035 - val_acc: 0.1508\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3743 - acc: 0.1642 - val_loss: 2.4036 - val_acc: 0.1476\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3742 - acc: 0.1633 - val_loss: 2.4035 - val_acc: 0.1493\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3731 - acc: 0.1646 - val_loss: 2.4037 - val_acc: 0.1511\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3688 - acc: 0.1672 - val_loss: 2.4039 - val_acc: 0.1496\n",
      "logloss val 2.40392986276421\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4455 - acc: 0.1277 - val_loss: 2.4191 - val_acc: 0.1401\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4119 - acc: 0.1421 - val_loss: 2.4092 - val_acc: 0.1453\n",
      "Epoch 3/20\n",
      "6s - loss: 2.4025 - acc: 0.1470 - val_loss: 2.4058 - val_acc: 0.1476\n",
      "Epoch 4/20\n",
      "7s - loss: 2.3986 - acc: 0.1490 - val_loss: 2.4042 - val_acc: 0.1507\n",
      "Epoch 5/20\n",
      "7s - loss: 2.3949 - acc: 0.1530 - val_loss: 2.4032 - val_acc: 0.1487\n",
      "Epoch 6/20\n",
      "6s - loss: 2.3916 - acc: 0.1551 - val_loss: 2.4025 - val_acc: 0.1447\n",
      "Epoch 7/20\n",
      "7s - loss: 2.3916 - acc: 0.1552 - val_loss: 2.4016 - val_acc: 0.1461\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3884 - acc: 0.1581 - val_loss: 2.4012 - val_acc: 0.1447\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3872 - acc: 0.1586 - val_loss: 2.4008 - val_acc: 0.1444\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3854 - acc: 0.1607 - val_loss: 2.4004 - val_acc: 0.1445\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3826 - acc: 0.1621 - val_loss: 2.4003 - val_acc: 0.1453\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3818 - acc: 0.1604 - val_loss: 2.4000 - val_acc: 0.1465\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3808 - acc: 0.1619 - val_loss: 2.4000 - val_acc: 0.1440\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3789 - acc: 0.1623 - val_loss: 2.3998 - val_acc: 0.1430\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3769 - acc: 0.1634 - val_loss: 2.3998 - val_acc: 0.1436\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3754 - acc: 0.1638 - val_loss: 2.3997 - val_acc: 0.1436\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3743 - acc: 0.1656 - val_loss: 2.4002 - val_acc: 0.1426\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3715 - acc: 0.1664 - val_loss: 2.4004 - val_acc: 0.1422\n",
      "Epoch 19/20\n",
      "6s - loss: 2.3718 - acc: 0.1669 - val_loss: 2.4006 - val_acc: 0.1417\n",
      "Epoch 20/20\n",
      "6s - loss: 2.3705 - acc: 0.1661 - val_loss: 2.4007 - val_acc: 0.1428\n",
      "logloss val 2.400682793204956\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4437 - acc: 0.1344 - val_loss: 2.4184 - val_acc: 0.1376\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4107 - acc: 0.1424 - val_loss: 2.4061 - val_acc: 0.1462\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4034 - acc: 0.1454 - val_loss: 2.4005 - val_acc: 0.1472\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3983 - acc: 0.1475 - val_loss: 2.3983 - val_acc: 0.1533\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3967 - acc: 0.1501 - val_loss: 2.3972 - val_acc: 0.1479\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3936 - acc: 0.1535 - val_loss: 2.3964 - val_acc: 0.1510\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3898 - acc: 0.1541 - val_loss: 2.3958 - val_acc: 0.1501\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3913 - acc: 0.1556 - val_loss: 2.3955 - val_acc: 0.1513\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3876 - acc: 0.1567 - val_loss: 2.3956 - val_acc: 0.1550\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3847 - acc: 0.1579 - val_loss: 2.3948 - val_acc: 0.1533\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3839 - acc: 0.1573 - val_loss: 2.3948 - val_acc: 0.1534\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3820 - acc: 0.1609 - val_loss: 2.3950 - val_acc: 0.1557\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3812 - acc: 0.1604 - val_loss: 2.3948 - val_acc: 0.1566\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3787 - acc: 0.1615 - val_loss: 2.3950 - val_acc: 0.1574\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3781 - acc: 0.1617 - val_loss: 2.3953 - val_acc: 0.1555\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3768 - acc: 0.1618 - val_loss: 2.3956 - val_acc: 0.1581\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3740 - acc: 0.1634 - val_loss: 2.3955 - val_acc: 0.1545\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3730 - acc: 0.1654 - val_loss: 2.3958 - val_acc: 0.1555\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3730 - acc: 0.1640 - val_loss: 2.3963 - val_acc: 0.1526\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3695 - acc: 0.1661 - val_loss: 2.3967 - val_acc: 0.1533\n",
      "logloss val 2.3966707892888186\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4454 - acc: 0.1330 - val_loss: 2.4179 - val_acc: 0.1414\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4129 - acc: 0.1417 - val_loss: 2.4060 - val_acc: 0.1419\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4033 - acc: 0.1448 - val_loss: 2.4005 - val_acc: 0.1482\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3995 - acc: 0.1478 - val_loss: 2.3980 - val_acc: 0.1505\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3963 - acc: 0.1524 - val_loss: 2.3963 - val_acc: 0.1502\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3934 - acc: 0.1540 - val_loss: 2.3951 - val_acc: 0.1534\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3921 - acc: 0.1547 - val_loss: 2.3943 - val_acc: 0.1522\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3887 - acc: 0.1568 - val_loss: 2.3935 - val_acc: 0.1489\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3875 - acc: 0.1579 - val_loss: 2.3934 - val_acc: 0.1497\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3867 - acc: 0.1580 - val_loss: 2.3926 - val_acc: 0.1521\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3853 - acc: 0.1592 - val_loss: 2.3923 - val_acc: 0.1528\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3829 - acc: 0.1591 - val_loss: 2.3919 - val_acc: 0.1533\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3812 - acc: 0.1607 - val_loss: 2.3919 - val_acc: 0.1536\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3784 - acc: 0.1621 - val_loss: 2.3917 - val_acc: 0.1526\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3790 - acc: 0.1622 - val_loss: 2.3919 - val_acc: 0.1541\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3758 - acc: 0.1639 - val_loss: 2.3918 - val_acc: 0.1518\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3763 - acc: 0.1635 - val_loss: 2.3923 - val_acc: 0.1533\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3736 - acc: 0.1646 - val_loss: 2.3918 - val_acc: 0.1549\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3715 - acc: 0.1668 - val_loss: 2.3922 - val_acc: 0.1510\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3714 - acc: 0.1663 - val_loss: 2.3920 - val_acc: 0.1529\n",
      "logloss val 2.391966977154103\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4460 - acc: 0.1338 - val_loss: 2.4183 - val_acc: 0.1384\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4121 - acc: 0.1443 - val_loss: 2.4069 - val_acc: 0.1400\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4026 - acc: 0.1448 - val_loss: 2.4015 - val_acc: 0.1419\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3989 - acc: 0.1506 - val_loss: 2.3980 - val_acc: 0.1459\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3962 - acc: 0.1518 - val_loss: 2.3961 - val_acc: 0.1448\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3926 - acc: 0.1546 - val_loss: 2.3951 - val_acc: 0.1522\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3924 - acc: 0.1546 - val_loss: 2.3940 - val_acc: 0.1537\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3875 - acc: 0.1571 - val_loss: 2.3931 - val_acc: 0.1537\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3882 - acc: 0.1568 - val_loss: 2.3930 - val_acc: 0.1542\n",
      "Epoch 10/20\n",
      "7s - loss: 2.3849 - acc: 0.1569 - val_loss: 2.3925 - val_acc: 0.1553\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3842 - acc: 0.1579 - val_loss: 2.3923 - val_acc: 0.1553\n",
      "Epoch 12/20\n",
      "7s - loss: 2.3819 - acc: 0.1599 - val_loss: 2.3923 - val_acc: 0.1544\n",
      "Epoch 13/20\n",
      "9s - loss: 2.3791 - acc: 0.1605 - val_loss: 2.3922 - val_acc: 0.1550\n",
      "Epoch 14/20\n",
      "7s - loss: 2.3789 - acc: 0.1607 - val_loss: 2.3925 - val_acc: 0.1509\n",
      "Epoch 15/20\n",
      "6s - loss: 2.3774 - acc: 0.1623 - val_loss: 2.3927 - val_acc: 0.1533\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3754 - acc: 0.1629 - val_loss: 2.3925 - val_acc: 0.1532\n",
      "Epoch 17/20\n",
      "6s - loss: 2.3745 - acc: 0.1635 - val_loss: 2.3930 - val_acc: 0.1530\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3718 - acc: 0.1641 - val_loss: 2.3932 - val_acc: 0.1530\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3714 - acc: 0.1655 - val_loss: 2.3934 - val_acc: 0.1522\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3697 - acc: 0.1651 - val_loss: 2.3936 - val_acc: 0.1533\n",
      "logloss val 2.393559002985046\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4450 - acc: 0.1312 - val_loss: 2.4196 - val_acc: 0.1426\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4117 - acc: 0.1446 - val_loss: 2.4080 - val_acc: 0.1432\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4030 - acc: 0.1479 - val_loss: 2.4034 - val_acc: 0.1430\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3983 - acc: 0.1491 - val_loss: 2.4008 - val_acc: 0.1458\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3951 - acc: 0.1535 - val_loss: 2.3998 - val_acc: 0.1466\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3928 - acc: 0.1540 - val_loss: 2.3991 - val_acc: 0.1475\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3912 - acc: 0.1574 - val_loss: 2.3985 - val_acc: 0.1485\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3886 - acc: 0.1580 - val_loss: 2.3979 - val_acc: 0.1488\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3864 - acc: 0.1591 - val_loss: 2.3978 - val_acc: 0.1475\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3857 - acc: 0.1593 - val_loss: 2.3972 - val_acc: 0.1477\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3821 - acc: 0.1602 - val_loss: 2.3972 - val_acc: 0.1480\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3842 - acc: 0.1614 - val_loss: 2.3962 - val_acc: 0.1488\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3784 - acc: 0.1618 - val_loss: 2.3967 - val_acc: 0.1469\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3781 - acc: 0.1625 - val_loss: 2.3970 - val_acc: 0.1496\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3773 - acc: 0.1635 - val_loss: 2.3971 - val_acc: 0.1480\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3747 - acc: 0.1648 - val_loss: 2.3967 - val_acc: 0.1462\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3736 - acc: 0.1660 - val_loss: 2.3972 - val_acc: 0.1497\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3730 - acc: 0.1653 - val_loss: 2.3977 - val_acc: 0.1484\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3699 - acc: 0.1667 - val_loss: 2.3976 - val_acc: 0.1483\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3700 - acc: 0.1675 - val_loss: 2.3978 - val_acc: 0.1499\n",
      "logloss val 2.397822140831633\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4454 - acc: 0.1252 - val_loss: 2.4187 - val_acc: 0.1465\n",
      "Epoch 2/20\n",
      "6s - loss: 2.4134 - acc: 0.1428 - val_loss: 2.4056 - val_acc: 0.1507\n",
      "Epoch 3/20\n",
      "6s - loss: 2.4044 - acc: 0.1463 - val_loss: 2.3990 - val_acc: 0.1519\n",
      "Epoch 4/20\n",
      "6s - loss: 2.3982 - acc: 0.1506 - val_loss: 2.3962 - val_acc: 0.1569\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3964 - acc: 0.1517 - val_loss: 2.3946 - val_acc: 0.1546\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3936 - acc: 0.1541 - val_loss: 2.3936 - val_acc: 0.1561\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3907 - acc: 0.1560 - val_loss: 2.3924 - val_acc: 0.1579\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3885 - acc: 0.1586 - val_loss: 2.3917 - val_acc: 0.1555\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3872 - acc: 0.1597 - val_loss: 2.3914 - val_acc: 0.1548\n",
      "Epoch 10/20\n",
      "6s - loss: 2.3868 - acc: 0.1595 - val_loss: 2.3910 - val_acc: 0.1550\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3837 - acc: 0.1609 - val_loss: 2.3906 - val_acc: 0.1540\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3837 - acc: 0.1603 - val_loss: 2.3905 - val_acc: 0.1543\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3786 - acc: 0.1630 - val_loss: 2.3908 - val_acc: 0.1539\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3791 - acc: 0.1638 - val_loss: 2.3903 - val_acc: 0.1538\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3767 - acc: 0.1644 - val_loss: 2.3905 - val_acc: 0.1538\n",
      "Epoch 16/20\n",
      "6s - loss: 2.3760 - acc: 0.1647 - val_loss: 2.3908 - val_acc: 0.1536\n",
      "Epoch 17/20\n",
      "6s - loss: 2.3737 - acc: 0.1663 - val_loss: 2.3907 - val_acc: 0.1532\n",
      "Epoch 18/20\n",
      "7s - loss: 2.3723 - acc: 0.1666 - val_loss: 2.3913 - val_acc: 0.1520\n",
      "Epoch 19/20\n",
      "6s - loss: 2.3723 - acc: 0.1685 - val_loss: 2.3912 - val_acc: 0.1516\n",
      "Epoch 20/20\n",
      "6s - loss: 2.3698 - acc: 0.1677 - val_loss: 2.3917 - val_acc: 0.1544\n",
      "logloss val 2.3917359330134036\n",
      "average logloss val 2.396895345853407\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4463 - acc: 0.1344 - val_loss: 2.4209 - val_acc: 0.1433\n",
      "Epoch 2/20\n",
      "7s - loss: 2.4112 - acc: 0.1447 - val_loss: 2.4131 - val_acc: 0.1419\n",
      "Epoch 3/20\n",
      "6s - loss: 2.4015 - acc: 0.1466 - val_loss: 2.4106 - val_acc: 0.1410\n",
      "Epoch 4/20\n",
      "6s - loss: 2.3974 - acc: 0.1517 - val_loss: 2.4096 - val_acc: 0.1398\n",
      "Epoch 5/20\n",
      "6s - loss: 2.3942 - acc: 0.1541 - val_loss: 2.4090 - val_acc: 0.1394\n",
      "Epoch 6/20\n",
      "6s - loss: 2.3916 - acc: 0.1562 - val_loss: 2.4083 - val_acc: 0.1417\n",
      "Epoch 7/20\n",
      "6s - loss: 2.3886 - acc: 0.1571 - val_loss: 2.4081 - val_acc: 0.1413\n",
      "Epoch 8/20\n",
      "7s - loss: 2.3878 - acc: 0.1569 - val_loss: 2.4073 - val_acc: 0.1399\n",
      "Epoch 9/20\n",
      "6s - loss: 2.3856 - acc: 0.1600 - val_loss: 2.4075 - val_acc: 0.1423\n",
      "Epoch 10/20\n",
      "6s - loss: 2.3854 - acc: 0.1589 - val_loss: 2.4074 - val_acc: 0.1425\n",
      "Epoch 11/20\n",
      "6s - loss: 2.3821 - acc: 0.1611 - val_loss: 2.4070 - val_acc: 0.1437\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3818 - acc: 0.1612 - val_loss: 2.4071 - val_acc: 0.1415\n",
      "Epoch 13/20\n",
      "8s - loss: 2.3801 - acc: 0.1627 - val_loss: 2.4066 - val_acc: 0.1426\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3763 - acc: 0.1647 - val_loss: 2.4073 - val_acc: 0.1408\n",
      "Epoch 15/20\n",
      "6s - loss: 2.3769 - acc: 0.1635 - val_loss: 2.4069 - val_acc: 0.1408\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3736 - acc: 0.1661 - val_loss: 2.4071 - val_acc: 0.1423\n",
      "Epoch 17/20\n",
      "7s - loss: 2.3735 - acc: 0.1652 - val_loss: 2.4079 - val_acc: 0.1425\n",
      "Epoch 18/20\n",
      "6s - loss: 2.3728 - acc: 0.1663 - val_loss: 2.4072 - val_acc: 0.1418\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3700 - acc: 0.1667 - val_loss: 2.4078 - val_acc: 0.1431\n",
      "Epoch 20/20\n",
      "6s - loss: 2.3703 - acc: 0.1665 - val_loss: 2.4082 - val_acc: 0.1433\n",
      "logloss val 2.408238458954119\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4434 - acc: 0.1329 - val_loss: 2.4189 - val_acc: 0.1413\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4109 - acc: 0.1440 - val_loss: 2.4078 - val_acc: 0.1414\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4040 - acc: 0.1445 - val_loss: 2.4026 - val_acc: 0.1434\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3991 - acc: 0.1489 - val_loss: 2.4002 - val_acc: 0.1440\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3957 - acc: 0.1517 - val_loss: 2.3984 - val_acc: 0.1511\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3925 - acc: 0.1543 - val_loss: 2.3971 - val_acc: 0.1524\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3916 - acc: 0.1543 - val_loss: 2.3964 - val_acc: 0.1525\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3908 - acc: 0.1546 - val_loss: 2.3957 - val_acc: 0.1521\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3872 - acc: 0.1561 - val_loss: 2.3949 - val_acc: 0.1519\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3860 - acc: 0.1583 - val_loss: 2.3944 - val_acc: 0.1529\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3837 - acc: 0.1580 - val_loss: 2.3942 - val_acc: 0.1533\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3835 - acc: 0.1592 - val_loss: 2.3936 - val_acc: 0.1543\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3815 - acc: 0.1585 - val_loss: 2.3937 - val_acc: 0.1548\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3806 - acc: 0.1591 - val_loss: 2.3935 - val_acc: 0.1576\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3775 - acc: 0.1624 - val_loss: 2.3930 - val_acc: 0.1580\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3772 - acc: 0.1625 - val_loss: 2.3926 - val_acc: 0.1567\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3764 - acc: 0.1627 - val_loss: 2.3927 - val_acc: 0.1578\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3749 - acc: 0.1644 - val_loss: 2.3926 - val_acc: 0.1580\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3724 - acc: 0.1650 - val_loss: 2.3928 - val_acc: 0.1570\n",
      "Epoch 20/20\n",
      "6s - loss: 2.3716 - acc: 0.1654 - val_loss: 2.3925 - val_acc: 0.1576\n",
      "logloss val 2.3925115173742806\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4460 - acc: 0.1280 - val_loss: 2.4211 - val_acc: 0.1399\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4131 - acc: 0.1444 - val_loss: 2.4102 - val_acc: 0.1429\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4034 - acc: 0.1448 - val_loss: 2.4044 - val_acc: 0.1489\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3991 - acc: 0.1483 - val_loss: 2.4014 - val_acc: 0.1485\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3952 - acc: 0.1521 - val_loss: 2.3992 - val_acc: 0.1533\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3928 - acc: 0.1547 - val_loss: 2.3978 - val_acc: 0.1543\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3921 - acc: 0.1542 - val_loss: 2.3967 - val_acc: 0.1549\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3875 - acc: 0.1572 - val_loss: 2.3959 - val_acc: 0.1562\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3883 - acc: 0.1558 - val_loss: 2.3952 - val_acc: 0.1549\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1576 - val_loss: 2.3947 - val_acc: 0.1584\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3840 - acc: 0.1588 - val_loss: 2.3940 - val_acc: 0.1580\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3828 - acc: 0.1599 - val_loss: 2.3939 - val_acc: 0.1579\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3801 - acc: 0.1606 - val_loss: 2.3939 - val_acc: 0.1582\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3806 - acc: 0.1607 - val_loss: 2.3934 - val_acc: 0.1582\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3778 - acc: 0.1621 - val_loss: 2.3934 - val_acc: 0.1584\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3779 - acc: 0.1625 - val_loss: 2.3933 - val_acc: 0.1578\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3734 - acc: 0.1634 - val_loss: 2.3930 - val_acc: 0.1579\n",
      "Epoch 18/20\n",
      "6s - loss: 2.3737 - acc: 0.1661 - val_loss: 2.3933 - val_acc: 0.1587\n",
      "Epoch 19/20\n",
      "6s - loss: 2.3731 - acc: 0.1645 - val_loss: 2.3933 - val_acc: 0.1579\n",
      "Epoch 20/20\n",
      "6s - loss: 2.3717 - acc: 0.1659 - val_loss: 2.3934 - val_acc: 0.1582\n",
      "logloss val 2.3934183211530446\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4445 - acc: 0.1315 - val_loss: 2.4219 - val_acc: 0.1444\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4125 - acc: 0.1442 - val_loss: 2.4130 - val_acc: 0.1398\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4034 - acc: 0.1469 - val_loss: 2.4091 - val_acc: 0.1394\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3981 - acc: 0.1507 - val_loss: 2.4079 - val_acc: 0.1430\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3938 - acc: 0.1555 - val_loss: 2.4068 - val_acc: 0.1425\n",
      "Epoch 6/20\n",
      "6s - loss: 2.3929 - acc: 0.1548 - val_loss: 2.4062 - val_acc: 0.1454\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3883 - acc: 0.1574 - val_loss: 2.4055 - val_acc: 0.1477\n",
      "Epoch 8/20\n",
      "6s - loss: 2.3900 - acc: 0.1562 - val_loss: 2.4051 - val_acc: 0.1466\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3852 - acc: 0.1604 - val_loss: 2.4045 - val_acc: 0.1485\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3851 - acc: 0.1595 - val_loss: 2.4044 - val_acc: 0.1487\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3836 - acc: 0.1597 - val_loss: 2.4041 - val_acc: 0.1469\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3798 - acc: 0.1629 - val_loss: 2.4040 - val_acc: 0.1446\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3795 - acc: 0.1615 - val_loss: 2.4041 - val_acc: 0.1465\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3798 - acc: 0.1617 - val_loss: 2.4039 - val_acc: 0.1444\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3773 - acc: 0.1640 - val_loss: 2.4039 - val_acc: 0.1473\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3755 - acc: 0.1637 - val_loss: 2.4043 - val_acc: 0.1461\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3731 - acc: 0.1646 - val_loss: 2.4038 - val_acc: 0.1456\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3736 - acc: 0.1657 - val_loss: 2.4041 - val_acc: 0.1441\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3713 - acc: 0.1655 - val_loss: 2.4042 - val_acc: 0.1479\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3690 - acc: 0.1674 - val_loss: 2.4045 - val_acc: 0.1466\n",
      "logloss val 2.404532575020902\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4440 - acc: 0.1329 - val_loss: 2.4210 - val_acc: 0.1457\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4117 - acc: 0.1446 - val_loss: 2.4106 - val_acc: 0.1447\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4024 - acc: 0.1478 - val_loss: 2.4064 - val_acc: 0.1445\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3988 - acc: 0.1502 - val_loss: 2.4047 - val_acc: 0.1422\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3947 - acc: 0.1543 - val_loss: 2.4036 - val_acc: 0.1479\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3923 - acc: 0.1557 - val_loss: 2.4029 - val_acc: 0.1464\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3907 - acc: 0.1563 - val_loss: 2.4023 - val_acc: 0.1456\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3876 - acc: 0.1577 - val_loss: 2.4017 - val_acc: 0.1440\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3864 - acc: 0.1584 - val_loss: 2.4011 - val_acc: 0.1453\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3853 - acc: 0.1594 - val_loss: 2.4010 - val_acc: 0.1459\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3835 - acc: 0.1591 - val_loss: 2.4006 - val_acc: 0.1465\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3821 - acc: 0.1608 - val_loss: 2.4007 - val_acc: 0.1448\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3779 - acc: 0.1621 - val_loss: 2.4005 - val_acc: 0.1456\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3786 - acc: 0.1624 - val_loss: 2.4004 - val_acc: 0.1477\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3778 - acc: 0.1627 - val_loss: 2.4004 - val_acc: 0.1460\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3757 - acc: 0.1643 - val_loss: 2.4007 - val_acc: 0.1452\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3736 - acc: 0.1639 - val_loss: 2.4007 - val_acc: 0.1447\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3714 - acc: 0.1658 - val_loss: 2.4013 - val_acc: 0.1455\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3720 - acc: 0.1660 - val_loss: 2.4015 - val_acc: 0.1429\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3689 - acc: 0.1674 - val_loss: 2.4017 - val_acc: 0.1457\n",
      "logloss val 2.4017377971580123\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4486 - acc: 0.1341 - val_loss: 2.4188 - val_acc: 0.1431\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4120 - acc: 0.1443 - val_loss: 2.4062 - val_acc: 0.1419\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4021 - acc: 0.1455 - val_loss: 2.4008 - val_acc: 0.1498\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3994 - acc: 0.1504 - val_loss: 2.3983 - val_acc: 0.1517\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3958 - acc: 0.1530 - val_loss: 2.3970 - val_acc: 0.1561\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3934 - acc: 0.1534 - val_loss: 2.3963 - val_acc: 0.1550\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3915 - acc: 0.1556 - val_loss: 2.3953 - val_acc: 0.1600\n",
      "Epoch 8/20\n",
      "4s - loss: 2.3887 - acc: 0.1567 - val_loss: 2.3952 - val_acc: 0.1580\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3879 - acc: 0.1573 - val_loss: 2.3950 - val_acc: 0.1577\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1592 - val_loss: 2.3948 - val_acc: 0.1589\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3842 - acc: 0.1593 - val_loss: 2.3948 - val_acc: 0.1586\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3821 - acc: 0.1616 - val_loss: 2.3953 - val_acc: 0.1559\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3794 - acc: 0.1613 - val_loss: 2.3946 - val_acc: 0.1585\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3810 - acc: 0.1610 - val_loss: 2.3950 - val_acc: 0.1578\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3780 - acc: 0.1640 - val_loss: 2.3949 - val_acc: 0.1572\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3773 - acc: 0.1627 - val_loss: 2.3955 - val_acc: 0.1569\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3744 - acc: 0.1645 - val_loss: 2.3956 - val_acc: 0.1564\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3734 - acc: 0.1658 - val_loss: 2.3960 - val_acc: 0.1551\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3715 - acc: 0.1667 - val_loss: 2.3957 - val_acc: 0.1580\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3706 - acc: 0.1658 - val_loss: 2.3963 - val_acc: 0.1551\n",
      "logloss val 2.396338728810274\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4441 - acc: 0.1321 - val_loss: 2.4185 - val_acc: 0.1418\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4140 - acc: 0.1418 - val_loss: 2.4075 - val_acc: 0.1439\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4041 - acc: 0.1455 - val_loss: 2.4022 - val_acc: 0.1463\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3993 - acc: 0.1487 - val_loss: 2.3994 - val_acc: 0.1431\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3968 - acc: 0.1522 - val_loss: 2.3976 - val_acc: 0.1430\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3938 - acc: 0.1535 - val_loss: 2.3966 - val_acc: 0.1444\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3922 - acc: 0.1541 - val_loss: 2.3956 - val_acc: 0.1465\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3907 - acc: 0.1566 - val_loss: 2.3951 - val_acc: 0.1463\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3872 - acc: 0.1574 - val_loss: 2.3941 - val_acc: 0.1457\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3865 - acc: 0.1587 - val_loss: 2.3938 - val_acc: 0.1455\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3849 - acc: 0.1582 - val_loss: 2.3935 - val_acc: 0.1477\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3825 - acc: 0.1604 - val_loss: 2.3930 - val_acc: 0.1486\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3813 - acc: 0.1607 - val_loss: 2.3928 - val_acc: 0.1479\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3808 - acc: 0.1604 - val_loss: 2.3931 - val_acc: 0.1487\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3779 - acc: 0.1624 - val_loss: 2.3928 - val_acc: 0.1487\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3783 - acc: 0.1619 - val_loss: 2.3929 - val_acc: 0.1477\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3744 - acc: 0.1645 - val_loss: 2.3928 - val_acc: 0.1478\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3748 - acc: 0.1654 - val_loss: 2.3930 - val_acc: 0.1474\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3721 - acc: 0.1657 - val_loss: 2.3931 - val_acc: 0.1486\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3724 - acc: 0.1651 - val_loss: 2.3932 - val_acc: 0.1489\n",
      "logloss val 2.3932075135105992\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4432 - acc: 0.1324 - val_loss: 2.4176 - val_acc: 0.1388\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4132 - acc: 0.1442 - val_loss: 2.4059 - val_acc: 0.1387\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4020 - acc: 0.1466 - val_loss: 2.4009 - val_acc: 0.1407\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3994 - acc: 0.1495 - val_loss: 2.3982 - val_acc: 0.1436\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3966 - acc: 0.1519 - val_loss: 2.3965 - val_acc: 0.1485\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3941 - acc: 0.1538 - val_loss: 2.3958 - val_acc: 0.1490\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3919 - acc: 0.1556 - val_loss: 2.3944 - val_acc: 0.1493\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3886 - acc: 0.1569 - val_loss: 2.3941 - val_acc: 0.1509\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3875 - acc: 0.1574 - val_loss: 2.3932 - val_acc: 0.1526\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3862 - acc: 0.1582 - val_loss: 2.3930 - val_acc: 0.1542\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3833 - acc: 0.1597 - val_loss: 2.3928 - val_acc: 0.1558\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3831 - acc: 0.1587 - val_loss: 2.3927 - val_acc: 0.1538\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3808 - acc: 0.1607 - val_loss: 2.3925 - val_acc: 0.1529\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3793 - acc: 0.1619 - val_loss: 2.3922 - val_acc: 0.1526\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3771 - acc: 0.1617 - val_loss: 2.3927 - val_acc: 0.1533\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3753 - acc: 0.1629 - val_loss: 2.3925 - val_acc: 0.1546\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3749 - acc: 0.1626 - val_loss: 2.3933 - val_acc: 0.1556\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3747 - acc: 0.1640 - val_loss: 2.3929 - val_acc: 0.1507\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3704 - acc: 0.1657 - val_loss: 2.3926 - val_acc: 0.1530\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3697 - acc: 0.1661 - val_loss: 2.3930 - val_acc: 0.1510\n",
      "logloss val 2.3930370021360834\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4458 - acc: 0.1302 - val_loss: 2.4215 - val_acc: 0.1413\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4126 - acc: 0.1456 - val_loss: 2.4091 - val_acc: 0.1438\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4035 - acc: 0.1448 - val_loss: 2.4034 - val_acc: 0.1437\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3986 - acc: 0.1501 - val_loss: 2.4007 - val_acc: 0.1480\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3960 - acc: 0.1520 - val_loss: 2.3993 - val_acc: 0.1491\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3928 - acc: 0.1546 - val_loss: 2.3982 - val_acc: 0.1489\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3911 - acc: 0.1560 - val_loss: 2.3972 - val_acc: 0.1487\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3880 - acc: 0.1577 - val_loss: 2.3965 - val_acc: 0.1492\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3877 - acc: 0.1586 - val_loss: 2.3957 - val_acc: 0.1511\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3850 - acc: 0.1600 - val_loss: 2.3955 - val_acc: 0.1492\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3834 - acc: 0.1600 - val_loss: 2.3954 - val_acc: 0.1507\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3819 - acc: 0.1611 - val_loss: 2.3952 - val_acc: 0.1496\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3793 - acc: 0.1624 - val_loss: 2.3951 - val_acc: 0.1504\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3798 - acc: 0.1618 - val_loss: 2.3944 - val_acc: 0.1513\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3759 - acc: 0.1624 - val_loss: 2.3949 - val_acc: 0.1501\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3751 - acc: 0.1652 - val_loss: 2.3949 - val_acc: 0.1515\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3735 - acc: 0.1657 - val_loss: 2.3953 - val_acc: 0.1500\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3728 - acc: 0.1647 - val_loss: 2.3946 - val_acc: 0.1511\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3703 - acc: 0.1670 - val_loss: 2.3954 - val_acc: 0.1500\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3692 - acc: 0.1677 - val_loss: 2.3959 - val_acc: 0.1511\n",
      "logloss val 2.3958799762971204\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4438 - acc: 0.1316 - val_loss: 2.4178 - val_acc: 0.1406\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4119 - acc: 0.1444 - val_loss: 2.4046 - val_acc: 0.1492\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4030 - acc: 0.1459 - val_loss: 2.3994 - val_acc: 0.1546\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3984 - acc: 0.1486 - val_loss: 2.3967 - val_acc: 0.1567\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3966 - acc: 0.1520 - val_loss: 2.3949 - val_acc: 0.1573\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3930 - acc: 0.1546 - val_loss: 2.3941 - val_acc: 0.1546\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3913 - acc: 0.1532 - val_loss: 2.3928 - val_acc: 0.1562\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3907 - acc: 0.1555 - val_loss: 2.3923 - val_acc: 0.1548\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3869 - acc: 0.1593 - val_loss: 2.3918 - val_acc: 0.1554\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1573 - val_loss: 2.3917 - val_acc: 0.1558\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3844 - acc: 0.1585 - val_loss: 2.3913 - val_acc: 0.1539\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3815 - acc: 0.1613 - val_loss: 2.3913 - val_acc: 0.1558\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3809 - acc: 0.1601 - val_loss: 2.3910 - val_acc: 0.1546\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3784 - acc: 0.1617 - val_loss: 2.3913 - val_acc: 0.1538\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3785 - acc: 0.1623 - val_loss: 2.3913 - val_acc: 0.1527\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3753 - acc: 0.1649 - val_loss: 2.3916 - val_acc: 0.1526\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3754 - acc: 0.1645 - val_loss: 2.3914 - val_acc: 0.1538\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3721 - acc: 0.1665 - val_loss: 2.3917 - val_acc: 0.1524\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3723 - acc: 0.1669 - val_loss: 2.3919 - val_acc: 0.1523\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3692 - acc: 0.1670 - val_loss: 2.3924 - val_acc: 0.1508\n",
      "logloss val 2.3923669396210117\n",
      "average logloss val 2.397126883003545\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4443 - acc: 0.1340 - val_loss: 2.4202 - val_acc: 0.1426\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4120 - acc: 0.1448 - val_loss: 2.4122 - val_acc: 0.1411\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4013 - acc: 0.1482 - val_loss: 2.4099 - val_acc: 0.1386\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3975 - acc: 0.1505 - val_loss: 2.4088 - val_acc: 0.1344\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3950 - acc: 0.1552 - val_loss: 2.4083 - val_acc: 0.1376\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3915 - acc: 0.1560 - val_loss: 2.4074 - val_acc: 0.1392\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3896 - acc: 0.1574 - val_loss: 2.4076 - val_acc: 0.1396\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3889 - acc: 0.1573 - val_loss: 2.4077 - val_acc: 0.1410\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3864 - acc: 0.1598 - val_loss: 2.4069 - val_acc: 0.1407\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3839 - acc: 0.1610 - val_loss: 2.4067 - val_acc: 0.1439\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3829 - acc: 0.1620 - val_loss: 2.4065 - val_acc: 0.1415\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3805 - acc: 0.1623 - val_loss: 2.4068 - val_acc: 0.1431\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3796 - acc: 0.1632 - val_loss: 2.4068 - val_acc: 0.1426\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3784 - acc: 0.1641 - val_loss: 2.4070 - val_acc: 0.1418\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3761 - acc: 0.1638 - val_loss: 2.4069 - val_acc: 0.1422\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3744 - acc: 0.1656 - val_loss: 2.4075 - val_acc: 0.1426\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3739 - acc: 0.1649 - val_loss: 2.4074 - val_acc: 0.1421\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3717 - acc: 0.1664 - val_loss: 2.4074 - val_acc: 0.1417\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3706 - acc: 0.1669 - val_loss: 2.4079 - val_acc: 0.1431\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3688 - acc: 0.1682 - val_loss: 2.4082 - val_acc: 0.1427\n",
      "logloss val 2.4081866157740257\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4425 - acc: 0.1336 - val_loss: 2.4177 - val_acc: 0.1428\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4088 - acc: 0.1443 - val_loss: 2.4073 - val_acc: 0.1432\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4024 - acc: 0.1457 - val_loss: 2.4038 - val_acc: 0.1453\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3976 - acc: 0.1502 - val_loss: 2.4014 - val_acc: 0.1495\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3959 - acc: 0.1526 - val_loss: 2.3997 - val_acc: 0.1504\n",
      "Epoch 6/20\n",
      "6s - loss: 2.3928 - acc: 0.1534 - val_loss: 2.3986 - val_acc: 0.1543\n",
      "Epoch 7/20\n",
      "6s - loss: 2.3904 - acc: 0.1553 - val_loss: 2.3976 - val_acc: 0.1556\n",
      "Epoch 8/20\n",
      "6s - loss: 2.3894 - acc: 0.1557 - val_loss: 2.3969 - val_acc: 0.1532\n",
      "Epoch 9/20\n",
      "6s - loss: 2.3885 - acc: 0.1566 - val_loss: 2.3965 - val_acc: 0.1543\n",
      "Epoch 10/20\n",
      "6s - loss: 2.3855 - acc: 0.1577 - val_loss: 2.3959 - val_acc: 0.1567\n",
      "Epoch 11/20\n",
      "6s - loss: 2.3841 - acc: 0.1595 - val_loss: 2.3954 - val_acc: 0.1559\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3823 - acc: 0.1596 - val_loss: 2.3948 - val_acc: 0.1576\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3810 - acc: 0.1610 - val_loss: 2.3946 - val_acc: 0.1566\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3802 - acc: 0.1602 - val_loss: 2.3946 - val_acc: 0.1549\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3783 - acc: 0.1625 - val_loss: 2.3943 - val_acc: 0.1555\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3762 - acc: 0.1629 - val_loss: 2.3944 - val_acc: 0.1554\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3744 - acc: 0.1634 - val_loss: 2.3939 - val_acc: 0.1578\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3743 - acc: 0.1637 - val_loss: 2.3937 - val_acc: 0.1567\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3742 - acc: 0.1643 - val_loss: 2.3944 - val_acc: 0.1572\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3702 - acc: 0.1671 - val_loss: 2.3943 - val_acc: 0.1583\n",
      "logloss val 2.3942642059995616\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4461 - acc: 0.1309 - val_loss: 2.4192 - val_acc: 0.1383\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4104 - acc: 0.1424 - val_loss: 2.4090 - val_acc: 0.1426\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4035 - acc: 0.1451 - val_loss: 2.4043 - val_acc: 0.1444\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3982 - acc: 0.1494 - val_loss: 2.4018 - val_acc: 0.1479\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3951 - acc: 0.1508 - val_loss: 2.4001 - val_acc: 0.1523\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3930 - acc: 0.1518 - val_loss: 2.3989 - val_acc: 0.1505\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3905 - acc: 0.1561 - val_loss: 2.3977 - val_acc: 0.1520\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3903 - acc: 0.1540 - val_loss: 2.3970 - val_acc: 0.1537\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3870 - acc: 0.1556 - val_loss: 2.3962 - val_acc: 0.1567\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3855 - acc: 0.1577 - val_loss: 2.3957 - val_acc: 0.1568\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3833 - acc: 0.1604 - val_loss: 2.3953 - val_acc: 0.1566\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3819 - acc: 0.1602 - val_loss: 2.3950 - val_acc: 0.1551\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3819 - acc: 0.1613 - val_loss: 2.3946 - val_acc: 0.1564\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3790 - acc: 0.1630 - val_loss: 2.3946 - val_acc: 0.1558\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3785 - acc: 0.1621 - val_loss: 2.3942 - val_acc: 0.1566\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3769 - acc: 0.1630 - val_loss: 2.3942 - val_acc: 0.1570\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3737 - acc: 0.1653 - val_loss: 2.3943 - val_acc: 0.1567\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3743 - acc: 0.1631 - val_loss: 2.3942 - val_acc: 0.1583\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3725 - acc: 0.1671 - val_loss: 2.3944 - val_acc: 0.1564\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3702 - acc: 0.1669 - val_loss: 2.3943 - val_acc: 0.1578\n",
      "logloss val 2.39431181870338\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4470 - acc: 0.1306 - val_loss: 2.4206 - val_acc: 0.1424\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4112 - acc: 0.1423 - val_loss: 2.4110 - val_acc: 0.1404\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4023 - acc: 0.1476 - val_loss: 2.4077 - val_acc: 0.1428\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3982 - acc: 0.1514 - val_loss: 2.4065 - val_acc: 0.1458\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3947 - acc: 0.1542 - val_loss: 2.4056 - val_acc: 0.1458\n",
      "Epoch 6/20\n",
      "6s - loss: 2.3924 - acc: 0.1560 - val_loss: 2.4050 - val_acc: 0.1452\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3903 - acc: 0.1563 - val_loss: 2.4046 - val_acc: 0.1432\n",
      "Epoch 8/20\n",
      "6s - loss: 2.3869 - acc: 0.1590 - val_loss: 2.4042 - val_acc: 0.1453\n",
      "Epoch 9/20\n",
      "6s - loss: 2.3877 - acc: 0.1589 - val_loss: 2.4037 - val_acc: 0.1449\n",
      "Epoch 10/20\n",
      "6s - loss: 2.3847 - acc: 0.1598 - val_loss: 2.4034 - val_acc: 0.1462\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3835 - acc: 0.1604 - val_loss: 2.4035 - val_acc: 0.1466\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3820 - acc: 0.1624 - val_loss: 2.4035 - val_acc: 0.1460\n",
      "Epoch 13/20\n",
      "6s - loss: 2.3793 - acc: 0.1617 - val_loss: 2.4029 - val_acc: 0.1457\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3778 - acc: 0.1652 - val_loss: 2.4032 - val_acc: 0.1456\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3776 - acc: 0.1629 - val_loss: 2.4032 - val_acc: 0.1469\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3752 - acc: 0.1637 - val_loss: 2.4030 - val_acc: 0.1456\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3750 - acc: 0.1650 - val_loss: 2.4033 - val_acc: 0.1453\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3738 - acc: 0.1653 - val_loss: 2.4035 - val_acc: 0.1474\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3692 - acc: 0.1675 - val_loss: 2.4034 - val_acc: 0.1453\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3715 - acc: 0.1658 - val_loss: 2.4037 - val_acc: 0.1465\n",
      "logloss val 2.403735078544508\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4430 - acc: 0.1332 - val_loss: 2.4195 - val_acc: 0.1397\n",
      "Epoch 2/20\n",
      "6s - loss: 2.4125 - acc: 0.1425 - val_loss: 2.4100 - val_acc: 0.1417\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4018 - acc: 0.1451 - val_loss: 2.4063 - val_acc: 0.1445\n",
      "Epoch 4/20\n",
      "4s - loss: 2.3987 - acc: 0.1485 - val_loss: 2.4045 - val_acc: 0.1448\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3951 - acc: 0.1523 - val_loss: 2.4035 - val_acc: 0.1435\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3927 - acc: 0.1544 - val_loss: 2.4027 - val_acc: 0.1404\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3901 - acc: 0.1565 - val_loss: 2.4019 - val_acc: 0.1417\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3882 - acc: 0.1583 - val_loss: 2.4014 - val_acc: 0.1445\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3871 - acc: 0.1583 - val_loss: 2.4009 - val_acc: 0.1420\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3861 - acc: 0.1594 - val_loss: 2.4008 - val_acc: 0.1437\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3834 - acc: 0.1615 - val_loss: 2.4004 - val_acc: 0.1436\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3819 - acc: 0.1591 - val_loss: 2.4001 - val_acc: 0.1441\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3795 - acc: 0.1630 - val_loss: 2.4003 - val_acc: 0.1430\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3788 - acc: 0.1624 - val_loss: 2.4001 - val_acc: 0.1435\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3769 - acc: 0.1636 - val_loss: 2.4000 - val_acc: 0.1437\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3753 - acc: 0.1639 - val_loss: 2.4002 - val_acc: 0.1437\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3740 - acc: 0.1642 - val_loss: 2.4005 - val_acc: 0.1430\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3732 - acc: 0.1653 - val_loss: 2.4003 - val_acc: 0.1408\n",
      "Epoch 19/20\n",
      "4s - loss: 2.3718 - acc: 0.1662 - val_loss: 2.4007 - val_acc: 0.1424\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3696 - acc: 0.1683 - val_loss: 2.4008 - val_acc: 0.1436\n",
      "logloss val 2.400824930284656\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4456 - acc: 0.1330 - val_loss: 2.4193 - val_acc: 0.1421\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4109 - acc: 0.1419 - val_loss: 2.4065 - val_acc: 0.1472\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4038 - acc: 0.1453 - val_loss: 2.4003 - val_acc: 0.1486\n",
      "Epoch 4/20\n",
      "5s - loss: 2.4007 - acc: 0.1468 - val_loss: 2.3977 - val_acc: 0.1478\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3961 - acc: 0.1510 - val_loss: 2.3963 - val_acc: 0.1530\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3933 - acc: 0.1530 - val_loss: 2.3954 - val_acc: 0.1518\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3913 - acc: 0.1537 - val_loss: 2.3948 - val_acc: 0.1537\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3888 - acc: 0.1569 - val_loss: 2.3946 - val_acc: 0.1555\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3891 - acc: 0.1565 - val_loss: 2.3944 - val_acc: 0.1546\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3858 - acc: 0.1584 - val_loss: 2.3942 - val_acc: 0.1578\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3851 - acc: 0.1585 - val_loss: 2.3941 - val_acc: 0.1549\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3813 - acc: 0.1602 - val_loss: 2.3940 - val_acc: 0.1572\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3822 - acc: 0.1608 - val_loss: 2.3941 - val_acc: 0.1581\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3791 - acc: 0.1613 - val_loss: 2.3940 - val_acc: 0.1558\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3780 - acc: 0.1624 - val_loss: 2.3942 - val_acc: 0.1577\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3762 - acc: 0.1625 - val_loss: 2.3949 - val_acc: 0.1551\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3749 - acc: 0.1632 - val_loss: 2.3946 - val_acc: 0.1593\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3726 - acc: 0.1636 - val_loss: 2.3953 - val_acc: 0.1570\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3717 - acc: 0.1660 - val_loss: 2.3954 - val_acc: 0.1547\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3713 - acc: 0.1648 - val_loss: 2.3958 - val_acc: 0.1584\n",
      "logloss val 2.395767828934742\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4470 - acc: 0.1240 - val_loss: 2.4185 - val_acc: 0.1408\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4113 - acc: 0.1441 - val_loss: 2.4060 - val_acc: 0.1418\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4042 - acc: 0.1454 - val_loss: 2.4010 - val_acc: 0.1475\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3981 - acc: 0.1514 - val_loss: 2.3985 - val_acc: 0.1513\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3960 - acc: 0.1519 - val_loss: 2.3968 - val_acc: 0.1528\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3931 - acc: 0.1546 - val_loss: 2.3959 - val_acc: 0.1560\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3913 - acc: 0.1549 - val_loss: 2.3950 - val_acc: 0.1517\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3899 - acc: 0.1565 - val_loss: 2.3943 - val_acc: 0.1528\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3859 - acc: 0.1594 - val_loss: 2.3938 - val_acc: 0.1536\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3873 - acc: 0.1575 - val_loss: 2.3934 - val_acc: 0.1506\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3836 - acc: 0.1604 - val_loss: 2.3928 - val_acc: 0.1494\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3825 - acc: 0.1603 - val_loss: 2.3927 - val_acc: 0.1511\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3811 - acc: 0.1619 - val_loss: 2.3924 - val_acc: 0.1514\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3792 - acc: 0.1620 - val_loss: 2.3927 - val_acc: 0.1534\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3781 - acc: 0.1619 - val_loss: 2.3922 - val_acc: 0.1521\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3771 - acc: 0.1648 - val_loss: 2.3923 - val_acc: 0.1533\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3736 - acc: 0.1645 - val_loss: 2.3924 - val_acc: 0.1533\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3754 - acc: 0.1645 - val_loss: 2.3923 - val_acc: 0.1524\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3704 - acc: 0.1671 - val_loss: 2.3925 - val_acc: 0.1528\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3714 - acc: 0.1664 - val_loss: 2.3927 - val_acc: 0.1525\n",
      "logloss val 2.3926657340872057\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4447 - acc: 0.1348 - val_loss: 2.4175 - val_acc: 0.1364\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4128 - acc: 0.1426 - val_loss: 2.4056 - val_acc: 0.1375\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4030 - acc: 0.1450 - val_loss: 2.3999 - val_acc: 0.1387\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3987 - acc: 0.1513 - val_loss: 2.3971 - val_acc: 0.1438\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3951 - acc: 0.1536 - val_loss: 2.3954 - val_acc: 0.1481\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3931 - acc: 0.1544 - val_loss: 2.3941 - val_acc: 0.1482\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3908 - acc: 0.1551 - val_loss: 2.3935 - val_acc: 0.1495\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3898 - acc: 0.1566 - val_loss: 2.3929 - val_acc: 0.1510\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3867 - acc: 0.1592 - val_loss: 2.3925 - val_acc: 0.1533\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3851 - acc: 0.1585 - val_loss: 2.3920 - val_acc: 0.1553\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3840 - acc: 0.1587 - val_loss: 2.3917 - val_acc: 0.1540\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3824 - acc: 0.1603 - val_loss: 2.3919 - val_acc: 0.1546\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3792 - acc: 0.1619 - val_loss: 2.3921 - val_acc: 0.1553\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3789 - acc: 0.1611 - val_loss: 2.3924 - val_acc: 0.1509\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3774 - acc: 0.1617 - val_loss: 2.3922 - val_acc: 0.1519\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3751 - acc: 0.1641 - val_loss: 2.3923 - val_acc: 0.1538\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3743 - acc: 0.1638 - val_loss: 2.3923 - val_acc: 0.1534\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3742 - acc: 0.1643 - val_loss: 2.3923 - val_acc: 0.1536\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3704 - acc: 0.1652 - val_loss: 2.3931 - val_acc: 0.1540\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3698 - acc: 0.1681 - val_loss: 2.3924 - val_acc: 0.1548\n",
      "logloss val 2.3924237462088525\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4423 - acc: 0.1365 - val_loss: 2.4196 - val_acc: 0.1393\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4116 - acc: 0.1432 - val_loss: 2.4080 - val_acc: 0.1369\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4023 - acc: 0.1453 - val_loss: 2.4029 - val_acc: 0.1436\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3985 - acc: 0.1497 - val_loss: 2.4012 - val_acc: 0.1452\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3960 - acc: 0.1527 - val_loss: 2.3993 - val_acc: 0.1453\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3927 - acc: 0.1541 - val_loss: 2.3989 - val_acc: 0.1446\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3903 - acc: 0.1555 - val_loss: 2.3977 - val_acc: 0.1458\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3899 - acc: 0.1572 - val_loss: 2.3974 - val_acc: 0.1458\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3869 - acc: 0.1578 - val_loss: 2.3969 - val_acc: 0.1488\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3853 - acc: 0.1590 - val_loss: 2.3965 - val_acc: 0.1491\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3825 - acc: 0.1602 - val_loss: 2.3970 - val_acc: 0.1461\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3831 - acc: 0.1612 - val_loss: 2.3961 - val_acc: 0.1454\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3812 - acc: 0.1610 - val_loss: 2.3958 - val_acc: 0.1487\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3787 - acc: 0.1634 - val_loss: 2.3957 - val_acc: 0.1468\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3768 - acc: 0.1623 - val_loss: 2.3959 - val_acc: 0.1477\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3758 - acc: 0.1640 - val_loss: 2.3960 - val_acc: 0.1489\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3743 - acc: 0.1644 - val_loss: 2.3961 - val_acc: 0.1487\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3734 - acc: 0.1658 - val_loss: 2.3961 - val_acc: 0.1489\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3689 - acc: 0.1677 - val_loss: 2.3972 - val_acc: 0.1492\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3709 - acc: 0.1663 - val_loss: 2.3966 - val_acc: 0.1477\n",
      "logloss val 2.396635044970478\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4445 - acc: 0.1298 - val_loss: 2.4186 - val_acc: 0.1437\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4124 - acc: 0.1421 - val_loss: 2.4060 - val_acc: 0.1460\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4033 - acc: 0.1471 - val_loss: 2.3996 - val_acc: 0.1496\n",
      "Epoch 4/20\n",
      "5s - loss: 2.4012 - acc: 0.1460 - val_loss: 2.3964 - val_acc: 0.1534\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3956 - acc: 0.1524 - val_loss: 2.3948 - val_acc: 0.1536\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3936 - acc: 0.1533 - val_loss: 2.3936 - val_acc: 0.1552\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3918 - acc: 0.1540 - val_loss: 2.3925 - val_acc: 0.1524\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3916 - acc: 0.1557 - val_loss: 2.3918 - val_acc: 0.1539\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3872 - acc: 0.1588 - val_loss: 2.3911 - val_acc: 0.1535\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3856 - acc: 0.1583 - val_loss: 2.3908 - val_acc: 0.1535\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3848 - acc: 0.1586 - val_loss: 2.3904 - val_acc: 0.1524\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3828 - acc: 0.1600 - val_loss: 2.3903 - val_acc: 0.1554\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3814 - acc: 0.1617 - val_loss: 2.3902 - val_acc: 0.1512\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3782 - acc: 0.1629 - val_loss: 2.3903 - val_acc: 0.1531\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3787 - acc: 0.1623 - val_loss: 2.3902 - val_acc: 0.1539\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3760 - acc: 0.1644 - val_loss: 2.3905 - val_acc: 0.1554\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3744 - acc: 0.1634 - val_loss: 2.3907 - val_acc: 0.1546\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3735 - acc: 0.1648 - val_loss: 2.3907 - val_acc: 0.1515\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3724 - acc: 0.1659 - val_loss: 2.3910 - val_acc: 0.1539\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3701 - acc: 0.1652 - val_loss: 2.3912 - val_acc: 0.1531\n",
      "logloss val 2.391235693394007\n",
      "average logloss val 2.3970050696901417\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4440 - acc: 0.1365 - val_loss: 2.4188 - val_acc: 0.1411\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4094 - acc: 0.1467 - val_loss: 2.4118 - val_acc: 0.1396\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4031 - acc: 0.1444 - val_loss: 2.4094 - val_acc: 0.1358\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3966 - acc: 0.1499 - val_loss: 2.4085 - val_acc: 0.1364\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3947 - acc: 0.1534 - val_loss: 2.4078 - val_acc: 0.1368\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3915 - acc: 0.1551 - val_loss: 2.4075 - val_acc: 0.1380\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3904 - acc: 0.1557 - val_loss: 2.4065 - val_acc: 0.1399\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3876 - acc: 0.1579 - val_loss: 2.4066 - val_acc: 0.1411\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3855 - acc: 0.1586 - val_loss: 2.4063 - val_acc: 0.1394\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3853 - acc: 0.1589 - val_loss: 2.4061 - val_acc: 0.1407\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3817 - acc: 0.1606 - val_loss: 2.4058 - val_acc: 0.1427\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3815 - acc: 0.1615 - val_loss: 2.4057 - val_acc: 0.1417\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3791 - acc: 0.1620 - val_loss: 2.4059 - val_acc: 0.1413\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3783 - acc: 0.1621 - val_loss: 2.4061 - val_acc: 0.1422\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3771 - acc: 0.1637 - val_loss: 2.4059 - val_acc: 0.1406\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3751 - acc: 0.1646 - val_loss: 2.4062 - val_acc: 0.1426\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3726 - acc: 0.1652 - val_loss: 2.4060 - val_acc: 0.1425\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3731 - acc: 0.1661 - val_loss: 2.4062 - val_acc: 0.1407\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3707 - acc: 0.1663 - val_loss: 2.4067 - val_acc: 0.1403\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3690 - acc: 0.1687 - val_loss: 2.4072 - val_acc: 0.1411\n",
      "logloss val 2.4071638783099742\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4447 - acc: 0.1327 - val_loss: 2.4191 - val_acc: 0.1432\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4131 - acc: 0.1433 - val_loss: 2.4081 - val_acc: 0.1448\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4028 - acc: 0.1462 - val_loss: 2.4033 - val_acc: 0.1436\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3979 - acc: 0.1502 - val_loss: 2.4002 - val_acc: 0.1449\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3971 - acc: 0.1512 - val_loss: 2.3985 - val_acc: 0.1479\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3934 - acc: 0.1535 - val_loss: 2.3974 - val_acc: 0.1493\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3923 - acc: 0.1538 - val_loss: 2.3962 - val_acc: 0.1509\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3886 - acc: 0.1552 - val_loss: 2.3952 - val_acc: 0.1519\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3878 - acc: 0.1560 - val_loss: 2.3945 - val_acc: 0.1536\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3860 - acc: 0.1572 - val_loss: 2.3942 - val_acc: 0.1529\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3845 - acc: 0.1583 - val_loss: 2.3937 - val_acc: 0.1537\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3833 - acc: 0.1588 - val_loss: 2.3933 - val_acc: 0.1527\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3804 - acc: 0.1602 - val_loss: 2.3929 - val_acc: 0.1576\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3816 - acc: 0.1585 - val_loss: 2.3929 - val_acc: 0.1571\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3782 - acc: 0.1609 - val_loss: 2.3927 - val_acc: 0.1576\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3760 - acc: 0.1633 - val_loss: 2.3926 - val_acc: 0.1547\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3767 - acc: 0.1633 - val_loss: 2.3926 - val_acc: 0.1566\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3743 - acc: 0.1635 - val_loss: 2.3922 - val_acc: 0.1584\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3736 - acc: 0.1644 - val_loss: 2.3927 - val_acc: 0.1595\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3703 - acc: 0.1666 - val_loss: 2.3926 - val_acc: 0.1598\n",
      "logloss val 2.392606214329824\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "8s - loss: 2.4448 - acc: 0.1369 - val_loss: 2.4201 - val_acc: 0.1367\n",
      "Epoch 2/20\n",
      "6s - loss: 2.4131 - acc: 0.1443 - val_loss: 2.4097 - val_acc: 0.1428\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4018 - acc: 0.1457 - val_loss: 2.4047 - val_acc: 0.1462\n",
      "Epoch 4/20\n",
      "6s - loss: 2.4000 - acc: 0.1483 - val_loss: 2.4023 - val_acc: 0.1480\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3956 - acc: 0.1542 - val_loss: 2.4002 - val_acc: 0.1532\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3933 - acc: 0.1533 - val_loss: 2.3988 - val_acc: 0.1516\n",
      "Epoch 7/20\n",
      "6s - loss: 2.3914 - acc: 0.1545 - val_loss: 2.3978 - val_acc: 0.1529\n",
      "Epoch 8/20\n",
      "6s - loss: 2.3878 - acc: 0.1568 - val_loss: 2.3969 - val_acc: 0.1543\n",
      "Epoch 9/20\n",
      "6s - loss: 2.3892 - acc: 0.1561 - val_loss: 2.3962 - val_acc: 0.1548\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3865 - acc: 0.1592 - val_loss: 2.3956 - val_acc: 0.1582\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3847 - acc: 0.1589 - val_loss: 2.3955 - val_acc: 0.1555\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3817 - acc: 0.1619 - val_loss: 2.3948 - val_acc: 0.1583\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3831 - acc: 0.1607 - val_loss: 2.3946 - val_acc: 0.1576\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3790 - acc: 0.1624 - val_loss: 2.3941 - val_acc: 0.1579\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3797 - acc: 0.1621 - val_loss: 2.3940 - val_acc: 0.1588\n",
      "Epoch 16/20\n",
      "6s - loss: 2.3757 - acc: 0.1635 - val_loss: 2.3941 - val_acc: 0.1588\n",
      "Epoch 17/20\n",
      "6s - loss: 2.3769 - acc: 0.1646 - val_loss: 2.3940 - val_acc: 0.1592\n",
      "Epoch 18/20\n",
      "6s - loss: 2.3741 - acc: 0.1637 - val_loss: 2.3937 - val_acc: 0.1606\n",
      "Epoch 19/20\n",
      "6s - loss: 2.3723 - acc: 0.1660 - val_loss: 2.3939 - val_acc: 0.1587\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3718 - acc: 0.1672 - val_loss: 2.3939 - val_acc: 0.1607\n",
      "logloss val 2.3938908468236293\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4444 - acc: 0.1357 - val_loss: 2.4192 - val_acc: 0.1417\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4106 - acc: 0.1433 - val_loss: 2.4103 - val_acc: 0.1425\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4019 - acc: 0.1475 - val_loss: 2.4077 - val_acc: 0.1408\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3967 - acc: 0.1505 - val_loss: 2.4065 - val_acc: 0.1424\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3949 - acc: 0.1530 - val_loss: 2.4057 - val_acc: 0.1382\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3924 - acc: 0.1548 - val_loss: 2.4052 - val_acc: 0.1390\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3899 - acc: 0.1544 - val_loss: 2.4047 - val_acc: 0.1441\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3890 - acc: 0.1571 - val_loss: 2.4043 - val_acc: 0.1450\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3868 - acc: 0.1576 - val_loss: 2.4041 - val_acc: 0.1460\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3844 - acc: 0.1594 - val_loss: 2.4040 - val_acc: 0.1453\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3820 - acc: 0.1600 - val_loss: 2.4040 - val_acc: 0.1449\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3824 - acc: 0.1605 - val_loss: 2.4038 - val_acc: 0.1420\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3798 - acc: 0.1622 - val_loss: 2.4039 - val_acc: 0.1445\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3797 - acc: 0.1607 - val_loss: 2.4036 - val_acc: 0.1452\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3777 - acc: 0.1632 - val_loss: 2.4037 - val_acc: 0.1432\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3765 - acc: 0.1635 - val_loss: 2.4040 - val_acc: 0.1440\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3726 - acc: 0.1638 - val_loss: 2.4039 - val_acc: 0.1464\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3732 - acc: 0.1643 - val_loss: 2.4044 - val_acc: 0.1450\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3716 - acc: 0.1655 - val_loss: 2.4042 - val_acc: 0.1479\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3712 - acc: 0.1661 - val_loss: 2.4043 - val_acc: 0.1469\n",
      "logloss val 2.404293366171029\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4439 - acc: 0.1325 - val_loss: 2.4193 - val_acc: 0.1380\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4106 - acc: 0.1437 - val_loss: 2.4090 - val_acc: 0.1443\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4025 - acc: 0.1481 - val_loss: 2.4056 - val_acc: 0.1456\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3970 - acc: 0.1517 - val_loss: 2.4042 - val_acc: 0.1469\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3948 - acc: 0.1546 - val_loss: 2.4032 - val_acc: 0.1447\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3920 - acc: 0.1554 - val_loss: 2.4026 - val_acc: 0.1455\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3917 - acc: 0.1554 - val_loss: 2.4021 - val_acc: 0.1439\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3872 - acc: 0.1584 - val_loss: 2.4018 - val_acc: 0.1451\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3863 - acc: 0.1571 - val_loss: 2.4013 - val_acc: 0.1447\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3843 - acc: 0.1588 - val_loss: 2.4011 - val_acc: 0.1447\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3829 - acc: 0.1591 - val_loss: 2.4008 - val_acc: 0.1447\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3817 - acc: 0.1602 - val_loss: 2.4010 - val_acc: 0.1409\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3794 - acc: 0.1622 - val_loss: 2.4008 - val_acc: 0.1436\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3781 - acc: 0.1609 - val_loss: 2.4008 - val_acc: 0.1443\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3778 - acc: 0.1628 - val_loss: 2.4007 - val_acc: 0.1421\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3754 - acc: 0.1636 - val_loss: 2.4009 - val_acc: 0.1435\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3736 - acc: 0.1659 - val_loss: 2.4012 - val_acc: 0.1406\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3718 - acc: 0.1661 - val_loss: 2.4014 - val_acc: 0.1420\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3717 - acc: 0.1662 - val_loss: 2.4016 - val_acc: 0.1420\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3691 - acc: 0.1677 - val_loss: 2.4018 - val_acc: 0.1409\n",
      "logloss val 2.4018006654725066\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4448 - acc: 0.1300 - val_loss: 2.4197 - val_acc: 0.1419\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4128 - acc: 0.1440 - val_loss: 2.4076 - val_acc: 0.1444\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4037 - acc: 0.1465 - val_loss: 2.4013 - val_acc: 0.1458\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3984 - acc: 0.1495 - val_loss: 2.3985 - val_acc: 0.1488\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3957 - acc: 0.1508 - val_loss: 2.3969 - val_acc: 0.1507\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3926 - acc: 0.1549 - val_loss: 2.3959 - val_acc: 0.1494\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3913 - acc: 0.1544 - val_loss: 2.3956 - val_acc: 0.1515\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3882 - acc: 0.1567 - val_loss: 2.3952 - val_acc: 0.1538\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3880 - acc: 0.1575 - val_loss: 2.3949 - val_acc: 0.1545\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3855 - acc: 0.1590 - val_loss: 2.3947 - val_acc: 0.1558\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3843 - acc: 0.1599 - val_loss: 2.3948 - val_acc: 0.1558\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3814 - acc: 0.1615 - val_loss: 2.3946 - val_acc: 0.1569\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3811 - acc: 0.1617 - val_loss: 2.3951 - val_acc: 0.1570\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3791 - acc: 0.1629 - val_loss: 2.3947 - val_acc: 0.1550\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3766 - acc: 0.1637 - val_loss: 2.3952 - val_acc: 0.1547\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3757 - acc: 0.1637 - val_loss: 2.3953 - val_acc: 0.1564\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3751 - acc: 0.1649 - val_loss: 2.3958 - val_acc: 0.1569\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3719 - acc: 0.1655 - val_loss: 2.3961 - val_acc: 0.1553\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3717 - acc: 0.1662 - val_loss: 2.3962 - val_acc: 0.1546\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3703 - acc: 0.1658 - val_loss: 2.3966 - val_acc: 0.1562\n",
      "logloss val 2.396575281491576\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4475 - acc: 0.1241 - val_loss: 2.4187 - val_acc: 0.1439\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4128 - acc: 0.1428 - val_loss: 2.4070 - val_acc: 0.1478\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4049 - acc: 0.1446 - val_loss: 2.4018 - val_acc: 0.1505\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3997 - acc: 0.1482 - val_loss: 2.3991 - val_acc: 0.1538\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3959 - acc: 0.1505 - val_loss: 2.3971 - val_acc: 0.1526\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3946 - acc: 0.1529 - val_loss: 2.3958 - val_acc: 0.1494\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3910 - acc: 0.1546 - val_loss: 2.3951 - val_acc: 0.1505\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3896 - acc: 0.1554 - val_loss: 2.3941 - val_acc: 0.1526\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3889 - acc: 0.1577 - val_loss: 2.3935 - val_acc: 0.1521\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3867 - acc: 0.1585 - val_loss: 2.3932 - val_acc: 0.1525\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3843 - acc: 0.1589 - val_loss: 2.3929 - val_acc: 0.1514\n",
      "Epoch 12/20\n",
      "6s - loss: 2.3836 - acc: 0.1596 - val_loss: 2.3923 - val_acc: 0.1513\n",
      "Epoch 13/20\n",
      "6s - loss: 2.3826 - acc: 0.1601 - val_loss: 2.3922 - val_acc: 0.1541\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3796 - acc: 0.1616 - val_loss: 2.3920 - val_acc: 0.1545\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3783 - acc: 0.1634 - val_loss: 2.3919 - val_acc: 0.1533\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3758 - acc: 0.1654 - val_loss: 2.3919 - val_acc: 0.1518\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3766 - acc: 0.1634 - val_loss: 2.3918 - val_acc: 0.1507\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3745 - acc: 0.1667 - val_loss: 2.3918 - val_acc: 0.1514\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3716 - acc: 0.1673 - val_loss: 2.3916 - val_acc: 0.1529\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3720 - acc: 0.1679 - val_loss: 2.3919 - val_acc: 0.1522\n",
      "logloss val 2.3918759934280422\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4454 - acc: 0.1327 - val_loss: 2.4186 - val_acc: 0.1395\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4116 - acc: 0.1438 - val_loss: 2.4070 - val_acc: 0.1379\n",
      "Epoch 3/20\n",
      "6s - loss: 2.4031 - acc: 0.1461 - val_loss: 2.4017 - val_acc: 0.1411\n",
      "Epoch 4/20\n",
      "7s - loss: 2.3989 - acc: 0.1484 - val_loss: 2.3987 - val_acc: 0.1386\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3954 - acc: 0.1524 - val_loss: 2.3969 - val_acc: 0.1483\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3937 - acc: 0.1547 - val_loss: 2.3956 - val_acc: 0.1471\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3903 - acc: 0.1562 - val_loss: 2.3949 - val_acc: 0.1493\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3893 - acc: 0.1564 - val_loss: 2.3943 - val_acc: 0.1491\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3868 - acc: 0.1573 - val_loss: 2.3934 - val_acc: 0.1537\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3853 - acc: 0.1581 - val_loss: 2.3931 - val_acc: 0.1525\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3839 - acc: 0.1613 - val_loss: 2.3926 - val_acc: 0.1546\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3815 - acc: 0.1605 - val_loss: 2.3929 - val_acc: 0.1537\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3801 - acc: 0.1621 - val_loss: 2.3928 - val_acc: 0.1517\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3780 - acc: 0.1622 - val_loss: 2.3926 - val_acc: 0.1525\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3769 - acc: 0.1619 - val_loss: 2.3928 - val_acc: 0.1534\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3756 - acc: 0.1630 - val_loss: 2.3929 - val_acc: 0.1546\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3725 - acc: 0.1658 - val_loss: 2.3934 - val_acc: 0.1536\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3736 - acc: 0.1635 - val_loss: 2.3932 - val_acc: 0.1542\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3711 - acc: 0.1659 - val_loss: 2.3938 - val_acc: 0.1525\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3692 - acc: 0.1662 - val_loss: 2.3940 - val_acc: 0.1533\n",
      "logloss val 2.394025537022034\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4466 - acc: 0.1276 - val_loss: 2.4205 - val_acc: 0.1408\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4130 - acc: 0.1433 - val_loss: 2.4085 - val_acc: 0.1390\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4040 - acc: 0.1443 - val_loss: 2.4024 - val_acc: 0.1442\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3975 - acc: 0.1491 - val_loss: 2.4003 - val_acc: 0.1493\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3959 - acc: 0.1525 - val_loss: 2.3990 - val_acc: 0.1488\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3929 - acc: 0.1545 - val_loss: 2.3980 - val_acc: 0.1500\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3903 - acc: 0.1563 - val_loss: 2.3972 - val_acc: 0.1515\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3876 - acc: 0.1575 - val_loss: 2.3969 - val_acc: 0.1524\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3882 - acc: 0.1580 - val_loss: 2.3965 - val_acc: 0.1527\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3850 - acc: 0.1602 - val_loss: 2.3957 - val_acc: 0.1512\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3831 - acc: 0.1617 - val_loss: 2.3958 - val_acc: 0.1521\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3823 - acc: 0.1612 - val_loss: 2.3956 - val_acc: 0.1503\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3788 - acc: 0.1644 - val_loss: 2.3955 - val_acc: 0.1513\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3788 - acc: 0.1632 - val_loss: 2.3957 - val_acc: 0.1464\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3773 - acc: 0.1646 - val_loss: 2.3952 - val_acc: 0.1480\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3750 - acc: 0.1664 - val_loss: 2.3957 - val_acc: 0.1466\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3736 - acc: 0.1650 - val_loss: 2.3956 - val_acc: 0.1505\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3724 - acc: 0.1679 - val_loss: 2.3959 - val_acc: 0.1491\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3712 - acc: 0.1672 - val_loss: 2.3961 - val_acc: 0.1495\n",
      "Epoch 20/20\n",
      "4s - loss: 2.3690 - acc: 0.1685 - val_loss: 2.3962 - val_acc: 0.1492\n",
      "logloss val 2.396178374623104\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4411 - acc: 0.1323 - val_loss: 2.4173 - val_acc: 0.1457\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4113 - acc: 0.1424 - val_loss: 2.4051 - val_acc: 0.1503\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4036 - acc: 0.1455 - val_loss: 2.3990 - val_acc: 0.1502\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3989 - acc: 0.1503 - val_loss: 2.3961 - val_acc: 0.1524\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3957 - acc: 0.1519 - val_loss: 2.3944 - val_acc: 0.1552\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3938 - acc: 0.1535 - val_loss: 2.3929 - val_acc: 0.1594\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3912 - acc: 0.1538 - val_loss: 2.3920 - val_acc: 0.1581\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3896 - acc: 0.1562 - val_loss: 2.3915 - val_acc: 0.1562\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3882 - acc: 0.1560 - val_loss: 2.3909 - val_acc: 0.1550\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3866 - acc: 0.1587 - val_loss: 2.3905 - val_acc: 0.1569\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3843 - acc: 0.1584 - val_loss: 2.3906 - val_acc: 0.1526\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3821 - acc: 0.1611 - val_loss: 2.3906 - val_acc: 0.1538\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3829 - acc: 0.1593 - val_loss: 2.3902 - val_acc: 0.1530\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3784 - acc: 0.1620 - val_loss: 2.3900 - val_acc: 0.1570\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3785 - acc: 0.1614 - val_loss: 2.3899 - val_acc: 0.1539\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3752 - acc: 0.1645 - val_loss: 2.3903 - val_acc: 0.1538\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3761 - acc: 0.1631 - val_loss: 2.3901 - val_acc: 0.1565\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3734 - acc: 0.1644 - val_loss: 2.3910 - val_acc: 0.1528\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3717 - acc: 0.1667 - val_loss: 2.3909 - val_acc: 0.1582\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3710 - acc: 0.1657 - val_loss: 2.3910 - val_acc: 0.1538\n",
      "logloss val 2.3910196731858906\n",
      "average logloss val 2.396942983085761\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4455 - acc: 0.1328 - val_loss: 2.4221 - val_acc: 0.1407\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4146 - acc: 0.1413 - val_loss: 2.4131 - val_acc: 0.1423\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4026 - acc: 0.1483 - val_loss: 2.4094 - val_acc: 0.1394\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3985 - acc: 0.1519 - val_loss: 2.4078 - val_acc: 0.1388\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3941 - acc: 0.1544 - val_loss: 2.4075 - val_acc: 0.1400\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3915 - acc: 0.1562 - val_loss: 2.4071 - val_acc: 0.1390\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3903 - acc: 0.1548 - val_loss: 2.4066 - val_acc: 0.1399\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3873 - acc: 0.1580 - val_loss: 2.4062 - val_acc: 0.1406\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3867 - acc: 0.1579 - val_loss: 2.4054 - val_acc: 0.1404\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3855 - acc: 0.1584 - val_loss: 2.4056 - val_acc: 0.1410\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3828 - acc: 0.1603 - val_loss: 2.4056 - val_acc: 0.1425\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3812 - acc: 0.1616 - val_loss: 2.4053 - val_acc: 0.1429\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3805 - acc: 0.1620 - val_loss: 2.4048 - val_acc: 0.1408\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3771 - acc: 0.1643 - val_loss: 2.4050 - val_acc: 0.1419\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3774 - acc: 0.1638 - val_loss: 2.4052 - val_acc: 0.1434\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3761 - acc: 0.1633 - val_loss: 2.4056 - val_acc: 0.1429\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3738 - acc: 0.1660 - val_loss: 2.4058 - val_acc: 0.1422\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3705 - acc: 0.1679 - val_loss: 2.4055 - val_acc: 0.1434\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3715 - acc: 0.1659 - val_loss: 2.4063 - val_acc: 0.1422\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3698 - acc: 0.1682 - val_loss: 2.4062 - val_acc: 0.1427\n",
      "logloss val 2.4061733727232526\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4433 - acc: 0.1336 - val_loss: 2.4193 - val_acc: 0.1408\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4128 - acc: 0.1419 - val_loss: 2.4079 - val_acc: 0.1434\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4023 - acc: 0.1459 - val_loss: 2.4027 - val_acc: 0.1481\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3992 - acc: 0.1482 - val_loss: 2.4008 - val_acc: 0.1472\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3965 - acc: 0.1520 - val_loss: 2.3990 - val_acc: 0.1497\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3938 - acc: 0.1525 - val_loss: 2.3980 - val_acc: 0.1555\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3909 - acc: 0.1547 - val_loss: 2.3969 - val_acc: 0.1529\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3899 - acc: 0.1561 - val_loss: 2.3963 - val_acc: 0.1578\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3885 - acc: 0.1557 - val_loss: 2.3955 - val_acc: 0.1555\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3863 - acc: 0.1587 - val_loss: 2.3952 - val_acc: 0.1549\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3839 - acc: 0.1587 - val_loss: 2.3948 - val_acc: 0.1563\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3836 - acc: 0.1597 - val_loss: 2.3942 - val_acc: 0.1567\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3817 - acc: 0.1602 - val_loss: 2.3943 - val_acc: 0.1555\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3793 - acc: 0.1612 - val_loss: 2.3938 - val_acc: 0.1570\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3796 - acc: 0.1623 - val_loss: 2.3934 - val_acc: 0.1584\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3770 - acc: 0.1635 - val_loss: 2.3933 - val_acc: 0.1576\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3752 - acc: 0.1631 - val_loss: 2.3932 - val_acc: 0.1615\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3749 - acc: 0.1648 - val_loss: 2.3931 - val_acc: 0.1603\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3721 - acc: 0.1660 - val_loss: 2.3934 - val_acc: 0.1572\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3724 - acc: 0.1662 - val_loss: 2.3935 - val_acc: 0.1596\n",
      "logloss val 2.3934874737489737\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4446 - acc: 0.1300 - val_loss: 2.4206 - val_acc: 0.1397\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4122 - acc: 0.1426 - val_loss: 2.4103 - val_acc: 0.1474\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4029 - acc: 0.1455 - val_loss: 2.4053 - val_acc: 0.1512\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3994 - acc: 0.1491 - val_loss: 2.4025 - val_acc: 0.1536\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3962 - acc: 0.1512 - val_loss: 2.4006 - val_acc: 0.1547\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3939 - acc: 0.1530 - val_loss: 2.3994 - val_acc: 0.1552\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3910 - acc: 0.1533 - val_loss: 2.3984 - val_acc: 0.1556\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3901 - acc: 0.1563 - val_loss: 2.3975 - val_acc: 0.1539\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3886 - acc: 0.1550 - val_loss: 2.3967 - val_acc: 0.1533\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3866 - acc: 0.1574 - val_loss: 2.3963 - val_acc: 0.1549\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3855 - acc: 0.1585 - val_loss: 2.3956 - val_acc: 0.1564\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3804 - acc: 0.1607 - val_loss: 2.3955 - val_acc: 0.1570\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3831 - acc: 0.1599 - val_loss: 2.3950 - val_acc: 0.1571\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3804 - acc: 0.1611 - val_loss: 2.3948 - val_acc: 0.1571\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3789 - acc: 0.1606 - val_loss: 2.3945 - val_acc: 0.1566\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3770 - acc: 0.1622 - val_loss: 2.3943 - val_acc: 0.1567\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3772 - acc: 0.1621 - val_loss: 2.3946 - val_acc: 0.1566\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3741 - acc: 0.1638 - val_loss: 2.3946 - val_acc: 0.1562\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3722 - acc: 0.1638 - val_loss: 2.3945 - val_acc: 0.1596\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3727 - acc: 0.1648 - val_loss: 2.3945 - val_acc: 0.1590\n",
      "logloss val 2.3945312711219886\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4459 - acc: 0.1295 - val_loss: 2.4213 - val_acc: 0.1327\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4111 - acc: 0.1448 - val_loss: 2.4127 - val_acc: 0.1391\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4046 - acc: 0.1455 - val_loss: 2.4089 - val_acc: 0.1347\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3980 - acc: 0.1511 - val_loss: 2.4075 - val_acc: 0.1399\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3948 - acc: 0.1541 - val_loss: 2.4065 - val_acc: 0.1425\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3917 - acc: 0.1565 - val_loss: 2.4059 - val_acc: 0.1397\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3916 - acc: 0.1562 - val_loss: 2.4052 - val_acc: 0.1398\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3877 - acc: 0.1584 - val_loss: 2.4049 - val_acc: 0.1416\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3871 - acc: 0.1583 - val_loss: 2.4046 - val_acc: 0.1436\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1586 - val_loss: 2.4040 - val_acc: 0.1432\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3825 - acc: 0.1608 - val_loss: 2.4039 - val_acc: 0.1433\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3824 - acc: 0.1614 - val_loss: 2.4037 - val_acc: 0.1456\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3796 - acc: 0.1617 - val_loss: 2.4037 - val_acc: 0.1445\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3786 - acc: 0.1637 - val_loss: 2.4035 - val_acc: 0.1457\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3780 - acc: 0.1633 - val_loss: 2.4036 - val_acc: 0.1469\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3763 - acc: 0.1638 - val_loss: 2.4039 - val_acc: 0.1492\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3757 - acc: 0.1639 - val_loss: 2.4039 - val_acc: 0.1492\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3706 - acc: 0.1673 - val_loss: 2.4039 - val_acc: 0.1492\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3710 - acc: 0.1665 - val_loss: 2.4041 - val_acc: 0.1485\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3706 - acc: 0.1670 - val_loss: 2.4042 - val_acc: 0.1491\n",
      "logloss val 2.4041662450898467\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4456 - acc: 0.1322 - val_loss: 2.4206 - val_acc: 0.1439\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4115 - acc: 0.1447 - val_loss: 2.4093 - val_acc: 0.1428\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4036 - acc: 0.1451 - val_loss: 2.4056 - val_acc: 0.1447\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3971 - acc: 0.1503 - val_loss: 2.4039 - val_acc: 0.1433\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3948 - acc: 0.1538 - val_loss: 2.4030 - val_acc: 0.1417\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3923 - acc: 0.1550 - val_loss: 2.4020 - val_acc: 0.1436\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3897 - acc: 0.1580 - val_loss: 2.4016 - val_acc: 0.1445\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3881 - acc: 0.1583 - val_loss: 2.4010 - val_acc: 0.1433\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3871 - acc: 0.1593 - val_loss: 2.4007 - val_acc: 0.1439\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3851 - acc: 0.1601 - val_loss: 2.4002 - val_acc: 0.1464\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3837 - acc: 0.1613 - val_loss: 2.4001 - val_acc: 0.1468\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3802 - acc: 0.1609 - val_loss: 2.4000 - val_acc: 0.1469\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3806 - acc: 0.1629 - val_loss: 2.3996 - val_acc: 0.1468\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3790 - acc: 0.1628 - val_loss: 2.3997 - val_acc: 0.1487\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3766 - acc: 0.1651 - val_loss: 2.3996 - val_acc: 0.1495\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3761 - acc: 0.1645 - val_loss: 2.4000 - val_acc: 0.1471\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3730 - acc: 0.1654 - val_loss: 2.3998 - val_acc: 0.1484\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3731 - acc: 0.1658 - val_loss: 2.4000 - val_acc: 0.1457\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3702 - acc: 0.1689 - val_loss: 2.4001 - val_acc: 0.1507\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3706 - acc: 0.1673 - val_loss: 2.4003 - val_acc: 0.1483\n",
      "logloss val 2.400273536335668\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4444 - acc: 0.1276 - val_loss: 2.4205 - val_acc: 0.1400\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4130 - acc: 0.1450 - val_loss: 2.4077 - val_acc: 0.1442\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4049 - acc: 0.1470 - val_loss: 2.4013 - val_acc: 0.1511\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3980 - acc: 0.1507 - val_loss: 2.3982 - val_acc: 0.1553\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3950 - acc: 0.1542 - val_loss: 2.3971 - val_acc: 0.1539\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3928 - acc: 0.1562 - val_loss: 2.3962 - val_acc: 0.1541\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3900 - acc: 0.1556 - val_loss: 2.3956 - val_acc: 0.1573\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3896 - acc: 0.1567 - val_loss: 2.3950 - val_acc: 0.1570\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3868 - acc: 0.1577 - val_loss: 2.3944 - val_acc: 0.1566\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3864 - acc: 0.1577 - val_loss: 2.3946 - val_acc: 0.1568\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3835 - acc: 0.1607 - val_loss: 2.3943 - val_acc: 0.1545\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3818 - acc: 0.1599 - val_loss: 2.3942 - val_acc: 0.1582\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3796 - acc: 0.1605 - val_loss: 2.3942 - val_acc: 0.1569\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3793 - acc: 0.1619 - val_loss: 2.3942 - val_acc: 0.1576\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3780 - acc: 0.1612 - val_loss: 2.3943 - val_acc: 0.1581\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3765 - acc: 0.1622 - val_loss: 2.3946 - val_acc: 0.1559\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3751 - acc: 0.1629 - val_loss: 2.3946 - val_acc: 0.1551\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3712 - acc: 0.1659 - val_loss: 2.3953 - val_acc: 0.1576\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3716 - acc: 0.1664 - val_loss: 2.3950 - val_acc: 0.1554\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3717 - acc: 0.1650 - val_loss: 2.3956 - val_acc: 0.1582\n",
      "logloss val 2.3955519839593626\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4462 - acc: 0.1332 - val_loss: 2.4183 - val_acc: 0.1444\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4107 - acc: 0.1446 - val_loss: 2.4060 - val_acc: 0.1447\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4040 - acc: 0.1447 - val_loss: 2.4003 - val_acc: 0.1458\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3994 - acc: 0.1485 - val_loss: 2.3979 - val_acc: 0.1498\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3951 - acc: 0.1524 - val_loss: 2.3964 - val_acc: 0.1507\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3944 - acc: 0.1534 - val_loss: 2.3956 - val_acc: 0.1489\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3904 - acc: 0.1557 - val_loss: 2.3948 - val_acc: 0.1497\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3888 - acc: 0.1567 - val_loss: 2.3942 - val_acc: 0.1497\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3878 - acc: 0.1582 - val_loss: 2.3938 - val_acc: 0.1490\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1579 - val_loss: 2.3933 - val_acc: 0.1497\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3847 - acc: 0.1589 - val_loss: 2.3929 - val_acc: 0.1509\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3837 - acc: 0.1597 - val_loss: 2.3930 - val_acc: 0.1502\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3798 - acc: 0.1611 - val_loss: 2.3924 - val_acc: 0.1513\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3789 - acc: 0.1619 - val_loss: 2.3923 - val_acc: 0.1501\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3786 - acc: 0.1627 - val_loss: 2.3923 - val_acc: 0.1518\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3765 - acc: 0.1623 - val_loss: 2.3918 - val_acc: 0.1515\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3740 - acc: 0.1649 - val_loss: 2.3921 - val_acc: 0.1533\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3741 - acc: 0.1634 - val_loss: 2.3922 - val_acc: 0.1513\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3715 - acc: 0.1665 - val_loss: 2.3924 - val_acc: 0.1530\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3720 - acc: 0.1650 - val_loss: 2.3924 - val_acc: 0.1517\n",
      "logloss val 2.392386459984305\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4450 - acc: 0.1337 - val_loss: 2.4179 - val_acc: 0.1361\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4122 - acc: 0.1441 - val_loss: 2.4060 - val_acc: 0.1377\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4020 - acc: 0.1484 - val_loss: 2.4004 - val_acc: 0.1410\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3993 - acc: 0.1522 - val_loss: 2.3979 - val_acc: 0.1470\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3955 - acc: 0.1534 - val_loss: 2.3963 - val_acc: 0.1462\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3929 - acc: 0.1544 - val_loss: 2.3949 - val_acc: 0.1452\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3907 - acc: 0.1561 - val_loss: 2.3944 - val_acc: 0.1499\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3881 - acc: 0.1564 - val_loss: 2.3935 - val_acc: 0.1489\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3893 - acc: 0.1578 - val_loss: 2.3929 - val_acc: 0.1495\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3851 - acc: 0.1580 - val_loss: 2.3928 - val_acc: 0.1513\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3841 - acc: 0.1599 - val_loss: 2.3920 - val_acc: 0.1540\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3814 - acc: 0.1609 - val_loss: 2.3919 - val_acc: 0.1526\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3802 - acc: 0.1627 - val_loss: 2.3925 - val_acc: 0.1528\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3801 - acc: 0.1639 - val_loss: 2.3915 - val_acc: 0.1514\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3766 - acc: 0.1642 - val_loss: 2.3922 - val_acc: 0.1513\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3748 - acc: 0.1647 - val_loss: 2.3925 - val_acc: 0.1526\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3746 - acc: 0.1659 - val_loss: 2.3921 - val_acc: 0.1525\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3736 - acc: 0.1658 - val_loss: 2.3925 - val_acc: 0.1524\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3702 - acc: 0.1669 - val_loss: 2.3927 - val_acc: 0.1524\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3695 - acc: 0.1679 - val_loss: 2.3932 - val_acc: 0.1532\n",
      "logloss val 2.393151357892624\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4440 - acc: 0.1330 - val_loss: 2.4200 - val_acc: 0.1402\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4118 - acc: 0.1435 - val_loss: 2.4080 - val_acc: 0.1401\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4035 - acc: 0.1463 - val_loss: 2.4027 - val_acc: 0.1424\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3983 - acc: 0.1495 - val_loss: 2.4003 - val_acc: 0.1457\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3958 - acc: 0.1520 - val_loss: 2.3992 - val_acc: 0.1469\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3935 - acc: 0.1537 - val_loss: 2.3984 - val_acc: 0.1473\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3898 - acc: 0.1540 - val_loss: 2.3983 - val_acc: 0.1484\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3917 - acc: 0.1565 - val_loss: 2.3969 - val_acc: 0.1492\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3867 - acc: 0.1583 - val_loss: 2.3967 - val_acc: 0.1472\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1586 - val_loss: 2.3962 - val_acc: 0.1477\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3839 - acc: 0.1597 - val_loss: 2.3962 - val_acc: 0.1493\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3816 - acc: 0.1613 - val_loss: 2.3961 - val_acc: 0.1468\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3816 - acc: 0.1606 - val_loss: 2.3959 - val_acc: 0.1483\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3793 - acc: 0.1612 - val_loss: 2.3958 - val_acc: 0.1496\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3779 - acc: 0.1620 - val_loss: 2.3956 - val_acc: 0.1496\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3763 - acc: 0.1634 - val_loss: 2.3954 - val_acc: 0.1484\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3735 - acc: 0.1639 - val_loss: 2.3959 - val_acc: 0.1485\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3728 - acc: 0.1654 - val_loss: 2.3957 - val_acc: 0.1499\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3712 - acc: 0.1664 - val_loss: 2.3963 - val_acc: 0.1517\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3713 - acc: 0.1658 - val_loss: 2.3962 - val_acc: 0.1488\n",
      "logloss val 2.396157967925084\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4460 - acc: 0.1275 - val_loss: 2.4183 - val_acc: 0.1460\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4121 - acc: 0.1447 - val_loss: 2.4058 - val_acc: 0.1489\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4046 - acc: 0.1458 - val_loss: 2.3989 - val_acc: 0.1531\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3983 - acc: 0.1492 - val_loss: 2.3958 - val_acc: 0.1593\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3962 - acc: 0.1545 - val_loss: 2.3937 - val_acc: 0.1566\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3932 - acc: 0.1549 - val_loss: 2.3928 - val_acc: 0.1551\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3910 - acc: 0.1562 - val_loss: 2.3916 - val_acc: 0.1598\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3885 - acc: 0.1565 - val_loss: 2.3912 - val_acc: 0.1578\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3888 - acc: 0.1571 - val_loss: 2.3907 - val_acc: 0.1544\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3844 - acc: 0.1606 - val_loss: 2.3901 - val_acc: 0.1562\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3842 - acc: 0.1600 - val_loss: 2.3899 - val_acc: 0.1543\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3818 - acc: 0.1622 - val_loss: 2.3900 - val_acc: 0.1548\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3798 - acc: 0.1622 - val_loss: 2.3895 - val_acc: 0.1543\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3781 - acc: 0.1626 - val_loss: 2.3894 - val_acc: 0.1543\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3780 - acc: 0.1616 - val_loss: 2.3899 - val_acc: 0.1546\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3753 - acc: 0.1641 - val_loss: 2.3898 - val_acc: 0.1562\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3747 - acc: 0.1648 - val_loss: 2.3897 - val_acc: 0.1554\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3720 - acc: 0.1650 - val_loss: 2.3901 - val_acc: 0.1543\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3726 - acc: 0.1649 - val_loss: 2.3904 - val_acc: 0.1524\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3681 - acc: 0.1678 - val_loss: 2.3908 - val_acc: 0.1540\n",
      "logloss val 2.390774738262931\n",
      "average logloss val 2.3966654407044037\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4456 - acc: 0.1346 - val_loss: 2.4209 - val_acc: 0.1404\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4096 - acc: 0.1456 - val_loss: 2.4123 - val_acc: 0.1400\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4029 - acc: 0.1485 - val_loss: 2.4096 - val_acc: 0.1390\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3979 - acc: 0.1510 - val_loss: 2.4088 - val_acc: 0.1395\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3938 - acc: 0.1535 - val_loss: 2.4081 - val_acc: 0.1414\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3925 - acc: 0.1555 - val_loss: 2.4076 - val_acc: 0.1427\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3898 - acc: 0.1573 - val_loss: 2.4072 - val_acc: 0.1418\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3879 - acc: 0.1576 - val_loss: 2.4067 - val_acc: 0.1399\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3863 - acc: 0.1596 - val_loss: 2.4068 - val_acc: 0.1394\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3850 - acc: 0.1597 - val_loss: 2.4064 - val_acc: 0.1395\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3827 - acc: 0.1607 - val_loss: 2.4061 - val_acc: 0.1400\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3811 - acc: 0.1628 - val_loss: 2.4065 - val_acc: 0.1407\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3798 - acc: 0.1622 - val_loss: 2.4064 - val_acc: 0.1426\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3795 - acc: 0.1620 - val_loss: 2.4064 - val_acc: 0.1425\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3763 - acc: 0.1652 - val_loss: 2.4063 - val_acc: 0.1418\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3749 - acc: 0.1655 - val_loss: 2.4062 - val_acc: 0.1421\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3741 - acc: 0.1659 - val_loss: 2.4066 - val_acc: 0.1415\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3723 - acc: 0.1662 - val_loss: 2.4068 - val_acc: 0.1407\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3724 - acc: 0.1672 - val_loss: 2.4072 - val_acc: 0.1408\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3686 - acc: 0.1681 - val_loss: 2.4074 - val_acc: 0.1396\n",
      "logloss val 2.407391012933627\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4460 - acc: 0.1248 - val_loss: 2.4213 - val_acc: 0.1398\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4132 - acc: 0.1427 - val_loss: 2.4097 - val_acc: 0.1454\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4044 - acc: 0.1445 - val_loss: 2.4039 - val_acc: 0.1460\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3986 - acc: 0.1472 - val_loss: 2.4007 - val_acc: 0.1483\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3961 - acc: 0.1501 - val_loss: 2.3991 - val_acc: 0.1537\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3927 - acc: 0.1531 - val_loss: 2.3981 - val_acc: 0.1535\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3919 - acc: 0.1547 - val_loss: 2.3970 - val_acc: 0.1552\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3895 - acc: 0.1558 - val_loss: 2.3961 - val_acc: 0.1547\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3892 - acc: 0.1543 - val_loss: 2.3956 - val_acc: 0.1566\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3854 - acc: 0.1575 - val_loss: 2.3951 - val_acc: 0.1603\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3848 - acc: 0.1579 - val_loss: 2.3946 - val_acc: 0.1548\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3842 - acc: 0.1580 - val_loss: 2.3947 - val_acc: 0.1571\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3813 - acc: 0.1598 - val_loss: 2.3943 - val_acc: 0.1560\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3802 - acc: 0.1602 - val_loss: 2.3937 - val_acc: 0.1548\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3782 - acc: 0.1622 - val_loss: 2.3935 - val_acc: 0.1552\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3760 - acc: 0.1630 - val_loss: 2.3934 - val_acc: 0.1564\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3784 - acc: 0.1615 - val_loss: 2.3937 - val_acc: 0.1566\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3727 - acc: 0.1650 - val_loss: 2.3935 - val_acc: 0.1552\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3738 - acc: 0.1632 - val_loss: 2.3931 - val_acc: 0.1570\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3704 - acc: 0.1659 - val_loss: 2.3934 - val_acc: 0.1560\n",
      "logloss val 2.3933992764678416\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4434 - acc: 0.1328 - val_loss: 2.4197 - val_acc: 0.1464\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4126 - acc: 0.1445 - val_loss: 2.4099 - val_acc: 0.1476\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4033 - acc: 0.1453 - val_loss: 2.4051 - val_acc: 0.1531\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3977 - acc: 0.1498 - val_loss: 2.4023 - val_acc: 0.1519\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3958 - acc: 0.1508 - val_loss: 2.4004 - val_acc: 0.1576\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3931 - acc: 0.1544 - val_loss: 2.3991 - val_acc: 0.1576\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3901 - acc: 0.1553 - val_loss: 2.3977 - val_acc: 0.1587\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3892 - acc: 0.1575 - val_loss: 2.3970 - val_acc: 0.1590\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3864 - acc: 0.1578 - val_loss: 2.3964 - val_acc: 0.1552\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3856 - acc: 0.1582 - val_loss: 2.3958 - val_acc: 0.1562\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3835 - acc: 0.1598 - val_loss: 2.3957 - val_acc: 0.1545\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3824 - acc: 0.1620 - val_loss: 2.3953 - val_acc: 0.1564\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3791 - acc: 0.1608 - val_loss: 2.3948 - val_acc: 0.1541\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3801 - acc: 0.1614 - val_loss: 2.3946 - val_acc: 0.1574\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3772 - acc: 0.1638 - val_loss: 2.3944 - val_acc: 0.1572\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3775 - acc: 0.1642 - val_loss: 2.3945 - val_acc: 0.1579\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3731 - acc: 0.1651 - val_loss: 2.3945 - val_acc: 0.1570\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3724 - acc: 0.1656 - val_loss: 2.3943 - val_acc: 0.1572\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3736 - acc: 0.1651 - val_loss: 2.3946 - val_acc: 0.1572\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3695 - acc: 0.1665 - val_loss: 2.3946 - val_acc: 0.1598\n",
      "logloss val 2.394577496242472\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4451 - acc: 0.1323 - val_loss: 2.4199 - val_acc: 0.1424\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4106 - acc: 0.1435 - val_loss: 2.4107 - val_acc: 0.1414\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4031 - acc: 0.1466 - val_loss: 2.4074 - val_acc: 0.1418\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3979 - acc: 0.1494 - val_loss: 2.4059 - val_acc: 0.1420\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3941 - acc: 0.1532 - val_loss: 2.4049 - val_acc: 0.1409\n",
      "Epoch 6/20\n",
      "4s - loss: 2.3915 - acc: 0.1553 - val_loss: 2.4044 - val_acc: 0.1440\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3903 - acc: 0.1567 - val_loss: 2.4036 - val_acc: 0.1453\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3875 - acc: 0.1587 - val_loss: 2.4035 - val_acc: 0.1453\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3860 - acc: 0.1587 - val_loss: 2.4031 - val_acc: 0.1438\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3840 - acc: 0.1597 - val_loss: 2.4028 - val_acc: 0.1448\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3817 - acc: 0.1612 - val_loss: 2.4027 - val_acc: 0.1454\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3812 - acc: 0.1626 - val_loss: 2.4026 - val_acc: 0.1474\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3806 - acc: 0.1619 - val_loss: 2.4024 - val_acc: 0.1488\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3765 - acc: 0.1631 - val_loss: 2.4025 - val_acc: 0.1457\n",
      "Epoch 15/20\n",
      "4s - loss: 2.3763 - acc: 0.1644 - val_loss: 2.4026 - val_acc: 0.1458\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3751 - acc: 0.1651 - val_loss: 2.4027 - val_acc: 0.1461\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3722 - acc: 0.1665 - val_loss: 2.4029 - val_acc: 0.1458\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3725 - acc: 0.1657 - val_loss: 2.4025 - val_acc: 0.1520\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3710 - acc: 0.1653 - val_loss: 2.4030 - val_acc: 0.1511\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3697 - acc: 0.1671 - val_loss: 2.4031 - val_acc: 0.1516\n",
      "logloss val 2.403086971374695\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4476 - acc: 0.1321 - val_loss: 2.4212 - val_acc: 0.1432\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4127 - acc: 0.1438 - val_loss: 2.4112 - val_acc: 0.1424\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4039 - acc: 0.1453 - val_loss: 2.4064 - val_acc: 0.1479\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3996 - acc: 0.1476 - val_loss: 2.4045 - val_acc: 0.1496\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3963 - acc: 0.1518 - val_loss: 2.4033 - val_acc: 0.1511\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3927 - acc: 0.1550 - val_loss: 2.4024 - val_acc: 0.1471\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3927 - acc: 0.1552 - val_loss: 2.4019 - val_acc: 0.1456\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3883 - acc: 0.1562 - val_loss: 2.4010 - val_acc: 0.1455\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3868 - acc: 0.1595 - val_loss: 2.4008 - val_acc: 0.1464\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3860 - acc: 0.1577 - val_loss: 2.4005 - val_acc: 0.1471\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3831 - acc: 0.1605 - val_loss: 2.4003 - val_acc: 0.1459\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3810 - acc: 0.1608 - val_loss: 2.4003 - val_acc: 0.1499\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3823 - acc: 0.1595 - val_loss: 2.3998 - val_acc: 0.1451\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3776 - acc: 0.1648 - val_loss: 2.4000 - val_acc: 0.1464\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3785 - acc: 0.1625 - val_loss: 2.3998 - val_acc: 0.1477\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3746 - acc: 0.1651 - val_loss: 2.4002 - val_acc: 0.1453\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3765 - acc: 0.1635 - val_loss: 2.4001 - val_acc: 0.1459\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3714 - acc: 0.1663 - val_loss: 2.4006 - val_acc: 0.1440\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3713 - acc: 0.1658 - val_loss: 2.4008 - val_acc: 0.1452\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3708 - acc: 0.1663 - val_loss: 2.4009 - val_acc: 0.1452\n",
      "logloss val 2.400884431444533\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4470 - acc: 0.1331 - val_loss: 2.4193 - val_acc: 0.1417\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4130 - acc: 0.1430 - val_loss: 2.4077 - val_acc: 0.1456\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4035 - acc: 0.1452 - val_loss: 2.4020 - val_acc: 0.1490\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3999 - acc: 0.1480 - val_loss: 2.3991 - val_acc: 0.1542\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3952 - acc: 0.1510 - val_loss: 2.3976 - val_acc: 0.1534\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3939 - acc: 0.1531 - val_loss: 2.3968 - val_acc: 0.1537\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3903 - acc: 0.1545 - val_loss: 2.3959 - val_acc: 0.1523\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3890 - acc: 0.1570 - val_loss: 2.3954 - val_acc: 0.1558\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3877 - acc: 0.1584 - val_loss: 2.3950 - val_acc: 0.1533\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3865 - acc: 0.1585 - val_loss: 2.3948 - val_acc: 0.1561\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3844 - acc: 0.1595 - val_loss: 2.3948 - val_acc: 0.1582\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3804 - acc: 0.1612 - val_loss: 2.3946 - val_acc: 0.1561\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3818 - acc: 0.1593 - val_loss: 2.3946 - val_acc: 0.1562\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3783 - acc: 0.1626 - val_loss: 2.3945 - val_acc: 0.1554\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3786 - acc: 0.1622 - val_loss: 2.3947 - val_acc: 0.1535\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3763 - acc: 0.1630 - val_loss: 2.3948 - val_acc: 0.1574\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3757 - acc: 0.1641 - val_loss: 2.3948 - val_acc: 0.1553\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3728 - acc: 0.1652 - val_loss: 2.3954 - val_acc: 0.1566\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3710 - acc: 0.1659 - val_loss: 2.3955 - val_acc: 0.1578\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3706 - acc: 0.1664 - val_loss: 2.3959 - val_acc: 0.1530\n",
      "logloss val 2.395903482222136\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4463 - acc: 0.1317 - val_loss: 2.4186 - val_acc: 0.1432\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4123 - acc: 0.1423 - val_loss: 2.4065 - val_acc: 0.1465\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4026 - acc: 0.1446 - val_loss: 2.4012 - val_acc: 0.1473\n",
      "Epoch 4/20\n",
      "5s - loss: 2.4002 - acc: 0.1481 - val_loss: 2.3983 - val_acc: 0.1493\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3955 - acc: 0.1522 - val_loss: 2.3969 - val_acc: 0.1515\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3943 - acc: 0.1548 - val_loss: 2.3958 - val_acc: 0.1495\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3914 - acc: 0.1553 - val_loss: 2.3950 - val_acc: 0.1446\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3891 - acc: 0.1548 - val_loss: 2.3944 - val_acc: 0.1466\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3880 - acc: 0.1589 - val_loss: 2.3937 - val_acc: 0.1487\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3864 - acc: 0.1592 - val_loss: 2.3932 - val_acc: 0.1491\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3842 - acc: 0.1596 - val_loss: 2.3933 - val_acc: 0.1503\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3825 - acc: 0.1612 - val_loss: 2.3927 - val_acc: 0.1509\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3818 - acc: 0.1620 - val_loss: 2.3924 - val_acc: 0.1538\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3799 - acc: 0.1609 - val_loss: 2.3921 - val_acc: 0.1525\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3778 - acc: 0.1643 - val_loss: 2.3923 - val_acc: 0.1510\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3767 - acc: 0.1640 - val_loss: 2.3920 - val_acc: 0.1532\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3747 - acc: 0.1654 - val_loss: 2.3923 - val_acc: 0.1511\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3740 - acc: 0.1659 - val_loss: 2.3922 - val_acc: 0.1515\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3719 - acc: 0.1664 - val_loss: 2.3923 - val_acc: 0.1529\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3716 - acc: 0.1674 - val_loss: 2.3923 - val_acc: 0.1498\n",
      "logloss val 2.392349307336056\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4463 - acc: 0.1267 - val_loss: 2.4188 - val_acc: 0.1357\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4135 - acc: 0.1425 - val_loss: 2.4079 - val_acc: 0.1359\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4041 - acc: 0.1446 - val_loss: 2.4012 - val_acc: 0.1376\n",
      "Epoch 4/20\n",
      "5s - loss: 2.4007 - acc: 0.1492 - val_loss: 2.3981 - val_acc: 0.1422\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3951 - acc: 0.1519 - val_loss: 2.3964 - val_acc: 0.1463\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3934 - acc: 0.1525 - val_loss: 2.3951 - val_acc: 0.1463\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3921 - acc: 0.1551 - val_loss: 2.3940 - val_acc: 0.1497\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3900 - acc: 0.1560 - val_loss: 2.3939 - val_acc: 0.1514\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3876 - acc: 0.1581 - val_loss: 2.3932 - val_acc: 0.1510\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3854 - acc: 0.1572 - val_loss: 2.3930 - val_acc: 0.1518\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3849 - acc: 0.1604 - val_loss: 2.3928 - val_acc: 0.1529\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3819 - acc: 0.1607 - val_loss: 2.3925 - val_acc: 0.1570\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3804 - acc: 0.1623 - val_loss: 2.3929 - val_acc: 0.1511\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3804 - acc: 0.1621 - val_loss: 2.3926 - val_acc: 0.1530\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3780 - acc: 0.1617 - val_loss: 2.3928 - val_acc: 0.1526\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3759 - acc: 0.1627 - val_loss: 2.3930 - val_acc: 0.1538\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3747 - acc: 0.1642 - val_loss: 2.3931 - val_acc: 0.1534\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3726 - acc: 0.1641 - val_loss: 2.3934 - val_acc: 0.1537\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3724 - acc: 0.1639 - val_loss: 2.3938 - val_acc: 0.1529\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3704 - acc: 0.1667 - val_loss: 2.3936 - val_acc: 0.1517\n",
      "logloss val 2.3936491901912613\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4457 - acc: 0.1328 - val_loss: 2.4201 - val_acc: 0.1340\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4134 - acc: 0.1418 - val_loss: 2.4083 - val_acc: 0.1403\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4041 - acc: 0.1449 - val_loss: 2.4028 - val_acc: 0.1421\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3985 - acc: 0.1488 - val_loss: 2.4006 - val_acc: 0.1460\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3959 - acc: 0.1530 - val_loss: 2.3992 - val_acc: 0.1436\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3930 - acc: 0.1550 - val_loss: 2.3986 - val_acc: 0.1471\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3908 - acc: 0.1563 - val_loss: 2.3976 - val_acc: 0.1481\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3893 - acc: 0.1576 - val_loss: 2.3971 - val_acc: 0.1484\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3876 - acc: 0.1579 - val_loss: 2.3968 - val_acc: 0.1485\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3850 - acc: 0.1591 - val_loss: 2.3963 - val_acc: 0.1472\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3839 - acc: 0.1599 - val_loss: 2.3961 - val_acc: 0.1465\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3815 - acc: 0.1609 - val_loss: 2.3960 - val_acc: 0.1469\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3809 - acc: 0.1616 - val_loss: 2.3956 - val_acc: 0.1469\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3763 - acc: 0.1634 - val_loss: 2.3960 - val_acc: 0.1485\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3783 - acc: 0.1630 - val_loss: 2.3956 - val_acc: 0.1469\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3742 - acc: 0.1648 - val_loss: 2.3958 - val_acc: 0.1495\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3742 - acc: 0.1650 - val_loss: 2.3959 - val_acc: 0.1520\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3731 - acc: 0.1659 - val_loss: 2.3962 - val_acc: 0.1489\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3697 - acc: 0.1684 - val_loss: 2.3963 - val_acc: 0.1495\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3694 - acc: 0.1663 - val_loss: 2.3961 - val_acc: 0.1495\n",
      "logloss val 2.396137997310327\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4443 - acc: 0.1297 - val_loss: 2.4185 - val_acc: 0.1473\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4117 - acc: 0.1439 - val_loss: 2.4065 - val_acc: 0.1481\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4055 - acc: 0.1446 - val_loss: 2.4000 - val_acc: 0.1543\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3989 - acc: 0.1504 - val_loss: 2.3973 - val_acc: 0.1527\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3959 - acc: 0.1521 - val_loss: 2.3951 - val_acc: 0.1534\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3933 - acc: 0.1516 - val_loss: 2.3940 - val_acc: 0.1551\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3920 - acc: 0.1553 - val_loss: 2.3932 - val_acc: 0.1542\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3883 - acc: 0.1574 - val_loss: 2.3925 - val_acc: 0.1550\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3876 - acc: 0.1579 - val_loss: 2.3919 - val_acc: 0.1539\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3866 - acc: 0.1584 - val_loss: 2.3915 - val_acc: 0.1550\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3840 - acc: 0.1595 - val_loss: 2.3909 - val_acc: 0.1532\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3816 - acc: 0.1603 - val_loss: 2.3909 - val_acc: 0.1546\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3814 - acc: 0.1614 - val_loss: 2.3908 - val_acc: 0.1534\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3787 - acc: 0.1624 - val_loss: 2.3905 - val_acc: 0.1552\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3784 - acc: 0.1635 - val_loss: 2.3907 - val_acc: 0.1552\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3761 - acc: 0.1640 - val_loss: 2.3904 - val_acc: 0.1518\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3734 - acc: 0.1662 - val_loss: 2.3907 - val_acc: 0.1539\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3742 - acc: 0.1650 - val_loss: 2.3917 - val_acc: 0.1532\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3714 - acc: 0.1661 - val_loss: 2.3913 - val_acc: 0.1536\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3704 - acc: 0.1664 - val_loss: 2.3916 - val_acc: 0.1532\n",
      "logloss val 2.391563055438222\n",
      "average logloss val 2.396894222096117\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4455 - acc: 0.1261 - val_loss: 2.4219 - val_acc: 0.1392\n",
      "Epoch 2/20\n",
      "4s - loss: 2.4115 - acc: 0.1427 - val_loss: 2.4139 - val_acc: 0.1421\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4033 - acc: 0.1453 - val_loss: 2.4108 - val_acc: 0.1391\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3975 - acc: 0.1516 - val_loss: 2.4096 - val_acc: 0.1387\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3947 - acc: 0.1538 - val_loss: 2.4088 - val_acc: 0.1392\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3922 - acc: 0.1557 - val_loss: 2.4083 - val_acc: 0.1392\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3906 - acc: 0.1547 - val_loss: 2.4074 - val_acc: 0.1410\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3869 - acc: 0.1591 - val_loss: 2.4073 - val_acc: 0.1427\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3866 - acc: 0.1583 - val_loss: 2.4069 - val_acc: 0.1418\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3853 - acc: 0.1597 - val_loss: 2.4066 - val_acc: 0.1415\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3824 - acc: 0.1603 - val_loss: 2.4070 - val_acc: 0.1413\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3826 - acc: 0.1602 - val_loss: 2.4066 - val_acc: 0.1426\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3798 - acc: 0.1634 - val_loss: 2.4063 - val_acc: 0.1421\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3781 - acc: 0.1630 - val_loss: 2.4068 - val_acc: 0.1438\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3770 - acc: 0.1645 - val_loss: 2.4062 - val_acc: 0.1431\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3739 - acc: 0.1659 - val_loss: 2.4070 - val_acc: 0.1423\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3758 - acc: 0.1640 - val_loss: 2.4068 - val_acc: 0.1423\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3739 - acc: 0.1653 - val_loss: 2.4061 - val_acc: 0.1415\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3701 - acc: 0.1685 - val_loss: 2.4075 - val_acc: 0.1414\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3694 - acc: 0.1682 - val_loss: 2.4075 - val_acc: 0.1422\n",
      "logloss val 2.4075425357972655\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4448 - acc: 0.1307 - val_loss: 2.4205 - val_acc: 0.1433\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4115 - acc: 0.1431 - val_loss: 2.4085 - val_acc: 0.1434\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4018 - acc: 0.1457 - val_loss: 2.4035 - val_acc: 0.1445\n",
      "Epoch 4/20\n",
      "4s - loss: 2.3994 - acc: 0.1488 - val_loss: 2.4013 - val_acc: 0.1513\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3962 - acc: 0.1517 - val_loss: 2.3993 - val_acc: 0.1516\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3925 - acc: 0.1528 - val_loss: 2.3983 - val_acc: 0.1504\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3921 - acc: 0.1526 - val_loss: 2.3972 - val_acc: 0.1529\n",
      "Epoch 8/20\n",
      "4s - loss: 2.3888 - acc: 0.1553 - val_loss: 2.3964 - val_acc: 0.1559\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3883 - acc: 0.1561 - val_loss: 2.3959 - val_acc: 0.1574\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3862 - acc: 0.1577 - val_loss: 2.3952 - val_acc: 0.1582\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3839 - acc: 0.1591 - val_loss: 2.3948 - val_acc: 0.1584\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3833 - acc: 0.1597 - val_loss: 2.3944 - val_acc: 0.1575\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3813 - acc: 0.1596 - val_loss: 2.3941 - val_acc: 0.1564\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3800 - acc: 0.1616 - val_loss: 2.3940 - val_acc: 0.1578\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3797 - acc: 0.1612 - val_loss: 2.3935 - val_acc: 0.1578\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3763 - acc: 0.1625 - val_loss: 2.3936 - val_acc: 0.1571\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3767 - acc: 0.1618 - val_loss: 2.3936 - val_acc: 0.1586\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3732 - acc: 0.1644 - val_loss: 2.3937 - val_acc: 0.1591\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3732 - acc: 0.1655 - val_loss: 2.3936 - val_acc: 0.1591\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3720 - acc: 0.1659 - val_loss: 2.3935 - val_acc: 0.1594\n",
      "logloss val 2.3935354792170047\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "5s - loss: 2.4454 - acc: 0.1312 - val_loss: 2.4205 - val_acc: 0.1412\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4110 - acc: 0.1449 - val_loss: 2.4097 - val_acc: 0.1450\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4031 - acc: 0.1465 - val_loss: 2.4049 - val_acc: 0.1480\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3975 - acc: 0.1509 - val_loss: 2.4024 - val_acc: 0.1511\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3957 - acc: 0.1524 - val_loss: 2.4007 - val_acc: 0.1549\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3939 - acc: 0.1535 - val_loss: 2.3994 - val_acc: 0.1567\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3900 - acc: 0.1561 - val_loss: 2.3984 - val_acc: 0.1559\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3904 - acc: 0.1569 - val_loss: 2.3974 - val_acc: 0.1574\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3863 - acc: 0.1572 - val_loss: 2.3967 - val_acc: 0.1558\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3865 - acc: 0.1579 - val_loss: 2.3961 - val_acc: 0.1567\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3843 - acc: 0.1593 - val_loss: 2.3956 - val_acc: 0.1586\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3823 - acc: 0.1605 - val_loss: 2.3955 - val_acc: 0.1582\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3813 - acc: 0.1610 - val_loss: 2.3950 - val_acc: 0.1562\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3783 - acc: 0.1631 - val_loss: 2.3946 - val_acc: 0.1571\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3787 - acc: 0.1615 - val_loss: 2.3945 - val_acc: 0.1566\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3769 - acc: 0.1636 - val_loss: 2.3946 - val_acc: 0.1568\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3738 - acc: 0.1643 - val_loss: 2.3944 - val_acc: 0.1574\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3743 - acc: 0.1645 - val_loss: 2.3949 - val_acc: 0.1558\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3724 - acc: 0.1669 - val_loss: 2.3945 - val_acc: 0.1547\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3712 - acc: 0.1660 - val_loss: 2.3950 - val_acc: 0.1564\n",
      "logloss val 2.3949616157126927\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4427 - acc: 0.1344 - val_loss: 2.4203 - val_acc: 0.1422\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4113 - acc: 0.1439 - val_loss: 2.4116 - val_acc: 0.1418\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4013 - acc: 0.1465 - val_loss: 2.4084 - val_acc: 0.1440\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3985 - acc: 0.1497 - val_loss: 2.4072 - val_acc: 0.1410\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3942 - acc: 0.1535 - val_loss: 2.4063 - val_acc: 0.1409\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3922 - acc: 0.1548 - val_loss: 2.4058 - val_acc: 0.1410\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3892 - acc: 0.1568 - val_loss: 2.4052 - val_acc: 0.1430\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3880 - acc: 0.1583 - val_loss: 2.4049 - val_acc: 0.1445\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3870 - acc: 0.1574 - val_loss: 2.4044 - val_acc: 0.1434\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3842 - acc: 0.1597 - val_loss: 2.4042 - val_acc: 0.1477\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3839 - acc: 0.1596 - val_loss: 2.4041 - val_acc: 0.1485\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3802 - acc: 0.1626 - val_loss: 2.4041 - val_acc: 0.1485\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3805 - acc: 0.1618 - val_loss: 2.4039 - val_acc: 0.1457\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3774 - acc: 0.1620 - val_loss: 2.4040 - val_acc: 0.1466\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3770 - acc: 0.1640 - val_loss: 2.4037 - val_acc: 0.1460\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3750 - acc: 0.1635 - val_loss: 2.4040 - val_acc: 0.1476\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3733 - acc: 0.1640 - val_loss: 2.4040 - val_acc: 0.1461\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3724 - acc: 0.1658 - val_loss: 2.4040 - val_acc: 0.1476\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3711 - acc: 0.1669 - val_loss: 2.4044 - val_acc: 0.1484\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3705 - acc: 0.1672 - val_loss: 2.4046 - val_acc: 0.1484\n",
      "logloss val 2.404603060349643\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4435 - acc: 0.1310 - val_loss: 2.4181 - val_acc: 0.1429\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4108 - acc: 0.1437 - val_loss: 2.4087 - val_acc: 0.1424\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4017 - acc: 0.1452 - val_loss: 2.4054 - val_acc: 0.1436\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3980 - acc: 0.1489 - val_loss: 2.4040 - val_acc: 0.1469\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3953 - acc: 0.1517 - val_loss: 2.4031 - val_acc: 0.1441\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3918 - acc: 0.1534 - val_loss: 2.4025 - val_acc: 0.1426\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3916 - acc: 0.1551 - val_loss: 2.4017 - val_acc: 0.1425\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3882 - acc: 0.1565 - val_loss: 2.4013 - val_acc: 0.1428\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3870 - acc: 0.1573 - val_loss: 2.4009 - val_acc: 0.1432\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1586 - val_loss: 2.4006 - val_acc: 0.1428\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3842 - acc: 0.1583 - val_loss: 2.4002 - val_acc: 0.1421\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3817 - acc: 0.1600 - val_loss: 2.4002 - val_acc: 0.1429\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3806 - acc: 0.1596 - val_loss: 2.4000 - val_acc: 0.1418\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3783 - acc: 0.1622 - val_loss: 2.3999 - val_acc: 0.1414\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3780 - acc: 0.1620 - val_loss: 2.3998 - val_acc: 0.1420\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3753 - acc: 0.1632 - val_loss: 2.3997 - val_acc: 0.1409\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3755 - acc: 0.1634 - val_loss: 2.3998 - val_acc: 0.1422\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3733 - acc: 0.1643 - val_loss: 2.3998 - val_acc: 0.1435\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3716 - acc: 0.1650 - val_loss: 2.4005 - val_acc: 0.1413\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3697 - acc: 0.1666 - val_loss: 2.4006 - val_acc: 0.1445\n",
      "logloss val 2.400618515263609\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4436 - acc: 0.1342 - val_loss: 2.4179 - val_acc: 0.1413\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4119 - acc: 0.1433 - val_loss: 2.4067 - val_acc: 0.1440\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4020 - acc: 0.1476 - val_loss: 2.4008 - val_acc: 0.1468\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3996 - acc: 0.1485 - val_loss: 2.3983 - val_acc: 0.1501\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3955 - acc: 0.1524 - val_loss: 2.3969 - val_acc: 0.1492\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3923 - acc: 0.1539 - val_loss: 2.3960 - val_acc: 0.1538\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3909 - acc: 0.1547 - val_loss: 2.3954 - val_acc: 0.1537\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3897 - acc: 0.1552 - val_loss: 2.3948 - val_acc: 0.1539\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3872 - acc: 0.1562 - val_loss: 2.3946 - val_acc: 0.1566\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3862 - acc: 0.1575 - val_loss: 2.3945 - val_acc: 0.1602\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3826 - acc: 0.1579 - val_loss: 2.3944 - val_acc: 0.1610\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3847 - acc: 0.1582 - val_loss: 2.3944 - val_acc: 0.1557\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3791 - acc: 0.1618 - val_loss: 2.3943 - val_acc: 0.1592\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3792 - acc: 0.1617 - val_loss: 2.3947 - val_acc: 0.1597\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3776 - acc: 0.1623 - val_loss: 2.3947 - val_acc: 0.1594\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3758 - acc: 0.1623 - val_loss: 2.3952 - val_acc: 0.1573\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3753 - acc: 0.1637 - val_loss: 2.3956 - val_acc: 0.1605\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3726 - acc: 0.1653 - val_loss: 2.3958 - val_acc: 0.1573\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3730 - acc: 0.1635 - val_loss: 2.3959 - val_acc: 0.1605\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3691 - acc: 0.1670 - val_loss: 2.3962 - val_acc: 0.1593\n",
      "logloss val 2.396249236463598\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4464 - acc: 0.1264 - val_loss: 2.4179 - val_acc: 0.1400\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4118 - acc: 0.1436 - val_loss: 2.4053 - val_acc: 0.1440\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4029 - acc: 0.1459 - val_loss: 2.4004 - val_acc: 0.1471\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3976 - acc: 0.1486 - val_loss: 2.3983 - val_acc: 0.1499\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3959 - acc: 0.1533 - val_loss: 2.3971 - val_acc: 0.1502\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3939 - acc: 0.1546 - val_loss: 2.3960 - val_acc: 0.1514\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3899 - acc: 0.1564 - val_loss: 2.3954 - val_acc: 0.1499\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3903 - acc: 0.1577 - val_loss: 2.3946 - val_acc: 0.1507\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3871 - acc: 0.1585 - val_loss: 2.3943 - val_acc: 0.1479\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1590 - val_loss: 2.3937 - val_acc: 0.1505\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3838 - acc: 0.1599 - val_loss: 2.3933 - val_acc: 0.1509\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3821 - acc: 0.1616 - val_loss: 2.3933 - val_acc: 0.1530\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3821 - acc: 0.1615 - val_loss: 2.3930 - val_acc: 0.1538\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3777 - acc: 0.1633 - val_loss: 2.3927 - val_acc: 0.1534\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3791 - acc: 0.1631 - val_loss: 2.3925 - val_acc: 0.1524\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3760 - acc: 0.1649 - val_loss: 2.3929 - val_acc: 0.1540\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3746 - acc: 0.1644 - val_loss: 2.3928 - val_acc: 0.1522\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3732 - acc: 0.1651 - val_loss: 2.3928 - val_acc: 0.1514\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3728 - acc: 0.1664 - val_loss: 2.3928 - val_acc: 0.1505\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3698 - acc: 0.1674 - val_loss: 2.3929 - val_acc: 0.1501\n",
      "logloss val 2.3929187271311734\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4445 - acc: 0.1303 - val_loss: 2.4195 - val_acc: 0.1347\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4142 - acc: 0.1413 - val_loss: 2.4079 - val_acc: 0.1391\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4039 - acc: 0.1446 - val_loss: 2.4014 - val_acc: 0.1416\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3993 - acc: 0.1494 - val_loss: 2.3984 - val_acc: 0.1454\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3970 - acc: 0.1519 - val_loss: 2.3965 - val_acc: 0.1448\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3945 - acc: 0.1531 - val_loss: 2.3951 - val_acc: 0.1521\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3914 - acc: 0.1554 - val_loss: 2.3943 - val_acc: 0.1534\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3894 - acc: 0.1574 - val_loss: 2.3937 - val_acc: 0.1514\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3874 - acc: 0.1584 - val_loss: 2.3933 - val_acc: 0.1517\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3861 - acc: 0.1579 - val_loss: 2.3932 - val_acc: 0.1521\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3846 - acc: 0.1595 - val_loss: 2.3923 - val_acc: 0.1524\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3818 - acc: 0.1599 - val_loss: 2.3928 - val_acc: 0.1525\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3807 - acc: 0.1612 - val_loss: 2.3925 - val_acc: 0.1521\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3797 - acc: 0.1630 - val_loss: 2.3921 - val_acc: 0.1541\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3792 - acc: 0.1616 - val_loss: 2.3927 - val_acc: 0.1532\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3758 - acc: 0.1631 - val_loss: 2.3925 - val_acc: 0.1528\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3749 - acc: 0.1643 - val_loss: 2.3933 - val_acc: 0.1536\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3741 - acc: 0.1657 - val_loss: 2.3930 - val_acc: 0.1519\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3717 - acc: 0.1653 - val_loss: 2.3936 - val_acc: 0.1519\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3706 - acc: 0.1672 - val_loss: 2.3937 - val_acc: 0.1530\n",
      "logloss val 2.393654510303363\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4449 - acc: 0.1318 - val_loss: 2.4207 - val_acc: 0.1390\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4117 - acc: 0.1413 - val_loss: 2.4089 - val_acc: 0.1412\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4053 - acc: 0.1429 - val_loss: 2.4030 - val_acc: 0.1438\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3982 - acc: 0.1499 - val_loss: 2.4002 - val_acc: 0.1495\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3962 - acc: 0.1515 - val_loss: 2.3988 - val_acc: 0.1484\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3933 - acc: 0.1552 - val_loss: 2.3980 - val_acc: 0.1499\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3919 - acc: 0.1554 - val_loss: 2.3975 - val_acc: 0.1491\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3889 - acc: 0.1566 - val_loss: 2.3969 - val_acc: 0.1489\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3867 - acc: 0.1587 - val_loss: 2.3965 - val_acc: 0.1487\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3859 - acc: 0.1592 - val_loss: 2.3965 - val_acc: 0.1477\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3832 - acc: 0.1603 - val_loss: 2.3965 - val_acc: 0.1504\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3830 - acc: 0.1619 - val_loss: 2.3957 - val_acc: 0.1507\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3801 - acc: 0.1613 - val_loss: 2.3962 - val_acc: 0.1491\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3792 - acc: 0.1631 - val_loss: 2.3958 - val_acc: 0.1484\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3782 - acc: 0.1642 - val_loss: 2.3962 - val_acc: 0.1503\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3759 - acc: 0.1652 - val_loss: 2.3961 - val_acc: 0.1505\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3755 - acc: 0.1645 - val_loss: 2.3960 - val_acc: 0.1505\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3719 - acc: 0.1677 - val_loss: 2.3957 - val_acc: 0.1519\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3715 - acc: 0.1674 - val_loss: 2.3963 - val_acc: 0.1505\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3700 - acc: 0.1679 - val_loss: 2.3965 - val_acc: 0.1523\n",
      "logloss val 2.3964542022950055\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4448 - acc: 0.1354 - val_loss: 2.4190 - val_acc: 0.1417\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4136 - acc: 0.1426 - val_loss: 2.4058 - val_acc: 0.1502\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4017 - acc: 0.1448 - val_loss: 2.3993 - val_acc: 0.1515\n",
      "Epoch 4/20\n",
      "5s - loss: 2.4001 - acc: 0.1492 - val_loss: 2.3963 - val_acc: 0.1492\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3970 - acc: 0.1532 - val_loss: 2.3944 - val_acc: 0.1570\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3937 - acc: 0.1546 - val_loss: 2.3930 - val_acc: 0.1557\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3910 - acc: 0.1563 - val_loss: 2.3926 - val_acc: 0.1554\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3889 - acc: 0.1579 - val_loss: 2.3915 - val_acc: 0.1550\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3874 - acc: 0.1592 - val_loss: 2.3910 - val_acc: 0.1530\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3869 - acc: 0.1586 - val_loss: 2.3905 - val_acc: 0.1516\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3836 - acc: 0.1604 - val_loss: 2.3907 - val_acc: 0.1542\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3833 - acc: 0.1618 - val_loss: 2.3899 - val_acc: 0.1522\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3797 - acc: 0.1608 - val_loss: 2.3902 - val_acc: 0.1528\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3796 - acc: 0.1638 - val_loss: 2.3901 - val_acc: 0.1536\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3781 - acc: 0.1618 - val_loss: 2.3900 - val_acc: 0.1548\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3764 - acc: 0.1635 - val_loss: 2.3901 - val_acc: 0.1522\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3746 - acc: 0.1646 - val_loss: 2.3907 - val_acc: 0.1559\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3730 - acc: 0.1655 - val_loss: 2.3907 - val_acc: 0.1551\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3710 - acc: 0.1665 - val_loss: 2.3908 - val_acc: 0.1528\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3707 - acc: 0.1673 - val_loss: 2.3909 - val_acc: 0.1536\n",
      "logloss val 2.390920225232862\n",
      "average logloss val 2.397145810776622\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4440 - acc: 0.1339 - val_loss: 2.4219 - val_acc: 0.1384\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4123 - acc: 0.1442 - val_loss: 2.4140 - val_acc: 0.1352\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4030 - acc: 0.1467 - val_loss: 2.4113 - val_acc: 0.1350\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3965 - acc: 0.1503 - val_loss: 2.4096 - val_acc: 0.1380\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3948 - acc: 0.1539 - val_loss: 2.4087 - val_acc: 0.1376\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3915 - acc: 0.1556 - val_loss: 2.4079 - val_acc: 0.1383\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3893 - acc: 0.1576 - val_loss: 2.4075 - val_acc: 0.1414\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3881 - acc: 0.1574 - val_loss: 2.4070 - val_acc: 0.1425\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3856 - acc: 0.1589 - val_loss: 2.4071 - val_acc: 0.1429\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3856 - acc: 0.1589 - val_loss: 2.4065 - val_acc: 0.1413\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3822 - acc: 0.1611 - val_loss: 2.4065 - val_acc: 0.1418\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3806 - acc: 0.1614 - val_loss: 2.4063 - val_acc: 0.1414\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3809 - acc: 0.1605 - val_loss: 2.4068 - val_acc: 0.1410\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3776 - acc: 0.1634 - val_loss: 2.4064 - val_acc: 0.1410\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3765 - acc: 0.1640 - val_loss: 2.4064 - val_acc: 0.1402\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3755 - acc: 0.1657 - val_loss: 2.4066 - val_acc: 0.1417\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3726 - acc: 0.1653 - val_loss: 2.4069 - val_acc: 0.1406\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3729 - acc: 0.1654 - val_loss: 2.4068 - val_acc: 0.1407\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3703 - acc: 0.1678 - val_loss: 2.4071 - val_acc: 0.1414\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3696 - acc: 0.1676 - val_loss: 2.4071 - val_acc: 0.1411\n",
      "logloss val 2.407135684505826\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4434 - acc: 0.1305 - val_loss: 2.4175 - val_acc: 0.1440\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4126 - acc: 0.1431 - val_loss: 2.4073 - val_acc: 0.1445\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4030 - acc: 0.1463 - val_loss: 2.4026 - val_acc: 0.1493\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3984 - acc: 0.1485 - val_loss: 2.4000 - val_acc: 0.1520\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3960 - acc: 0.1533 - val_loss: 2.3983 - val_acc: 0.1567\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3931 - acc: 0.1534 - val_loss: 2.3971 - val_acc: 0.1551\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3910 - acc: 0.1555 - val_loss: 2.3958 - val_acc: 0.1592\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3903 - acc: 0.1557 - val_loss: 2.3955 - val_acc: 0.1556\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3866 - acc: 0.1573 - val_loss: 2.3946 - val_acc: 0.1560\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3871 - acc: 0.1581 - val_loss: 2.3942 - val_acc: 0.1578\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3852 - acc: 0.1586 - val_loss: 2.3939 - val_acc: 0.1563\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3821 - acc: 0.1604 - val_loss: 2.3933 - val_acc: 0.1572\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3809 - acc: 0.1608 - val_loss: 2.3928 - val_acc: 0.1587\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3810 - acc: 0.1617 - val_loss: 2.3925 - val_acc: 0.1596\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3779 - acc: 0.1622 - val_loss: 2.3923 - val_acc: 0.1579\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3772 - acc: 0.1617 - val_loss: 2.3923 - val_acc: 0.1592\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3753 - acc: 0.1643 - val_loss: 2.3919 - val_acc: 0.1599\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3750 - acc: 0.1633 - val_loss: 2.3924 - val_acc: 0.1551\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3716 - acc: 0.1669 - val_loss: 2.3918 - val_acc: 0.1580\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3729 - acc: 0.1653 - val_loss: 2.3923 - val_acc: 0.1578\n",
      "logloss val 2.39228853038369\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4431 - acc: 0.1329 - val_loss: 2.4193 - val_acc: 0.1433\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4086 - acc: 0.1447 - val_loss: 2.4086 - val_acc: 0.1454\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4029 - acc: 0.1462 - val_loss: 2.4041 - val_acc: 0.1487\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3991 - acc: 0.1493 - val_loss: 2.4020 - val_acc: 0.1536\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3946 - acc: 0.1525 - val_loss: 2.4004 - val_acc: 0.1533\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3926 - acc: 0.1548 - val_loss: 2.3988 - val_acc: 0.1552\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3911 - acc: 0.1539 - val_loss: 2.3979 - val_acc: 0.1547\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3884 - acc: 0.1556 - val_loss: 2.3968 - val_acc: 0.1541\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3879 - acc: 0.1568 - val_loss: 2.3964 - val_acc: 0.1571\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3860 - acc: 0.1579 - val_loss: 2.3957 - val_acc: 0.1562\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3845 - acc: 0.1586 - val_loss: 2.3953 - val_acc: 0.1560\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3807 - acc: 0.1611 - val_loss: 2.3949 - val_acc: 0.1598\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3824 - acc: 0.1598 - val_loss: 2.3949 - val_acc: 0.1583\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3797 - acc: 0.1606 - val_loss: 2.3945 - val_acc: 0.1596\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3780 - acc: 0.1631 - val_loss: 2.3943 - val_acc: 0.1590\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3766 - acc: 0.1622 - val_loss: 2.3943 - val_acc: 0.1580\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3758 - acc: 0.1632 - val_loss: 2.3940 - val_acc: 0.1582\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3737 - acc: 0.1659 - val_loss: 2.3944 - val_acc: 0.1578\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3724 - acc: 0.1644 - val_loss: 2.3944 - val_acc: 0.1590\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3707 - acc: 0.1658 - val_loss: 2.3945 - val_acc: 0.1552\n",
      "logloss val 2.394512775016348\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4469 - acc: 0.1259 - val_loss: 2.4217 - val_acc: 0.1379\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4133 - acc: 0.1425 - val_loss: 2.4118 - val_acc: 0.1429\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4032 - acc: 0.1466 - val_loss: 2.4078 - val_acc: 0.1383\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3960 - acc: 0.1509 - val_loss: 2.4069 - val_acc: 0.1413\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3964 - acc: 0.1532 - val_loss: 2.4058 - val_acc: 0.1440\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3926 - acc: 0.1550 - val_loss: 2.4054 - val_acc: 0.1429\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3898 - acc: 0.1581 - val_loss: 2.4050 - val_acc: 0.1420\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3880 - acc: 0.1580 - val_loss: 2.4044 - val_acc: 0.1440\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3866 - acc: 0.1585 - val_loss: 2.4040 - val_acc: 0.1453\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3853 - acc: 0.1601 - val_loss: 2.4038 - val_acc: 0.1437\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3828 - acc: 0.1609 - val_loss: 2.4037 - val_acc: 0.1469\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3820 - acc: 0.1605 - val_loss: 2.4035 - val_acc: 0.1462\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3802 - acc: 0.1629 - val_loss: 2.4037 - val_acc: 0.1470\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3788 - acc: 0.1627 - val_loss: 2.4038 - val_acc: 0.1472\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3763 - acc: 0.1631 - val_loss: 2.4038 - val_acc: 0.1454\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3755 - acc: 0.1642 - val_loss: 2.4038 - val_acc: 0.1485\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3745 - acc: 0.1653 - val_loss: 2.4040 - val_acc: 0.1464\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3716 - acc: 0.1659 - val_loss: 2.4042 - val_acc: 0.1481\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3708 - acc: 0.1648 - val_loss: 2.4045 - val_acc: 0.1492\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3705 - acc: 0.1649 - val_loss: 2.4045 - val_acc: 0.1511\n",
      "logloss val 2.404531806838892\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4477 - acc: 0.1258 - val_loss: 2.4213 - val_acc: 0.1406\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4123 - acc: 0.1415 - val_loss: 2.4107 - val_acc: 0.1422\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4049 - acc: 0.1433 - val_loss: 2.4058 - val_acc: 0.1425\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3988 - acc: 0.1497 - val_loss: 2.4041 - val_acc: 0.1428\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3948 - acc: 0.1536 - val_loss: 2.4029 - val_acc: 0.1420\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3930 - acc: 0.1544 - val_loss: 2.4019 - val_acc: 0.1404\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3893 - acc: 0.1579 - val_loss: 2.4014 - val_acc: 0.1439\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3892 - acc: 0.1573 - val_loss: 2.4011 - val_acc: 0.1414\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3873 - acc: 0.1573 - val_loss: 2.4005 - val_acc: 0.1408\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3850 - acc: 0.1600 - val_loss: 2.4001 - val_acc: 0.1428\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3828 - acc: 0.1599 - val_loss: 2.3999 - val_acc: 0.1451\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3818 - acc: 0.1598 - val_loss: 2.4000 - val_acc: 0.1468\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3802 - acc: 0.1620 - val_loss: 2.3995 - val_acc: 0.1481\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3798 - acc: 0.1620 - val_loss: 2.3996 - val_acc: 0.1455\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3763 - acc: 0.1635 - val_loss: 2.3996 - val_acc: 0.1465\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3761 - acc: 0.1636 - val_loss: 2.3998 - val_acc: 0.1452\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3743 - acc: 0.1648 - val_loss: 2.3997 - val_acc: 0.1455\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3727 - acc: 0.1648 - val_loss: 2.4001 - val_acc: 0.1443\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3715 - acc: 0.1671 - val_loss: 2.4001 - val_acc: 0.1452\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3706 - acc: 0.1670 - val_loss: 2.4004 - val_acc: 0.1449\n",
      "logloss val 2.400369555591967\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4444 - acc: 0.1305 - val_loss: 2.4190 - val_acc: 0.1397\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4115 - acc: 0.1417 - val_loss: 2.4067 - val_acc: 0.1417\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4035 - acc: 0.1464 - val_loss: 2.4011 - val_acc: 0.1484\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3986 - acc: 0.1506 - val_loss: 2.3985 - val_acc: 0.1499\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3958 - acc: 0.1532 - val_loss: 2.3971 - val_acc: 0.1542\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3938 - acc: 0.1551 - val_loss: 2.3963 - val_acc: 0.1519\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3910 - acc: 0.1552 - val_loss: 2.3956 - val_acc: 0.1497\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3892 - acc: 0.1563 - val_loss: 2.3957 - val_acc: 0.1553\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3870 - acc: 0.1572 - val_loss: 2.3950 - val_acc: 0.1526\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3862 - acc: 0.1584 - val_loss: 2.3949 - val_acc: 0.1557\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3853 - acc: 0.1590 - val_loss: 2.3952 - val_acc: 0.1553\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3813 - acc: 0.1601 - val_loss: 2.3947 - val_acc: 0.1525\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3811 - acc: 0.1608 - val_loss: 2.3948 - val_acc: 0.1553\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3790 - acc: 0.1616 - val_loss: 2.3948 - val_acc: 0.1578\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3785 - acc: 0.1611 - val_loss: 2.3950 - val_acc: 0.1530\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3754 - acc: 0.1641 - val_loss: 2.3953 - val_acc: 0.1553\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3760 - acc: 0.1631 - val_loss: 2.3956 - val_acc: 0.1542\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3732 - acc: 0.1655 - val_loss: 2.3961 - val_acc: 0.1554\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3706 - acc: 0.1659 - val_loss: 2.3961 - val_acc: 0.1558\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3716 - acc: 0.1652 - val_loss: 2.3966 - val_acc: 0.1557\n",
      "logloss val 2.3966104659421927\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4445 - acc: 0.1282 - val_loss: 2.4170 - val_acc: 0.1419\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4136 - acc: 0.1411 - val_loss: 2.4053 - val_acc: 0.1474\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4043 - acc: 0.1448 - val_loss: 2.4003 - val_acc: 0.1526\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3984 - acc: 0.1512 - val_loss: 2.3980 - val_acc: 0.1518\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3959 - acc: 0.1521 - val_loss: 2.3962 - val_acc: 0.1521\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3932 - acc: 0.1543 - val_loss: 2.3952 - val_acc: 0.1529\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3898 - acc: 0.1550 - val_loss: 2.3945 - val_acc: 0.1529\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3910 - acc: 0.1554 - val_loss: 2.3942 - val_acc: 0.1498\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3875 - acc: 0.1573 - val_loss: 2.3933 - val_acc: 0.1525\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3857 - acc: 0.1572 - val_loss: 2.3929 - val_acc: 0.1517\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3839 - acc: 0.1581 - val_loss: 2.3923 - val_acc: 0.1526\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3823 - acc: 0.1595 - val_loss: 2.3923 - val_acc: 0.1524\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3816 - acc: 0.1601 - val_loss: 2.3923 - val_acc: 0.1525\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3795 - acc: 0.1613 - val_loss: 2.3919 - val_acc: 0.1501\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3787 - acc: 0.1614 - val_loss: 2.3919 - val_acc: 0.1536\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3756 - acc: 0.1632 - val_loss: 2.3920 - val_acc: 0.1518\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3752 - acc: 0.1626 - val_loss: 2.3921 - val_acc: 0.1518\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3736 - acc: 0.1653 - val_loss: 2.3922 - val_acc: 0.1514\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3714 - acc: 0.1658 - val_loss: 2.3923 - val_acc: 0.1507\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3709 - acc: 0.1669 - val_loss: 2.3925 - val_acc: 0.1507\n",
      "logloss val 2.3924973502880347\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4438 - acc: 0.1343 - val_loss: 2.4183 - val_acc: 0.1377\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4109 - acc: 0.1450 - val_loss: 2.4074 - val_acc: 0.1380\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4038 - acc: 0.1443 - val_loss: 2.4024 - val_acc: 0.1398\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3988 - acc: 0.1504 - val_loss: 2.3993 - val_acc: 0.1473\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3962 - acc: 0.1525 - val_loss: 2.3969 - val_acc: 0.1479\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3938 - acc: 0.1541 - val_loss: 2.3957 - val_acc: 0.1491\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3908 - acc: 0.1552 - val_loss: 2.3946 - val_acc: 0.1501\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3888 - acc: 0.1570 - val_loss: 2.3940 - val_acc: 0.1521\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3884 - acc: 0.1565 - val_loss: 2.3935 - val_acc: 0.1550\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3856 - acc: 0.1577 - val_loss: 2.3929 - val_acc: 0.1550\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3840 - acc: 0.1592 - val_loss: 2.3930 - val_acc: 0.1541\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3812 - acc: 0.1612 - val_loss: 2.3932 - val_acc: 0.1569\n",
      "Epoch 13/20\n",
      "5s - loss: 2.3813 - acc: 0.1592 - val_loss: 2.3927 - val_acc: 0.1570\n",
      "Epoch 14/20\n",
      "5s - loss: 2.3798 - acc: 0.1608 - val_loss: 2.3923 - val_acc: 0.1562\n",
      "Epoch 15/20\n",
      "5s - loss: 2.3772 - acc: 0.1629 - val_loss: 2.3925 - val_acc: 0.1548\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3762 - acc: 0.1610 - val_loss: 2.3924 - val_acc: 0.1554\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3739 - acc: 0.1642 - val_loss: 2.3924 - val_acc: 0.1540\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3726 - acc: 0.1650 - val_loss: 2.3934 - val_acc: 0.1564\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3725 - acc: 0.1646 - val_loss: 2.3934 - val_acc: 0.1562\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3700 - acc: 0.1661 - val_loss: 2.3929 - val_acc: 0.1553\n",
      "logloss val 2.392940456154828\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "6s - loss: 2.4494 - acc: 0.1244 - val_loss: 2.4227 - val_acc: 0.1359\n",
      "Epoch 2/20\n",
      "5s - loss: 2.4140 - acc: 0.1435 - val_loss: 2.4108 - val_acc: 0.1405\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4036 - acc: 0.1462 - val_loss: 2.4041 - val_acc: 0.1433\n",
      "Epoch 4/20\n",
      "5s - loss: 2.3997 - acc: 0.1500 - val_loss: 2.4016 - val_acc: 0.1475\n",
      "Epoch 5/20\n",
      "5s - loss: 2.3958 - acc: 0.1524 - val_loss: 2.4003 - val_acc: 0.1491\n",
      "Epoch 6/20\n",
      "5s - loss: 2.3929 - acc: 0.1544 - val_loss: 2.3997 - val_acc: 0.1489\n",
      "Epoch 7/20\n",
      "5s - loss: 2.3905 - acc: 0.1572 - val_loss: 2.3987 - val_acc: 0.1480\n",
      "Epoch 8/20\n",
      "5s - loss: 2.3892 - acc: 0.1580 - val_loss: 2.3984 - val_acc: 0.1504\n",
      "Epoch 9/20\n",
      "5s - loss: 2.3874 - acc: 0.1599 - val_loss: 2.3975 - val_acc: 0.1503\n",
      "Epoch 10/20\n",
      "5s - loss: 2.3855 - acc: 0.1601 - val_loss: 2.3973 - val_acc: 0.1508\n",
      "Epoch 11/20\n",
      "5s - loss: 2.3834 - acc: 0.1614 - val_loss: 2.3973 - val_acc: 0.1499\n",
      "Epoch 12/20\n",
      "5s - loss: 2.3819 - acc: 0.1630 - val_loss: 2.3972 - val_acc: 0.1504\n",
      "Epoch 13/20\n",
      "6s - loss: 2.3790 - acc: 0.1636 - val_loss: 2.3970 - val_acc: 0.1505\n",
      "Epoch 14/20\n",
      "6s - loss: 2.3797 - acc: 0.1614 - val_loss: 2.3968 - val_acc: 0.1515\n",
      "Epoch 15/20\n",
      "6s - loss: 2.3766 - acc: 0.1649 - val_loss: 2.3967 - val_acc: 0.1501\n",
      "Epoch 16/20\n",
      "5s - loss: 2.3740 - acc: 0.1655 - val_loss: 2.3977 - val_acc: 0.1521\n",
      "Epoch 17/20\n",
      "5s - loss: 2.3742 - acc: 0.1657 - val_loss: 2.3973 - val_acc: 0.1517\n",
      "Epoch 18/20\n",
      "5s - loss: 2.3725 - acc: 0.1661 - val_loss: 2.3974 - val_acc: 0.1479\n",
      "Epoch 19/20\n",
      "5s - loss: 2.3710 - acc: 0.1670 - val_loss: 2.3973 - val_acc: 0.1497\n",
      "Epoch 20/20\n",
      "5s - loss: 2.3685 - acc: 0.1681 - val_loss: 2.3978 - val_acc: 0.1509\n",
      "logloss val 2.3978372932647734\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "7s - loss: 2.4446 - acc: 0.1300 - val_loss: 2.4176 - val_acc: 0.1453\n",
      "Epoch 2/20\n",
      "6s - loss: 2.4114 - acc: 0.1417 - val_loss: 2.4050 - val_acc: 0.1495\n",
      "Epoch 3/20\n",
      "5s - loss: 2.4047 - acc: 0.1443 - val_loss: 2.3987 - val_acc: 0.1514\n",
      "Epoch 4/20\n",
      "6s - loss: 2.3988 - acc: 0.1496 - val_loss: 2.3960 - val_acc: 0.1534\n",
      "Epoch 5/20\n",
      "7s - loss: 2.3961 - acc: 0.1513 - val_loss: 2.3945 - val_acc: 0.1555\n",
      "Epoch 6/20\n",
      "6s - loss: 2.3941 - acc: 0.1535 - val_loss: 2.3936 - val_acc: 0.1557\n",
      "Epoch 7/20\n",
      "6s - loss: 2.3912 - acc: 0.1546 - val_loss: 2.3931 - val_acc: 0.1569\n",
      "Epoch 8/20\n",
      "7s - loss: 2.3901 - acc: 0.1559 - val_loss: 2.3920 - val_acc: 0.1547\n",
      "Epoch 9/20\n",
      "7s - loss: 2.3876 - acc: 0.1576 - val_loss: 2.3917 - val_acc: 0.1544\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py:1403: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-8c0f6d7fad82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                              \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                              \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_without\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_without\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                              )\n\u001b[1;32m     35\u001b[0m         scores_val_without = model.predict_generator(generator=batch_generatorp(X_val_without, 512, False), \n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                                         \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                                         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                                         max_q_size=max_q_size)\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1383\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1385\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 564\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 637\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Yuyang/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m--> 628\u001b[0;31m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define baseline model\n",
    "def without_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    #model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "dummy_y_without = np_utils.to_categorical(y_train_total_without)\n",
    "for i in range(8):\n",
    "    kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = i*2)\n",
    "    score_list_without=[]\n",
    "    val_loss_list_without = []\n",
    "    for index,(train, test) in enumerate(kf):\n",
    "        X_train_without = X_train_total_without[train]\n",
    "        y_train_without = dummy_y_without[train]\n",
    "        X_val_without = X_train_total_without[test]\n",
    "        y_val_without = dummy_y_without[test]\n",
    "        print('*****************************************************')\n",
    "        print('{}_fold'.format(index))\n",
    "        model=without_model(X_train_total_without.shape[1])\n",
    "        fit= model.fit_generator(generator=batch_generator(X_train_without, y_train_without, 512, True),\n",
    "                             nb_epoch=20,\n",
    "                             samples_per_epoch=80000,\n",
    "                             validation_data=(X_val_without.todense(), y_val_without), verbose=2\n",
    "                             )\n",
    "        scores_val_without = model.predict_generator(generator=batch_generatorp(X_val_without, 512, False), \n",
    "                                             val_samples=X_val_without.shape[0])\n",
    "        scores_without = model.predict_generator(generator=batch_generatorp(X_test_total_without, 512, False), \n",
    "                                         val_samples=X_test_total_without.shape[0])\n",
    "        score_list_without.append(scores_without)\n",
    "\n",
    "        val_loss = log_loss(y_val_without, scores_val_without)\n",
    "        val_loss_list_without.append(val_loss)\n",
    "        print('logloss val {}'.format(val_loss))\n",
    "\n",
    "    for index,i in enumerate(val_loss_list_without):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    val_loss_ave_without = sumi/len(score_list_without)\n",
    "    print('average logloss val {}'.format(val_loss_ave_without))\n",
    "    for index,i in enumerate(score_list_without):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    score_ave_without = sumi/len(score_list_without)\n",
    "    pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)\n",
    "    pred_without.to_csv('nnt_without_100_relu{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without eventsIII: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.02,\n",
    "                                                    stratify=y_train_total_without)\n",
    "#grid search cv\n",
    "xgbclassifier = xgb.XGBClassifier(objective=\"multi:softprob\", nthread=1)\n",
    "\n",
    "clf = GridSearchCV(estimator=xgbclassifier,param_grid={\n",
    "        'max_depth': [ 4,5,6,7,8,9,10],\n",
    "        'learning_rate': [0.01,0.02, 0.1, 0.2],\n",
    "    },verbose=10,scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "val_loss_ave_with= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_with)\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.47491\ttest-mlogloss:2.47573\n",
      "[1]\ttrain-mlogloss:2.46606\ttest-mlogloss:2.46759\n",
      "[2]\ttrain-mlogloss:2.45823\ttest-mlogloss:2.46055\n",
      "[3]\ttrain-mlogloss:2.45125\ttest-mlogloss:2.45427\n",
      "[4]\ttrain-mlogloss:2.44501\ttest-mlogloss:2.44875\n",
      "[5]\ttrain-mlogloss:2.43941\ttest-mlogloss:2.44385\n",
      "[6]\ttrain-mlogloss:2.4344\ttest-mlogloss:2.43937\n",
      "[7]\ttrain-mlogloss:2.42993\ttest-mlogloss:2.43555\n",
      "[8]\ttrain-mlogloss:2.4259\ttest-mlogloss:2.432\n",
      "[9]\ttrain-mlogloss:2.42225\ttest-mlogloss:2.42893\n",
      "[10]\ttrain-mlogloss:2.41895\ttest-mlogloss:2.42602\n",
      "[11]\ttrain-mlogloss:2.41599\ttest-mlogloss:2.42357\n",
      "[12]\ttrain-mlogloss:2.4133\ttest-mlogloss:2.42122\n",
      "[13]\ttrain-mlogloss:2.41087\ttest-mlogloss:2.41913\n",
      "[14]\ttrain-mlogloss:2.40865\ttest-mlogloss:2.41731\n",
      "[15]\ttrain-mlogloss:2.40665\ttest-mlogloss:2.41567\n",
      "[16]\ttrain-mlogloss:2.40483\ttest-mlogloss:2.4142\n",
      "[17]\ttrain-mlogloss:2.40317\ttest-mlogloss:2.41288\n",
      "[18]\ttrain-mlogloss:2.4017\ttest-mlogloss:2.41174\n",
      "[19]\ttrain-mlogloss:2.4003\ttest-mlogloss:2.4107\n",
      "[20]\ttrain-mlogloss:2.39905\ttest-mlogloss:2.4098\n",
      "[21]\ttrain-mlogloss:2.39786\ttest-mlogloss:2.40883\n",
      "[22]\ttrain-mlogloss:2.3968\ttest-mlogloss:2.40813\n",
      "[23]\ttrain-mlogloss:2.39576\ttest-mlogloss:2.40749\n",
      "[24]\ttrain-mlogloss:2.39484\ttest-mlogloss:2.40671\n",
      "[25]\ttrain-mlogloss:2.39402\ttest-mlogloss:2.40623\n",
      "[26]\ttrain-mlogloss:2.39322\ttest-mlogloss:2.40567\n",
      "[27]\ttrain-mlogloss:2.3925\ttest-mlogloss:2.40526\n",
      "[28]\ttrain-mlogloss:2.39182\ttest-mlogloss:2.40472\n",
      "[29]\ttrain-mlogloss:2.39118\ttest-mlogloss:2.40426\n",
      "[30]\ttrain-mlogloss:2.39064\ttest-mlogloss:2.40394\n",
      "[31]\ttrain-mlogloss:2.39011\ttest-mlogloss:2.40366\n",
      "[32]\ttrain-mlogloss:2.38958\ttest-mlogloss:2.40328\n",
      "[33]\ttrain-mlogloss:2.38913\ttest-mlogloss:2.4031\n",
      "[34]\ttrain-mlogloss:2.38864\ttest-mlogloss:2.40269\n",
      "[35]\ttrain-mlogloss:2.38819\ttest-mlogloss:2.40231\n",
      "[36]\ttrain-mlogloss:2.38779\ttest-mlogloss:2.40216\n",
      "[37]\ttrain-mlogloss:2.3874\ttest-mlogloss:2.40195\n",
      "[38]\ttrain-mlogloss:2.38701\ttest-mlogloss:2.40163\n",
      "[39]\ttrain-mlogloss:2.3867\ttest-mlogloss:2.4015\n",
      "[40]\ttrain-mlogloss:2.38634\ttest-mlogloss:2.40133\n",
      "[41]\ttrain-mlogloss:2.38605\ttest-mlogloss:2.40123\n",
      "[42]\ttrain-mlogloss:2.38576\ttest-mlogloss:2.40109\n",
      "[43]\ttrain-mlogloss:2.38546\ttest-mlogloss:2.40086\n",
      "[44]\ttrain-mlogloss:2.3852\ttest-mlogloss:2.40072\n",
      "[45]\ttrain-mlogloss:2.38495\ttest-mlogloss:2.40061\n",
      "[46]\ttrain-mlogloss:2.38471\ttest-mlogloss:2.4005\n",
      "[47]\ttrain-mlogloss:2.38448\ttest-mlogloss:2.40042\n",
      "[48]\ttrain-mlogloss:2.38426\ttest-mlogloss:2.40035\n",
      "[49]\ttrain-mlogloss:2.38403\ttest-mlogloss:2.40026\n",
      "[50]\ttrain-mlogloss:2.38382\ttest-mlogloss:2.40023\n",
      "[51]\ttrain-mlogloss:2.38361\ttest-mlogloss:2.40016\n",
      "[52]\ttrain-mlogloss:2.38342\ttest-mlogloss:2.40005\n",
      "[53]\ttrain-mlogloss:2.38322\ttest-mlogloss:2.39998\n",
      "[54]\ttrain-mlogloss:2.38303\ttest-mlogloss:2.39994\n",
      "[55]\ttrain-mlogloss:2.38284\ttest-mlogloss:2.39992\n",
      "[56]\ttrain-mlogloss:2.38265\ttest-mlogloss:2.3998\n",
      "[57]\ttrain-mlogloss:2.38248\ttest-mlogloss:2.39975\n",
      "[58]\ttrain-mlogloss:2.38231\ttest-mlogloss:2.39979\n",
      "[59]\ttrain-mlogloss:2.38214\ttest-mlogloss:2.3997\n",
      "[60]\ttrain-mlogloss:2.38198\ttest-mlogloss:2.39963\n",
      "[61]\ttrain-mlogloss:2.38181\ttest-mlogloss:2.39959\n",
      "[62]\ttrain-mlogloss:2.38164\ttest-mlogloss:2.39954\n",
      "[63]\ttrain-mlogloss:2.38149\ttest-mlogloss:2.39949\n",
      "[64]\ttrain-mlogloss:2.38131\ttest-mlogloss:2.39952\n",
      "[65]\ttrain-mlogloss:2.38116\ttest-mlogloss:2.39937\n",
      "[66]\ttrain-mlogloss:2.38101\ttest-mlogloss:2.39938\n",
      "[67]\ttrain-mlogloss:2.38085\ttest-mlogloss:2.3994\n",
      "[68]\ttrain-mlogloss:2.38071\ttest-mlogloss:2.39931\n",
      "[69]\ttrain-mlogloss:2.38056\ttest-mlogloss:2.39927\n",
      "[70]\ttrain-mlogloss:2.38042\ttest-mlogloss:2.39927\n",
      "[71]\ttrain-mlogloss:2.38027\ttest-mlogloss:2.39923\n",
      "[72]\ttrain-mlogloss:2.38012\ttest-mlogloss:2.39919\n",
      "[73]\ttrain-mlogloss:2.37998\ttest-mlogloss:2.39918\n",
      "[74]\ttrain-mlogloss:2.37984\ttest-mlogloss:2.3991\n",
      "[75]\ttrain-mlogloss:2.3797\ttest-mlogloss:2.39919\n",
      "[76]\ttrain-mlogloss:2.37957\ttest-mlogloss:2.39917\n",
      "[77]\ttrain-mlogloss:2.37942\ttest-mlogloss:2.39913\n",
      "[78]\ttrain-mlogloss:2.37929\ttest-mlogloss:2.39908\n",
      "[79]\ttrain-mlogloss:2.37916\ttest-mlogloss:2.39904\n",
      "[80]\ttrain-mlogloss:2.37903\ttest-mlogloss:2.39898\n",
      "[81]\ttrain-mlogloss:2.37891\ttest-mlogloss:2.39892\n",
      "[82]\ttrain-mlogloss:2.37877\ttest-mlogloss:2.39894\n",
      "[83]\ttrain-mlogloss:2.37865\ttest-mlogloss:2.39896\n",
      "[84]\ttrain-mlogloss:2.37851\ttest-mlogloss:2.39895\n",
      "[85]\ttrain-mlogloss:2.37839\ttest-mlogloss:2.39895\n",
      "[86]\ttrain-mlogloss:2.37827\ttest-mlogloss:2.39892\n",
      "[87]\ttrain-mlogloss:2.37814\ttest-mlogloss:2.39887\n",
      "[88]\ttrain-mlogloss:2.37801\ttest-mlogloss:2.39888\n",
      "[89]\ttrain-mlogloss:2.3779\ttest-mlogloss:2.3988\n",
      "[90]\ttrain-mlogloss:2.37778\ttest-mlogloss:2.39877\n",
      "[91]\ttrain-mlogloss:2.37766\ttest-mlogloss:2.39865\n",
      "[92]\ttrain-mlogloss:2.37755\ttest-mlogloss:2.39869\n",
      "[93]\ttrain-mlogloss:2.37742\ttest-mlogloss:2.39867\n",
      "[94]\ttrain-mlogloss:2.37731\ttest-mlogloss:2.39868\n",
      "[95]\ttrain-mlogloss:2.3772\ttest-mlogloss:2.39865\n",
      "[96]\ttrain-mlogloss:2.37708\ttest-mlogloss:2.39865\n",
      "[97]\ttrain-mlogloss:2.37697\ttest-mlogloss:2.39861\n",
      "[98]\ttrain-mlogloss:2.37686\ttest-mlogloss:2.39854\n",
      "[99]\ttrain-mlogloss:2.37675\ttest-mlogloss:2.39851\n",
      "[100]\ttrain-mlogloss:2.37663\ttest-mlogloss:2.39856\n",
      "[101]\ttrain-mlogloss:2.37652\ttest-mlogloss:2.39846\n",
      "[102]\ttrain-mlogloss:2.37641\ttest-mlogloss:2.39841\n",
      "[103]\ttrain-mlogloss:2.3763\ttest-mlogloss:2.39837\n",
      "[104]\ttrain-mlogloss:2.37619\ttest-mlogloss:2.39836\n",
      "[105]\ttrain-mlogloss:2.37609\ttest-mlogloss:2.39832\n",
      "[106]\ttrain-mlogloss:2.37598\ttest-mlogloss:2.39833\n",
      "[107]\ttrain-mlogloss:2.37588\ttest-mlogloss:2.39837\n",
      "[108]\ttrain-mlogloss:2.37577\ttest-mlogloss:2.39832\n",
      "[109]\ttrain-mlogloss:2.37567\ttest-mlogloss:2.3983\n",
      "[110]\ttrain-mlogloss:2.37556\ttest-mlogloss:2.39833\n",
      "[111]\ttrain-mlogloss:2.37546\ttest-mlogloss:2.39828\n",
      "[112]\ttrain-mlogloss:2.37535\ttest-mlogloss:2.39822\n",
      "[113]\ttrain-mlogloss:2.37525\ttest-mlogloss:2.39807\n",
      "[114]\ttrain-mlogloss:2.37515\ttest-mlogloss:2.39812\n",
      "[115]\ttrain-mlogloss:2.37505\ttest-mlogloss:2.39821\n",
      "[116]\ttrain-mlogloss:2.37495\ttest-mlogloss:2.39821\n",
      "[117]\ttrain-mlogloss:2.37484\ttest-mlogloss:2.3982\n",
      "[118]\ttrain-mlogloss:2.37474\ttest-mlogloss:2.39818\n",
      "[119]\ttrain-mlogloss:2.37465\ttest-mlogloss:2.39814\n",
      "[120]\ttrain-mlogloss:2.37455\ttest-mlogloss:2.39815\n",
      "[121]\ttrain-mlogloss:2.37446\ttest-mlogloss:2.39819\n",
      "[122]\ttrain-mlogloss:2.37435\ttest-mlogloss:2.39813\n",
      "[123]\ttrain-mlogloss:2.37425\ttest-mlogloss:2.39819\n",
      "[124]\ttrain-mlogloss:2.37415\ttest-mlogloss:2.39804\n",
      "[125]\ttrain-mlogloss:2.37406\ttest-mlogloss:2.39803\n",
      "[126]\ttrain-mlogloss:2.37396\ttest-mlogloss:2.39809\n",
      "[127]\ttrain-mlogloss:2.37386\ttest-mlogloss:2.39805\n",
      "[128]\ttrain-mlogloss:2.37377\ttest-mlogloss:2.39799\n",
      "[129]\ttrain-mlogloss:2.37367\ttest-mlogloss:2.398\n",
      "[130]\ttrain-mlogloss:2.37358\ttest-mlogloss:2.39798\n",
      "[131]\ttrain-mlogloss:2.37349\ttest-mlogloss:2.398\n",
      "[132]\ttrain-mlogloss:2.3734\ttest-mlogloss:2.39796\n",
      "[133]\ttrain-mlogloss:2.37331\ttest-mlogloss:2.39799\n",
      "[134]\ttrain-mlogloss:2.37322\ttest-mlogloss:2.39789\n",
      "[135]\ttrain-mlogloss:2.37313\ttest-mlogloss:2.3979\n",
      "[136]\ttrain-mlogloss:2.37303\ttest-mlogloss:2.39783\n",
      "[137]\ttrain-mlogloss:2.37293\ttest-mlogloss:2.39785\n",
      "[138]\ttrain-mlogloss:2.37284\ttest-mlogloss:2.39789\n",
      "[139]\ttrain-mlogloss:2.37275\ttest-mlogloss:2.39792\n",
      "[140]\ttrain-mlogloss:2.37267\ttest-mlogloss:2.39791\n",
      "[141]\ttrain-mlogloss:2.37258\ttest-mlogloss:2.39793\n",
      "[142]\ttrain-mlogloss:2.37249\ttest-mlogloss:2.39791\n",
      "[143]\ttrain-mlogloss:2.3724\ttest-mlogloss:2.39789\n",
      "[144]\ttrain-mlogloss:2.37231\ttest-mlogloss:2.39789\n",
      "[145]\ttrain-mlogloss:2.37223\ttest-mlogloss:2.39784\n",
      "[146]\ttrain-mlogloss:2.37214\ttest-mlogloss:2.39784\n",
      "[147]\ttrain-mlogloss:2.37206\ttest-mlogloss:2.39769\n",
      "[148]\ttrain-mlogloss:2.37197\ttest-mlogloss:2.39773\n",
      "[149]\ttrain-mlogloss:2.37189\ttest-mlogloss:2.39778\n",
      "[150]\ttrain-mlogloss:2.3718\ttest-mlogloss:2.39782\n",
      "[151]\ttrain-mlogloss:2.37172\ttest-mlogloss:2.39775\n",
      "[152]\ttrain-mlogloss:2.37164\ttest-mlogloss:2.3978\n",
      "[153]\ttrain-mlogloss:2.37156\ttest-mlogloss:2.39778\n",
      "[154]\ttrain-mlogloss:2.37148\ttest-mlogloss:2.39779\n",
      "[155]\ttrain-mlogloss:2.37139\ttest-mlogloss:2.39766\n",
      "[156]\ttrain-mlogloss:2.37131\ttest-mlogloss:2.39765\n",
      "[157]\ttrain-mlogloss:2.37123\ttest-mlogloss:2.39772\n",
      "[158]\ttrain-mlogloss:2.37115\ttest-mlogloss:2.39773\n",
      "[159]\ttrain-mlogloss:2.37107\ttest-mlogloss:2.39767\n",
      "[160]\ttrain-mlogloss:2.37099\ttest-mlogloss:2.39765\n",
      "[161]\ttrain-mlogloss:2.3709\ttest-mlogloss:2.39765\n",
      "[162]\ttrain-mlogloss:2.37083\ttest-mlogloss:2.39766\n",
      "[163]\ttrain-mlogloss:2.37075\ttest-mlogloss:2.39763\n",
      "[164]\ttrain-mlogloss:2.37067\ttest-mlogloss:2.39764\n",
      "[165]\ttrain-mlogloss:2.37059\ttest-mlogloss:2.39763\n",
      "[166]\ttrain-mlogloss:2.37051\ttest-mlogloss:2.39765\n",
      "[167]\ttrain-mlogloss:2.37043\ttest-mlogloss:2.39769\n",
      "[168]\ttrain-mlogloss:2.37035\ttest-mlogloss:2.39763\n",
      "[169]\ttrain-mlogloss:2.37027\ttest-mlogloss:2.39766\n",
      "[170]\ttrain-mlogloss:2.37019\ttest-mlogloss:2.39772\n",
      "[171]\ttrain-mlogloss:2.37011\ttest-mlogloss:2.39771\n",
      "[172]\ttrain-mlogloss:2.37003\ttest-mlogloss:2.3977\n",
      "[173]\ttrain-mlogloss:2.36995\ttest-mlogloss:2.39762\n",
      "[174]\ttrain-mlogloss:2.36988\ttest-mlogloss:2.39761\n",
      "[175]\ttrain-mlogloss:2.36981\ttest-mlogloss:2.3976\n",
      "[176]\ttrain-mlogloss:2.36973\ttest-mlogloss:2.39759\n",
      "[177]\ttrain-mlogloss:2.36966\ttest-mlogloss:2.39759\n",
      "[178]\ttrain-mlogloss:2.36959\ttest-mlogloss:2.3976\n",
      "[179]\ttrain-mlogloss:2.36951\ttest-mlogloss:2.39759\n",
      "[180]\ttrain-mlogloss:2.36944\ttest-mlogloss:2.39758\n",
      "[181]\ttrain-mlogloss:2.36937\ttest-mlogloss:2.39762\n",
      "[182]\ttrain-mlogloss:2.36929\ttest-mlogloss:2.3976\n",
      "[183]\ttrain-mlogloss:2.36922\ttest-mlogloss:2.39758\n",
      "[184]\ttrain-mlogloss:2.36914\ttest-mlogloss:2.39762\n",
      "[185]\ttrain-mlogloss:2.36907\ttest-mlogloss:2.39756\n",
      "[186]\ttrain-mlogloss:2.36899\ttest-mlogloss:2.39754\n",
      "[187]\ttrain-mlogloss:2.36892\ttest-mlogloss:2.39757\n",
      "[188]\ttrain-mlogloss:2.36885\ttest-mlogloss:2.39751\n",
      "[189]\ttrain-mlogloss:2.36878\ttest-mlogloss:2.39752\n",
      "[190]\ttrain-mlogloss:2.3687\ttest-mlogloss:2.39752\n",
      "[191]\ttrain-mlogloss:2.36863\ttest-mlogloss:2.3975\n",
      "[192]\ttrain-mlogloss:2.36855\ttest-mlogloss:2.39751\n",
      "[193]\ttrain-mlogloss:2.36848\ttest-mlogloss:2.39749\n",
      "[194]\ttrain-mlogloss:2.36841\ttest-mlogloss:2.39742\n",
      "[195]\ttrain-mlogloss:2.36834\ttest-mlogloss:2.39741\n",
      "[196]\ttrain-mlogloss:2.36828\ttest-mlogloss:2.39742\n",
      "[197]\ttrain-mlogloss:2.3682\ttest-mlogloss:2.39745\n",
      "[198]\ttrain-mlogloss:2.36814\ttest-mlogloss:2.39751\n",
      "[199]\ttrain-mlogloss:2.36807\ttest-mlogloss:2.39745\n",
      "[200]\ttrain-mlogloss:2.368\ttest-mlogloss:2.3975\n",
      "[201]\ttrain-mlogloss:2.36794\ttest-mlogloss:2.39748\n",
      "[202]\ttrain-mlogloss:2.36787\ttest-mlogloss:2.39754\n",
      "[203]\ttrain-mlogloss:2.3678\ttest-mlogloss:2.39753\n",
      "[204]\ttrain-mlogloss:2.36773\ttest-mlogloss:2.39749\n",
      "[205]\ttrain-mlogloss:2.36766\ttest-mlogloss:2.39744\n",
      "[206]\ttrain-mlogloss:2.3676\ttest-mlogloss:2.39744\n",
      "[207]\ttrain-mlogloss:2.36753\ttest-mlogloss:2.39737\n",
      "[208]\ttrain-mlogloss:2.36746\ttest-mlogloss:2.39734\n",
      "[209]\ttrain-mlogloss:2.3674\ttest-mlogloss:2.39733\n",
      "[210]\ttrain-mlogloss:2.36733\ttest-mlogloss:2.39739\n",
      "[211]\ttrain-mlogloss:2.36727\ttest-mlogloss:2.39736\n",
      "[212]\ttrain-mlogloss:2.3672\ttest-mlogloss:2.39737\n",
      "[213]\ttrain-mlogloss:2.36714\ttest-mlogloss:2.39737\n",
      "[214]\ttrain-mlogloss:2.36707\ttest-mlogloss:2.39742\n",
      "[215]\ttrain-mlogloss:2.36701\ttest-mlogloss:2.39746\n",
      "[216]\ttrain-mlogloss:2.36695\ttest-mlogloss:2.39746\n",
      "[217]\ttrain-mlogloss:2.36688\ttest-mlogloss:2.39739\n",
      "[218]\ttrain-mlogloss:2.36682\ttest-mlogloss:2.3974\n",
      "[219]\ttrain-mlogloss:2.36676\ttest-mlogloss:2.39738\n",
      "[220]\ttrain-mlogloss:2.3667\ttest-mlogloss:2.39737\n",
      "[221]\ttrain-mlogloss:2.36663\ttest-mlogloss:2.39732\n",
      "[222]\ttrain-mlogloss:2.36657\ttest-mlogloss:2.3973\n",
      "[223]\ttrain-mlogloss:2.36651\ttest-mlogloss:2.3973\n",
      "[224]\ttrain-mlogloss:2.36645\ttest-mlogloss:2.39728\n",
      "[225]\ttrain-mlogloss:2.36639\ttest-mlogloss:2.39726\n",
      "[226]\ttrain-mlogloss:2.36632\ttest-mlogloss:2.39722\n",
      "[227]\ttrain-mlogloss:2.36626\ttest-mlogloss:2.39719\n",
      "[228]\ttrain-mlogloss:2.3662\ttest-mlogloss:2.39721\n",
      "[229]\ttrain-mlogloss:2.36614\ttest-mlogloss:2.39719\n",
      "[230]\ttrain-mlogloss:2.36607\ttest-mlogloss:2.39718\n",
      "[231]\ttrain-mlogloss:2.36602\ttest-mlogloss:2.39722\n",
      "[232]\ttrain-mlogloss:2.36595\ttest-mlogloss:2.39718\n",
      "[233]\ttrain-mlogloss:2.3659\ttest-mlogloss:2.3972\n",
      "[234]\ttrain-mlogloss:2.36584\ttest-mlogloss:2.39722\n",
      "[235]\ttrain-mlogloss:2.36578\ttest-mlogloss:2.39721\n",
      "[236]\ttrain-mlogloss:2.36572\ttest-mlogloss:2.39726\n",
      "[237]\ttrain-mlogloss:2.36565\ttest-mlogloss:2.39723\n",
      "[238]\ttrain-mlogloss:2.36559\ttest-mlogloss:2.39722\n",
      "[239]\ttrain-mlogloss:2.36553\ttest-mlogloss:2.39727\n",
      "[240]\ttrain-mlogloss:2.36548\ttest-mlogloss:2.39729\n",
      "[241]\ttrain-mlogloss:2.36542\ttest-mlogloss:2.3973\n",
      "[242]\ttrain-mlogloss:2.36536\ttest-mlogloss:2.39725\n",
      "[243]\ttrain-mlogloss:2.3653\ttest-mlogloss:2.39722\n",
      "[244]\ttrain-mlogloss:2.36524\ttest-mlogloss:2.39722\n",
      "[245]\ttrain-mlogloss:2.36518\ttest-mlogloss:2.39721\n",
      "[246]\ttrain-mlogloss:2.36511\ttest-mlogloss:2.39724\n",
      "[247]\ttrain-mlogloss:2.36506\ttest-mlogloss:2.39721\n",
      "[248]\ttrain-mlogloss:2.365\ttest-mlogloss:2.39716\n",
      "[249]\ttrain-mlogloss:2.36494\ttest-mlogloss:2.39715\n",
      "[250]\ttrain-mlogloss:2.36489\ttest-mlogloss:2.3972\n",
      "[251]\ttrain-mlogloss:2.36483\ttest-mlogloss:2.39719\n",
      "[252]\ttrain-mlogloss:2.36477\ttest-mlogloss:2.39724\n",
      "[253]\ttrain-mlogloss:2.36471\ttest-mlogloss:2.39726\n",
      "[254]\ttrain-mlogloss:2.36465\ttest-mlogloss:2.39731\n",
      "[255]\ttrain-mlogloss:2.3646\ttest-mlogloss:2.3973\n",
      "[256]\ttrain-mlogloss:2.36454\ttest-mlogloss:2.39732\n",
      "[257]\ttrain-mlogloss:2.36448\ttest-mlogloss:2.39725\n",
      "[258]\ttrain-mlogloss:2.36442\ttest-mlogloss:2.39728\n",
      "[259]\ttrain-mlogloss:2.36436\ttest-mlogloss:2.39725\n",
      "[260]\ttrain-mlogloss:2.36431\ttest-mlogloss:2.39719\n",
      "[261]\ttrain-mlogloss:2.36425\ttest-mlogloss:2.39718\n",
      "[262]\ttrain-mlogloss:2.3642\ttest-mlogloss:2.3972\n",
      "[263]\ttrain-mlogloss:2.36414\ttest-mlogloss:2.39718\n",
      "[264]\ttrain-mlogloss:2.36409\ttest-mlogloss:2.3972\n",
      "[265]\ttrain-mlogloss:2.36404\ttest-mlogloss:2.39722\n",
      "[266]\ttrain-mlogloss:2.36398\ttest-mlogloss:2.39722\n",
      "[267]\ttrain-mlogloss:2.36393\ttest-mlogloss:2.39721\n",
      "[268]\ttrain-mlogloss:2.36387\ttest-mlogloss:2.39717\n",
      "[269]\ttrain-mlogloss:2.36382\ttest-mlogloss:2.39716\n",
      "[270]\ttrain-mlogloss:2.36376\ttest-mlogloss:2.39717\n",
      "[271]\ttrain-mlogloss:2.36371\ttest-mlogloss:2.39724\n",
      "[272]\ttrain-mlogloss:2.36366\ttest-mlogloss:2.39726\n",
      "[273]\ttrain-mlogloss:2.3636\ttest-mlogloss:2.39731\n",
      "[274]\ttrain-mlogloss:2.36355\ttest-mlogloss:2.3973\n",
      "[275]\ttrain-mlogloss:2.36349\ttest-mlogloss:2.39731\n",
      "[276]\ttrain-mlogloss:2.36344\ttest-mlogloss:2.3973\n",
      "[277]\ttrain-mlogloss:2.36339\ttest-mlogloss:2.39733\n",
      "[278]\ttrain-mlogloss:2.36334\ttest-mlogloss:2.39727\n",
      "[279]\ttrain-mlogloss:2.36328\ttest-mlogloss:2.39727\n",
      "[280]\ttrain-mlogloss:2.36323\ttest-mlogloss:2.39724\n",
      "[281]\ttrain-mlogloss:2.36317\ttest-mlogloss:2.39723\n",
      "[282]\ttrain-mlogloss:2.36312\ttest-mlogloss:2.39725\n",
      "[283]\ttrain-mlogloss:2.36307\ttest-mlogloss:2.39729\n",
      "[284]\ttrain-mlogloss:2.36302\ttest-mlogloss:2.39729\n",
      "[285]\ttrain-mlogloss:2.36297\ttest-mlogloss:2.3973\n",
      "[286]\ttrain-mlogloss:2.36291\ttest-mlogloss:2.39733\n",
      "[287]\ttrain-mlogloss:2.36286\ttest-mlogloss:2.39733\n",
      "[288]\ttrain-mlogloss:2.36281\ttest-mlogloss:2.3973\n",
      "[289]\ttrain-mlogloss:2.36276\ttest-mlogloss:2.3973\n",
      "[290]\ttrain-mlogloss:2.3627\ttest-mlogloss:2.39733\n",
      "[291]\ttrain-mlogloss:2.36265\ttest-mlogloss:2.39733\n",
      "[292]\ttrain-mlogloss:2.3626\ttest-mlogloss:2.39732\n",
      "[293]\ttrain-mlogloss:2.36255\ttest-mlogloss:2.39736\n",
      "[294]\ttrain-mlogloss:2.36249\ttest-mlogloss:2.39738\n",
      "[295]\ttrain-mlogloss:2.36245\ttest-mlogloss:2.39737\n",
      "[296]\ttrain-mlogloss:2.36239\ttest-mlogloss:2.39733\n",
      "[297]\ttrain-mlogloss:2.36234\ttest-mlogloss:2.39734\n",
      "[298]\ttrain-mlogloss:2.36229\ttest-mlogloss:2.39735\n",
      "[299]\ttrain-mlogloss:2.36224\ttest-mlogloss:2.39736\n",
      "logloss val 2.3973634590705237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.02,\n",
    "                                                    stratify=y_train_total_without,random_state=1)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':6,\n",
    "         'eta':0.1,\n",
    "         'silent':0,\n",
    "         'objective':'multi:softprob',\n",
    "         'nthread':2,\n",
    "         'num_class':12,\n",
    "         'eval_metric':'mlogloss',\n",
    "        'lambda':4,\n",
    "        'lambda_bias':0,\n",
    "        'alpha':0}\n",
    "num_round = 300\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train_total_without,label = y_train_total_without)\n",
    "xg_test = xgb.DMatrix(X_test_total_without)\n",
    "bst = xgb.train(param,xg_train,num_round)\n",
    "yprob = bst.predict(xg_test).reshape(X_test_total_without.shape[0],12)\n",
    "pred_without_xgb = pd.DataFrame(yprob, \n",
    "                            index = gender_age_test_without.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_without_xgb.to_csv('xgb_without_result{}.csv'.format(val_loss))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# putting together and save into final file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final score based on the percentage of testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with score:1.9392115926279074\n",
      "without score:2.3931157227003554\n",
      "final validation score:2.2505748160093315\n"
     ]
    }
   ],
   "source": [
    "#val_score_final = val_loss_ave_without*76877/112071+val_loss_ave_with*35194/112071\n",
    "val_score_final = (val_loss_ave_without*X_test_total_without.shape[0]+\n",
    "                   val_loss_ave_with*X_test_total_with.shape[0])/(X_test_total_without.shape[0]+X_test_total_with.shape[0])\n",
    "print('with score:{}'.format(val_loss_ave_with))\n",
    "print('without score:{}'.format(val_loss_ave_without))\n",
    "print('final validation score:{}'.format(val_score_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pd.concat((pred_with,pred_without))\n",
    "pred.to_csv('doublemodel_v6.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
