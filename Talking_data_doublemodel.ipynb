{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from scipy.sparse import csr_matrix,hstack,vstack\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold,KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('input/events.csv',index_col='event_id')\n",
    "label = pd.read_csv('input/label_categories.csv')\n",
    "app_event = pd.read_csv('input/app_events.csv')\n",
    "app_label = pd.read_csv('input/app_labels.csv')\n",
    "device = pd.read_csv('input/phone_brand_device_model.csv')\n",
    "device = device.drop_duplicates('device_id').set_index('device_id')\n",
    "gender_age_train = pd.read_csv('input/gender_age_train.csv',index_col = 'device_id')\n",
    "gender_age_test = pd.read_csv('input/gender_age_test.csv',index_col = 'device_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convinience of creating sparse matrix, we create another integer index for the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_age_train\n",
      "                      gender  age   group\n",
      "device_id                               \n",
      "-8076087639492063270      M   35  M32-38\n",
      "\n",
      "gender_age_test\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [1002079943728939269]\n",
      "\n",
      "device\n",
      "                      phone_brand device_model\n",
      "device_id                                    \n",
      "-8890648629457979026          小米           红米\n",
      "\n",
      "events\n",
      "                   device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
      "\n",
      "label\n",
      "    label_id category\n",
      "0         1      NaN\n",
      "\n",
      "app_event\n",
      "    event_id               app_id  is_installed  is_active\n",
      "0         2  5927333115845830913             1          1\n",
      "\n",
      "app_label\n",
      "                 app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print('gender_age_train\\n',gender_age_train.head(1))\n",
    "print('\\ngender_age_test\\n',gender_age_test.head(1))\n",
    "print('\\ndevice\\n',device.head(1))\n",
    "print('\\nevents\\n',events.head(1))\n",
    "print('\\nlabel\\n',label.head(1))\n",
    "print('\\napp_event\\n',app_event.head(1))\n",
    "print('\\napp_label\\n',app_label.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of two set of devices: with events and without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set without events:    51336\n",
      "Size of training set with events:       23309\n",
      "Total size of training set:             74645\n",
      "Size of testing set without events:     76877\n",
      "Size of training set with events:       35194\n",
      "Total size of training set:             112071\n"
     ]
    }
   ],
   "source": [
    "gender_age_train_with = gender_age_train.loc[gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_train_without = gender_age_train.loc[~gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_with = gender_age_test.loc[gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_without = gender_age_test.loc[~gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set without events:',gender_age_train_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_train_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_train.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of testing set without events:',gender_age_test_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_test_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_age_train_with['int_index'] = np.arange(gender_age_train_with.shape[0])\n",
    "gender_age_test_with['int_index'] = np.arange(gender_age_test_with.shape[0])\n",
    "gender_age_train_without['int_index'] = np.arange(gender_age_train_without.shape[0])\n",
    "gender_age_test_without['int_index'] = np.arange(gender_age_test_without.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering I: phone brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the phone brand, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(device.phone_brand)\n",
    "device['brand'] = encoder.transform(device.phone_brand)\n",
    "gender_age_train_with['brand'] = device['brand']\n",
    "gender_age_test_with['brand'] = device['brand']\n",
    "gender_age_train_without['brand'] = device['brand']\n",
    "gender_age_test_without['brand'] = device['brand']\n",
    "brandnumber = len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sparse matrix with each row representing one device and each column representing one brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 131)\n",
      "X_test_brand_with shape: (35194, 131)\n",
      "X_train_brand_without shape: (51336, 131)\n",
      "X_test_brand_without shape: (76877, 131)\n"
     ]
    }
   ],
   "source": [
    "X_train_brand_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                            (gender_age_train_with.int_index,gender_age_train_with.brand)),\n",
    "                               shape = (gender_age_train_with.shape[0],brandnumber))\n",
    "X_test_brand_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                           (gender_age_test_with.int_index,gender_age_test_with.brand)),\n",
    "                              shape = (gender_age_test_with.shape[0],brandnumber))\n",
    "print('X_train_brand_with shape:',X_train_brand_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_brand_with.shape)\n",
    "X_train_brand_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                            (gender_age_train_without.int_index,gender_age_train_without.brand)),\n",
    "                                  shape = (gender_age_train_without.shape[0],brandnumber))\n",
    "X_test_brand_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                           (gender_age_test_without.int_index,gender_age_test_without.brand)),\n",
    "                                 shape = (gender_age_test_without.shape[0],brandnumber))\n",
    "print('X_train_brand_without shape:',X_train_brand_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_brand_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering II: phone device model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brand_model = device.phone_brand.str.cat(device.device_model)\n",
    "encoder3 = LabelEncoder()\n",
    "encoder3.fit(brand_model)\n",
    "device['model'] = encoder3.transform(brand_model)\n",
    "gender_age_train_with['model'] = device['model']\n",
    "gender_age_test_with['model'] = device['model']\n",
    "gender_age_train_without['model'] = device['model']\n",
    "gender_age_test_without['model'] = device['model']\n",
    "modelnumber = len(encoder3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 1667)\n",
      "X_test_brand_with shape: (35194, 1667)\n",
      "X_train_brand_without shape: (51336, 1667)\n",
      "X_test_brand_without shape: (76877, 1667)\n"
     ]
    }
   ],
   "source": [
    "X_train_model_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                                 (gender_age_train_with.int_index,gender_age_train_with.model)),\n",
    "                               shape = (gender_age_train_with.shape[0],modelnumber))\n",
    "X_test_model_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                                (gender_age_test_with.int_index,gender_age_test_with.model)),\n",
    "                              shape = (gender_age_test_with.shape[0],modelnumber))\n",
    "X_train_model_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                                    (gender_age_train_without.int_index,gender_age_train_without.model)),\n",
    "                                  shape = (gender_age_train_without.shape[0],modelnumber))\n",
    "X_test_model_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                                   (gender_age_test_without.int_index,gender_age_test_without.model)),\n",
    "                                 shape = (gender_age_test_without.shape[0],modelnumber))\n",
    "\n",
    "print('X_train_brand_with shape:',X_train_model_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_model_with.shape)\n",
    "print('X_train_brand_without shape:',X_train_model_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_model_without.shape)\n",
    "del device,brand_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering III: Installed app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the app_id and store it into app column, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = LabelEncoder()\n",
    "encoder2.fit(app_event.app_id)\n",
    "app_event['app'] = encoder2.transform(app_event.app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 19234, 19235, 19236])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(app_event.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   event_id               app_id  is_installed  is_active    app\n",
      "0         2  5927333115845830913             1          1  15408\n",
      "                  device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n"
     ]
    }
   ],
   "source": [
    "print(app_event.head(1))\n",
    "print(events.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  event_id    app  is_installed\n",
      "0 -6401643145415154744         2  15408             1\n",
      "1 -6401643145415154744         2   3384             1\n",
      "2 -6401643145415154744         2   7620             1\n",
      "3 -6401643145415154744         2   8902             1\n",
      "4 -6401643145415154744         2  18686             1\n"
     ]
    }
   ],
   "source": [
    "installed_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_installed']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "print(installed_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_app_train:\n",
      "                           size  int_index\n",
      "device_id            app                  \n",
      "-9222956879900151005 548     18       5145\n",
      "                     1096    18       5145\n",
      "                     1248    26       5145\n",
      "                     1545    12       5145\n",
      "                     1664    18       5145\n"
     ]
    }
   ],
   "source": [
    "installed_app_grouped = installed_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_app_train_with = pd.merge(installed_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_index=True)\n",
    "installed_app_test_with = pd.merge(installed_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_index=True)\n",
    "print('installed_app_train:')\n",
    "print(installed_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id   app  size  int_index\n",
      "0 -9222956879900151005   548    18       5145\n",
      "1 -9222956879900151005  1096    18       5145\n",
      "2 -9222956879900151005  1248    26       5145\n",
      "3 -9222956879900151005  1545    12       5145\n",
      "4 -9222956879900151005  1664    18       5145\n",
      "             device_id    app  size  int_index\n",
      "0 -9222661944218806987   1867     3       2851\n",
      "1 -9222661944218806987   7519     8       2851\n",
      "2 -9222661944218806987   7843     1       2851\n",
      "3 -9222661944218806987   8704     4       2851\n",
      "4 -9222661944218806987  10000     1       2851\n"
     ]
    }
   ],
   "source": [
    "installed_app_train_with = installed_app_train_with.reset_index()\n",
    "installed_app_test_with = installed_app_test_with.reset_index()\n",
    "installed_app_train_with = installed_app_train_with.dropna(subset=['int_index'])\n",
    "installed_app_test_with = installed_app_test_with.dropna(subset=['int_index'])\n",
    "print(installed_app_train_with.head())\n",
    "print(installed_app_test_with.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of unique app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35194\n",
      "915632\n"
     ]
    }
   ],
   "source": [
    "print(gender_age_test_with.shape[0])\n",
    "print(installed_app_train_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique apps:\n",
      "19237\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique apps:')\n",
    "print(np.size(installed_app.app.unique()))\n",
    "appnumber = np.size(installed_app.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ..., 19234 19235 19236]\n",
      "1387337\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(installed_app_train_with.app.unique()))\n",
    "print(installed_app_test_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed shape: (23309, 19237)\n",
      "X_test_installed shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "X_train_installed_with = csr_matrix((np.ones(installed_app_train_with.shape[0]),\n",
    "                                (installed_app_train_with.int_index,installed_app_train_with.app)), \n",
    "                               shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_installed_with = csr_matrix((np.ones(installed_app_test_with.shape[0]),\n",
    "                               (installed_app_test_with.int_index,installed_app_test_with.app)),\n",
    "                               shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_installed shape:',X_train_installed_with.shape)\n",
    "print('X_test_installed shape:',X_test_installed_with.shape)\n",
    "del installed_app_test_with,installed_app_train_with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering IV: app label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                app_id  event_id\n",
      "0  5927333115845830913         2\n",
      "                app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print(app_event[['app_id','event_id']].head(1))\n",
    "print(app_label[['app_id','label_id']].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_label_new:\n",
      "                app_id  label_id    app  label\n",
      "0  7324884708820027918       251  17355    207\n",
      "1 -4494216993218550286       251   4618    207\n",
      "2  6058196446775239644       406  15548    247\n",
      "3  6058196446775239644       407  15548    248\n",
      "4  8694625920731541625       406  18689    247\n"
     ]
    }
   ],
   "source": [
    "app_label_new = app_label.loc[app_label.app_id.isin(app_event.app_id.unique())].copy()\n",
    "app_label_new['app'] = encoder2.transform(app_label_new.app_id)\n",
    "encoder4 = LabelEncoder().fit(app_label_new.label_id)\n",
    "app_label_new['label'] = encoder4.transform(app_label_new.label_id)\n",
    "labelnumber = len(encoder4.classes_)\n",
    "print('app_label_new:')\n",
    "print(app_label_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919886\n",
      "129892268\n",
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_label_grouped:\n",
      "             device_id  label  size\n",
      "0 -9222956879900151005    117     1\n",
      "1 -9222956879900151005    120     1\n",
      "2 -9222956879900151005    126     1\n",
      "3 -9222956879900151005    138     2\n",
      "4 -9222956879900151005    147     2\n"
     ]
    }
   ],
   "source": [
    "print(app_label.size)\n",
    "print(installed_app.size)\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_label_grouped = (installed_app_grouped.reset_index()[['device_id','app']]\n",
    "                          .merge(app_label_new[['app','label']])\n",
    "                          .groupby(['device_id','label']))['app'].agg(['size']).reset_index()\n",
    "                          \n",
    "print('installed_label_grouped:')\n",
    "print(installed_label_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_app_train_with = pd.merge(installed_label_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_on='device_id')\n",
    "label_app_test_with = pd.merge(installed_label_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_on ='device_id' )\n",
    "label_app_train_with = label_app_train_with.dropna(subset= ['int_index','label'])\n",
    "label_app_test_with = label_app_test_with.dropna(subset= ['int_index','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed_with shape: (23309, 492)\n",
      "X_test_installed_with shape: (35194, 492)\n"
     ]
    }
   ],
   "source": [
    "#binary\n",
    "X_train_label_with = csr_matrix((np.ones(label_app_train_with.shape[0]),\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((np.ones(label_app_test_with.shape[0]),(label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))\n",
    "#count\n",
    "'''X_train_label_with = csr_matrix((label_app_train_with['size'],\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((label_app_test_with['size'],\n",
    "                                (label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))'''\n",
    "print('X_train_installed_with shape:',X_train_label_with.shape)\n",
    "print('X_test_installed_with shape:',X_test_label_with.shape)\n",
    "del installed_app_grouped,label,app_label,app_label_new,label_app_test_with,label_app_train_with,encoder4,installed_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering V: active app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f4daa6d00c1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m active_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_active']],\n\u001b[0;32m----> 2\u001b[0;31m                          how='right',right_on = 'event_id',left_index = True)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mactive_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactive_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_active\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     37\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                          copy=copy, indicator=indicator)\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m'\\nleft : DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 self.left, self.right)\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 _left_join_on_index(right_ax, left_ax, self.right_join_keys,\n\u001b[0;32m--> 348\u001b[0;31m                                     sort=self.sort)\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             (left_indexer,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36m_left_join_on_index\u001b[0;34m(left_ax, right_ax, join_keys, sort)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0m_get_single_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_ax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_indexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36m_get_single_indexer\u001b[0;34m(join_key, index, sort)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         count, sort=sort)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/join.pyx\u001b[0m in \u001b[0;36mpandas.algos.left_outer_join (pandas/algos.c:59942)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/join.pyx\u001b[0m in \u001b[0;36mpandas.algos._get_result_indexer (pandas/algos.c:61978)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "active_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_active']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "active_app = active_app.loc[active_app.is_active==1]\n",
    "print(active_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_grouped = active_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('active_app_grouped:')\n",
    "print(active_app_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_train_with = pd.merge(active_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'left',right_index=True,left_index=True)\n",
    "active_app_test_with = pd.merge(active_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'left',right_index=True,left_index=True)\n",
    "print('active_app_train_with:')\n",
    "print(active_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_train_with = active_app_train_with.reset_index()\n",
    "active_app_test_with = active_app_test_with.reset_index()\n",
    "active_app_train_with = active_app_train_with.dropna(subset=['int_index'])\n",
    "active_app_test_with = active_app_test_with.dropna(subset=['int_index'])\n",
    "print(active_app_train_with.head())\n",
    "print(active_app_test_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# binary active map\n",
    "#X_train_active_with = csr_matrix((np.ones(active_app_train_with.shape[0]),\n",
    "#                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "#                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "#X_test_active = csr_matrix((np.ones(active_app_test_with.shape[0]),\n",
    "#                            (active_app_test.int_index,active_app_test_with.app)),\n",
    "#                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "# count the number of active app\n",
    "X_train_active_with = csr_matrix((active_app_train_with['size'],\n",
    "                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_active_with = csr_matrix((active_app_test_with['size'],\n",
    "                            (active_app_test_with.int_index,active_app_test_with.app)),\n",
    "                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_active shape:',X_train_active_with.shape)\n",
    "print('X_test_active shape:',X_test_active_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_active_with = scaler.fit_transform(X_train_active_with)\n",
    "X_test_active_with = scaler.transform(X_test_active_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering VI: active time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  time  times\n",
      "0 -9222956879900151005     7      2\n",
      "1 -9222956879900151005    11      7\n",
      "2 -9222956879900151005    12     13\n",
      "3 -9222956879900151005    13      3\n",
      "4 -9222956879900151005    14      5\n"
     ]
    }
   ],
   "source": [
    "events_time = events[['device_id','timestamp']].copy()\n",
    "events_time['time']  = events_time['timestamp'].str[11:13].astype(int)\n",
    "events_time.drop(['timestamp'],axis=1,inplace=True)\n",
    "events_time = events_time.groupby(['device_id','time'])['time'].agg({'times':'count'}).reset_index()\n",
    "print(events_time.head())\n",
    "timenumber= events_time.time.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_time_with shape: (23309, 24)\n",
      "X_test_time_with shape: (35194, 24)\n"
     ]
    }
   ],
   "source": [
    "time_train_with = pd.merge(events_time,gender_age_train_with[['int_index']],\n",
    "                               right_index=True,left_on='device_id')\n",
    "time_test_with = pd.merge(events_time,gender_age_test_with[['int_index']],\n",
    "                               right_index=True,left_on ='device_id' )\n",
    "#binary\n",
    "X_train_time_with = csr_matrix((np.ones(time_train_with.shape[0]),\n",
    "                            (time_train_with.int_index,time_train_with.time)), \n",
    "                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "X_test_time_with = csr_matrix((np.ones(time_test_with.shape[0]),\n",
    "                            (time_test_with.int_index,time_test_with.time)),\n",
    "                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "\n",
    "#number\n",
    "#X_train_time_with = csr_matrix((time_train_with['times'],\n",
    "#                            (time_train_with.int_index,time_train_with.time)), \n",
    "#                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "#X_test_time_with = csr_matrix((time_test_with['times'],\n",
    "#                            (time_test_with.int_index,time_test_with.time)),\n",
    "#                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "print('X_train_time_with shape:',X_train_time_with.shape)\n",
    "print('X_test_time_with shape:',X_test_time_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the time period count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_time_with = scaler.fit_transform(X_train_time_with)\n",
    "X_test_time_with = scaler.transform(X_test_time_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature join and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(74645, 1798)\n",
      "Testing shape:\n",
      "(76877, 1798)\n",
      "y shape:\n",
      "(74645, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_without = hstack((X_train_brand_without,X_train_model_without),format='csr')\n",
    "temp_train = hstack((X_train_brand_with,X_train_model_with),format='csr')\n",
    "X_test_total_without = hstack((X_test_brand_without,X_test_model_without),format='csr')\n",
    "\n",
    "X_train_total_without= vstack((X_train_total_without,temp_train),format = 'csr')\n",
    "gender_age_train_without_temp = pd.concat((gender_age_train_without,gender_age_train_with))\n",
    "\n",
    "print('Training shape:')\n",
    "print(X_train_total_without.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_without.shape)\n",
    "print('y shape:')\n",
    "print(gender_age_train_without_temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device with events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(23309, 21551)\n",
      "Testing shape:\n",
      "(35194, 21551)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_with = hstack((X_train_brand_with,X_train_model_with,\n",
    "                             #X_train_active_with,\n",
    "                             X_train_time_with,\n",
    "                             X_train_installed_with,X_train_label_with),format='csr')\n",
    "X_test_total_with = hstack((X_test_brand_with,X_test_model_with,\n",
    "                            #X_test_active_with,\n",
    "                            X_test_time_with,\n",
    "                           X_test_installed_with,X_test_label_with),format='csr')\n",
    "print('Training shape:')\n",
    "print(X_train_total_with.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentile selction\n",
    "#selector = SelectPercentile(f_classif, percentile=80)\n",
    "#selector.fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#X_val.shape\n",
    "\n",
    "# Selection using chi-square\n",
    "#selector = SelectKBest(chi2, k=15155).fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#print('Training shape:')\n",
    "#print(X_train_total.shape)\n",
    "#print('Testing shape:')\n",
    "#print(X_test_total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear the memory before we do the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del app_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Start training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetencoder = LabelEncoder().fit(gender_age_train_with.group)\n",
    "nclasses = len(targetencoder.classes_)\n",
    "y_train_total_with = targetencoder.transform(gender_age_train_with.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset I: device with events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator \n",
    "    #(https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/keras/engine/training.py:1460: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11s - loss: 2.4084 - acc: 0.1427 - val_loss: 2.3477 - val_acc: 0.1627\n",
      "Epoch 2/20\n",
      "11s - loss: 2.2397 - acc: 0.2160 - val_loss: 2.2432 - val_acc: 0.1973\n",
      "Epoch 3/20\n",
      "12s - loss: 2.1262 - acc: 0.2479 - val_loss: 2.2271 - val_acc: 0.2145\n",
      "Epoch 4/20\n",
      "11s - loss: 2.0607 - acc: 0.2724 - val_loss: 2.1842 - val_acc: 0.2295\n",
      "Epoch 5/20\n",
      "11s - loss: 2.0194 - acc: 0.2851 - val_loss: 2.1608 - val_acc: 0.2504\n",
      "Epoch 6/20\n",
      "11s - loss: 1.9814 - acc: 0.2982 - val_loss: 2.2211 - val_acc: 0.2230\n",
      "Epoch 7/20\n",
      "11s - loss: 1.9610 - acc: 0.3092 - val_loss: 2.1383 - val_acc: 0.2539\n",
      "Epoch 8/20\n",
      "11s - loss: 1.9338 - acc: 0.3167 - val_loss: 2.1167 - val_acc: 0.2551\n",
      "Epoch 9/20\n",
      "11s - loss: 1.9031 - acc: 0.3271 - val_loss: 2.1202 - val_acc: 0.2628\n",
      "Epoch 10/20\n",
      "11s - loss: 1.8904 - acc: 0.3308 - val_loss: 2.1307 - val_acc: 0.2586\n",
      "Epoch 11/20\n",
      "11s - loss: 1.8791 - acc: 0.3373 - val_loss: 2.1143 - val_acc: 0.2594\n",
      "Epoch 12/20\n",
      "11s - loss: 1.8607 - acc: 0.3396 - val_loss: 2.1657 - val_acc: 0.2513\n",
      "Epoch 13/20\n",
      "11s - loss: 1.8418 - acc: 0.3485 - val_loss: 2.1616 - val_acc: 0.2543\n",
      "Epoch 14/20\n",
      "11s - loss: 1.8230 - acc: 0.3551 - val_loss: 2.1104 - val_acc: 0.2564\n",
      "Epoch 15/20\n",
      "11s - loss: 1.8089 - acc: 0.3585 - val_loss: 2.1105 - val_acc: 0.2568\n",
      "Epoch 16/20\n",
      "11s - loss: 1.7941 - acc: 0.3646 - val_loss: 2.1153 - val_acc: 0.2616\n",
      "Epoch 17/20\n",
      "11s - loss: 1.7798 - acc: 0.3672 - val_loss: 2.1158 - val_acc: 0.2620\n",
      "Epoch 18/20\n",
      "11s - loss: 1.7762 - acc: 0.3707 - val_loss: 2.1279 - val_acc: 0.2581\n",
      "Epoch 19/20\n",
      "11s - loss: 1.7589 - acc: 0.3796 - val_loss: 2.1443 - val_acc: 0.2509\n",
      "Epoch 20/20\n",
      "11s - loss: 1.7417 - acc: 0.3824 - val_loss: 2.1725 - val_acc: 0.2509\n",
      "logloss val 2.1724923770358044\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "13s - loss: 2.4153 - acc: 0.1359 - val_loss: 2.3576 - val_acc: 0.1509\n",
      "Epoch 2/20\n",
      "14s - loss: 2.2756 - acc: 0.1989 - val_loss: 2.2126 - val_acc: 0.2302\n",
      "Epoch 3/20\n",
      "14s - loss: 2.1333 - acc: 0.2454 - val_loss: 2.1155 - val_acc: 0.2486\n",
      "Epoch 4/20\n",
      "14s - loss: 2.0623 - acc: 0.2733 - val_loss: 2.1096 - val_acc: 0.2610\n",
      "Epoch 5/20\n",
      "14s - loss: 2.0140 - acc: 0.2890 - val_loss: 2.0448 - val_acc: 0.2846\n",
      "Epoch 6/20\n",
      "14s - loss: 1.9837 - acc: 0.2996 - val_loss: 2.0203 - val_acc: 0.2902\n",
      "Epoch 7/20\n",
      "15s - loss: 1.9569 - acc: 0.3086 - val_loss: 2.0586 - val_acc: 0.2795\n",
      "Epoch 8/20\n",
      "14s - loss: 1.9288 - acc: 0.3182 - val_loss: 2.0425 - val_acc: 0.2838\n",
      "Epoch 9/20\n",
      "16s - loss: 1.9178 - acc: 0.3233 - val_loss: 2.0034 - val_acc: 0.2936\n",
      "Epoch 10/20\n",
      "14s - loss: 1.8846 - acc: 0.3365 - val_loss: 2.0248 - val_acc: 0.2842\n",
      "Epoch 11/20\n",
      "14s - loss: 1.8772 - acc: 0.3356 - val_loss: 1.9898 - val_acc: 0.2988\n",
      "Epoch 12/20\n",
      "14s - loss: 1.8675 - acc: 0.3409 - val_loss: 1.9838 - val_acc: 0.3000\n",
      "Epoch 13/20\n",
      "14s - loss: 1.8479 - acc: 0.3456 - val_loss: 2.0526 - val_acc: 0.2885\n",
      "Epoch 14/20\n",
      "15s - loss: 1.8291 - acc: 0.3550 - val_loss: 1.9806 - val_acc: 0.3026\n",
      "Epoch 15/20\n",
      "212s - loss: 1.8204 - acc: 0.3566 - val_loss: 1.9978 - val_acc: 0.3052\n",
      "Epoch 16/20\n"
     ]
    }
   ],
   "source": [
    "def with_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, input_dim=X_dim_input, init='normal', activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(150, input_dim=X_dim_input, init='normal', activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "\n",
    "dummy_y_with = np_utils.to_categorical(y_train_total_with)\n",
    "for i in range(8):\n",
    "    kf = StratifiedKFold(y_train_total_with,n_folds = 10,random_state = i)\n",
    "    score_list_with=[]\n",
    "    val_loss_list_with = []\n",
    "    for index,(train, test) in enumerate(kf):\n",
    "        X_train_with = X_train_total_with[train]\n",
    "        y_train_with = dummy_y_with[train]\n",
    "        X_val_with = X_train_total_with[test]\n",
    "        y_val_with = dummy_y_with[test]\n",
    "        #print(X_val.shape)\n",
    "        print('*****************************************************')\n",
    "        print('{}_fold'.format(index))\n",
    "        model=with_model(X_train_total_with.shape[1])\n",
    "        fit= model.fit_generator(generator=batch_generator(X_train_with, y_train_with, 1024, True),\n",
    "                             nb_epoch=20,\n",
    "                             samples_per_epoch=40000,\n",
    "                             validation_data=(X_val_with.todense(), y_val_with), verbose=2\n",
    "                             )\n",
    "        scores_val_with = model.predict_generator(generator=batch_generatorp(X_val_with, 512, False), \n",
    "                                             val_samples=X_val_with.shape[0])\n",
    "        scores_with = model.predict_generator(generator=batch_generatorp(X_test_total_with, 512, False), \n",
    "                                         val_samples=X_test_total_with.shape[0])\n",
    "        score_list_with.append(scores_with)\n",
    "        val_loss = log_loss(y_val_with, scores_val_with)\n",
    "        val_loss_list_with.append(val_loss)\n",
    "        print('logloss val {}'.format(val_loss))\n",
    "\n",
    "    for index,i in enumerate(val_loss_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    val_loss_ave_with = sumi/len(val_loss_list_with)\n",
    "    print('average logloss val {}'.format(val_loss_ave_with))\n",
    "    for index,i in enumerate(score_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    score_ave_with = sumi/len(score_list_with)\n",
    "    pred_with = pd.DataFrame(score_ave_with, index = gender_age_test_with.index, columns=targetencoder.classes_)\n",
    "    pred_with.to_csv('nnet_with_50tanh_150tanh_100relu_softmax{}.csv'.format(val_loss_ave_with))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.31303\ttest-mlogloss:2.44626\n",
      "[1]\ttrain-mlogloss:2.15781\ttest-mlogloss:2.41479\n",
      "[2]\ttrain-mlogloss:2.0156\ttest-mlogloss:2.38906\n",
      "[3]\ttrain-mlogloss:1.88523\ttest-mlogloss:2.36827\n",
      "[4]\ttrain-mlogloss:1.76583\ttest-mlogloss:2.3508\n",
      "[5]\ttrain-mlogloss:1.65476\ttest-mlogloss:2.33634\n",
      "[6]\ttrain-mlogloss:1.55228\ttest-mlogloss:2.32204\n",
      "[7]\ttrain-mlogloss:1.4564\ttest-mlogloss:2.31109\n",
      "[8]\ttrain-mlogloss:1.36693\ttest-mlogloss:2.29872\n",
      "[9]\ttrain-mlogloss:1.28346\ttest-mlogloss:2.2878\n",
      "[10]\ttrain-mlogloss:1.20583\ttest-mlogloss:2.27857\n",
      "[11]\ttrain-mlogloss:1.13388\ttest-mlogloss:2.26988\n",
      "[12]\ttrain-mlogloss:1.06634\ttest-mlogloss:2.262\n",
      "[13]\ttrain-mlogloss:1.00325\ttest-mlogloss:2.25463\n",
      "[14]\ttrain-mlogloss:0.944401\ttest-mlogloss:2.24789\n",
      "[15]\ttrain-mlogloss:0.889462\ttest-mlogloss:2.24204\n",
      "[16]\ttrain-mlogloss:0.838447\ttest-mlogloss:2.23669\n",
      "[17]\ttrain-mlogloss:0.790767\ttest-mlogloss:2.23152\n",
      "[18]\ttrain-mlogloss:0.745958\ttest-mlogloss:2.22677\n",
      "[19]\ttrain-mlogloss:0.704158\ttest-mlogloss:2.2214\n",
      "[20]\ttrain-mlogloss:0.665113\ttest-mlogloss:2.21668\n",
      "[21]\ttrain-mlogloss:0.628711\ttest-mlogloss:2.21241\n",
      "[22]\ttrain-mlogloss:0.594786\ttest-mlogloss:2.20869\n",
      "[23]\ttrain-mlogloss:0.56294\ttest-mlogloss:2.20485\n",
      "[24]\ttrain-mlogloss:0.533311\ttest-mlogloss:2.20109\n",
      "[25]\ttrain-mlogloss:0.505508\ttest-mlogloss:2.19744\n",
      "[26]\ttrain-mlogloss:0.479518\ttest-mlogloss:2.19398\n",
      "[27]\ttrain-mlogloss:0.455269\ttest-mlogloss:2.19104\n",
      "[28]\ttrain-mlogloss:0.432509\ttest-mlogloss:2.18829\n",
      "[29]\ttrain-mlogloss:0.411326\ttest-mlogloss:2.1855\n",
      "[30]\ttrain-mlogloss:0.391538\ttest-mlogloss:2.18339\n",
      "[31]\ttrain-mlogloss:0.372948\ttest-mlogloss:2.18004\n",
      "[32]\ttrain-mlogloss:0.35553\ttest-mlogloss:2.17753\n",
      "[33]\ttrain-mlogloss:0.339281\ttest-mlogloss:2.17457\n",
      "[34]\ttrain-mlogloss:0.324094\ttest-mlogloss:2.17312\n",
      "[35]\ttrain-mlogloss:0.309821\ttest-mlogloss:2.1707\n",
      "[36]\ttrain-mlogloss:0.296371\ttest-mlogloss:2.16791\n",
      "[37]\ttrain-mlogloss:0.28374\ttest-mlogloss:2.16566\n",
      "[38]\ttrain-mlogloss:0.271887\ttest-mlogloss:2.16414\n",
      "[39]\ttrain-mlogloss:0.260771\ttest-mlogloss:2.16296\n",
      "[40]\ttrain-mlogloss:0.250243\ttest-mlogloss:2.16115\n",
      "[41]\ttrain-mlogloss:0.240351\ttest-mlogloss:2.15975\n",
      "[42]\ttrain-mlogloss:0.231067\ttest-mlogloss:2.15826\n",
      "[43]\ttrain-mlogloss:0.222286\ttest-mlogloss:2.15694\n",
      "[44]\ttrain-mlogloss:0.213982\ttest-mlogloss:2.15629\n",
      "[45]\ttrain-mlogloss:0.206196\ttest-mlogloss:2.15488\n",
      "[46]\ttrain-mlogloss:0.198838\ttest-mlogloss:2.15411\n",
      "[47]\ttrain-mlogloss:0.191863\ttest-mlogloss:2.15313\n",
      "[48]\ttrain-mlogloss:0.185265\ttest-mlogloss:2.15219\n",
      "[49]\ttrain-mlogloss:0.179007\ttest-mlogloss:2.15168\n",
      "[50]\ttrain-mlogloss:0.173084\ttest-mlogloss:2.15051\n",
      "[51]\ttrain-mlogloss:0.167456\ttest-mlogloss:2.15023\n",
      "[52]\ttrain-mlogloss:0.162172\ttest-mlogloss:2.14923\n",
      "[53]\ttrain-mlogloss:0.15715\ttest-mlogloss:2.14884\n",
      "[54]\ttrain-mlogloss:0.15238\ttest-mlogloss:2.14906\n",
      "[55]\ttrain-mlogloss:0.147846\ttest-mlogloss:2.14857\n",
      "[56]\ttrain-mlogloss:0.143531\ttest-mlogloss:2.14843\n",
      "[57]\ttrain-mlogloss:0.139391\ttest-mlogloss:2.14781\n",
      "[58]\ttrain-mlogloss:0.135447\ttest-mlogloss:2.14759\n",
      "[59]\ttrain-mlogloss:0.13171\ttest-mlogloss:2.14621\n",
      "[60]\ttrain-mlogloss:0.128172\ttest-mlogloss:2.14585\n",
      "[61]\ttrain-mlogloss:0.124758\ttest-mlogloss:2.14571\n",
      "[62]\ttrain-mlogloss:0.121541\ttest-mlogloss:2.14586\n",
      "[63]\ttrain-mlogloss:0.118462\ttest-mlogloss:2.14546\n",
      "[64]\ttrain-mlogloss:0.115497\ttest-mlogloss:2.14519\n",
      "[65]\ttrain-mlogloss:0.112645\ttest-mlogloss:2.14567\n",
      "[66]\ttrain-mlogloss:0.10993\ttest-mlogloss:2.14572\n",
      "[67]\ttrain-mlogloss:0.107323\ttest-mlogloss:2.1454\n",
      "[68]\ttrain-mlogloss:0.104845\ttest-mlogloss:2.14562\n",
      "[69]\ttrain-mlogloss:0.102448\ttest-mlogloss:2.146\n",
      "[70]\ttrain-mlogloss:0.100157\ttest-mlogloss:2.14577\n",
      "[71]\ttrain-mlogloss:0.097927\ttest-mlogloss:2.14594\n",
      "[72]\ttrain-mlogloss:0.0958\ttest-mlogloss:2.14667\n",
      "[73]\ttrain-mlogloss:0.093765\ttest-mlogloss:2.14679\n",
      "[74]\ttrain-mlogloss:0.091805\ttest-mlogloss:2.14678\n",
      "[75]\ttrain-mlogloss:0.089893\ttest-mlogloss:2.1469\n",
      "[76]\ttrain-mlogloss:0.088073\ttest-mlogloss:2.14723\n",
      "[77]\ttrain-mlogloss:0.086338\ttest-mlogloss:2.14757\n",
      "[78]\ttrain-mlogloss:0.084658\ttest-mlogloss:2.14764\n",
      "[79]\ttrain-mlogloss:0.083037\ttest-mlogloss:2.14795\n",
      "[80]\ttrain-mlogloss:0.081459\ttest-mlogloss:2.14835\n",
      "[81]\ttrain-mlogloss:0.079966\ttest-mlogloss:2.1489\n",
      "[82]\ttrain-mlogloss:0.078514\ttest-mlogloss:2.14919\n",
      "[83]\ttrain-mlogloss:0.077088\ttest-mlogloss:2.14939\n",
      "[84]\ttrain-mlogloss:0.075719\ttest-mlogloss:2.1497\n",
      "[85]\ttrain-mlogloss:0.07439\ttest-mlogloss:2.14986\n",
      "[86]\ttrain-mlogloss:0.07313\ttest-mlogloss:2.15016\n",
      "[87]\ttrain-mlogloss:0.071891\ttest-mlogloss:2.15099\n",
      "[88]\ttrain-mlogloss:0.070696\ttest-mlogloss:2.15118\n",
      "[89]\ttrain-mlogloss:0.06955\ttest-mlogloss:2.15121\n",
      "[90]\ttrain-mlogloss:0.068445\ttest-mlogloss:2.15152\n",
      "[91]\ttrain-mlogloss:0.067344\ttest-mlogloss:2.15144\n",
      "[92]\ttrain-mlogloss:0.066308\ttest-mlogloss:2.15177\n",
      "[93]\ttrain-mlogloss:0.065294\ttest-mlogloss:2.15222\n",
      "[94]\ttrain-mlogloss:0.064314\ttest-mlogloss:2.15297\n",
      "[95]\ttrain-mlogloss:0.063355\ttest-mlogloss:2.15335\n",
      "[96]\ttrain-mlogloss:0.062403\ttest-mlogloss:2.15359\n",
      "[97]\ttrain-mlogloss:0.061489\ttest-mlogloss:2.15444\n",
      "[98]\ttrain-mlogloss:0.060605\ttest-mlogloss:2.155\n",
      "[99]\ttrain-mlogloss:0.059747\ttest-mlogloss:2.1554\n",
      "[100]\ttrain-mlogloss:0.058902\ttest-mlogloss:2.15575\n",
      "[101]\ttrain-mlogloss:0.0581\ttest-mlogloss:2.15616\n",
      "[102]\ttrain-mlogloss:0.057299\ttest-mlogloss:2.15664\n",
      "[103]\ttrain-mlogloss:0.056533\ttest-mlogloss:2.15725\n",
      "[104]\ttrain-mlogloss:0.055793\ttest-mlogloss:2.15753\n",
      "[105]\ttrain-mlogloss:0.05505\ttest-mlogloss:2.1576\n",
      "[106]\ttrain-mlogloss:0.054347\ttest-mlogloss:2.15778\n",
      "[107]\ttrain-mlogloss:0.053657\ttest-mlogloss:2.1586\n",
      "[108]\ttrain-mlogloss:0.052971\ttest-mlogloss:2.15881\n",
      "[109]\ttrain-mlogloss:0.052321\ttest-mlogloss:2.1596\n",
      "[110]\ttrain-mlogloss:0.051681\ttest-mlogloss:2.16036\n",
      "[111]\ttrain-mlogloss:0.051055\ttest-mlogloss:2.16086\n",
      "[112]\ttrain-mlogloss:0.050437\ttest-mlogloss:2.16157\n",
      "[113]\ttrain-mlogloss:0.049837\ttest-mlogloss:2.16235\n",
      "[114]\ttrain-mlogloss:0.049259\ttest-mlogloss:2.1629\n",
      "[115]\ttrain-mlogloss:0.048684\ttest-mlogloss:2.1632\n",
      "[116]\ttrain-mlogloss:0.048126\ttest-mlogloss:2.16376\n",
      "[117]\ttrain-mlogloss:0.047586\ttest-mlogloss:2.1639\n",
      "[118]\ttrain-mlogloss:0.047053\ttest-mlogloss:2.16457\n",
      "[119]\ttrain-mlogloss:0.046538\ttest-mlogloss:2.16528\n",
      "[120]\ttrain-mlogloss:0.046023\ttest-mlogloss:2.16567\n",
      "[121]\ttrain-mlogloss:0.045529\ttest-mlogloss:2.16632\n",
      "[122]\ttrain-mlogloss:0.045039\ttest-mlogloss:2.16653\n",
      "[123]\ttrain-mlogloss:0.044559\ttest-mlogloss:2.16693\n",
      "[124]\ttrain-mlogloss:0.044093\ttest-mlogloss:2.16698\n",
      "[125]\ttrain-mlogloss:0.043645\ttest-mlogloss:2.1671\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-1cb4bb1b5b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxg_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0myprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_with)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':50,\n",
    "         'eta':0.01,\n",
    "         'silent':0,\n",
    "         'objective':'multi:softprob',\n",
    "         'nthread':2,\n",
    "         'num_class':12,\n",
    "         'eval_metric':'mlogloss',\n",
    "        'lambda':5,\n",
    "        'lambda_bias':0,\n",
    "        'alpha':2}\n",
    "num_round = 200\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0180472176683\n",
      "newton-cg\n",
      "1.99455721395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_with)\n",
    "#lr grid search\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['newton-cg']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_without= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.0180472176683,multi_class='multinomial',solver='newton-cg')\n",
    "lr.fit(X_train_total_with,y_train_total_with)\n",
    "score_ave_with_lr = lr.predict_proba(X_test_total_with)\n",
    "pred_with_lr = pd.DataFrame(score_ave_with_lr, \n",
    "                            index = gender_age_test_with.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_with_lr.to_csv('lr_with_result{}.csv'.format(val_loss_ave_with))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset II: device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_total_without = targetencoder.transform(gender_age_train_without_temp.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Device without eventsI: Naive Bayes, Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204.50354026\n",
      "2.42330723892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#NB grid search\n",
    "nbc = MultinomialNB()\n",
    "alpha_value = np.logspace(-3,4,100)\n",
    "clf = GridSearchCV(estimator=nbc,param_grid = dict(alpha=alpha_value),scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.alpha)\n",
    "print(-clf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0744380301325\n",
      "lbfgs\n",
      "2.39019928895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#lr grid search\n",
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_without)\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['lbfgs']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_without= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_without)\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(C=0.02,multi_class='multinomial',solver='newton-cg')\n",
    "lr = LogisticRegression(C=0.0744380301325,multi_class='multinomial',solver='lbfgs')\n",
    "lr.fit(X_train_total_without,y_train_total_without)\n",
    "score_ave_without_lr = lr.predict_proba(X_test_total_without)\n",
    "pred_without_lr = pd.DataFrame(score_ave_without_lr, \n",
    "                            index = gender_age_test_without.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_without_lr.to_csv('lr_without_result{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\\nscore_list_without=[]\\nval_loss_list_without = []\\nfor index,(train, test) in enumerate(kf):\\n    X_train_without = X_train_total_without[train]\\n    y_train_without = y_train_total_without[train]\\n    X_val_without = X_train_total_without[test]\\n    y_val_without = y_train_total_without[test]\\n    print('*****************************************************')\\n    print('{}_fold'.format(index))\\n    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\\n    lr.fit(X_train_without,y_train_without)\\n    scores_val_without = lr.predict_proba(X_val_without)\\n    val_loss = log_loss(y_val_without, scores_val_without)\\n    val_loss_list_without.append(val_loss)\\n    print('logloss val {}'.format(val_loss))\\n    \\n    scores_without = lr.predict_proba(X_test_total_without)\\n    score_list_without.append(scores_without)\\n    \\nfor index,i in enumerate(val_loss_list_without):\\n    if(index==0):\\n        sumi = i\\n    else:\\n        sumi = i+sumi\\nval_loss_ave_without = sumi/len(score_list_without)\\nprint('average logloss val {}'.format(val_loss_ave_without))\\nfor index,i in enumerate(score_list_without):\\n    if(index==0):\\n        sumi = i\\n    else:\\n        sumi = i+sumi\\nscore_ave_without = sumi/len(score_list_without)\\npred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\n",
    "score_list_without=[]\n",
    "val_loss_list_without = []\n",
    "for index,(train, test) in enumerate(kf):\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = y_train_total_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = y_train_total_without[test]\n",
    "    print('*****************************************************')\n",
    "    print('{}_fold'.format(index))\n",
    "    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\n",
    "    lr.fit(X_train_without,y_train_without)\n",
    "    scores_val_without = lr.predict_proba(X_val_without)\n",
    "    val_loss = log_loss(y_val_without, scores_val_without)\n",
    "    val_loss_list_without.append(val_loss)\n",
    "    print('logloss val {}'.format(val_loss))\n",
    "    \n",
    "    scores_without = lr.predict_proba(X_test_total_without)\n",
    "    score_list_without.append(scores_without)\n",
    "    \n",
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(score_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without eventsII: Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/keras/engine/training.py:1460: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 2.4629 - acc: 0.1261 - val_loss: 2.4279 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4256 - acc: 0.1298 - val_loss: 2.4264 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4268 - acc: 0.1271 - val_loss: 2.4253 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4219 - acc: 0.1285 - val_loss: 2.4250 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4209 - acc: 0.1289 - val_loss: 2.4248 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4194 - acc: 0.1308 - val_loss: 2.4247 - val_acc: 0.1293\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4163 - acc: 0.1341 - val_loss: 2.4246 - val_acc: 0.1342\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4120 - acc: 0.1401 - val_loss: 2.4236 - val_acc: 0.1407\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4066 - acc: 0.1465 - val_loss: 2.4183 - val_acc: 0.1399\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4017 - acc: 0.1440 - val_loss: 2.4161 - val_acc: 0.1390\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3980 - acc: 0.1443 - val_loss: 2.4128 - val_acc: 0.1402\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3968 - acc: 0.1431 - val_loss: 2.4130 - val_acc: 0.1431\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3945 - acc: 0.1450 - val_loss: 2.4107 - val_acc: 0.1453\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3915 - acc: 0.1491 - val_loss: 2.4097 - val_acc: 0.1513\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3920 - acc: 0.1489 - val_loss: 2.4081 - val_acc: 0.1512\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3887 - acc: 0.1519 - val_loss: 2.4084 - val_acc: 0.1494\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3877 - acc: 0.1501 - val_loss: 2.4071 - val_acc: 0.1504\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3863 - acc: 0.1521 - val_loss: 2.4079 - val_acc: 0.1512\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3848 - acc: 0.1529 - val_loss: 2.4072 - val_acc: 0.1474\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3841 - acc: 0.1529 - val_loss: 2.4065 - val_acc: 0.1505\n",
      "logloss val 2.406513364236188\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4639 - acc: 0.1261 - val_loss: 2.4276 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4269 - acc: 0.1280 - val_loss: 2.4253 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4235 - acc: 0.1282 - val_loss: 2.4235 - val_acc: 0.1294\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4233 - acc: 0.1288 - val_loss: 2.4219 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4215 - acc: 0.1292 - val_loss: 2.4213 - val_acc: 0.1284\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4191 - acc: 0.1310 - val_loss: 2.4207 - val_acc: 0.1307\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4194 - acc: 0.1319 - val_loss: 2.4199 - val_acc: 0.1291\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4168 - acc: 0.1325 - val_loss: 2.4193 - val_acc: 0.1288\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4157 - acc: 0.1368 - val_loss: 2.4172 - val_acc: 0.1390\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4109 - acc: 0.1394 - val_loss: 2.4134 - val_acc: 0.1433\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4066 - acc: 0.1433 - val_loss: 2.4080 - val_acc: 0.1409\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4021 - acc: 0.1423 - val_loss: 2.4046 - val_acc: 0.1404\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3983 - acc: 0.1427 - val_loss: 2.4025 - val_acc: 0.1430\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3971 - acc: 0.1440 - val_loss: 2.4006 - val_acc: 0.1422\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3950 - acc: 0.1449 - val_loss: 2.3994 - val_acc: 0.1450\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3940 - acc: 0.1443 - val_loss: 2.3985 - val_acc: 0.1466\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3909 - acc: 0.1476 - val_loss: 2.3975 - val_acc: 0.1476\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3900 - acc: 0.1493 - val_loss: 2.3972 - val_acc: 0.1466\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3893 - acc: 0.1504 - val_loss: 2.3964 - val_acc: 0.1487\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3877 - acc: 0.1511 - val_loss: 2.3967 - val_acc: 0.1503\n",
      "logloss val 2.39665597203874\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4605 - acc: 0.1268 - val_loss: 2.4274 - val_acc: 0.1288\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4270 - acc: 0.1277 - val_loss: 2.4252 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4254 - acc: 0.1285 - val_loss: 2.4232 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4227 - acc: 0.1284 - val_loss: 2.4213 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4207 - acc: 0.1298 - val_loss: 2.4198 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4200 - acc: 0.1318 - val_loss: 2.4190 - val_acc: 0.1303\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4186 - acc: 0.1370 - val_loss: 2.4176 - val_acc: 0.1375\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4135 - acc: 0.1423 - val_loss: 2.4145 - val_acc: 0.1420\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4095 - acc: 0.1416 - val_loss: 2.4083 - val_acc: 0.1405\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4025 - acc: 0.1427 - val_loss: 2.4046 - val_acc: 0.1442\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3983 - acc: 0.1449 - val_loss: 2.4027 - val_acc: 0.1428\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3971 - acc: 0.1445 - val_loss: 2.4010 - val_acc: 0.1445\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3941 - acc: 0.1463 - val_loss: 2.3999 - val_acc: 0.1469\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3943 - acc: 0.1479 - val_loss: 2.3990 - val_acc: 0.1493\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3914 - acc: 0.1476 - val_loss: 2.3987 - val_acc: 0.1537\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3908 - acc: 0.1482 - val_loss: 2.3983 - val_acc: 0.1568\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3881 - acc: 0.1507 - val_loss: 2.3975 - val_acc: 0.1578\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3862 - acc: 0.1529 - val_loss: 2.3976 - val_acc: 0.1578\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3870 - acc: 0.1520 - val_loss: 2.3976 - val_acc: 0.1537\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3850 - acc: 0.1533 - val_loss: 2.3979 - val_acc: 0.1543\n",
      "logloss val 2.3978786770719847\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "3s - loss: 2.4695 - acc: 0.1253 - val_loss: 2.4306 - val_acc: 0.1298\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4272 - acc: 0.1294 - val_loss: 2.4265 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4256 - acc: 0.1278 - val_loss: 2.4249 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4236 - acc: 0.1291 - val_loss: 2.4235 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4209 - acc: 0.1278 - val_loss: 2.4225 - val_acc: 0.1354\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4202 - acc: 0.1300 - val_loss: 2.4214 - val_acc: 0.1302\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4191 - acc: 0.1320 - val_loss: 2.4209 - val_acc: 0.1302\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4157 - acc: 0.1355 - val_loss: 2.4198 - val_acc: 0.1343\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4154 - acc: 0.1396 - val_loss: 2.4179 - val_acc: 0.1382\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4121 - acc: 0.1412 - val_loss: 2.4136 - val_acc: 0.1433\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4045 - acc: 0.1431 - val_loss: 2.4093 - val_acc: 0.1370\n",
      "Epoch 12/20\n",
      "2s - loss: 2.3978 - acc: 0.1443 - val_loss: 2.4081 - val_acc: 0.1323\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3973 - acc: 0.1463 - val_loss: 2.4082 - val_acc: 0.1275\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3944 - acc: 0.1471 - val_loss: 2.4067 - val_acc: 0.1342\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3922 - acc: 0.1485 - val_loss: 2.4059 - val_acc: 0.1347\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3910 - acc: 0.1495 - val_loss: 2.4057 - val_acc: 0.1355\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3887 - acc: 0.1518 - val_loss: 2.4058 - val_acc: 0.1382\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3887 - acc: 0.1526 - val_loss: 2.4057 - val_acc: 0.1397\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3845 - acc: 0.1545 - val_loss: 2.4056 - val_acc: 0.1383\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3865 - acc: 0.1538 - val_loss: 2.4058 - val_acc: 0.1410\n",
      "logloss val 2.405777173219826\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4660 - acc: 0.1281 - val_loss: 2.4280 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4262 - acc: 0.1278 - val_loss: 2.4261 - val_acc: 0.1270\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4251 - acc: 0.1281 - val_loss: 2.4245 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4228 - acc: 0.1299 - val_loss: 2.4232 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4211 - acc: 0.1281 - val_loss: 2.4222 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4194 - acc: 0.1286 - val_loss: 2.4213 - val_acc: 0.1364\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4178 - acc: 0.1333 - val_loss: 2.4198 - val_acc: 0.1369\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4164 - acc: 0.1384 - val_loss: 2.4167 - val_acc: 0.1406\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4099 - acc: 0.1414 - val_loss: 2.4104 - val_acc: 0.1424\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4027 - acc: 0.1438 - val_loss: 2.4057 - val_acc: 0.1467\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3989 - acc: 0.1431 - val_loss: 2.4043 - val_acc: 0.1501\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3962 - acc: 0.1471 - val_loss: 2.4031 - val_acc: 0.1477\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3942 - acc: 0.1477 - val_loss: 2.4019 - val_acc: 0.1460\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3923 - acc: 0.1501 - val_loss: 2.4016 - val_acc: 0.1449\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3907 - acc: 0.1509 - val_loss: 2.4010 - val_acc: 0.1408\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3876 - acc: 0.1527 - val_loss: 2.4011 - val_acc: 0.1436\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3891 - acc: 0.1512 - val_loss: 2.4011 - val_acc: 0.1447\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3846 - acc: 0.1537 - val_loss: 2.4009 - val_acc: 0.1428\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3855 - acc: 0.1526 - val_loss: 2.4004 - val_acc: 0.1426\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3835 - acc: 0.1537 - val_loss: 2.4002 - val_acc: 0.1449\n",
      "logloss val 2.400220066269058\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4627 - acc: 0.1263 - val_loss: 2.4280 - val_acc: 0.1286\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4262 - acc: 0.1278 - val_loss: 2.4265 - val_acc: 0.1330\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4259 - acc: 0.1300 - val_loss: 2.4254 - val_acc: 0.1286\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4224 - acc: 0.1282 - val_loss: 2.4244 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4203 - acc: 0.1295 - val_loss: 2.4234 - val_acc: 0.1286\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4202 - acc: 0.1296 - val_loss: 2.4226 - val_acc: 0.1326\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4182 - acc: 0.1319 - val_loss: 2.4216 - val_acc: 0.1316\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4166 - acc: 0.1331 - val_loss: 2.4200 - val_acc: 0.1332\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4145 - acc: 0.1366 - val_loss: 2.4177 - val_acc: 0.1353\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4126 - acc: 0.1401 - val_loss: 2.4124 - val_acc: 0.1416\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4049 - acc: 0.1425 - val_loss: 2.4045 - val_acc: 0.1462\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4004 - acc: 0.1436 - val_loss: 2.4011 - val_acc: 0.1454\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3983 - acc: 0.1440 - val_loss: 2.4000 - val_acc: 0.1448\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3951 - acc: 0.1456 - val_loss: 2.3995 - val_acc: 0.1456\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3935 - acc: 0.1477 - val_loss: 2.3990 - val_acc: 0.1459\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3922 - acc: 0.1485 - val_loss: 2.3986 - val_acc: 0.1509\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3908 - acc: 0.1492 - val_loss: 2.3987 - val_acc: 0.1515\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3884 - acc: 0.1523 - val_loss: 2.3984 - val_acc: 0.1521\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3886 - acc: 0.1518 - val_loss: 2.3983 - val_acc: 0.1530\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3856 - acc: 0.1518 - val_loss: 2.3984 - val_acc: 0.1530\n",
      "logloss val 2.398418695389394\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4667 - acc: 0.1260 - val_loss: 2.4284 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4274 - acc: 0.1279 - val_loss: 2.4257 - val_acc: 0.1286\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4252 - acc: 0.1268 - val_loss: 2.4237 - val_acc: 0.1306\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4236 - acc: 0.1300 - val_loss: 2.4215 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4221 - acc: 0.1296 - val_loss: 2.4205 - val_acc: 0.1286\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4199 - acc: 0.1297 - val_loss: 2.4180 - val_acc: 0.1316\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4187 - acc: 0.1373 - val_loss: 2.4152 - val_acc: 0.1428\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4139 - acc: 0.1413 - val_loss: 2.4084 - val_acc: 0.1411\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4050 - acc: 0.1428 - val_loss: 2.4012 - val_acc: 0.1439\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4014 - acc: 0.1430 - val_loss: 2.3986 - val_acc: 0.1444\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3983 - acc: 0.1446 - val_loss: 2.3979 - val_acc: 0.1451\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3944 - acc: 0.1460 - val_loss: 2.3972 - val_acc: 0.1473\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3931 - acc: 0.1475 - val_loss: 2.3967 - val_acc: 0.1490\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3922 - acc: 0.1478 - val_loss: 2.3970 - val_acc: 0.1502\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3903 - acc: 0.1515 - val_loss: 2.3964 - val_acc: 0.1487\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3884 - acc: 0.1521 - val_loss: 2.3967 - val_acc: 0.1501\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3868 - acc: 0.1529 - val_loss: 2.3961 - val_acc: 0.1473\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3853 - acc: 0.1533 - val_loss: 2.3963 - val_acc: 0.1485\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3850 - acc: 0.1534 - val_loss: 2.3960 - val_acc: 0.1481\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3846 - acc: 0.1529 - val_loss: 2.3963 - val_acc: 0.1491\n",
      "logloss val 2.3963135852101947\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4646 - acc: 0.1268 - val_loss: 2.4273 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4274 - acc: 0.1288 - val_loss: 2.4244 - val_acc: 0.1286\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4250 - acc: 0.1272 - val_loss: 2.4221 - val_acc: 0.1286\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4218 - acc: 0.1303 - val_loss: 2.4198 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4205 - acc: 0.1352 - val_loss: 2.4166 - val_acc: 0.1372\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4164 - acc: 0.1422 - val_loss: 2.4102 - val_acc: 0.1359\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4077 - acc: 0.1419 - val_loss: 2.4014 - val_acc: 0.1367\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4040 - acc: 0.1425 - val_loss: 2.3988 - val_acc: 0.1403\n",
      "Epoch 9/20\n",
      "2s - loss: 2.3994 - acc: 0.1455 - val_loss: 2.3967 - val_acc: 0.1406\n",
      "Epoch 10/20\n",
      "2s - loss: 2.3976 - acc: 0.1469 - val_loss: 2.3962 - val_acc: 0.1431\n",
      "Epoch 11/20\n",
      "2s - loss: 2.3957 - acc: 0.1463 - val_loss: 2.3952 - val_acc: 0.1404\n",
      "Epoch 12/20\n",
      "2s - loss: 2.3943 - acc: 0.1479 - val_loss: 2.3951 - val_acc: 0.1446\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3921 - acc: 0.1511 - val_loss: 2.3952 - val_acc: 0.1448\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3904 - acc: 0.1505 - val_loss: 2.3947 - val_acc: 0.1442\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3895 - acc: 0.1510 - val_loss: 2.3943 - val_acc: 0.1446\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3883 - acc: 0.1522 - val_loss: 2.3943 - val_acc: 0.1463\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3858 - acc: 0.1547 - val_loss: 2.3939 - val_acc: 0.1467\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3852 - acc: 0.1534 - val_loss: 2.3948 - val_acc: 0.1481\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3830 - acc: 0.1559 - val_loss: 2.3949 - val_acc: 0.1471\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3830 - acc: 0.1543 - val_loss: 2.3949 - val_acc: 0.1475\n",
      "logloss val 2.3949207724634225\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4654 - acc: 0.1257 - val_loss: 2.4283 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4258 - acc: 0.1290 - val_loss: 2.4266 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4268 - acc: 0.1284 - val_loss: 2.4251 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4225 - acc: 0.1292 - val_loss: 2.4240 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4223 - acc: 0.1281 - val_loss: 2.4225 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4212 - acc: 0.1283 - val_loss: 2.4218 - val_acc: 0.1287\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4190 - acc: 0.1306 - val_loss: 2.4202 - val_acc: 0.1308\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4178 - acc: 0.1309 - val_loss: 2.4186 - val_acc: 0.1304\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4170 - acc: 0.1327 - val_loss: 2.4160 - val_acc: 0.1371\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4110 - acc: 0.1419 - val_loss: 2.4107 - val_acc: 0.1446\n",
      "Epoch 11/20\n",
      "1s - loss: 2.4054 - acc: 0.1434 - val_loss: 2.4059 - val_acc: 0.1414\n",
      "Epoch 12/20\n",
      "1s - loss: 2.4018 - acc: 0.1428 - val_loss: 2.4030 - val_acc: 0.1416\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3993 - acc: 0.1439 - val_loss: 2.4019 - val_acc: 0.1405\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3954 - acc: 0.1453 - val_loss: 2.4019 - val_acc: 0.1410\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3956 - acc: 0.1453 - val_loss: 2.4006 - val_acc: 0.1420\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3932 - acc: 0.1473 - val_loss: 2.4004 - val_acc: 0.1424\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3913 - acc: 0.1480 - val_loss: 2.4000 - val_acc: 0.1436\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3889 - acc: 0.1502 - val_loss: 2.3986 - val_acc: 0.1445\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3893 - acc: 0.1502 - val_loss: 2.3987 - val_acc: 0.1444\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3866 - acc: 0.1522 - val_loss: 2.3976 - val_acc: 0.1424\n",
      "logloss val 2.397624038275701\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4651 - acc: 0.1247 - val_loss: 2.4280 - val_acc: 0.1270\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4280 - acc: 0.1284 - val_loss: 2.4263 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4248 - acc: 0.1292 - val_loss: 2.4249 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4241 - acc: 0.1270 - val_loss: 2.4235 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4218 - acc: 0.1293 - val_loss: 2.4223 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4205 - acc: 0.1286 - val_loss: 2.4211 - val_acc: 0.1287\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4206 - acc: 0.1272 - val_loss: 2.4201 - val_acc: 0.1278\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4179 - acc: 0.1278 - val_loss: 2.4190 - val_acc: 0.1287\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4178 - acc: 0.1280 - val_loss: 2.4176 - val_acc: 0.1327\n",
      "Epoch 10/20\n",
      "3s - loss: 2.4161 - acc: 0.1289 - val_loss: 2.4160 - val_acc: 0.1358\n",
      "Epoch 11/20\n",
      "1s - loss: 2.4132 - acc: 0.1364 - val_loss: 2.4123 - val_acc: 0.1468\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4085 - acc: 0.1420 - val_loss: 2.4044 - val_acc: 0.1476\n",
      "Epoch 13/20\n",
      "2s - loss: 2.4018 - acc: 0.1433 - val_loss: 2.3984 - val_acc: 0.1471\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3971 - acc: 0.1451 - val_loss: 2.3963 - val_acc: 0.1471\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3946 - acc: 0.1455 - val_loss: 2.3953 - val_acc: 0.1473\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3926 - acc: 0.1484 - val_loss: 2.3941 - val_acc: 0.1499\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3913 - acc: 0.1501 - val_loss: 2.3935 - val_acc: 0.1460\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3894 - acc: 0.1513 - val_loss: 2.3930 - val_acc: 0.1496\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3878 - acc: 0.1528 - val_loss: 2.3932 - val_acc: 0.1489\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3862 - acc: 0.1520 - val_loss: 2.3923 - val_acc: 0.1493\n",
      "logloss val 2.392325430377301\n",
      "average logloss val 2.3986647774551813\n"
     ]
    }
   ],
   "source": [
    "# define baseline model\n",
    "def without_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "dummy_y_without = np_utils.to_categorical(y_train_total_without)\n",
    "kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\n",
    "score_list_without=[]\n",
    "val_loss_list_without = []\n",
    "for index,(train, test) in enumerate(kf):\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = dummy_y_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = dummy_y_without[test]\n",
    "    print('*****************************************************')\n",
    "    print('{}_fold'.format(index))\n",
    "    model=without_model(X_train_total_without.shape[1])\n",
    "    fit= model.fit_generator(generator=batch_generator(X_train_without, y_train_without, 512, True),\n",
    "                         nb_epoch=20,\n",
    "                         samples_per_epoch=80000,\n",
    "                         validation_data=(X_val_without.todense(), y_val_without), verbose=2\n",
    "                         )\n",
    "    scores_val_without = model.predict_generator(generator=batch_generatorp(X_val_without, 512, False), \n",
    "                                         val_samples=X_val_without.shape[0])\n",
    "    scores_without = model.predict_generator(generator=batch_generatorp(X_test_total_without, 512, False), \n",
    "                                     val_samples=X_test_total_without.shape[0])\n",
    "    score_list_without.append(scores_without)\n",
    "    \n",
    "    val_loss = log_loss(y_val_without, scores_val_without)\n",
    "    val_loss_list_without.append(val_loss)\n",
    "    print('logloss val {}'.format(val_loss))\n",
    "\n",
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(score_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_without.to_csv('nnt_without_result{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_ensemble = (score_ave_without+score_ave_without_lr)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without eventsIII: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.48343\ttest-mlogloss:2.48377\n",
      "[1]\ttrain-mlogloss:2.48198\ttest-mlogloss:2.48265\n",
      "[2]\ttrain-mlogloss:2.48054\ttest-mlogloss:2.48154\n",
      "[3]\ttrain-mlogloss:2.47912\ttest-mlogloss:2.48045\n",
      "[4]\ttrain-mlogloss:2.47772\ttest-mlogloss:2.47938\n",
      "[5]\ttrain-mlogloss:2.47633\ttest-mlogloss:2.47831\n",
      "[6]\ttrain-mlogloss:2.47496\ttest-mlogloss:2.47727\n",
      "[7]\ttrain-mlogloss:2.47361\ttest-mlogloss:2.47623\n",
      "[8]\ttrain-mlogloss:2.47227\ttest-mlogloss:2.47521\n",
      "[9]\ttrain-mlogloss:2.47095\ttest-mlogloss:2.4742\n",
      "[10]\ttrain-mlogloss:2.46964\ttest-mlogloss:2.4732\n",
      "[11]\ttrain-mlogloss:2.46835\ttest-mlogloss:2.47222\n",
      "[12]\ttrain-mlogloss:2.46707\ttest-mlogloss:2.47125\n",
      "[13]\ttrain-mlogloss:2.46581\ttest-mlogloss:2.47029\n",
      "[14]\ttrain-mlogloss:2.46456\ttest-mlogloss:2.46935\n",
      "[15]\ttrain-mlogloss:2.46333\ttest-mlogloss:2.46841\n",
      "[16]\ttrain-mlogloss:2.46211\ttest-mlogloss:2.4675\n",
      "[17]\ttrain-mlogloss:2.4609\ttest-mlogloss:2.46659\n",
      "[18]\ttrain-mlogloss:2.4597\ttest-mlogloss:2.4657\n",
      "[19]\ttrain-mlogloss:2.45852\ttest-mlogloss:2.46483\n",
      "[20]\ttrain-mlogloss:2.45735\ttest-mlogloss:2.46396\n",
      "[21]\ttrain-mlogloss:2.45619\ttest-mlogloss:2.46311\n",
      "[22]\ttrain-mlogloss:2.45504\ttest-mlogloss:2.46225\n",
      "[23]\ttrain-mlogloss:2.45391\ttest-mlogloss:2.46141\n",
      "[24]\ttrain-mlogloss:2.45279\ttest-mlogloss:2.46058\n",
      "[25]\ttrain-mlogloss:2.45168\ttest-mlogloss:2.45976\n",
      "[26]\ttrain-mlogloss:2.45058\ttest-mlogloss:2.45896\n",
      "[27]\ttrain-mlogloss:2.4495\ttest-mlogloss:2.45816\n",
      "[28]\ttrain-mlogloss:2.44842\ttest-mlogloss:2.45738\n",
      "[29]\ttrain-mlogloss:2.44736\ttest-mlogloss:2.4566\n",
      "[30]\ttrain-mlogloss:2.44631\ttest-mlogloss:2.45583\n",
      "[31]\ttrain-mlogloss:2.44527\ttest-mlogloss:2.45507\n",
      "[32]\ttrain-mlogloss:2.44424\ttest-mlogloss:2.45432\n",
      "[33]\ttrain-mlogloss:2.44323\ttest-mlogloss:2.45358\n",
      "[34]\ttrain-mlogloss:2.44222\ttest-mlogloss:2.45286\n",
      "[35]\ttrain-mlogloss:2.44123\ttest-mlogloss:2.45213\n",
      "[36]\ttrain-mlogloss:2.44024\ttest-mlogloss:2.45142\n",
      "[37]\ttrain-mlogloss:2.43926\ttest-mlogloss:2.45072\n",
      "[38]\ttrain-mlogloss:2.4383\ttest-mlogloss:2.45003\n",
      "[39]\ttrain-mlogloss:2.43735\ttest-mlogloss:2.44934\n",
      "[40]\ttrain-mlogloss:2.4364\ttest-mlogloss:2.44867\n",
      "[41]\ttrain-mlogloss:2.43547\ttest-mlogloss:2.448\n",
      "[42]\ttrain-mlogloss:2.43455\ttest-mlogloss:2.44734\n",
      "[43]\ttrain-mlogloss:2.43364\ttest-mlogloss:2.44669\n",
      "[44]\ttrain-mlogloss:2.43273\ttest-mlogloss:2.44605\n",
      "[45]\ttrain-mlogloss:2.43184\ttest-mlogloss:2.44541\n",
      "[46]\ttrain-mlogloss:2.43095\ttest-mlogloss:2.44479\n",
      "[47]\ttrain-mlogloss:2.43007\ttest-mlogloss:2.44417\n",
      "[48]\ttrain-mlogloss:2.42921\ttest-mlogloss:2.44357\n",
      "[49]\ttrain-mlogloss:2.42835\ttest-mlogloss:2.44297\n",
      "[50]\ttrain-mlogloss:2.4275\ttest-mlogloss:2.44238\n",
      "[51]\ttrain-mlogloss:2.42666\ttest-mlogloss:2.44179\n",
      "[52]\ttrain-mlogloss:2.42583\ttest-mlogloss:2.44122\n",
      "[53]\ttrain-mlogloss:2.425\ttest-mlogloss:2.44064\n",
      "[54]\ttrain-mlogloss:2.42419\ttest-mlogloss:2.44008\n",
      "[55]\ttrain-mlogloss:2.42338\ttest-mlogloss:2.43951\n",
      "[56]\ttrain-mlogloss:2.42258\ttest-mlogloss:2.43897\n",
      "[57]\ttrain-mlogloss:2.42179\ttest-mlogloss:2.43842\n",
      "[58]\ttrain-mlogloss:2.421\ttest-mlogloss:2.43788\n",
      "[59]\ttrain-mlogloss:2.42022\ttest-mlogloss:2.43735\n",
      "[60]\ttrain-mlogloss:2.41945\ttest-mlogloss:2.43683\n",
      "[61]\ttrain-mlogloss:2.41869\ttest-mlogloss:2.4363\n",
      "[62]\ttrain-mlogloss:2.41794\ttest-mlogloss:2.4358\n",
      "[63]\ttrain-mlogloss:2.41719\ttest-mlogloss:2.43529\n",
      "[64]\ttrain-mlogloss:2.41645\ttest-mlogloss:2.4348\n",
      "[65]\ttrain-mlogloss:2.41571\ttest-mlogloss:2.43431\n",
      "[66]\ttrain-mlogloss:2.41499\ttest-mlogloss:2.43382\n",
      "[67]\ttrain-mlogloss:2.41427\ttest-mlogloss:2.43334\n",
      "[68]\ttrain-mlogloss:2.41356\ttest-mlogloss:2.43286\n",
      "[69]\ttrain-mlogloss:2.41285\ttest-mlogloss:2.4324\n",
      "[70]\ttrain-mlogloss:2.41216\ttest-mlogloss:2.43193\n",
      "[71]\ttrain-mlogloss:2.41147\ttest-mlogloss:2.43147\n",
      "[72]\ttrain-mlogloss:2.41078\ttest-mlogloss:2.43103\n",
      "[73]\ttrain-mlogloss:2.4101\ttest-mlogloss:2.43059\n",
      "[74]\ttrain-mlogloss:2.40943\ttest-mlogloss:2.43015\n",
      "[75]\ttrain-mlogloss:2.40877\ttest-mlogloss:2.42972\n",
      "[76]\ttrain-mlogloss:2.40811\ttest-mlogloss:2.42929\n",
      "[77]\ttrain-mlogloss:2.40746\ttest-mlogloss:2.42887\n",
      "[78]\ttrain-mlogloss:2.40682\ttest-mlogloss:2.42846\n",
      "[79]\ttrain-mlogloss:2.40618\ttest-mlogloss:2.42806\n",
      "[80]\ttrain-mlogloss:2.40555\ttest-mlogloss:2.42765\n",
      "[81]\ttrain-mlogloss:2.40492\ttest-mlogloss:2.42724\n",
      "[82]\ttrain-mlogloss:2.4043\ttest-mlogloss:2.42686\n",
      "[83]\ttrain-mlogloss:2.40368\ttest-mlogloss:2.42646\n",
      "[84]\ttrain-mlogloss:2.40307\ttest-mlogloss:2.42608\n",
      "[85]\ttrain-mlogloss:2.40247\ttest-mlogloss:2.4257\n",
      "[86]\ttrain-mlogloss:2.40188\ttest-mlogloss:2.42532\n",
      "[87]\ttrain-mlogloss:2.40129\ttest-mlogloss:2.42496\n",
      "[88]\ttrain-mlogloss:2.4007\ttest-mlogloss:2.42459\n",
      "[89]\ttrain-mlogloss:2.40012\ttest-mlogloss:2.42423\n",
      "[90]\ttrain-mlogloss:2.39955\ttest-mlogloss:2.42387\n",
      "[91]\ttrain-mlogloss:2.39898\ttest-mlogloss:2.42352\n",
      "[92]\ttrain-mlogloss:2.39842\ttest-mlogloss:2.42318\n",
      "[93]\ttrain-mlogloss:2.39786\ttest-mlogloss:2.42285\n",
      "[94]\ttrain-mlogloss:2.3973\ttest-mlogloss:2.42251\n",
      "[95]\ttrain-mlogloss:2.39676\ttest-mlogloss:2.42218\n",
      "[96]\ttrain-mlogloss:2.39622\ttest-mlogloss:2.42185\n",
      "[97]\ttrain-mlogloss:2.39568\ttest-mlogloss:2.42153\n",
      "[98]\ttrain-mlogloss:2.39514\ttest-mlogloss:2.42122\n",
      "[99]\ttrain-mlogloss:2.39461\ttest-mlogloss:2.4209\n",
      "[100]\ttrain-mlogloss:2.39409\ttest-mlogloss:2.42059\n",
      "[101]\ttrain-mlogloss:2.39357\ttest-mlogloss:2.42029\n",
      "[102]\ttrain-mlogloss:2.39306\ttest-mlogloss:2.41998\n",
      "[103]\ttrain-mlogloss:2.39255\ttest-mlogloss:2.41967\n",
      "[104]\ttrain-mlogloss:2.39205\ttest-mlogloss:2.41938\n",
      "[105]\ttrain-mlogloss:2.39155\ttest-mlogloss:2.41909\n",
      "[106]\ttrain-mlogloss:2.39106\ttest-mlogloss:2.4188\n",
      "[107]\ttrain-mlogloss:2.39057\ttest-mlogloss:2.41852\n",
      "[108]\ttrain-mlogloss:2.39008\ttest-mlogloss:2.41824\n",
      "[109]\ttrain-mlogloss:2.3896\ttest-mlogloss:2.41796\n",
      "[110]\ttrain-mlogloss:2.38912\ttest-mlogloss:2.41768\n",
      "[111]\ttrain-mlogloss:2.38865\ttest-mlogloss:2.41742\n",
      "[112]\ttrain-mlogloss:2.38818\ttest-mlogloss:2.41715\n",
      "[113]\ttrain-mlogloss:2.38772\ttest-mlogloss:2.41689\n",
      "[114]\ttrain-mlogloss:2.38726\ttest-mlogloss:2.41663\n",
      "[115]\ttrain-mlogloss:2.3868\ttest-mlogloss:2.41637\n",
      "[116]\ttrain-mlogloss:2.38635\ttest-mlogloss:2.41612\n",
      "[117]\ttrain-mlogloss:2.3859\ttest-mlogloss:2.41586\n",
      "[118]\ttrain-mlogloss:2.38545\ttest-mlogloss:2.41562\n",
      "[119]\ttrain-mlogloss:2.38502\ttest-mlogloss:2.41538\n",
      "[120]\ttrain-mlogloss:2.38458\ttest-mlogloss:2.41513\n",
      "[121]\ttrain-mlogloss:2.38415\ttest-mlogloss:2.41489\n",
      "[122]\ttrain-mlogloss:2.38372\ttest-mlogloss:2.41466\n",
      "[123]\ttrain-mlogloss:2.38329\ttest-mlogloss:2.41443\n",
      "[124]\ttrain-mlogloss:2.38287\ttest-mlogloss:2.41421\n",
      "[125]\ttrain-mlogloss:2.38245\ttest-mlogloss:2.41398\n",
      "[126]\ttrain-mlogloss:2.38204\ttest-mlogloss:2.41376\n",
      "[127]\ttrain-mlogloss:2.38163\ttest-mlogloss:2.41354\n",
      "[128]\ttrain-mlogloss:2.38123\ttest-mlogloss:2.41332\n",
      "[129]\ttrain-mlogloss:2.38082\ttest-mlogloss:2.41311\n",
      "[130]\ttrain-mlogloss:2.38042\ttest-mlogloss:2.4129\n",
      "[131]\ttrain-mlogloss:2.38002\ttest-mlogloss:2.4127\n",
      "[132]\ttrain-mlogloss:2.37963\ttest-mlogloss:2.41249\n",
      "[133]\ttrain-mlogloss:2.37924\ttest-mlogloss:2.41229\n",
      "[134]\ttrain-mlogloss:2.37886\ttest-mlogloss:2.41208\n",
      "[135]\ttrain-mlogloss:2.37847\ttest-mlogloss:2.41188\n",
      "[136]\ttrain-mlogloss:2.3781\ttest-mlogloss:2.41168\n",
      "[137]\ttrain-mlogloss:2.37772\ttest-mlogloss:2.41149\n",
      "[138]\ttrain-mlogloss:2.37735\ttest-mlogloss:2.4113\n",
      "[139]\ttrain-mlogloss:2.37698\ttest-mlogloss:2.41111\n",
      "[140]\ttrain-mlogloss:2.37661\ttest-mlogloss:2.41093\n",
      "[141]\ttrain-mlogloss:2.37624\ttest-mlogloss:2.41075\n",
      "[142]\ttrain-mlogloss:2.37588\ttest-mlogloss:2.41057\n",
      "[143]\ttrain-mlogloss:2.37553\ttest-mlogloss:2.41039\n",
      "[144]\ttrain-mlogloss:2.37517\ttest-mlogloss:2.41023\n",
      "[145]\ttrain-mlogloss:2.37482\ttest-mlogloss:2.41005\n",
      "[146]\ttrain-mlogloss:2.37447\ttest-mlogloss:2.40988\n",
      "[147]\ttrain-mlogloss:2.37413\ttest-mlogloss:2.40971\n",
      "[148]\ttrain-mlogloss:2.37379\ttest-mlogloss:2.40954\n",
      "[149]\ttrain-mlogloss:2.37345\ttest-mlogloss:2.40938\n",
      "[150]\ttrain-mlogloss:2.37311\ttest-mlogloss:2.40921\n",
      "[151]\ttrain-mlogloss:2.37278\ttest-mlogloss:2.40906\n",
      "[152]\ttrain-mlogloss:2.37244\ttest-mlogloss:2.4089\n",
      "[153]\ttrain-mlogloss:2.37212\ttest-mlogloss:2.40874\n",
      "[154]\ttrain-mlogloss:2.37179\ttest-mlogloss:2.4086\n",
      "[155]\ttrain-mlogloss:2.37147\ttest-mlogloss:2.40845\n",
      "[156]\ttrain-mlogloss:2.37115\ttest-mlogloss:2.40831\n",
      "[157]\ttrain-mlogloss:2.37083\ttest-mlogloss:2.40816\n",
      "[158]\ttrain-mlogloss:2.37051\ttest-mlogloss:2.40802\n",
      "[159]\ttrain-mlogloss:2.3702\ttest-mlogloss:2.40788\n",
      "[160]\ttrain-mlogloss:2.36989\ttest-mlogloss:2.40774\n",
      "[161]\ttrain-mlogloss:2.36958\ttest-mlogloss:2.4076\n",
      "[162]\ttrain-mlogloss:2.36928\ttest-mlogloss:2.40746\n",
      "[163]\ttrain-mlogloss:2.36897\ttest-mlogloss:2.40733\n",
      "[164]\ttrain-mlogloss:2.36867\ttest-mlogloss:2.4072\n",
      "[165]\ttrain-mlogloss:2.36837\ttest-mlogloss:2.40707\n",
      "[166]\ttrain-mlogloss:2.36808\ttest-mlogloss:2.40694\n",
      "[167]\ttrain-mlogloss:2.36779\ttest-mlogloss:2.40681\n",
      "[168]\ttrain-mlogloss:2.3675\ttest-mlogloss:2.40668\n",
      "[169]\ttrain-mlogloss:2.36721\ttest-mlogloss:2.40655\n",
      "[170]\ttrain-mlogloss:2.36693\ttest-mlogloss:2.40643\n",
      "[171]\ttrain-mlogloss:2.36664\ttest-mlogloss:2.40631\n",
      "[172]\ttrain-mlogloss:2.36637\ttest-mlogloss:2.40618\n",
      "[173]\ttrain-mlogloss:2.36608\ttest-mlogloss:2.40607\n",
      "[174]\ttrain-mlogloss:2.36581\ttest-mlogloss:2.40595\n",
      "[175]\ttrain-mlogloss:2.36553\ttest-mlogloss:2.40584\n",
      "[176]\ttrain-mlogloss:2.36526\ttest-mlogloss:2.40572\n",
      "[177]\ttrain-mlogloss:2.36499\ttest-mlogloss:2.40561\n",
      "[178]\ttrain-mlogloss:2.36472\ttest-mlogloss:2.4055\n",
      "[179]\ttrain-mlogloss:2.36446\ttest-mlogloss:2.40539\n",
      "[180]\ttrain-mlogloss:2.3642\ttest-mlogloss:2.40529\n",
      "[181]\ttrain-mlogloss:2.36393\ttest-mlogloss:2.40519\n",
      "[182]\ttrain-mlogloss:2.36368\ttest-mlogloss:2.40508\n",
      "[183]\ttrain-mlogloss:2.36343\ttest-mlogloss:2.40497\n",
      "[184]\ttrain-mlogloss:2.36317\ttest-mlogloss:2.40487\n",
      "[185]\ttrain-mlogloss:2.36292\ttest-mlogloss:2.40477\n",
      "[186]\ttrain-mlogloss:2.36267\ttest-mlogloss:2.40468\n",
      "[187]\ttrain-mlogloss:2.36242\ttest-mlogloss:2.40458\n",
      "[188]\ttrain-mlogloss:2.36217\ttest-mlogloss:2.40449\n",
      "[189]\ttrain-mlogloss:2.36192\ttest-mlogloss:2.4044\n",
      "[190]\ttrain-mlogloss:2.36168\ttest-mlogloss:2.40431\n",
      "[191]\ttrain-mlogloss:2.36143\ttest-mlogloss:2.40422\n",
      "[192]\ttrain-mlogloss:2.36119\ttest-mlogloss:2.40414\n",
      "[193]\ttrain-mlogloss:2.36095\ttest-mlogloss:2.40406\n",
      "[194]\ttrain-mlogloss:2.36071\ttest-mlogloss:2.40397\n",
      "[195]\ttrain-mlogloss:2.36048\ttest-mlogloss:2.40388\n",
      "[196]\ttrain-mlogloss:2.36024\ttest-mlogloss:2.40379\n",
      "[197]\ttrain-mlogloss:2.36002\ttest-mlogloss:2.40371\n",
      "[198]\ttrain-mlogloss:2.35979\ttest-mlogloss:2.40363\n",
      "[199]\ttrain-mlogloss:2.35956\ttest-mlogloss:2.40355\n",
      "logloss val 2.4035553134214296\n"
     ]
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.2,\n",
    "                                                    stratify=y_train_total_without)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':400,\n",
    "         'eta':0.01,\n",
    "         'silent':0,\n",
    "         'objective':'multi:softprob',\n",
    "         'nthread':2,\n",
    "         'num_class':12,\n",
    "         'eval_metric':'mlogloss',\n",
    "        'lambda':5,\n",
    "        'lambda_bias':0,\n",
    "        'alpha':2}\n",
    "num_round = 200\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# putting together and save into final file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final score based on the percentage of testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with score:1.9392115926279074\n",
      "without score:2.3931157227003554\n",
      "final validation score:2.2505748160093315\n"
     ]
    }
   ],
   "source": [
    "#val_score_final = val_loss_ave_without*76877/112071+val_loss_ave_with*35194/112071\n",
    "val_score_final = (val_loss_ave_without*X_test_total_without.shape[0]+\n",
    "                   val_loss_ave_with*X_test_total_with.shape[0])/(X_test_total_without.shape[0]+X_test_total_with.shape[0])\n",
    "print('with score:{}'.format(val_loss_ave_with))\n",
    "print('without score:{}'.format(val_loss_ave_without))\n",
    "print('final validation score:{}'.format(val_score_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pd.concat((pred_with,pred_without))\n",
    "pred.to_csv('doublemodel_v6.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
