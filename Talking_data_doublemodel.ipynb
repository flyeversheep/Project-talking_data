{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from scipy.sparse import csr_matrix,hstack,vstack\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold,KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('input/events.csv',index_col='event_id')\n",
    "label = pd.read_csv('input/label_categories.csv')\n",
    "app_event = pd.read_csv('input/app_events.csv')\n",
    "app_label = pd.read_csv('input/app_labels.csv')\n",
    "device = pd.read_csv('input/phone_brand_device_model.csv')\n",
    "device = device.drop_duplicates('device_id').set_index('device_id')\n",
    "gender_age_train = pd.read_csv('input/gender_age_train.csv',index_col = 'device_id')\n",
    "gender_age_test = pd.read_csv('input/gender_age_test.csv',index_col = 'device_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convinience of creating sparse matrix, we create another integer index for the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_age_train\n",
      "                      gender  age   group\n",
      "device_id                               \n",
      "-8076087639492063270      M   35  M32-38\n",
      "\n",
      "gender_age_test\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [1002079943728939269]\n",
      "\n",
      "device\n",
      "                      phone_brand device_model\n",
      "device_id                                    \n",
      "-8890648629457979026          小米           红米\n",
      "\n",
      "events\n",
      "                   device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
      "\n",
      "label\n",
      "    label_id category\n",
      "0         1      NaN\n",
      "\n",
      "app_event\n",
      "    event_id               app_id  is_installed  is_active\n",
      "0         2  5927333115845830913             1          1\n",
      "\n",
      "app_label\n",
      "                 app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print('gender_age_train\\n',gender_age_train.head(1))\n",
    "print('\\ngender_age_test\\n',gender_age_test.head(1))\n",
    "print('\\ndevice\\n',device.head(1))\n",
    "print('\\nevents\\n',events.head(1))\n",
    "print('\\nlabel\\n',label.head(1))\n",
    "print('\\napp_event\\n',app_event.head(1))\n",
    "print('\\napp_label\\n',app_label.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of two set of devices: with events and without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set without events:    51336\n",
      "Size of training set with events:       23309\n",
      "Total size of training set:             74645\n",
      "Size of testing set without events:     76877\n",
      "Size of training set with events:       35194\n",
      "Total size of training set:             112071\n"
     ]
    }
   ],
   "source": [
    "gender_age_train_with = gender_age_train.loc[gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_train_without = gender_age_train.loc[~gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_with = gender_age_test.loc[gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "gender_age_test_without = gender_age_test.loc[~gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set without events:',gender_age_train_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_train_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_train.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of testing set without events:',gender_age_test_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_test_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_age_train_with['int_index'] = np.arange(gender_age_train_with.shape[0])\n",
    "gender_age_test_with['int_index'] = np.arange(gender_age_test_with.shape[0])\n",
    "gender_age_train_without['int_index'] = np.arange(gender_age_train_without.shape[0])\n",
    "gender_age_test_without['int_index'] = np.arange(gender_age_test_without.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering I: phone brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the phone brand, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(device.phone_brand)\n",
    "device['brand'] = encoder.transform(device.phone_brand)\n",
    "gender_age_train_with['brand'] = device['brand']\n",
    "gender_age_test_with['brand'] = device['brand']\n",
    "gender_age_train_without['brand'] = device['brand']\n",
    "gender_age_test_without['brand'] = device['brand']\n",
    "brandnumber = len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sparse matrix with each row representing one device and each column representing one brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 131)\n",
      "X_test_brand_with shape: (35194, 131)\n",
      "X_train_brand_without shape: (51336, 131)\n",
      "X_test_brand_without shape: (76877, 131)\n"
     ]
    }
   ],
   "source": [
    "X_train_brand_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                            (gender_age_train_with.int_index,gender_age_train_with.brand)),\n",
    "                               shape = (gender_age_train_with.shape[0],brandnumber))\n",
    "X_test_brand_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                           (gender_age_test_with.int_index,gender_age_test_with.brand)),\n",
    "                              shape = (gender_age_test_with.shape[0],brandnumber))\n",
    "print('X_train_brand_with shape:',X_train_brand_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_brand_with.shape)\n",
    "X_train_brand_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                            (gender_age_train_without.int_index,gender_age_train_without.brand)),\n",
    "                                  shape = (gender_age_train_without.shape[0],brandnumber))\n",
    "X_test_brand_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                           (gender_age_test_without.int_index,gender_age_test_without.brand)),\n",
    "                                 shape = (gender_age_test_without.shape[0],brandnumber))\n",
    "print('X_train_brand_without shape:',X_train_brand_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_brand_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering II: phone device model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brand_model = device.phone_brand.str.cat(device.device_model)\n",
    "encoder3 = LabelEncoder()\n",
    "encoder3.fit(brand_model)\n",
    "device['model'] = encoder3.transform(brand_model)\n",
    "gender_age_train_with['model'] = device['model']\n",
    "gender_age_test_with['model'] = device['model']\n",
    "gender_age_train_without['model'] = device['model']\n",
    "gender_age_test_without['model'] = device['model']\n",
    "modelnumber = len(encoder3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 1667)\n",
      "X_test_brand_with shape: (35194, 1667)\n",
      "X_train_brand_without shape: (51336, 1667)\n",
      "X_test_brand_without shape: (76877, 1667)\n"
     ]
    }
   ],
   "source": [
    "X_train_model_with = csr_matrix((np.ones(gender_age_train_with.shape[0]),\n",
    "                                 (gender_age_train_with.int_index,gender_age_train_with.model)),\n",
    "                               shape = (gender_age_train_with.shape[0],modelnumber))\n",
    "X_test_model_with = csr_matrix((np.ones(gender_age_test_with.shape[0]),\n",
    "                                (gender_age_test_with.int_index,gender_age_test_with.model)),\n",
    "                              shape = (gender_age_test_with.shape[0],modelnumber))\n",
    "X_train_model_without = csr_matrix((np.ones(gender_age_train_without.shape[0]),\n",
    "                                    (gender_age_train_without.int_index,gender_age_train_without.model)),\n",
    "                                  shape = (gender_age_train_without.shape[0],modelnumber))\n",
    "X_test_model_without = csr_matrix((np.ones(gender_age_test_without.shape[0]),\n",
    "                                   (gender_age_test_without.int_index,gender_age_test_without.model)),\n",
    "                                 shape = (gender_age_test_without.shape[0],modelnumber))\n",
    "\n",
    "print('X_train_brand_with shape:',X_train_model_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_model_with.shape)\n",
    "print('X_train_brand_without shape:',X_train_model_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_model_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering III: Installed app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the app_id and store it into app column, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = LabelEncoder()\n",
    "encoder2.fit(app_event.app_id)\n",
    "app_event['app'] = encoder2.transform(app_event.app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 19234, 19235, 19236])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(app_event.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   event_id               app_id  is_installed  is_active    app\n",
      "0         2  5927333115845830913             1          1  15408\n",
      "                  device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24\n"
     ]
    }
   ],
   "source": [
    "print(app_event.head(1))\n",
    "print(events.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  event_id    app  is_installed\n",
      "0 -6401643145415154744         2  15408             1\n",
      "1 -6401643145415154744         2   3384             1\n",
      "2 -6401643145415154744         2   7620             1\n",
      "3 -6401643145415154744         2   8902             1\n",
      "4 -6401643145415154744         2  18686             1\n"
     ]
    }
   ],
   "source": [
    "installed_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_installed']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "print(installed_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_app_train:\n",
      "                           size  int_index\n",
      "device_id            app                  \n",
      "-9222956879900151005 548     18       5145\n",
      "                     1096    18       5145\n",
      "                     1248    26       5145\n",
      "                     1545    12       5145\n",
      "                     1664    18       5145\n"
     ]
    }
   ],
   "source": [
    "installed_app_grouped = installed_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_app_train_with = pd.merge(installed_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_index=True)\n",
    "installed_app_test_with = pd.merge(installed_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_index=True)\n",
    "print('installed_app_train:')\n",
    "print(installed_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id   app  size  int_index\n",
      "0 -9222956879900151005   548    18       5145\n",
      "1 -9222956879900151005  1096    18       5145\n",
      "2 -9222956879900151005  1248    26       5145\n",
      "3 -9222956879900151005  1545    12       5145\n",
      "4 -9222956879900151005  1664    18       5145\n",
      "             device_id    app  size  int_index\n",
      "0 -9222661944218806987   1867     3       2851\n",
      "1 -9222661944218806987   7519     8       2851\n",
      "2 -9222661944218806987   7843     1       2851\n",
      "3 -9222661944218806987   8704     4       2851\n",
      "4 -9222661944218806987  10000     1       2851\n"
     ]
    }
   ],
   "source": [
    "installed_app_train_with = installed_app_train_with.reset_index()\n",
    "installed_app_test_with = installed_app_test_with.reset_index()\n",
    "installed_app_train_with = installed_app_train_with.dropna(subset=['int_index'])\n",
    "installed_app_test_with = installed_app_test_with.dropna(subset=['int_index'])\n",
    "print(installed_app_train_with.head())\n",
    "print(installed_app_test_with.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of unique app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35194\n",
      "915632\n"
     ]
    }
   ],
   "source": [
    "print(gender_age_test_with.shape[0])\n",
    "print(installed_app_train_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique apps:\n",
      "19237\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique apps:')\n",
    "print(np.size(installed_app.app.unique()))\n",
    "appnumber = np.size(installed_app.app.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ..., 19234 19235 19236]\n",
      "1387337\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(installed_app_train_with.app.unique()))\n",
    "print(installed_app_test_with.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed shape: (23309, 19237)\n",
      "X_test_installed shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "X_train_installed_with = csr_matrix((np.ones(installed_app_train_with.shape[0]),\n",
    "                                (installed_app_train_with.int_index,installed_app_train_with.app)), \n",
    "                               shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_installed_with = csr_matrix((np.ones(installed_app_test_with.shape[0]),\n",
    "                               (installed_app_test_with.int_index,installed_app_test_with.app)),\n",
    "                               shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_installed shape:',X_train_installed_with.shape)\n",
    "print('X_test_installed shape:',X_test_installed_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 35191, 35192, 35193])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(installed_app_test_with.int_index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering IV: app label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                app_id  event_id\n",
      "0  5927333115845830913         2\n",
      "                app_id  label_id\n",
      "0  7324884708820027918       251\n"
     ]
    }
   ],
   "source": [
    "print(app_event[['app_id','event_id']].head(1))\n",
    "print(app_label[['app_id','label_id']].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_label_new:\n",
      "                app_id  label_id    app  label\n",
      "0  7324884708820027918       251  17355    207\n",
      "1 -4494216993218550286       251   4618    207\n",
      "2  6058196446775239644       406  15548    247\n",
      "3  6058196446775239644       407  15548    248\n",
      "4  8694625920731541625       406  18689    247\n"
     ]
    }
   ],
   "source": [
    "app_label_new = app_label.loc[app_label.app_id.isin(app_event.app_id.unique())].copy()\n",
    "app_label_new['app'] = encoder2.transform(app_label_new.app_id)\n",
    "encoder4 = LabelEncoder().fit(app_label_new.label_id)\n",
    "app_label_new['label'] = encoder4.transform(app_label_new.label_id)\n",
    "labelnumber = len(encoder4.classes_)\n",
    "print('app_label_new:')\n",
    "print(app_label_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919886\n",
      "129892268\n",
      "installed_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548     18\n",
      "                     1096    18\n",
      "                     1248    26\n",
      "                     1545    12\n",
      "                     1664    18\n",
      "installed_label_grouped:\n",
      "             device_id  label  size\n",
      "0 -9222956879900151005    117     1\n",
      "1 -9222956879900151005    120     1\n",
      "2 -9222956879900151005    126     1\n",
      "3 -9222956879900151005    138     2\n",
      "4 -9222956879900151005    147     2\n"
     ]
    }
   ],
   "source": [
    "print(app_label.size)\n",
    "print(installed_app.size)\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head())\n",
    "installed_label_grouped = (installed_app_grouped.reset_index()[['device_id','app']]\n",
    "                          .merge(app_label_new[['app','label']])\n",
    "                          .groupby(['device_id','label']))['app'].agg(['size']).reset_index()\n",
    "                          \n",
    "print('installed_label_grouped:')\n",
    "print(installed_label_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_app_train_with = pd.merge(installed_label_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'right',right_index=True,left_on='device_id')\n",
    "label_app_test_with = pd.merge(installed_label_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'right',right_index=True,left_on ='device_id' )\n",
    "label_app_train_with = label_app_train_with.dropna(subset= ['int_index','label'])\n",
    "label_app_test_with = label_app_test_with.dropna(subset= ['int_index','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed_with shape: (23309, 492)\n",
      "X_test_installed_with shape: (35194, 492)\n"
     ]
    }
   ],
   "source": [
    "#binary\n",
    "X_train_label_with = csr_matrix((np.ones(label_app_train_with.shape[0]),\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((np.ones(label_app_test_with.shape[0]),(label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))\n",
    "#count\n",
    "'''X_train_label_with = csr_matrix((label_app_train_with['size'],\n",
    "                                 (label_app_train_with.int_index,label_app_train_with.label)),\n",
    "                              shape = (gender_age_train_with.shape[0],labelnumber))\n",
    "X_test_label_with = csr_matrix((label_app_test_with['size'],\n",
    "                                (label_app_test_with.int_index,label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],labelnumber))'''\n",
    "print('X_train_installed_with shape:',X_train_label_with.shape)\n",
    "print('X_test_installed_with shape:',X_test_label_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering V: active app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_active']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "active_app = active_app.loc[active_app.is_active==1]\n",
    "print(active_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_grouped = active_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "print('active_app_grouped:')\n",
    "print(active_app_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_train_with = pd.merge(active_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'left',right_index=True,left_index=True)\n",
    "active_app_test_with = pd.merge(active_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'left',right_index=True,left_index=True)\n",
    "print('active_app_train_with:')\n",
    "print(active_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_app_train_with = active_app_train_with.reset_index()\n",
    "active_app_test_with = active_app_test_with.reset_index()\n",
    "active_app_train_with = active_app_train_with.dropna(subset=['int_index'])\n",
    "active_app_test_with = active_app_test_with.dropna(subset=['int_index'])\n",
    "print(active_app_train_with.head())\n",
    "print(active_app_test_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# binary active map\n",
    "#X_train_active_with = csr_matrix((np.ones(active_app_train_with.shape[0]),\n",
    "#                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "#                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "#X_test_active = csr_matrix((np.ones(active_app_test_with.shape[0]),\n",
    "#                            (active_app_test.int_index,active_app_test_with.app)),\n",
    "#                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "# count the number of active app\n",
    "X_train_active_with = csr_matrix((active_app_train_with['size'],\n",
    "                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "X_test_active_with = csr_matrix((active_app_test_with['size'],\n",
    "                            (active_app_test_with.int_index,active_app_test_with.app)),\n",
    "                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "print('X_train_active shape:',X_train_active_with.shape)\n",
    "print('X_test_active shape:',X_test_active_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_active_with = scaler.fit_transform(X_train_active_with)\n",
    "X_test_active_with = scaler.transform(X_test_active_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering VI: active time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events_time = events[['device_id','timestamp']].copy()\n",
    "events_time['time']  = events_time['timestamp'].str[11:13].astype(int)\n",
    "events_time.drop(['timestamp'],axis=1,inplace=True)\n",
    "events_time = events_time.groupby(['device_id','time'])['time'].agg({'times':'count'}).reset_index()\n",
    "print(events_time.head())\n",
    "timenumber= events_time.time.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_train_with = pd.merge(events_time,gender_age_train_with[['int_index']],\n",
    "                               right_index=True,left_on='device_id')\n",
    "time_test_with = pd.merge(events_time,gender_age_test_with[['int_index']],\n",
    "                               right_index=True,left_on ='device_id' )\n",
    "#binary\n",
    "X_train_time_with = csr_matrix((np.ones(time_train_with.shape[0]),\n",
    "                            (time_train_with.int_index,time_train_with.time)), \n",
    "                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "X_test_time_with = csr_matrix((np.ones(time_test_with.shape[0]),\n",
    "                            (time_test_with.int_index,time_test_with.time)),\n",
    "                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "\n",
    "#number\n",
    "#X_train_time_with = csr_matrix((time_train_with['times'],\n",
    "#                            (time_train_with.int_index,time_train_with.time)), \n",
    "#                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "#X_test_time_with = csr_matrix((time_test_with['times'],\n",
    "#                            (time_test_with.int_index,time_test_with.time)),\n",
    "#                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "print('X_train_time_with shape:',X_train_time_with.shape)\n",
    "print('X_test_time_with shape:',X_test_time_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the time period count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_time_with = scaler.fit_transform(X_train_time_with)\n",
    "X_test_time_with = scaler.transform(X_test_time_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature join and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(74645, 1798)\n",
      "Testing shape:\n",
      "(76877, 1798)\n",
      "y shape:\n",
      "(74645, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_without = hstack((X_train_brand_without,X_train_model_without),format='csr')\n",
    "temp_train = hstack((X_train_brand_with,X_train_model_with),format='csr')\n",
    "X_test_total_without = hstack((X_test_brand_without,X_test_model_without),format='csr')\n",
    "\n",
    "X_train_total_without= vstack((X_train_total_without,temp_train),format = 'csr')\n",
    "gender_age_train_without_temp = pd.concat((gender_age_train_without,gender_age_train_with))\n",
    "\n",
    "print('Training shape:')\n",
    "print(X_train_total_without.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_without.shape)\n",
    "print('y shape:')\n",
    "print(gender_age_train_without_temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device with events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(23309, 21527)\n",
      "Testing shape:\n",
      "(35194, 21527)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_with = hstack((X_train_brand_with,X_train_model_with,\n",
    "                             #X_train_time_with,\n",
    "                             X_train_installed_with,X_train_label_with),format='csr')\n",
    "X_test_total_with = hstack((X_test_brand_with,X_test_model_with,\n",
    "                            #X_test_time_with,\n",
    "                           X_test_installed_with,X_test_label_with),format='csr')\n",
    "print('Training shape:')\n",
    "print(X_train_total_with.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentile selction\n",
    "#selector = SelectPercentile(f_classif, percentile=80)\n",
    "#selector.fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#X_val.shape\n",
    "\n",
    "# Selection using chi-square\n",
    "#selector = SelectKBest(chi2, k=15155).fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#print('Training shape:')\n",
    "#print(X_train_total.shape)\n",
    "#print('Testing shape:')\n",
    "#print(X_test_total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear the memory before we do the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del events,label,app_event,app_label,app_label_new,device,brand_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del gender_age_test,gender_age_train,installed_app,installed_app_grouped#,active_app_grouped,active_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Start training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetencoder = LabelEncoder().fit(gender_age_train_with.group)\n",
    "nclasses = len(targetencoder.classes_)\n",
    "y_train_total_with = targetencoder.transform(gender_age_train_with.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset I: device with events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator \n",
    "    #(https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/keras/engine/training.py:1460: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29s - loss: 2.4013 - acc: 0.1405 - val_loss: 2.3524 - val_acc: 0.1631\n",
      "Epoch 2/15\n",
      "14s - loss: 2.2976 - acc: 0.1865 - val_loss: 2.2873 - val_acc: 0.1871\n",
      "Epoch 3/15\n",
      "9s - loss: 2.2027 - acc: 0.2224 - val_loss: 2.2244 - val_acc: 0.2200\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1254 - acc: 0.2507 - val_loss: 2.1772 - val_acc: 0.2333\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0769 - acc: 0.2636 - val_loss: 2.1447 - val_acc: 0.2517\n",
      "Epoch 6/15\n",
      "9s - loss: 2.0365 - acc: 0.2845 - val_loss: 2.1370 - val_acc: 0.2543\n",
      "Epoch 7/15\n",
      "10s - loss: 2.0044 - acc: 0.2930 - val_loss: 2.1237 - val_acc: 0.2564\n",
      "Epoch 8/15\n",
      "9s - loss: 1.9801 - acc: 0.3038 - val_loss: 2.1212 - val_acc: 0.2560\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9568 - acc: 0.3098 - val_loss: 2.1155 - val_acc: 0.2693\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9374 - acc: 0.3160 - val_loss: 2.1140 - val_acc: 0.2654\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9123 - acc: 0.3239 - val_loss: 2.1170 - val_acc: 0.2671\n",
      "Epoch 12/15\n",
      "9s - loss: 1.8992 - acc: 0.3316 - val_loss: 2.1081 - val_acc: 0.2671\n",
      "Epoch 13/15\n",
      "9s - loss: 1.8755 - acc: 0.3409 - val_loss: 2.1108 - val_acc: 0.2714\n",
      "Epoch 14/15\n",
      "9s - loss: 1.8603 - acc: 0.3419 - val_loss: 2.1068 - val_acc: 0.2680\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8458 - acc: 0.3492 - val_loss: 2.1192 - val_acc: 0.2710\n",
      "logloss val 2.119242092567394\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "8s - loss: 2.4069 - acc: 0.1431 - val_loss: 2.3373 - val_acc: 0.1740\n",
      "Epoch 2/15\n",
      "9s - loss: 2.2878 - acc: 0.1904 - val_loss: 2.2285 - val_acc: 0.2122\n",
      "Epoch 3/15\n",
      "9s - loss: 2.1897 - acc: 0.2223 - val_loss: 2.1477 - val_acc: 0.2473\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1194 - acc: 0.2566 - val_loss: 2.0959 - val_acc: 0.2593\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0777 - acc: 0.2683 - val_loss: 2.0618 - val_acc: 0.2739\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0394 - acc: 0.2820 - val_loss: 2.0482 - val_acc: 0.2842\n",
      "Epoch 7/15\n",
      "10s - loss: 2.0113 - acc: 0.2890 - val_loss: 2.0328 - val_acc: 0.2898\n",
      "Epoch 8/15\n",
      "9s - loss: 1.9825 - acc: 0.3050 - val_loss: 2.0175 - val_acc: 0.2949\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9660 - acc: 0.3066 - val_loss: 2.0078 - val_acc: 0.2953\n",
      "Epoch 10/15\n",
      "9s - loss: 1.9412 - acc: 0.3185 - val_loss: 2.0031 - val_acc: 0.3018\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9238 - acc: 0.3198 - val_loss: 2.0087 - val_acc: 0.2889\n",
      "Epoch 12/15\n",
      "9s - loss: 1.9014 - acc: 0.3285 - val_loss: 1.9933 - val_acc: 0.3065\n",
      "Epoch 13/15\n",
      "9s - loss: 1.8881 - acc: 0.3300 - val_loss: 1.9980 - val_acc: 0.2992\n",
      "Epoch 14/15\n",
      "9s - loss: 1.8718 - acc: 0.3391 - val_loss: 1.9842 - val_acc: 0.3073\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8569 - acc: 0.3444 - val_loss: 1.9904 - val_acc: 0.3065\n",
      "logloss val 1.9904005164196703\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "13s - loss: 2.4052 - acc: 0.1400 - val_loss: 2.3465 - val_acc: 0.1569\n",
      "Epoch 2/15\n",
      "13s - loss: 2.3105 - acc: 0.1825 - val_loss: 2.2573 - val_acc: 0.2070\n",
      "Epoch 3/15\n",
      "213s - loss: 2.2173 - acc: 0.2151 - val_loss: 2.1884 - val_acc: 0.2327\n",
      "Epoch 4/15\n",
      "316s - loss: 2.1440 - acc: 0.2432 - val_loss: 2.1229 - val_acc: 0.2593\n",
      "Epoch 5/15\n",
      "331s - loss: 2.0867 - acc: 0.2643 - val_loss: 2.1058 - val_acc: 0.2658\n",
      "Epoch 6/15\n",
      "299s - loss: 2.0452 - acc: 0.2801 - val_loss: 2.0762 - val_acc: 0.2718\n",
      "Epoch 7/15\n",
      "298s - loss: 2.0122 - acc: 0.2894 - val_loss: 2.0590 - val_acc: 0.2816\n",
      "Epoch 8/15\n",
      "284s - loss: 1.9912 - acc: 0.2970 - val_loss: 2.0513 - val_acc: 0.2820\n",
      "Epoch 9/15\n",
      "274s - loss: 1.9649 - acc: 0.3101 - val_loss: 2.0514 - val_acc: 0.2868\n",
      "Epoch 10/15\n",
      "291s - loss: 1.9482 - acc: 0.3122 - val_loss: 2.0393 - val_acc: 0.2868\n",
      "Epoch 11/15\n",
      "272s - loss: 1.9299 - acc: 0.3182 - val_loss: 2.0383 - val_acc: 0.2919\n",
      "Epoch 12/15\n",
      "280s - loss: 1.9050 - acc: 0.3276 - val_loss: 2.0346 - val_acc: 0.2898\n",
      "Epoch 13/15\n",
      "283s - loss: 1.8931 - acc: 0.3308 - val_loss: 2.0314 - val_acc: 0.2876\n",
      "Epoch 14/15\n",
      "208s - loss: 1.8706 - acc: 0.3383 - val_loss: 2.0402 - val_acc: 0.2898\n",
      "Epoch 15/15\n",
      "57s - loss: 1.8613 - acc: 0.3419 - val_loss: 2.0261 - val_acc: 0.2953\n",
      "logloss val 2.026081200907836\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "12s - loss: 2.4148 - acc: 0.1375 - val_loss: 2.3405 - val_acc: 0.1690\n",
      "Epoch 2/15\n",
      "13s - loss: 2.3207 - acc: 0.1771 - val_loss: 2.2309 - val_acc: 0.2277\n",
      "Epoch 3/15\n",
      "12s - loss: 2.2200 - acc: 0.2165 - val_loss: 2.1337 - val_acc: 0.2461\n",
      "Epoch 4/15\n",
      "15s - loss: 2.1488 - acc: 0.2387 - val_loss: 2.0716 - val_acc: 0.2762\n",
      "Epoch 5/15\n",
      "13s - loss: 2.0990 - acc: 0.2580 - val_loss: 2.0417 - val_acc: 0.2847\n",
      "Epoch 6/15\n",
      "12s - loss: 2.0507 - acc: 0.2747 - val_loss: 2.0133 - val_acc: 0.2907\n",
      "Epoch 7/15\n",
      "14s - loss: 2.0315 - acc: 0.2801 - val_loss: 2.0028 - val_acc: 0.2942\n",
      "Epoch 8/15\n",
      "12s - loss: 1.9988 - acc: 0.2960 - val_loss: 1.9944 - val_acc: 0.2929\n",
      "Epoch 9/15\n",
      "13s - loss: 1.9728 - acc: 0.3016 - val_loss: 1.9835 - val_acc: 0.2993\n",
      "Epoch 10/15\n",
      "12s - loss: 1.9589 - acc: 0.3102 - val_loss: 1.9823 - val_acc: 0.3096\n",
      "Epoch 11/15\n",
      "13s - loss: 1.9396 - acc: 0.3166 - val_loss: 1.9686 - val_acc: 0.3036\n",
      "Epoch 12/15\n",
      "13s - loss: 1.9157 - acc: 0.3197 - val_loss: 1.9644 - val_acc: 0.3143\n",
      "Epoch 13/15\n",
      "12s - loss: 1.9021 - acc: 0.3273 - val_loss: 1.9596 - val_acc: 0.3087\n",
      "Epoch 14/15\n",
      "12s - loss: 1.8805 - acc: 0.3357 - val_loss: 1.9671 - val_acc: 0.3126\n",
      "Epoch 15/15\n",
      "13s - loss: 1.8750 - acc: 0.3385 - val_loss: 1.9594 - val_acc: 0.3113\n",
      "logloss val 1.9593999812237306\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "13s - loss: 2.4043 - acc: 0.1436 - val_loss: 2.3213 - val_acc: 0.2003\n",
      "Epoch 2/15\n",
      "24s - loss: 2.3000 - acc: 0.1873 - val_loss: 2.1941 - val_acc: 0.2491\n",
      "Epoch 3/15\n",
      "35s - loss: 2.2088 - acc: 0.2163 - val_loss: 2.1019 - val_acc: 0.2792\n",
      "Epoch 4/15\n",
      "20s - loss: 2.1350 - acc: 0.2481 - val_loss: 2.0376 - val_acc: 0.2967\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0851 - acc: 0.2676 - val_loss: 2.0011 - val_acc: 0.3066\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0489 - acc: 0.2799 - val_loss: 1.9756 - val_acc: 0.3130\n",
      "Epoch 7/15\n",
      "15s - loss: 2.0153 - acc: 0.2899 - val_loss: 1.9604 - val_acc: 0.3148\n",
      "Epoch 8/15\n",
      "11s - loss: 1.9978 - acc: 0.2928 - val_loss: 1.9473 - val_acc: 0.3130\n",
      "Epoch 9/15\n",
      "10s - loss: 1.9727 - acc: 0.3039 - val_loss: 1.9356 - val_acc: 0.3135\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9500 - acc: 0.3133 - val_loss: 1.9352 - val_acc: 0.3212\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9331 - acc: 0.3197 - val_loss: 1.9264 - val_acc: 0.3195\n",
      "Epoch 12/15\n",
      "16s - loss: 1.9145 - acc: 0.3235 - val_loss: 1.9219 - val_acc: 0.3280\n",
      "Epoch 13/15\n",
      "14s - loss: 1.8926 - acc: 0.3302 - val_loss: 1.9235 - val_acc: 0.3199\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8753 - acc: 0.3399 - val_loss: 1.9159 - val_acc: 0.3289\n",
      "Epoch 15/15\n",
      "14s - loss: 1.8602 - acc: 0.3470 - val_loss: 1.9117 - val_acc: 0.3272\n",
      "logloss val 1.9117152538201667\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "12s - loss: 2.4161 - acc: 0.1329 - val_loss: 2.3449 - val_acc: 0.1703\n",
      "Epoch 2/15\n",
      "13s - loss: 2.3251 - acc: 0.1752 - val_loss: 2.2339 - val_acc: 0.2269\n",
      "Epoch 3/15\n",
      "12s - loss: 2.2260 - acc: 0.2146 - val_loss: 2.1245 - val_acc: 0.2634\n",
      "Epoch 4/15\n",
      "12s - loss: 2.1396 - acc: 0.2463 - val_loss: 2.0576 - val_acc: 0.2814\n",
      "Epoch 5/15\n",
      "12s - loss: 2.0834 - acc: 0.2666 - val_loss: 2.0185 - val_acc: 0.2857\n",
      "Epoch 6/15\n",
      "12s - loss: 2.0547 - acc: 0.2765 - val_loss: 1.9932 - val_acc: 0.2960\n",
      "Epoch 7/15\n",
      "12s - loss: 2.0213 - acc: 0.2898 - val_loss: 1.9731 - val_acc: 0.3050\n",
      "Epoch 8/15\n",
      "12s - loss: 1.9941 - acc: 0.2948 - val_loss: 1.9643 - val_acc: 0.3080\n",
      "Epoch 9/15\n",
      "12s - loss: 1.9692 - acc: 0.3041 - val_loss: 1.9547 - val_acc: 0.3110\n",
      "Epoch 10/15\n",
      "12s - loss: 1.9518 - acc: 0.3094 - val_loss: 1.9479 - val_acc: 0.3175\n",
      "Epoch 11/15\n",
      "12s - loss: 1.9309 - acc: 0.3198 - val_loss: 1.9421 - val_acc: 0.3170\n",
      "Epoch 12/15\n",
      "12s - loss: 1.9132 - acc: 0.3276 - val_loss: 1.9383 - val_acc: 0.3179\n",
      "Epoch 13/15\n",
      "12s - loss: 1.8928 - acc: 0.3334 - val_loss: 1.9373 - val_acc: 0.3192\n",
      "Epoch 14/15\n",
      "12s - loss: 1.8759 - acc: 0.3366 - val_loss: 1.9322 - val_acc: 0.3243\n",
      "Epoch 15/15\n",
      "12s - loss: 1.8654 - acc: 0.3415 - val_loss: 1.9298 - val_acc: 0.3213\n",
      "logloss val 1.929815956246362\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "9s - loss: 2.4086 - acc: 0.1394 - val_loss: 2.3228 - val_acc: 0.1889\n",
      "Epoch 2/15\n",
      "9s - loss: 2.3076 - acc: 0.1812 - val_loss: 2.1995 - val_acc: 0.2550\n",
      "Epoch 3/15\n",
      "9s - loss: 2.2230 - acc: 0.2152 - val_loss: 2.0941 - val_acc: 0.2847\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1458 - acc: 0.2442 - val_loss: 2.0172 - val_acc: 0.3010\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0960 - acc: 0.2629 - val_loss: 1.9791 - val_acc: 0.3040\n",
      "Epoch 6/15\n",
      "9s - loss: 2.0581 - acc: 0.2759 - val_loss: 1.9446 - val_acc: 0.3113\n",
      "Epoch 7/15\n",
      "9s - loss: 2.0308 - acc: 0.2833 - val_loss: 1.9141 - val_acc: 0.3263\n",
      "Epoch 8/15\n",
      "9s - loss: 2.0054 - acc: 0.2913 - val_loss: 1.9057 - val_acc: 0.3280\n",
      "Epoch 9/15\n",
      "24s - loss: 1.9804 - acc: 0.3028 - val_loss: 1.8864 - val_acc: 0.3349\n",
      "Epoch 10/15\n",
      "25s - loss: 1.9684 - acc: 0.3079 - val_loss: 1.8790 - val_acc: 0.3336\n",
      "Epoch 11/15\n",
      "25s - loss: 1.9490 - acc: 0.3129 - val_loss: 1.8741 - val_acc: 0.3396\n",
      "Epoch 12/15\n",
      "29s - loss: 1.9271 - acc: 0.3188 - val_loss: 1.8676 - val_acc: 0.3358\n",
      "Epoch 13/15\n",
      "41s - loss: 1.9124 - acc: 0.3225 - val_loss: 1.8636 - val_acc: 0.3379\n",
      "Epoch 14/15\n",
      "26s - loss: 1.8884 - acc: 0.3352 - val_loss: 1.8517 - val_acc: 0.3439\n",
      "Epoch 15/15\n",
      "30s - loss: 1.8789 - acc: 0.3365 - val_loss: 1.8532 - val_acc: 0.3448\n",
      "logloss val 1.8531961030202422\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "8s - loss: 2.4144 - acc: 0.1407 - val_loss: 2.3361 - val_acc: 0.1717\n",
      "Epoch 2/15\n",
      "8s - loss: 2.3200 - acc: 0.1791 - val_loss: 2.2080 - val_acc: 0.2327\n",
      "Epoch 3/15\n",
      "8s - loss: 2.2282 - acc: 0.2156 - val_loss: 2.0940 - val_acc: 0.2847\n",
      "Epoch 4/15\n",
      "8s - loss: 2.1529 - acc: 0.2431 - val_loss: 2.0163 - val_acc: 0.2963\n",
      "Epoch 5/15\n",
      "8s - loss: 2.1015 - acc: 0.2574 - val_loss: 1.9727 - val_acc: 0.3079\n",
      "Epoch 6/15\n",
      "13s - loss: 2.0599 - acc: 0.2783 - val_loss: 1.9418 - val_acc: 0.3122\n",
      "Epoch 7/15\n",
      "14s - loss: 2.0251 - acc: 0.2872 - val_loss: 1.9261 - val_acc: 0.3233\n",
      "Epoch 8/15\n",
      "10s - loss: 2.0150 - acc: 0.2912 - val_loss: 1.9116 - val_acc: 0.3195\n",
      "Epoch 9/15\n",
      "16s - loss: 1.9862 - acc: 0.2996 - val_loss: 1.8969 - val_acc: 0.3267\n",
      "Epoch 10/15\n",
      "12s - loss: 1.9673 - acc: 0.3085 - val_loss: 1.8865 - val_acc: 0.3255\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9451 - acc: 0.3173 - val_loss: 1.8813 - val_acc: 0.3229\n",
      "Epoch 12/15\n",
      "12s - loss: 1.9244 - acc: 0.3214 - val_loss: 1.8737 - val_acc: 0.3328\n",
      "Epoch 13/15\n",
      "9s - loss: 1.9056 - acc: 0.3291 - val_loss: 1.8694 - val_acc: 0.3379\n",
      "Epoch 14/15\n",
      "8s - loss: 1.8903 - acc: 0.3336 - val_loss: 1.8648 - val_acc: 0.3323\n",
      "Epoch 15/15\n",
      "8s - loss: 1.8756 - acc: 0.3326 - val_loss: 1.8624 - val_acc: 0.3323\n",
      "logloss val 1.8624395243359666\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "12s - loss: 2.4083 - acc: 0.1394 - val_loss: 2.3293 - val_acc: 0.1727\n",
      "Epoch 2/15\n",
      "12s - loss: 2.3046 - acc: 0.1790 - val_loss: 2.2018 - val_acc: 0.2332\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2181 - acc: 0.2143 - val_loss: 2.1024 - val_acc: 0.2616\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1448 - acc: 0.2401 - val_loss: 2.0526 - val_acc: 0.2784\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0940 - acc: 0.2604 - val_loss: 2.0000 - val_acc: 0.2960\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0668 - acc: 0.2680 - val_loss: 1.9604 - val_acc: 0.3050\n",
      "Epoch 7/15\n",
      "11s - loss: 2.0349 - acc: 0.2817 - val_loss: 1.9450 - val_acc: 0.3136\n",
      "Epoch 8/15\n",
      "11s - loss: 2.0084 - acc: 0.2924 - val_loss: 1.9428 - val_acc: 0.3157\n",
      "Epoch 9/15\n",
      "11s - loss: 1.9832 - acc: 0.2981 - val_loss: 1.9210 - val_acc: 0.3196\n",
      "Epoch 10/15\n",
      "11s - loss: 1.9596 - acc: 0.3087 - val_loss: 1.9120 - val_acc: 0.3260\n",
      "Epoch 11/15\n",
      "11s - loss: 1.9410 - acc: 0.3138 - val_loss: 1.9050 - val_acc: 0.3290\n",
      "Epoch 12/15\n",
      "11s - loss: 1.9311 - acc: 0.3204 - val_loss: 1.9007 - val_acc: 0.3295\n",
      "Epoch 13/15\n",
      "11s - loss: 1.9088 - acc: 0.3245 - val_loss: 1.9003 - val_acc: 0.3269\n",
      "Epoch 14/15\n",
      "12s - loss: 1.9010 - acc: 0.3290 - val_loss: 1.8857 - val_acc: 0.3333\n",
      "Epoch 15/15\n",
      "11s - loss: 1.8716 - acc: 0.3412 - val_loss: 1.8923 - val_acc: 0.3359\n",
      "logloss val 1.8922605146933986\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "9s - loss: 2.4086 - acc: 0.1389 - val_loss: 2.3401 - val_acc: 0.1801\n",
      "Epoch 2/15\n",
      "9s - loss: 2.3130 - acc: 0.1801 - val_loss: 2.2150 - val_acc: 0.2326\n",
      "Epoch 3/15\n",
      "9s - loss: 2.2121 - acc: 0.2216 - val_loss: 2.1223 - val_acc: 0.2648\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1285 - acc: 0.2497 - val_loss: 2.0566 - val_acc: 0.2859\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0835 - acc: 0.2662 - val_loss: 2.0235 - val_acc: 0.2945\n",
      "Epoch 6/15\n",
      "9s - loss: 2.0464 - acc: 0.2799 - val_loss: 2.0205 - val_acc: 0.2979\n",
      "Epoch 7/15\n",
      "9s - loss: 2.0138 - acc: 0.2890 - val_loss: 1.9953 - val_acc: 0.2966\n",
      "Epoch 8/15\n",
      "9s - loss: 1.9832 - acc: 0.2995 - val_loss: 1.9791 - val_acc: 0.3031\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9652 - acc: 0.3079 - val_loss: 1.9736 - val_acc: 0.3061\n",
      "Epoch 10/15\n",
      "9s - loss: 1.9493 - acc: 0.3119 - val_loss: 1.9602 - val_acc: 0.3113\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9233 - acc: 0.3215 - val_loss: 1.9637 - val_acc: 0.3143\n",
      "Epoch 12/15\n",
      "9s - loss: 1.9131 - acc: 0.3240 - val_loss: 1.9585 - val_acc: 0.3143\n",
      "Epoch 13/15\n",
      "9s - loss: 1.8959 - acc: 0.3311 - val_loss: 1.9626 - val_acc: 0.3104\n",
      "Epoch 14/15\n",
      "9s - loss: 1.8711 - acc: 0.3418 - val_loss: 1.9640 - val_acc: 0.3126\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8609 - acc: 0.3438 - val_loss: 1.9738 - val_acc: 0.3151\n",
      "logloss val 1.9737832606245578\n",
      "average logloss val 1.9518334403859323\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "9s - loss: 2.4061 - acc: 0.1365 - val_loss: 2.3595 - val_acc: 0.1580\n",
      "Epoch 2/15\n",
      "36s - loss: 2.3004 - acc: 0.1844 - val_loss: 2.2901 - val_acc: 0.2003\n",
      "Epoch 3/15\n",
      "18s - loss: 2.1974 - acc: 0.2236 - val_loss: 2.2237 - val_acc: 0.2166\n",
      "Epoch 4/15\n",
      "30s - loss: 2.1218 - acc: 0.2501 - val_loss: 2.1754 - val_acc: 0.2235\n",
      "Epoch 5/15\n",
      "48s - loss: 2.0608 - acc: 0.2685 - val_loss: 2.1602 - val_acc: 0.2376\n",
      "Epoch 6/15\n",
      "8s - loss: 2.0382 - acc: 0.2751 - val_loss: 2.1500 - val_acc: 0.2444\n",
      "Epoch 7/15\n",
      "8s - loss: 2.0028 - acc: 0.2945 - val_loss: 2.1329 - val_acc: 0.2496\n",
      "Epoch 8/15\n",
      "8s - loss: 1.9792 - acc: 0.3025 - val_loss: 2.1346 - val_acc: 0.2551\n",
      "Epoch 9/15\n",
      "8s - loss: 1.9611 - acc: 0.3077 - val_loss: 2.1212 - val_acc: 0.2551\n",
      "Epoch 10/15\n",
      "8s - loss: 1.9313 - acc: 0.3171 - val_loss: 2.1232 - val_acc: 0.2560\n",
      "Epoch 11/15\n",
      "8s - loss: 1.9169 - acc: 0.3209 - val_loss: 2.1234 - val_acc: 0.2590\n",
      "Epoch 12/15\n",
      "8s - loss: 1.9066 - acc: 0.3243 - val_loss: 2.1228 - val_acc: 0.2573\n",
      "Epoch 13/15\n",
      "8s - loss: 1.8755 - acc: 0.3362 - val_loss: 2.1229 - val_acc: 0.2641\n",
      "Epoch 14/15\n",
      "8s - loss: 1.8595 - acc: 0.3440 - val_loss: 2.1227 - val_acc: 0.2641\n",
      "Epoch 15/15\n",
      "8s - loss: 1.8481 - acc: 0.3489 - val_loss: 2.1184 - val_acc: 0.2603\n",
      "logloss val 2.1183537714540552\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4112 - acc: 0.1409 - val_loss: 2.3525 - val_acc: 0.1685\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3159 - acc: 0.1840 - val_loss: 2.2600 - val_acc: 0.2036\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2146 - acc: 0.2179 - val_loss: 2.1730 - val_acc: 0.2392\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1501 - acc: 0.2463 - val_loss: 2.1136 - val_acc: 0.2546\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0890 - acc: 0.2652 - val_loss: 2.0819 - val_acc: 0.2645\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0527 - acc: 0.2736 - val_loss: 2.0511 - val_acc: 0.2760\n",
      "Epoch 7/15\n",
      "11s - loss: 2.0221 - acc: 0.2839 - val_loss: 2.0351 - val_acc: 0.2885\n",
      "Epoch 8/15\n",
      "11s - loss: 1.9926 - acc: 0.2993 - val_loss: 2.0248 - val_acc: 0.2868\n",
      "Epoch 9/15\n",
      "12s - loss: 1.9758 - acc: 0.2994 - val_loss: 2.0245 - val_acc: 0.2829\n",
      "Epoch 10/15\n",
      "11s - loss: 1.9461 - acc: 0.3150 - val_loss: 2.0131 - val_acc: 0.2992\n",
      "Epoch 11/15\n",
      "11s - loss: 1.9297 - acc: 0.3181 - val_loss: 2.0015 - val_acc: 0.2992\n",
      "Epoch 12/15\n",
      "12s - loss: 1.9151 - acc: 0.3218 - val_loss: 1.9975 - val_acc: 0.3022\n",
      "Epoch 13/15\n",
      "11s - loss: 1.8959 - acc: 0.3265 - val_loss: 1.9913 - val_acc: 0.3043\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8807 - acc: 0.3376 - val_loss: 1.9876 - val_acc: 0.3073\n",
      "Epoch 15/15\n",
      "12s - loss: 1.8576 - acc: 0.3472 - val_loss: 1.9863 - val_acc: 0.3026\n",
      "logloss val 1.986252563531709\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "10s - loss: 2.4038 - acc: 0.1496 - val_loss: 2.3486 - val_acc: 0.1689\n",
      "Epoch 2/15\n",
      "10s - loss: 2.3033 - acc: 0.1820 - val_loss: 2.2505 - val_acc: 0.1967\n",
      "Epoch 3/15\n",
      "10s - loss: 2.2092 - acc: 0.2207 - val_loss: 2.1739 - val_acc: 0.2323\n",
      "Epoch 4/15\n",
      "10s - loss: 2.1362 - acc: 0.2474 - val_loss: 2.1166 - val_acc: 0.2662\n",
      "Epoch 5/15\n",
      "10s - loss: 2.0787 - acc: 0.2661 - val_loss: 2.1027 - val_acc: 0.2598\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0437 - acc: 0.2777 - val_loss: 2.0764 - val_acc: 0.2739\n",
      "Epoch 7/15\n",
      "10s - loss: 2.0064 - acc: 0.2936 - val_loss: 2.0639 - val_acc: 0.2829\n",
      "Epoch 8/15\n",
      "10s - loss: 1.9890 - acc: 0.2974 - val_loss: 2.0504 - val_acc: 0.2850\n",
      "Epoch 9/15\n",
      "10s - loss: 1.9655 - acc: 0.3051 - val_loss: 2.0476 - val_acc: 0.2846\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9385 - acc: 0.3159 - val_loss: 2.0396 - val_acc: 0.2859\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9250 - acc: 0.3190 - val_loss: 2.0413 - val_acc: 0.2885\n",
      "Epoch 12/15\n",
      "11s - loss: 1.9005 - acc: 0.3290 - val_loss: 2.0330 - val_acc: 0.2910\n",
      "Epoch 13/15\n",
      "11s - loss: 1.8910 - acc: 0.3312 - val_loss: 2.0264 - val_acc: 0.2975\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8689 - acc: 0.3376 - val_loss: 2.0299 - val_acc: 0.2919\n",
      "Epoch 15/15\n",
      "10s - loss: 1.8524 - acc: 0.3432 - val_loss: 2.0246 - val_acc: 0.2983\n",
      "logloss val 2.024563518515279\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "8s - loss: 2.3970 - acc: 0.1485 - val_loss: 2.3236 - val_acc: 0.1685\n",
      "Epoch 2/15\n",
      "7s - loss: 2.3011 - acc: 0.1870 - val_loss: 2.2199 - val_acc: 0.2105\n",
      "Epoch 3/15\n",
      "8s - loss: 2.2146 - acc: 0.2210 - val_loss: 2.1295 - val_acc: 0.2491\n",
      "Epoch 4/15\n",
      "8s - loss: 2.1389 - acc: 0.2441 - val_loss: 2.0710 - val_acc: 0.2792\n",
      "Epoch 5/15\n",
      "8s - loss: 2.0850 - acc: 0.2652 - val_loss: 2.0402 - val_acc: 0.2864\n",
      "Epoch 6/15\n",
      "8s - loss: 2.0477 - acc: 0.2716 - val_loss: 2.0193 - val_acc: 0.2899\n",
      "Epoch 7/15\n",
      "8s - loss: 2.0173 - acc: 0.2866 - val_loss: 2.0089 - val_acc: 0.2864\n",
      "Epoch 8/15\n",
      "7s - loss: 1.9884 - acc: 0.3011 - val_loss: 2.0098 - val_acc: 0.2993\n",
      "Epoch 9/15\n",
      "8s - loss: 1.9750 - acc: 0.3022 - val_loss: 1.9881 - val_acc: 0.2972\n",
      "Epoch 10/15\n",
      "8s - loss: 1.9552 - acc: 0.3091 - val_loss: 1.9824 - val_acc: 0.3023\n",
      "Epoch 11/15\n",
      "8s - loss: 1.9315 - acc: 0.3169 - val_loss: 1.9770 - val_acc: 0.3019\n",
      "Epoch 12/15\n",
      "8s - loss: 1.9211 - acc: 0.3235 - val_loss: 1.9792 - val_acc: 0.3045\n",
      "Epoch 13/15\n",
      "8s - loss: 1.8910 - acc: 0.3336 - val_loss: 1.9736 - val_acc: 0.3079\n",
      "Epoch 14/15\n",
      "8s - loss: 1.8772 - acc: 0.3369 - val_loss: 1.9713 - val_acc: 0.3053\n",
      "Epoch 15/15\n",
      "8s - loss: 1.8690 - acc: 0.3386 - val_loss: 1.9698 - val_acc: 0.3070\n",
      "logloss val 1.969773117727624\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4048 - acc: 0.1396 - val_loss: 2.3234 - val_acc: 0.1900\n",
      "Epoch 2/15\n",
      "13s - loss: 2.3048 - acc: 0.1828 - val_loss: 2.1985 - val_acc: 0.2341\n",
      "Epoch 3/15\n",
      "35s - loss: 2.2104 - acc: 0.2191 - val_loss: 2.0986 - val_acc: 0.2689\n",
      "Epoch 4/15\n",
      "25s - loss: 2.1353 - acc: 0.2487 - val_loss: 2.0333 - val_acc: 0.2817\n",
      "Epoch 5/15\n",
      "12s - loss: 2.0912 - acc: 0.2635 - val_loss: 1.9967 - val_acc: 0.2976\n",
      "Epoch 6/15\n",
      "12s - loss: 2.0413 - acc: 0.2819 - val_loss: 1.9715 - val_acc: 0.3036\n",
      "Epoch 7/15\n",
      "31s - loss: 2.0118 - acc: 0.2899 - val_loss: 1.9597 - val_acc: 0.3019\n",
      "Epoch 8/15\n",
      "36s - loss: 2.0038 - acc: 0.2948 - val_loss: 1.9442 - val_acc: 0.3178\n",
      "Epoch 9/15\n",
      "37s - loss: 1.9742 - acc: 0.3047 - val_loss: 1.9367 - val_acc: 0.3173\n",
      "Epoch 10/15\n",
      "32s - loss: 1.9522 - acc: 0.3106 - val_loss: 1.9300 - val_acc: 0.3220\n",
      "Epoch 11/15\n",
      "32s - loss: 1.9336 - acc: 0.3145 - val_loss: 1.9238 - val_acc: 0.3225\n",
      "Epoch 12/15\n",
      "34s - loss: 1.9197 - acc: 0.3263 - val_loss: 1.9175 - val_acc: 0.3238\n",
      "Epoch 13/15\n",
      "79s - loss: 1.8978 - acc: 0.3294 - val_loss: 1.9131 - val_acc: 0.3280\n",
      "Epoch 14/15\n",
      "30s - loss: 1.8792 - acc: 0.3336 - val_loss: 1.9122 - val_acc: 0.3250\n",
      "Epoch 15/15\n",
      "34s - loss: 1.8652 - acc: 0.3403 - val_loss: 1.9113 - val_acc: 0.3259\n",
      "logloss val 1.9112641582374124\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "19s - loss: 2.4076 - acc: 0.1420 - val_loss: 2.3334 - val_acc: 0.1725\n",
      "Epoch 2/15\n",
      "19s - loss: 2.3129 - acc: 0.1794 - val_loss: 2.2236 - val_acc: 0.2278\n",
      "Epoch 3/15\n",
      "10s - loss: 2.2246 - acc: 0.2146 - val_loss: 2.1298 - val_acc: 0.2587\n",
      "Epoch 4/15\n",
      "10s - loss: 2.1399 - acc: 0.2437 - val_loss: 2.0666 - val_acc: 0.2793\n",
      "Epoch 5/15\n",
      "10s - loss: 2.0922 - acc: 0.2567 - val_loss: 2.0252 - val_acc: 0.2930\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0638 - acc: 0.2720 - val_loss: 2.0066 - val_acc: 0.3033\n",
      "Epoch 7/15\n",
      "10s - loss: 2.0226 - acc: 0.2822 - val_loss: 1.9840 - val_acc: 0.3059\n",
      "Epoch 8/15\n",
      "17s - loss: 2.0049 - acc: 0.2900 - val_loss: 1.9686 - val_acc: 0.3149\n",
      "Epoch 9/15\n",
      "11s - loss: 1.9757 - acc: 0.3051 - val_loss: 1.9629 - val_acc: 0.3157\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9593 - acc: 0.3054 - val_loss: 1.9528 - val_acc: 0.3067\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9375 - acc: 0.3177 - val_loss: 1.9439 - val_acc: 0.3162\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9237 - acc: 0.3225 - val_loss: 1.9385 - val_acc: 0.3076\n",
      "Epoch 13/15\n",
      "10s - loss: 1.9013 - acc: 0.3320 - val_loss: 1.9347 - val_acc: 0.3162\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8807 - acc: 0.3374 - val_loss: 1.9311 - val_acc: 0.3239\n",
      "Epoch 15/15\n",
      "10s - loss: 1.8731 - acc: 0.3391 - val_loss: 1.9296 - val_acc: 0.3175\n",
      "logloss val 1.9296018521607894\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "12s - loss: 2.3981 - acc: 0.1476 - val_loss: 2.3255 - val_acc: 0.1958\n",
      "Epoch 2/15\n",
      "13s - loss: 2.3101 - acc: 0.1868 - val_loss: 2.2056 - val_acc: 0.2430\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2163 - acc: 0.2191 - val_loss: 2.1028 - val_acc: 0.2675\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1447 - acc: 0.2461 - val_loss: 2.0186 - val_acc: 0.2976\n",
      "Epoch 5/15\n",
      "15s - loss: 2.0901 - acc: 0.2639 - val_loss: 1.9774 - val_acc: 0.3040\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0577 - acc: 0.2778 - val_loss: 1.9493 - val_acc: 0.3096\n",
      "Epoch 7/15\n",
      "12s - loss: 2.0303 - acc: 0.2837 - val_loss: 1.9238 - val_acc: 0.3169\n",
      "Epoch 8/15\n",
      "17s - loss: 2.0114 - acc: 0.2913 - val_loss: 1.9116 - val_acc: 0.3263\n",
      "Epoch 9/15\n",
      "12s - loss: 1.9794 - acc: 0.3006 - val_loss: 1.8983 - val_acc: 0.3255\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9644 - acc: 0.3080 - val_loss: 1.8924 - val_acc: 0.3336\n",
      "Epoch 11/15\n",
      "11s - loss: 1.9415 - acc: 0.3149 - val_loss: 1.8810 - val_acc: 0.3302\n",
      "Epoch 12/15\n",
      "16s - loss: 1.9223 - acc: 0.3240 - val_loss: 1.8677 - val_acc: 0.3362\n",
      "Epoch 13/15\n",
      "9s - loss: 1.9076 - acc: 0.3301 - val_loss: 1.8650 - val_acc: 0.3392\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8937 - acc: 0.3309 - val_loss: 1.8640 - val_acc: 0.3375\n",
      "Epoch 15/15\n",
      "8s - loss: 1.8760 - acc: 0.3372 - val_loss: 1.8544 - val_acc: 0.3405\n",
      "logloss val 1.8543697837284319\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "18s - loss: 2.4082 - acc: 0.1430 - val_loss: 2.3220 - val_acc: 0.1739\n",
      "Epoch 2/15\n",
      "13s - loss: 2.3139 - acc: 0.1847 - val_loss: 2.1927 - val_acc: 0.2404\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2235 - acc: 0.2182 - val_loss: 2.0804 - val_acc: 0.2782\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1477 - acc: 0.2474 - val_loss: 2.0157 - val_acc: 0.3040\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0937 - acc: 0.2610 - val_loss: 1.9691 - val_acc: 0.3087\n",
      "Epoch 6/15\n",
      "15s - loss: 2.0543 - acc: 0.2734 - val_loss: 1.9372 - val_acc: 0.3104\n",
      "Epoch 7/15\n",
      "23s - loss: 2.0345 - acc: 0.2811 - val_loss: 1.9204 - val_acc: 0.3237\n",
      "Epoch 8/15\n",
      "11s - loss: 2.0041 - acc: 0.2977 - val_loss: 1.9080 - val_acc: 0.3263\n",
      "Epoch 9/15\n",
      "12s - loss: 1.9862 - acc: 0.2985 - val_loss: 1.8957 - val_acc: 0.3237\n",
      "Epoch 10/15\n",
      "12s - loss: 1.9632 - acc: 0.3111 - val_loss: 1.8891 - val_acc: 0.3293\n",
      "Epoch 11/15\n",
      "11s - loss: 1.9442 - acc: 0.3152 - val_loss: 1.8783 - val_acc: 0.3298\n",
      "Epoch 12/15\n",
      "11s - loss: 1.9290 - acc: 0.3190 - val_loss: 1.8712 - val_acc: 0.3349\n",
      "Epoch 13/15\n",
      "11s - loss: 1.9057 - acc: 0.3317 - val_loss: 1.8691 - val_acc: 0.3323\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8978 - acc: 0.3307 - val_loss: 1.8682 - val_acc: 0.3401\n",
      "Epoch 15/15\n",
      "11s - loss: 1.8735 - acc: 0.3388 - val_loss: 1.8599 - val_acc: 0.3345\n",
      "logloss val 1.8599347858411808\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "10s - loss: 2.4049 - acc: 0.1375 - val_loss: 2.3248 - val_acc: 0.1856\n",
      "Epoch 2/15\n",
      "10s - loss: 2.3023 - acc: 0.1859 - val_loss: 2.1981 - val_acc: 0.2311\n",
      "Epoch 3/15\n",
      "10s - loss: 2.2141 - acc: 0.2186 - val_loss: 2.0893 - val_acc: 0.2732\n",
      "Epoch 4/15\n",
      "10s - loss: 2.1318 - acc: 0.2479 - val_loss: 2.0224 - val_acc: 0.2762\n",
      "Epoch 5/15\n",
      "10s - loss: 2.0938 - acc: 0.2615 - val_loss: 1.9874 - val_acc: 0.3076\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0525 - acc: 0.2759 - val_loss: 1.9591 - val_acc: 0.3101\n",
      "Epoch 7/15\n",
      "10s - loss: 2.0243 - acc: 0.2874 - val_loss: 1.9573 - val_acc: 0.3003\n",
      "Epoch 8/15\n",
      "10s - loss: 2.0010 - acc: 0.2934 - val_loss: 1.9409 - val_acc: 0.3110\n",
      "Epoch 9/15\n",
      "10s - loss: 1.9808 - acc: 0.3019 - val_loss: 1.9327 - val_acc: 0.3153\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9585 - acc: 0.3073 - val_loss: 1.9088 - val_acc: 0.3243\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9401 - acc: 0.3171 - val_loss: 1.9094 - val_acc: 0.3260\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9266 - acc: 0.3225 - val_loss: 1.9053 - val_acc: 0.3230\n",
      "Epoch 13/15\n",
      "10s - loss: 1.9087 - acc: 0.3255 - val_loss: 1.8981 - val_acc: 0.3303\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8870 - acc: 0.3330 - val_loss: 1.8952 - val_acc: 0.3329\n",
      "Epoch 15/15\n",
      "10s - loss: 1.8696 - acc: 0.3421 - val_loss: 1.8990 - val_acc: 0.3372\n",
      "logloss val 1.8990455939357658\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "8s - loss: 2.4084 - acc: 0.1432 - val_loss: 2.3246 - val_acc: 0.1909\n",
      "Epoch 2/15\n",
      "8s - loss: 2.2975 - acc: 0.1897 - val_loss: 2.1957 - val_acc: 0.2339\n",
      "Epoch 3/15\n",
      "8s - loss: 2.2084 - acc: 0.2240 - val_loss: 2.1108 - val_acc: 0.2640\n",
      "Epoch 4/15\n",
      "8s - loss: 2.1343 - acc: 0.2459 - val_loss: 2.0628 - val_acc: 0.2812\n",
      "Epoch 5/15\n",
      "8s - loss: 2.0791 - acc: 0.2697 - val_loss: 2.0409 - val_acc: 0.2816\n",
      "Epoch 6/15\n",
      "8s - loss: 2.0435 - acc: 0.2835 - val_loss: 2.0253 - val_acc: 0.2898\n",
      "Epoch 7/15\n",
      "7s - loss: 2.0189 - acc: 0.2841 - val_loss: 1.9962 - val_acc: 0.2941\n",
      "Epoch 8/15\n",
      "8s - loss: 1.9789 - acc: 0.3034 - val_loss: 1.9906 - val_acc: 0.2984\n",
      "Epoch 9/15\n",
      "8s - loss: 1.9650 - acc: 0.3066 - val_loss: 1.9917 - val_acc: 0.2949\n",
      "Epoch 10/15\n",
      "8s - loss: 1.9446 - acc: 0.3108 - val_loss: 1.9707 - val_acc: 0.3087\n",
      "Epoch 11/15\n",
      "8s - loss: 1.9297 - acc: 0.3187 - val_loss: 1.9686 - val_acc: 0.3061\n",
      "Epoch 12/15\n",
      "8s - loss: 1.9120 - acc: 0.3269 - val_loss: 1.9585 - val_acc: 0.3113\n",
      "Epoch 13/15\n",
      "8s - loss: 1.8989 - acc: 0.3326 - val_loss: 1.9648 - val_acc: 0.3061\n",
      "Epoch 14/15\n",
      "8s - loss: 1.8733 - acc: 0.3383 - val_loss: 1.9650 - val_acc: 0.3091\n",
      "Epoch 15/15\n",
      "10s - loss: 1.8579 - acc: 0.3443 - val_loss: 1.9584 - val_acc: 0.3009\n",
      "logloss val 1.958363759455528\n",
      "average logloss val 1.951152290458778\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "104s - loss: 2.4120 - acc: 0.1357 - val_loss: 2.3602 - val_acc: 0.1507\n",
      "Epoch 2/15\n",
      "27s - loss: 2.3065 - acc: 0.1860 - val_loss: 2.2972 - val_acc: 0.1828\n",
      "Epoch 3/15\n",
      "14s - loss: 2.2131 - acc: 0.2214 - val_loss: 2.2392 - val_acc: 0.2123\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1328 - acc: 0.2496 - val_loss: 2.1924 - val_acc: 0.2247\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0796 - acc: 0.2631 - val_loss: 2.1629 - val_acc: 0.2419\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0439 - acc: 0.2805 - val_loss: 2.1595 - val_acc: 0.2410\n",
      "Epoch 7/15\n",
      "11s - loss: 2.0124 - acc: 0.2904 - val_loss: 2.1339 - val_acc: 0.2517\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9798 - acc: 0.2979 - val_loss: 2.1339 - val_acc: 0.2568\n",
      "Epoch 9/15\n",
      "18s - loss: 1.9648 - acc: 0.3069 - val_loss: 2.1303 - val_acc: 0.2504\n",
      "Epoch 10/15\n",
      "11s - loss: 1.9388 - acc: 0.3114 - val_loss: 2.1273 - val_acc: 0.2603\n",
      "Epoch 11/15\n",
      "11s - loss: 1.9202 - acc: 0.3243 - val_loss: 2.1240 - val_acc: 0.2568\n",
      "Epoch 12/15\n",
      "13s - loss: 1.9031 - acc: 0.3252 - val_loss: 2.1160 - val_acc: 0.2611\n",
      "Epoch 13/15\n",
      "24s - loss: 1.8916 - acc: 0.3341 - val_loss: 2.1226 - val_acc: 0.2581\n",
      "Epoch 14/15\n",
      "15s - loss: 1.8581 - acc: 0.3430 - val_loss: 2.1242 - val_acc: 0.2603\n",
      "Epoch 15/15\n",
      "11s - loss: 1.8565 - acc: 0.3462 - val_loss: 2.1195 - val_acc: 0.2564\n",
      "logloss val 2.119467981987352\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "10s - loss: 2.4079 - acc: 0.1413 - val_loss: 2.3533 - val_acc: 0.1582\n",
      "Epoch 2/15\n",
      "10s - loss: 2.3133 - acc: 0.1767 - val_loss: 2.2593 - val_acc: 0.2105\n",
      "Epoch 3/15\n",
      "10s - loss: 2.2135 - acc: 0.2184 - val_loss: 2.1631 - val_acc: 0.2417\n",
      "Epoch 4/15\n",
      "10s - loss: 2.1320 - acc: 0.2456 - val_loss: 2.1168 - val_acc: 0.2589\n",
      "Epoch 5/15\n",
      "10s - loss: 2.0805 - acc: 0.2685 - val_loss: 2.0715 - val_acc: 0.2735\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0440 - acc: 0.2806 - val_loss: 2.0619 - val_acc: 0.2756\n",
      "Epoch 7/15\n",
      "10s - loss: 2.0203 - acc: 0.2878 - val_loss: 2.0385 - val_acc: 0.2808\n",
      "Epoch 8/15\n",
      "10s - loss: 2.0015 - acc: 0.2970 - val_loss: 2.0282 - val_acc: 0.2893\n",
      "Epoch 9/15\n",
      "10s - loss: 1.9625 - acc: 0.3082 - val_loss: 2.0115 - val_acc: 0.2863\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9478 - acc: 0.3133 - val_loss: 2.0085 - val_acc: 0.2949\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9363 - acc: 0.3137 - val_loss: 2.0064 - val_acc: 0.2898\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9115 - acc: 0.3261 - val_loss: 1.9925 - val_acc: 0.3022\n",
      "Epoch 13/15\n",
      "10s - loss: 1.8955 - acc: 0.3306 - val_loss: 1.9897 - val_acc: 0.3026\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8761 - acc: 0.3381 - val_loss: 1.9966 - val_acc: 0.2949\n",
      "Epoch 15/15\n",
      "10s - loss: 1.8671 - acc: 0.3382 - val_loss: 1.9836 - val_acc: 0.3013\n",
      "logloss val 1.983591224841751\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "9s - loss: 2.4032 - acc: 0.1432 - val_loss: 2.3383 - val_acc: 0.1787\n",
      "Epoch 2/15\n",
      "9s - loss: 2.3063 - acc: 0.1822 - val_loss: 2.2484 - val_acc: 0.2190\n",
      "Epoch 3/15\n",
      "9s - loss: 2.2007 - acc: 0.2252 - val_loss: 2.1617 - val_acc: 0.2486\n",
      "Epoch 4/15\n",
      "8s - loss: 2.1252 - acc: 0.2490 - val_loss: 2.1159 - val_acc: 0.2555\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0777 - acc: 0.2693 - val_loss: 2.0857 - val_acc: 0.2718\n",
      "Epoch 6/15\n",
      "9s - loss: 2.0310 - acc: 0.2854 - val_loss: 2.0768 - val_acc: 0.2769\n",
      "Epoch 7/15\n",
      "8s - loss: 2.0142 - acc: 0.2906 - val_loss: 2.0617 - val_acc: 0.2803\n",
      "Epoch 8/15\n",
      "9s - loss: 1.9776 - acc: 0.3038 - val_loss: 2.0495 - val_acc: 0.2816\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9643 - acc: 0.3112 - val_loss: 2.0435 - val_acc: 0.2790\n",
      "Epoch 10/15\n",
      "9s - loss: 1.9438 - acc: 0.3163 - val_loss: 2.0378 - val_acc: 0.2855\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9202 - acc: 0.3221 - val_loss: 2.0404 - val_acc: 0.2880\n",
      "Epoch 12/15\n",
      "9s - loss: 1.9035 - acc: 0.3269 - val_loss: 2.0374 - val_acc: 0.2940\n",
      "Epoch 13/15\n",
      "9s - loss: 1.8870 - acc: 0.3359 - val_loss: 2.0345 - val_acc: 0.2842\n",
      "Epoch 14/15\n",
      "9s - loss: 1.8718 - acc: 0.3393 - val_loss: 2.0364 - val_acc: 0.2910\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8472 - acc: 0.3481 - val_loss: 2.0350 - val_acc: 0.2928\n",
      "logloss val 2.0349910336722643\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "10s - loss: 2.4085 - acc: 0.1383 - val_loss: 2.3428 - val_acc: 0.1728\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3171 - acc: 0.1779 - val_loss: 2.2265 - val_acc: 0.2183\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2224 - acc: 0.2165 - val_loss: 2.1377 - val_acc: 0.2547\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1545 - acc: 0.2421 - val_loss: 2.0765 - val_acc: 0.2740\n",
      "Epoch 5/15\n",
      "17s - loss: 2.0923 - acc: 0.2624 - val_loss: 2.0446 - val_acc: 0.2783\n",
      "Epoch 6/15\n",
      "18s - loss: 2.0492 - acc: 0.2765 - val_loss: 2.0233 - val_acc: 0.2882\n",
      "Epoch 7/15\n",
      "21s - loss: 2.0265 - acc: 0.2833 - val_loss: 2.0052 - val_acc: 0.2967\n",
      "Epoch 8/15\n",
      "18s - loss: 2.0034 - acc: 0.2969 - val_loss: 1.9964 - val_acc: 0.2976\n",
      "Epoch 9/15\n",
      "16s - loss: 1.9827 - acc: 0.2990 - val_loss: 1.9893 - val_acc: 0.2955\n",
      "Epoch 10/15\n",
      "17s - loss: 1.9549 - acc: 0.3104 - val_loss: 1.9814 - val_acc: 0.3045\n",
      "Epoch 11/15\n",
      "15s - loss: 1.9354 - acc: 0.3195 - val_loss: 1.9808 - val_acc: 0.3075\n",
      "Epoch 12/15\n",
      "19s - loss: 1.9159 - acc: 0.3290 - val_loss: 1.9729 - val_acc: 0.3152\n",
      "Epoch 13/15\n",
      "28s - loss: 1.9016 - acc: 0.3295 - val_loss: 1.9714 - val_acc: 0.3109\n",
      "Epoch 14/15\n",
      "45s - loss: 1.8779 - acc: 0.3366 - val_loss: 1.9732 - val_acc: 0.3105\n",
      "Epoch 15/15\n",
      "44s - loss: 1.8662 - acc: 0.3396 - val_loss: 1.9675 - val_acc: 0.3148\n",
      "logloss val 1.9674711526398696\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "22s - loss: 2.4048 - acc: 0.1431 - val_loss: 2.3260 - val_acc: 0.1925\n",
      "Epoch 2/15\n",
      "29s - loss: 2.3115 - acc: 0.1841 - val_loss: 2.2035 - val_acc: 0.2427\n",
      "Epoch 3/15\n",
      "27s - loss: 2.2248 - acc: 0.2129 - val_loss: 2.1150 - val_acc: 0.2684\n",
      "Epoch 4/15\n",
      "42s - loss: 2.1514 - acc: 0.2385 - val_loss: 2.0468 - val_acc: 0.2796\n",
      "Epoch 5/15\n",
      "26s - loss: 2.1017 - acc: 0.2579 - val_loss: 2.0026 - val_acc: 0.2925\n",
      "Epoch 6/15\n",
      "21s - loss: 2.0566 - acc: 0.2737 - val_loss: 1.9817 - val_acc: 0.2972\n",
      "Epoch 7/15\n",
      "36s - loss: 2.0311 - acc: 0.2807 - val_loss: 1.9624 - val_acc: 0.3053\n",
      "Epoch 8/15\n",
      "30s - loss: 2.0031 - acc: 0.2949 - val_loss: 1.9473 - val_acc: 0.3087\n",
      "Epoch 9/15\n",
      "42s - loss: 1.9809 - acc: 0.2984 - val_loss: 1.9379 - val_acc: 0.3083\n",
      "Epoch 10/15\n",
      "23s - loss: 1.9637 - acc: 0.3082 - val_loss: 1.9319 - val_acc: 0.3096\n",
      "Epoch 11/15\n",
      "48s - loss: 1.9404 - acc: 0.3136 - val_loss: 1.9247 - val_acc: 0.3130\n",
      "Epoch 12/15\n",
      "33s - loss: 1.9194 - acc: 0.3238 - val_loss: 1.9219 - val_acc: 0.3109\n",
      "Epoch 13/15\n",
      "26s - loss: 1.9079 - acc: 0.3259 - val_loss: 1.9151 - val_acc: 0.3160\n",
      "Epoch 14/15\n",
      "27s - loss: 1.8862 - acc: 0.3360 - val_loss: 1.9099 - val_acc: 0.3165\n",
      "Epoch 15/15\n",
      "10s - loss: 1.8797 - acc: 0.3314 - val_loss: 1.9090 - val_acc: 0.3169\n",
      "logloss val 1.9090493208398056\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "8s - loss: 2.4185 - acc: 0.1303 - val_loss: 2.3353 - val_acc: 0.1798\n",
      "Epoch 2/15\n",
      "9s - loss: 2.3121 - acc: 0.1791 - val_loss: 2.2161 - val_acc: 0.2192\n",
      "Epoch 3/15\n",
      "9s - loss: 2.2207 - acc: 0.2157 - val_loss: 2.1301 - val_acc: 0.2587\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1457 - acc: 0.2405 - val_loss: 2.0615 - val_acc: 0.2789\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0977 - acc: 0.2582 - val_loss: 2.0231 - val_acc: 0.2969\n",
      "Epoch 6/15\n",
      "9s - loss: 2.0562 - acc: 0.2767 - val_loss: 1.9941 - val_acc: 0.3046\n",
      "Epoch 7/15\n",
      "10s - loss: 2.0327 - acc: 0.2849 - val_loss: 1.9793 - val_acc: 0.3042\n",
      "Epoch 8/15\n",
      "9s - loss: 2.0025 - acc: 0.2983 - val_loss: 1.9652 - val_acc: 0.3110\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9732 - acc: 0.3025 - val_loss: 1.9533 - val_acc: 0.3192\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9645 - acc: 0.3071 - val_loss: 1.9467 - val_acc: 0.3183\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9407 - acc: 0.3152 - val_loss: 1.9400 - val_acc: 0.3213\n",
      "Epoch 12/15\n",
      "9s - loss: 1.9240 - acc: 0.3196 - val_loss: 1.9371 - val_acc: 0.3179\n",
      "Epoch 13/15\n",
      "9s - loss: 1.9117 - acc: 0.3285 - val_loss: 1.9337 - val_acc: 0.3290\n",
      "Epoch 14/15\n",
      "9s - loss: 1.8834 - acc: 0.3329 - val_loss: 1.9301 - val_acc: 0.3239\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8759 - acc: 0.3421 - val_loss: 1.9278 - val_acc: 0.3179\n",
      "logloss val 1.9278020496335935\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4124 - acc: 0.1407 - val_loss: 2.3201 - val_acc: 0.1928\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3073 - acc: 0.1839 - val_loss: 2.2000 - val_acc: 0.2456\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2150 - acc: 0.2193 - val_loss: 2.0982 - val_acc: 0.2825\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1508 - acc: 0.2427 - val_loss: 2.0237 - val_acc: 0.2907\n",
      "Epoch 5/15\n",
      "11s - loss: 2.1008 - acc: 0.2567 - val_loss: 1.9806 - val_acc: 0.3113\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0608 - acc: 0.2743 - val_loss: 1.9505 - val_acc: 0.3195\n",
      "Epoch 7/15\n",
      "17s - loss: 2.0403 - acc: 0.2814 - val_loss: 1.9316 - val_acc: 0.3229\n",
      "Epoch 8/15\n",
      "18s - loss: 2.0030 - acc: 0.2937 - val_loss: 1.9130 - val_acc: 0.3298\n",
      "Epoch 9/15\n",
      "18s - loss: 1.9891 - acc: 0.2984 - val_loss: 1.8959 - val_acc: 0.3336\n",
      "Epoch 10/15\n",
      "21s - loss: 1.9757 - acc: 0.3065 - val_loss: 1.8897 - val_acc: 0.3405\n",
      "Epoch 11/15\n",
      "16s - loss: 1.9466 - acc: 0.3137 - val_loss: 1.8818 - val_acc: 0.3444\n",
      "Epoch 12/15\n",
      "16s - loss: 1.9294 - acc: 0.3208 - val_loss: 1.8715 - val_acc: 0.3366\n",
      "Epoch 13/15\n",
      "16s - loss: 1.9163 - acc: 0.3257 - val_loss: 1.8658 - val_acc: 0.3388\n",
      "Epoch 14/15\n",
      "15s - loss: 1.8974 - acc: 0.3260 - val_loss: 1.8591 - val_acc: 0.3465\n",
      "Epoch 15/15\n",
      "15s - loss: 1.8834 - acc: 0.3392 - val_loss: 1.8568 - val_acc: 0.3371\n",
      "logloss val 1.8568182790683108\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "19s - loss: 2.4176 - acc: 0.1338 - val_loss: 2.3376 - val_acc: 0.1812\n",
      "Epoch 2/15\n",
      "18s - loss: 2.3318 - acc: 0.1721 - val_loss: 2.2299 - val_acc: 0.2254\n",
      "Epoch 3/15\n",
      "14s - loss: 2.2434 - acc: 0.2075 - val_loss: 2.1126 - val_acc: 0.2714\n",
      "Epoch 4/15\n",
      "10s - loss: 2.1715 - acc: 0.2351 - val_loss: 2.0295 - val_acc: 0.3001\n",
      "Epoch 5/15\n",
      "10s - loss: 2.1067 - acc: 0.2560 - val_loss: 1.9792 - val_acc: 0.3126\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0689 - acc: 0.2728 - val_loss: 1.9515 - val_acc: 0.3139\n",
      "Epoch 7/15\n",
      "16s - loss: 2.0333 - acc: 0.2867 - val_loss: 1.9279 - val_acc: 0.3199\n",
      "Epoch 8/15\n",
      "10s - loss: 2.0157 - acc: 0.2879 - val_loss: 1.9127 - val_acc: 0.3276\n",
      "Epoch 9/15\n",
      "11s - loss: 1.9792 - acc: 0.3022 - val_loss: 1.8965 - val_acc: 0.3306\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9630 - acc: 0.3101 - val_loss: 1.8848 - val_acc: 0.3366\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9405 - acc: 0.3173 - val_loss: 1.8795 - val_acc: 0.3336\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9203 - acc: 0.3215 - val_loss: 1.8710 - val_acc: 0.3306\n",
      "Epoch 13/15\n",
      "10s - loss: 1.9104 - acc: 0.3285 - val_loss: 1.8694 - val_acc: 0.3319\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8927 - acc: 0.3326 - val_loss: 1.8628 - val_acc: 0.3371\n",
      "Epoch 15/15\n",
      "11s - loss: 1.8729 - acc: 0.3424 - val_loss: 1.8624 - val_acc: 0.3328\n",
      "logloss val 1.8624472687170452\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "9s - loss: 2.4134 - acc: 0.1304 - val_loss: 2.3371 - val_acc: 0.1662\n",
      "Epoch 2/15\n",
      "9s - loss: 2.3102 - acc: 0.1817 - val_loss: 2.2084 - val_acc: 0.2367\n",
      "Epoch 3/15\n",
      "10s - loss: 2.2196 - acc: 0.2176 - val_loss: 2.1044 - val_acc: 0.2646\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1468 - acc: 0.2448 - val_loss: 2.0413 - val_acc: 0.2801\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0901 - acc: 0.2610 - val_loss: 1.9911 - val_acc: 0.3067\n",
      "Epoch 6/15\n",
      "9s - loss: 2.0654 - acc: 0.2694 - val_loss: 1.9694 - val_acc: 0.3063\n",
      "Epoch 7/15\n",
      "9s - loss: 2.0259 - acc: 0.2865 - val_loss: 1.9584 - val_acc: 0.3084\n",
      "Epoch 8/15\n",
      "9s - loss: 2.0130 - acc: 0.2901 - val_loss: 1.9340 - val_acc: 0.3131\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9863 - acc: 0.3012 - val_loss: 1.9284 - val_acc: 0.3157\n",
      "Epoch 10/15\n",
      "9s - loss: 1.9615 - acc: 0.3072 - val_loss: 1.9234 - val_acc: 0.3222\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9519 - acc: 0.3134 - val_loss: 1.9110 - val_acc: 0.3256\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9222 - acc: 0.3236 - val_loss: 1.8989 - val_acc: 0.3239\n",
      "Epoch 13/15\n",
      "9s - loss: 1.9067 - acc: 0.3296 - val_loss: 1.8944 - val_acc: 0.3187\n",
      "Epoch 14/15\n",
      "9s - loss: 1.8949 - acc: 0.3279 - val_loss: 1.8918 - val_acc: 0.3277\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8722 - acc: 0.3381 - val_loss: 1.9030 - val_acc: 0.3265\n",
      "logloss val 1.9029975356306092\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4120 - acc: 0.1371 - val_loss: 2.3409 - val_acc: 0.1819\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3112 - acc: 0.1790 - val_loss: 2.2183 - val_acc: 0.2296\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2188 - acc: 0.2161 - val_loss: 2.1417 - val_acc: 0.2446\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1484 - acc: 0.2446 - val_loss: 2.0723 - val_acc: 0.2713\n",
      "Epoch 5/15\n",
      "15s - loss: 2.0952 - acc: 0.2584 - val_loss: 2.0524 - val_acc: 0.2769\n",
      "Epoch 6/15\n",
      "17s - loss: 2.0617 - acc: 0.2734 - val_loss: 2.0297 - val_acc: 0.2846\n",
      "Epoch 7/15\n",
      "16s - loss: 2.0357 - acc: 0.2818 - val_loss: 2.0151 - val_acc: 0.2893\n",
      "Epoch 8/15\n",
      "20s - loss: 1.9999 - acc: 0.2971 - val_loss: 1.9941 - val_acc: 0.3014\n",
      "Epoch 9/15\n",
      "17s - loss: 1.9849 - acc: 0.3009 - val_loss: 1.9796 - val_acc: 0.2988\n",
      "Epoch 10/15\n",
      "16s - loss: 1.9609 - acc: 0.3085 - val_loss: 1.9807 - val_acc: 0.2954\n",
      "Epoch 11/15\n",
      "16s - loss: 1.9422 - acc: 0.3147 - val_loss: 1.9837 - val_acc: 0.2954\n",
      "Epoch 12/15\n",
      "15s - loss: 1.9277 - acc: 0.3205 - val_loss: 1.9625 - val_acc: 0.2988\n",
      "Epoch 13/15\n",
      "15s - loss: 1.9083 - acc: 0.3256 - val_loss: 1.9638 - val_acc: 0.3022\n",
      "Epoch 14/15\n",
      "33s - loss: 1.8901 - acc: 0.3315 - val_loss: 1.9720 - val_acc: 0.3005\n",
      "Epoch 15/15\n",
      "36s - loss: 1.8663 - acc: 0.3423 - val_loss: 1.9649 - val_acc: 0.3009\n",
      "logloss val 1.9649205511725754\n",
      "average logloss val 1.9529556398203176\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "59s - loss: 2.4067 - acc: 0.1406 - val_loss: 2.3634 - val_acc: 0.1562\n",
      "Epoch 2/15\n",
      "36s - loss: 2.3013 - acc: 0.1862 - val_loss: 2.2947 - val_acc: 0.1914\n",
      "Epoch 3/15\n",
      "15s - loss: 2.2040 - acc: 0.2188 - val_loss: 2.2384 - val_acc: 0.2153\n",
      "Epoch 4/15\n",
      "12s - loss: 2.1298 - acc: 0.2515 - val_loss: 2.1782 - val_acc: 0.2320\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0823 - acc: 0.2651 - val_loss: 2.1608 - val_acc: 0.2393\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0392 - acc: 0.2826 - val_loss: 2.1432 - val_acc: 0.2461\n",
      "Epoch 7/15\n",
      "10s - loss: 2.0144 - acc: 0.2886 - val_loss: 2.1384 - val_acc: 0.2521\n",
      "Epoch 8/15\n",
      "10s - loss: 1.9874 - acc: 0.2982 - val_loss: 2.1252 - val_acc: 0.2530\n",
      "Epoch 9/15\n",
      "11s - loss: 1.9564 - acc: 0.3085 - val_loss: 2.1208 - val_acc: 0.2633\n",
      "Epoch 10/15\n",
      "16s - loss: 1.9377 - acc: 0.3137 - val_loss: 2.1200 - val_acc: 0.2573\n",
      "Epoch 11/15\n",
      "12s - loss: 1.9180 - acc: 0.3212 - val_loss: 2.1216 - val_acc: 0.2556\n",
      "Epoch 12/15\n",
      "11s - loss: 1.8999 - acc: 0.3278 - val_loss: 2.1133 - val_acc: 0.2611\n",
      "Epoch 13/15\n",
      "11s - loss: 1.8792 - acc: 0.3368 - val_loss: 2.1118 - val_acc: 0.2603\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8716 - acc: 0.3383 - val_loss: 2.1239 - val_acc: 0.2598\n",
      "Epoch 15/15\n",
      "11s - loss: 1.8517 - acc: 0.3457 - val_loss: 2.1160 - val_acc: 0.2568\n",
      "logloss val 2.116000292790824\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "9s - loss: 2.4150 - acc: 0.1342 - val_loss: 2.3474 - val_acc: 0.1629\n",
      "Epoch 2/15\n",
      "9s - loss: 2.2991 - acc: 0.1896 - val_loss: 2.2356 - val_acc: 0.2233\n",
      "Epoch 3/15\n",
      "9s - loss: 2.2020 - acc: 0.2242 - val_loss: 2.1488 - val_acc: 0.2482\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1228 - acc: 0.2512 - val_loss: 2.0918 - val_acc: 0.2696\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0754 - acc: 0.2697 - val_loss: 2.0600 - val_acc: 0.2808\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0364 - acc: 0.2803 - val_loss: 2.0402 - val_acc: 0.2928\n",
      "Epoch 7/15\n",
      "9s - loss: 2.0145 - acc: 0.2896 - val_loss: 2.0308 - val_acc: 0.2949\n",
      "Epoch 8/15\n",
      "9s - loss: 1.9822 - acc: 0.3026 - val_loss: 2.0212 - val_acc: 0.2945\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9662 - acc: 0.3065 - val_loss: 2.0118 - val_acc: 0.3060\n",
      "Epoch 10/15\n",
      "9s - loss: 1.9472 - acc: 0.3131 - val_loss: 2.0021 - val_acc: 0.3009\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9264 - acc: 0.3205 - val_loss: 2.0034 - val_acc: 0.3039\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9062 - acc: 0.3251 - val_loss: 1.9927 - val_acc: 0.3112\n",
      "Epoch 13/15\n",
      "9s - loss: 1.8886 - acc: 0.3336 - val_loss: 1.9915 - val_acc: 0.3146\n",
      "Epoch 14/15\n",
      "9s - loss: 1.8739 - acc: 0.3397 - val_loss: 1.9865 - val_acc: 0.3129\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8546 - acc: 0.3452 - val_loss: 1.9844 - val_acc: 0.3095\n",
      "logloss val 1.9843616397070158\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4027 - acc: 0.1468 - val_loss: 2.3420 - val_acc: 0.1805\n",
      "Epoch 2/15\n",
      "11s - loss: 2.2929 - acc: 0.1915 - val_loss: 2.2422 - val_acc: 0.2066\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2048 - acc: 0.2172 - val_loss: 2.1737 - val_acc: 0.2452\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1300 - acc: 0.2495 - val_loss: 2.1220 - val_acc: 0.2679\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0732 - acc: 0.2674 - val_loss: 2.0939 - val_acc: 0.2700\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0378 - acc: 0.2799 - val_loss: 2.0747 - val_acc: 0.2782\n",
      "Epoch 7/15\n",
      "11s - loss: 2.0115 - acc: 0.2903 - val_loss: 2.0588 - val_acc: 0.2846\n",
      "Epoch 8/15\n",
      "11s - loss: 1.9798 - acc: 0.2998 - val_loss: 2.0528 - val_acc: 0.2820\n",
      "Epoch 9/15\n",
      "11s - loss: 1.9616 - acc: 0.3073 - val_loss: 2.0446 - val_acc: 0.2906\n",
      "Epoch 10/15\n",
      "11s - loss: 1.9424 - acc: 0.3143 - val_loss: 2.0369 - val_acc: 0.2902\n",
      "Epoch 11/15\n",
      "11s - loss: 1.9207 - acc: 0.3229 - val_loss: 2.0397 - val_acc: 0.2893\n",
      "Epoch 12/15\n",
      "11s - loss: 1.9025 - acc: 0.3284 - val_loss: 2.0312 - val_acc: 0.2949\n",
      "Epoch 13/15\n",
      "11s - loss: 1.8811 - acc: 0.3329 - val_loss: 2.0286 - val_acc: 0.2962\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8779 - acc: 0.3383 - val_loss: 2.0427 - val_acc: 0.2855\n",
      "Epoch 15/15\n",
      "11s - loss: 1.8415 - acc: 0.3518 - val_loss: 2.0389 - val_acc: 0.2846\n",
      "logloss val 2.0389013386978596\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "10s - loss: 2.4078 - acc: 0.1432 - val_loss: 2.3358 - val_acc: 0.1831\n",
      "Epoch 2/15\n",
      "9s - loss: 2.3147 - acc: 0.1808 - val_loss: 2.2148 - val_acc: 0.2226\n",
      "Epoch 3/15\n",
      "10s - loss: 2.2154 - acc: 0.2165 - val_loss: 2.1175 - val_acc: 0.2603\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1367 - acc: 0.2475 - val_loss: 2.0597 - val_acc: 0.2882\n",
      "Epoch 5/15\n",
      "10s - loss: 2.0788 - acc: 0.2645 - val_loss: 2.0296 - val_acc: 0.2950\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0473 - acc: 0.2822 - val_loss: 2.0079 - val_acc: 0.2976\n",
      "Epoch 7/15\n",
      "9s - loss: 2.0178 - acc: 0.2868 - val_loss: 1.9987 - val_acc: 0.3087\n",
      "Epoch 8/15\n",
      "10s - loss: 1.9913 - acc: 0.2966 - val_loss: 1.9846 - val_acc: 0.3045\n",
      "Epoch 9/15\n",
      "10s - loss: 1.9673 - acc: 0.3089 - val_loss: 1.9840 - val_acc: 0.3045\n",
      "Epoch 10/15\n",
      "10s - loss: 1.9510 - acc: 0.3117 - val_loss: 1.9713 - val_acc: 0.3143\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9282 - acc: 0.3189 - val_loss: 1.9706 - val_acc: 0.3105\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9157 - acc: 0.3249 - val_loss: 1.9646 - val_acc: 0.3130\n",
      "Epoch 13/15\n",
      "10s - loss: 1.8947 - acc: 0.3309 - val_loss: 1.9600 - val_acc: 0.3126\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8769 - acc: 0.3357 - val_loss: 1.9596 - val_acc: 0.3066\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8586 - acc: 0.3406 - val_loss: 1.9604 - val_acc: 0.3135\n",
      "logloss val 1.9603791702011566\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "9s - loss: 2.4115 - acc: 0.1376 - val_loss: 2.3293 - val_acc: 0.1827\n",
      "Epoch 2/15\n",
      "9s - loss: 2.3083 - acc: 0.1811 - val_loss: 2.2037 - val_acc: 0.2401\n",
      "Epoch 3/15\n",
      "9s - loss: 2.2170 - acc: 0.2194 - val_loss: 2.1047 - val_acc: 0.2723\n",
      "Epoch 4/15\n",
      "9s - loss: 2.1476 - acc: 0.2464 - val_loss: 2.0417 - val_acc: 0.2869\n",
      "Epoch 5/15\n",
      "9s - loss: 2.0949 - acc: 0.2614 - val_loss: 2.0016 - val_acc: 0.2916\n",
      "Epoch 6/15\n",
      "9s - loss: 2.0562 - acc: 0.2785 - val_loss: 1.9831 - val_acc: 0.2980\n",
      "Epoch 7/15\n",
      "9s - loss: 2.0292 - acc: 0.2874 - val_loss: 1.9570 - val_acc: 0.3075\n",
      "Epoch 8/15\n",
      "9s - loss: 2.0019 - acc: 0.2959 - val_loss: 1.9495 - val_acc: 0.3079\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9842 - acc: 0.3017 - val_loss: 1.9372 - val_acc: 0.3105\n",
      "Epoch 10/15\n",
      "9s - loss: 1.9681 - acc: 0.3104 - val_loss: 1.9367 - val_acc: 0.3169\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9374 - acc: 0.3140 - val_loss: 1.9238 - val_acc: 0.3238\n",
      "Epoch 12/15\n",
      "9s - loss: 1.9278 - acc: 0.3258 - val_loss: 1.9242 - val_acc: 0.3195\n",
      "Epoch 13/15\n",
      "9s - loss: 1.9057 - acc: 0.3302 - val_loss: 1.9175 - val_acc: 0.3216\n",
      "Epoch 14/15\n",
      "9s - loss: 1.8952 - acc: 0.3319 - val_loss: 1.9133 - val_acc: 0.3340\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8605 - acc: 0.3422 - val_loss: 1.9136 - val_acc: 0.3280\n",
      "logloss val 1.913626800235329\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4027 - acc: 0.1391 - val_loss: 2.3152 - val_acc: 0.1759\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3034 - acc: 0.1878 - val_loss: 2.2041 - val_acc: 0.2432\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2049 - acc: 0.2235 - val_loss: 2.1163 - val_acc: 0.2690\n",
      "Epoch 4/15\n",
      "21s - loss: 2.1375 - acc: 0.2457 - val_loss: 2.0489 - val_acc: 0.2823\n",
      "Epoch 5/15\n",
      "23s - loss: 2.0907 - acc: 0.2624 - val_loss: 2.0132 - val_acc: 0.2956\n",
      "Epoch 6/15\n",
      "19s - loss: 2.0446 - acc: 0.2772 - val_loss: 1.9903 - val_acc: 0.3059\n",
      "Epoch 7/15\n",
      "23s - loss: 2.0283 - acc: 0.2827 - val_loss: 1.9762 - val_acc: 0.3097\n",
      "Epoch 8/15\n",
      "24s - loss: 1.9969 - acc: 0.2955 - val_loss: 1.9621 - val_acc: 0.3063\n",
      "Epoch 9/15\n",
      "11s - loss: 1.9713 - acc: 0.3055 - val_loss: 1.9576 - val_acc: 0.3123\n",
      "Epoch 10/15\n",
      "11s - loss: 1.9513 - acc: 0.3120 - val_loss: 1.9478 - val_acc: 0.3205\n",
      "Epoch 11/15\n",
      "11s - loss: 1.9410 - acc: 0.3146 - val_loss: 1.9434 - val_acc: 0.3218\n",
      "Epoch 12/15\n",
      "20s - loss: 1.9195 - acc: 0.3215 - val_loss: 1.9356 - val_acc: 0.3175\n",
      "Epoch 13/15\n",
      "15s - loss: 1.9004 - acc: 0.3331 - val_loss: 1.9320 - val_acc: 0.3192\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8858 - acc: 0.3321 - val_loss: 1.9285 - val_acc: 0.3110\n",
      "Epoch 15/15\n",
      "11s - loss: 1.8734 - acc: 0.3379 - val_loss: 1.9228 - val_acc: 0.3209\n",
      "logloss val 1.922783545582387\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4065 - acc: 0.1402 - val_loss: 2.3172 - val_acc: 0.1786\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3086 - acc: 0.1797 - val_loss: 2.1968 - val_acc: 0.2396\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2217 - acc: 0.2140 - val_loss: 2.0961 - val_acc: 0.2808\n",
      "Epoch 4/15\n",
      "20s - loss: 2.1510 - acc: 0.2417 - val_loss: 2.0219 - val_acc: 0.3040\n",
      "Epoch 5/15\n",
      "10s - loss: 2.0954 - acc: 0.2608 - val_loss: 1.9712 - val_acc: 0.3113\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0658 - acc: 0.2705 - val_loss: 1.9440 - val_acc: 0.3220\n",
      "Epoch 7/15\n",
      "11s - loss: 2.0339 - acc: 0.2834 - val_loss: 1.9216 - val_acc: 0.3203\n",
      "Epoch 8/15\n",
      "11s - loss: 2.0116 - acc: 0.2923 - val_loss: 1.9050 - val_acc: 0.3220\n",
      "Epoch 9/15\n",
      "15s - loss: 1.9853 - acc: 0.3028 - val_loss: 1.8904 - val_acc: 0.3298\n",
      "Epoch 10/15\n",
      "11s - loss: 1.9654 - acc: 0.3065 - val_loss: 1.8836 - val_acc: 0.3358\n",
      "Epoch 11/15\n",
      "11s - loss: 1.9525 - acc: 0.3073 - val_loss: 1.8751 - val_acc: 0.3392\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9311 - acc: 0.3201 - val_loss: 1.8681 - val_acc: 0.3371\n",
      "Epoch 13/15\n",
      "10s - loss: 1.9082 - acc: 0.3249 - val_loss: 1.8644 - val_acc: 0.3465\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8941 - acc: 0.3304 - val_loss: 1.8606 - val_acc: 0.3448\n",
      "Epoch 15/15\n",
      "10s - loss: 1.8818 - acc: 0.3355 - val_loss: 1.8556 - val_acc: 0.3444\n",
      "logloss val 1.8556049310643437\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "8s - loss: 2.4207 - acc: 0.1304 - val_loss: 2.3344 - val_acc: 0.1790\n",
      "Epoch 2/15\n",
      "8s - loss: 2.3223 - acc: 0.1768 - val_loss: 2.2094 - val_acc: 0.2417\n",
      "Epoch 3/15\n",
      "8s - loss: 2.2301 - acc: 0.2121 - val_loss: 2.0947 - val_acc: 0.2696\n",
      "Epoch 4/15\n",
      "8s - loss: 2.1561 - acc: 0.2385 - val_loss: 2.0166 - val_acc: 0.2860\n",
      "Epoch 5/15\n",
      "9s - loss: 2.1057 - acc: 0.2554 - val_loss: 1.9766 - val_acc: 0.2988\n",
      "Epoch 6/15\n",
      "8s - loss: 2.0644 - acc: 0.2708 - val_loss: 1.9433 - val_acc: 0.3096\n",
      "Epoch 7/15\n",
      "8s - loss: 2.0318 - acc: 0.2874 - val_loss: 1.9277 - val_acc: 0.3096\n",
      "Epoch 8/15\n",
      "9s - loss: 2.0150 - acc: 0.2931 - val_loss: 1.9070 - val_acc: 0.3250\n",
      "Epoch 9/15\n",
      "8s - loss: 1.9915 - acc: 0.3020 - val_loss: 1.8979 - val_acc: 0.3255\n",
      "Epoch 10/15\n",
      "9s - loss: 1.9669 - acc: 0.3038 - val_loss: 1.8852 - val_acc: 0.3293\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9478 - acc: 0.3164 - val_loss: 1.8854 - val_acc: 0.3293\n",
      "Epoch 12/15\n",
      "9s - loss: 1.9318 - acc: 0.3201 - val_loss: 1.8779 - val_acc: 0.3345\n",
      "Epoch 13/15\n",
      "9s - loss: 1.9078 - acc: 0.3220 - val_loss: 1.8694 - val_acc: 0.3293\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8979 - acc: 0.3273 - val_loss: 1.8666 - val_acc: 0.3306\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8862 - acc: 0.3351 - val_loss: 1.8640 - val_acc: 0.3293\n",
      "logloss val 1.864007601791976\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "18s - loss: 2.4051 - acc: 0.1397 - val_loss: 2.3248 - val_acc: 0.1869\n",
      "Epoch 2/15\n",
      "15s - loss: 2.3113 - acc: 0.1783 - val_loss: 2.2073 - val_acc: 0.2281\n",
      "Epoch 3/15\n",
      "14s - loss: 2.2216 - acc: 0.2165 - val_loss: 2.1005 - val_acc: 0.2659\n",
      "Epoch 4/15\n",
      "16s - loss: 2.1449 - acc: 0.2447 - val_loss: 2.0282 - val_acc: 0.2869\n",
      "Epoch 5/15\n",
      "19s - loss: 2.0942 - acc: 0.2631 - val_loss: 1.9924 - val_acc: 0.3003\n",
      "Epoch 6/15\n",
      "19s - loss: 2.0573 - acc: 0.2746 - val_loss: 1.9750 - val_acc: 0.3084\n",
      "Epoch 7/15\n",
      "15s - loss: 2.0253 - acc: 0.2882 - val_loss: 1.9525 - val_acc: 0.3114\n",
      "Epoch 8/15\n",
      "18s - loss: 2.0046 - acc: 0.2956 - val_loss: 1.9314 - val_acc: 0.3162\n",
      "Epoch 9/15\n",
      "20s - loss: 1.9828 - acc: 0.3013 - val_loss: 1.9240 - val_acc: 0.3153\n",
      "Epoch 10/15\n",
      "18s - loss: 1.9570 - acc: 0.3071 - val_loss: 1.9176 - val_acc: 0.3093\n",
      "Epoch 11/15\n",
      "19s - loss: 1.9431 - acc: 0.3126 - val_loss: 1.9169 - val_acc: 0.3179\n",
      "Epoch 12/15\n",
      "20s - loss: 1.9187 - acc: 0.3220 - val_loss: 1.9024 - val_acc: 0.3235\n",
      "Epoch 13/15\n",
      "20s - loss: 1.9047 - acc: 0.3273 - val_loss: 1.8965 - val_acc: 0.3222\n",
      "Epoch 14/15\n",
      "22s - loss: 1.8869 - acc: 0.3290 - val_loss: 1.8927 - val_acc: 0.3222\n",
      "Epoch 15/15\n",
      "52s - loss: 1.8732 - acc: 0.3404 - val_loss: 1.8996 - val_acc: 0.3286\n",
      "logloss val 1.8995897675695577\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "15s - loss: 2.4082 - acc: 0.1382 - val_loss: 2.3331 - val_acc: 0.1853\n",
      "Epoch 2/15\n",
      "27s - loss: 2.3141 - acc: 0.1834 - val_loss: 2.2227 - val_acc: 0.2154\n",
      "Epoch 3/15\n",
      "37s - loss: 2.2218 - acc: 0.2098 - val_loss: 2.1348 - val_acc: 0.2494\n",
      "Epoch 4/15\n",
      "22s - loss: 2.1463 - acc: 0.2386 - val_loss: 2.0683 - val_acc: 0.2734\n",
      "Epoch 5/15\n",
      "26s - loss: 2.0871 - acc: 0.2647 - val_loss: 2.0349 - val_acc: 0.2855\n",
      "Epoch 6/15\n",
      "9s - loss: 2.0531 - acc: 0.2770 - val_loss: 2.0157 - val_acc: 0.2876\n",
      "Epoch 7/15\n",
      "8s - loss: 2.0246 - acc: 0.2863 - val_loss: 2.0006 - val_acc: 0.2954\n",
      "Epoch 8/15\n",
      "8s - loss: 1.9942 - acc: 0.2979 - val_loss: 1.9931 - val_acc: 0.2954\n",
      "Epoch 9/15\n",
      "8s - loss: 1.9728 - acc: 0.3048 - val_loss: 1.9770 - val_acc: 0.2988\n",
      "Epoch 10/15\n",
      "8s - loss: 1.9501 - acc: 0.3118 - val_loss: 1.9616 - val_acc: 0.3087\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9274 - acc: 0.3210 - val_loss: 1.9632 - val_acc: 0.3027\n",
      "Epoch 12/15\n",
      "9s - loss: 1.9156 - acc: 0.3270 - val_loss: 1.9595 - val_acc: 0.3018\n",
      "Epoch 13/15\n",
      "11s - loss: 1.9002 - acc: 0.3301 - val_loss: 1.9528 - val_acc: 0.3018\n",
      "Epoch 14/15\n",
      "11s - loss: 1.8756 - acc: 0.3367 - val_loss: 1.9519 - val_acc: 0.3095\n",
      "Epoch 15/15\n",
      "15s - loss: 1.8592 - acc: 0.3424 - val_loss: 1.9616 - val_acc: 0.3065\n",
      "logloss val 1.9616145966278256\n",
      "average logloss val 1.9516869684268277\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "17s - loss: 2.3980 - acc: 0.1405 - val_loss: 2.3448 - val_acc: 0.1627\n",
      "Epoch 2/15\n",
      "13s - loss: 2.2777 - acc: 0.1921 - val_loss: 2.2755 - val_acc: 0.1884\n",
      "Epoch 3/15\n",
      "12s - loss: 2.1873 - acc: 0.2211 - val_loss: 2.2214 - val_acc: 0.2162\n",
      "Epoch 4/15\n",
      "13s - loss: 2.1165 - acc: 0.2518 - val_loss: 2.1956 - val_acc: 0.2277\n",
      "Epoch 5/15\n",
      "16s - loss: 2.0770 - acc: 0.2675 - val_loss: 2.1562 - val_acc: 0.2457\n",
      "Epoch 6/15\n",
      "14s - loss: 2.0313 - acc: 0.2841 - val_loss: 2.1575 - val_acc: 0.2389\n",
      "Epoch 7/15\n",
      "13s - loss: 2.0043 - acc: 0.2906 - val_loss: 2.1484 - val_acc: 0.2500\n",
      "Epoch 8/15\n",
      "11s - loss: 1.9773 - acc: 0.3049 - val_loss: 2.1298 - val_acc: 0.2594\n",
      "Epoch 9/15\n",
      "15s - loss: 1.9613 - acc: 0.3079 - val_loss: 2.1212 - val_acc: 0.2543\n",
      "Epoch 10/15\n",
      "13s - loss: 1.9359 - acc: 0.3166 - val_loss: 2.1155 - val_acc: 0.2646\n",
      "Epoch 11/15\n",
      "13s - loss: 1.9163 - acc: 0.3233 - val_loss: 2.1168 - val_acc: 0.2594\n",
      "Epoch 12/15\n",
      "19s - loss: 1.9008 - acc: 0.3298 - val_loss: 2.1273 - val_acc: 0.2573\n",
      "Epoch 13/15\n",
      "13s - loss: 1.8833 - acc: 0.3377 - val_loss: 2.1116 - val_acc: 0.2658\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8634 - acc: 0.3416 - val_loss: 2.1154 - val_acc: 0.2697\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8510 - acc: 0.3494 - val_loss: 2.1139 - val_acc: 0.2624\n",
      "logloss val 2.1139271584377712\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n",
      "142s - loss: 2.4030 - acc: 0.1436 - val_loss: 2.3394 - val_acc: 0.1775\n",
      "Epoch 2/15\n",
      "66s - loss: 2.2952 - acc: 0.1870 - val_loss: 2.2417 - val_acc: 0.2122\n",
      "Epoch 3/15\n",
      "11s - loss: 2.1991 - acc: 0.2240 - val_loss: 2.1562 - val_acc: 0.2460\n",
      "Epoch 4/15\n",
      "38s - loss: 2.1351 - acc: 0.2463 - val_loss: 2.1046 - val_acc: 0.2636\n",
      "Epoch 5/15\n",
      "33s - loss: 2.0750 - acc: 0.2661 - val_loss: 2.0713 - val_acc: 0.2718\n",
      "Epoch 6/15\n",
      "33s - loss: 2.0394 - acc: 0.2793 - val_loss: 2.0497 - val_acc: 0.2833\n",
      "Epoch 7/15\n",
      "34s - loss: 2.0141 - acc: 0.2858 - val_loss: 2.0385 - val_acc: 0.2880\n",
      "Epoch 8/15\n",
      "34s - loss: 1.9854 - acc: 0.2986 - val_loss: 2.0314 - val_acc: 0.2923\n",
      "Epoch 9/15\n",
      "33s - loss: 1.9676 - acc: 0.3074 - val_loss: 2.0222 - val_acc: 0.2979\n",
      "Epoch 10/15\n",
      "32s - loss: 1.9445 - acc: 0.3135 - val_loss: 2.0157 - val_acc: 0.2953\n",
      "Epoch 11/15\n",
      "31s - loss: 1.9235 - acc: 0.3181 - val_loss: 2.0033 - val_acc: 0.2962\n",
      "Epoch 12/15\n",
      "17s - loss: 1.9079 - acc: 0.3288 - val_loss: 2.0010 - val_acc: 0.2962\n",
      "Epoch 13/15\n",
      "11s - loss: 1.8950 - acc: 0.3276 - val_loss: 1.9920 - val_acc: 0.3043\n",
      "Epoch 14/15\n",
      "21s - loss: 1.8726 - acc: 0.3386 - val_loss: 1.9921 - val_acc: 0.3030\n",
      "Epoch 15/15\n",
      "36s - loss: 1.8515 - acc: 0.3442 - val_loss: 1.9835 - val_acc: 0.3052\n",
      "logloss val 1.9834564425154204\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/15\n",
      "9s - loss: 2.4094 - acc: 0.1360 - val_loss: 2.3521 - val_acc: 0.1517\n",
      "Epoch 2/15\n",
      "9s - loss: 2.3111 - acc: 0.1862 - val_loss: 2.2585 - val_acc: 0.2027\n",
      "Epoch 3/15\n",
      "8s - loss: 2.2102 - acc: 0.2187 - val_loss: 2.1748 - val_acc: 0.2362\n",
      "Epoch 4/15\n",
      "8s - loss: 2.1295 - acc: 0.2488 - val_loss: 2.1195 - val_acc: 0.2486\n",
      "Epoch 5/15\n",
      "8s - loss: 2.0759 - acc: 0.2665 - val_loss: 2.1033 - val_acc: 0.2610\n",
      "Epoch 6/15\n",
      "8s - loss: 2.0379 - acc: 0.2818 - val_loss: 2.0900 - val_acc: 0.2679\n",
      "Epoch 7/15\n",
      "8s - loss: 2.0092 - acc: 0.2903 - val_loss: 2.0759 - val_acc: 0.2726\n",
      "Epoch 8/15\n",
      "8s - loss: 1.9877 - acc: 0.2984 - val_loss: 2.0554 - val_acc: 0.2773\n",
      "Epoch 9/15\n",
      "9s - loss: 1.9625 - acc: 0.3059 - val_loss: 2.0656 - val_acc: 0.2748\n",
      "Epoch 10/15\n",
      "8s - loss: 1.9362 - acc: 0.3133 - val_loss: 2.0415 - val_acc: 0.2880\n",
      "Epoch 11/15\n",
      "9s - loss: 1.9254 - acc: 0.3234 - val_loss: 2.0373 - val_acc: 0.2859\n",
      "Epoch 12/15\n",
      "12s - loss: 1.9114 - acc: 0.3249 - val_loss: 2.0439 - val_acc: 0.2885\n",
      "Epoch 13/15\n",
      "8s - loss: 1.8903 - acc: 0.3354 - val_loss: 2.0424 - val_acc: 0.2872\n",
      "Epoch 14/15\n",
      "8s - loss: 1.8738 - acc: 0.3360 - val_loss: 2.0369 - val_acc: 0.2932\n",
      "Epoch 15/15\n",
      "9s - loss: 1.8494 - acc: 0.3451 - val_loss: 2.0337 - val_acc: 0.2958\n",
      "logloss val 2.033680709681693\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/15\n",
      "10s - loss: 2.4073 - acc: 0.1441 - val_loss: 2.3338 - val_acc: 0.1788\n",
      "Epoch 2/15\n",
      "10s - loss: 2.3129 - acc: 0.1792 - val_loss: 2.2200 - val_acc: 0.2243\n",
      "Epoch 3/15\n",
      "10s - loss: 2.2233 - acc: 0.2179 - val_loss: 2.1306 - val_acc: 0.2629\n",
      "Epoch 4/15\n",
      "10s - loss: 2.1411 - acc: 0.2438 - val_loss: 2.0845 - val_acc: 0.2706\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0882 - acc: 0.2611 - val_loss: 2.0379 - val_acc: 0.2822\n",
      "Epoch 6/15\n",
      "12s - loss: 2.0532 - acc: 0.2736 - val_loss: 2.0216 - val_acc: 0.2877\n",
      "Epoch 7/15\n",
      "18s - loss: 2.0112 - acc: 0.2864 - val_loss: 2.0074 - val_acc: 0.3010\n",
      "Epoch 8/15\n",
      "14s - loss: 1.9934 - acc: 0.2932 - val_loss: 1.9964 - val_acc: 0.2963\n",
      "Epoch 9/15\n",
      "14s - loss: 1.9716 - acc: 0.3018 - val_loss: 1.9913 - val_acc: 0.3006\n",
      "Epoch 10/15\n",
      "14s - loss: 1.9509 - acc: 0.3167 - val_loss: 1.9861 - val_acc: 0.3032\n",
      "Epoch 11/15\n",
      "15s - loss: 1.9312 - acc: 0.3189 - val_loss: 1.9808 - val_acc: 0.3015\n",
      "Epoch 12/15\n",
      "12s - loss: 1.9137 - acc: 0.3241 - val_loss: 1.9783 - val_acc: 0.2997\n",
      "Epoch 13/15\n",
      "10s - loss: 1.8927 - acc: 0.3290 - val_loss: 1.9747 - val_acc: 0.3070\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8764 - acc: 0.3353 - val_loss: 1.9754 - val_acc: 0.3105\n",
      "Epoch 15/15\n",
      "10s - loss: 1.8705 - acc: 0.3359 - val_loss: 1.9692 - val_acc: 0.3139\n",
      "logloss val 1.9691809294649478\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4116 - acc: 0.1423 - val_loss: 2.3413 - val_acc: 0.1844\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3237 - acc: 0.1744 - val_loss: 2.2260 - val_acc: 0.2247\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2240 - acc: 0.2112 - val_loss: 2.1063 - val_acc: 0.2736\n",
      "Epoch 4/15\n",
      "18s - loss: 2.1465 - acc: 0.2403 - val_loss: 2.0399 - val_acc: 0.2869\n",
      "Epoch 5/15\n",
      "18s - loss: 2.0857 - acc: 0.2625 - val_loss: 2.0024 - val_acc: 0.2955\n",
      "Epoch 6/15\n",
      "18s - loss: 2.0598 - acc: 0.2737 - val_loss: 1.9826 - val_acc: 0.2933\n",
      "Epoch 7/15\n",
      "17s - loss: 2.0170 - acc: 0.2871 - val_loss: 1.9597 - val_acc: 0.3049\n",
      "Epoch 8/15\n",
      "20s - loss: 2.0032 - acc: 0.2929 - val_loss: 1.9488 - val_acc: 0.3105\n",
      "Epoch 9/15\n",
      "21s - loss: 1.9762 - acc: 0.3041 - val_loss: 1.9447 - val_acc: 0.3087\n",
      "Epoch 10/15\n",
      "19s - loss: 1.9625 - acc: 0.3080 - val_loss: 1.9258 - val_acc: 0.3143\n",
      "Epoch 11/15\n",
      "18s - loss: 1.9394 - acc: 0.3167 - val_loss: 1.9216 - val_acc: 0.3173\n",
      "Epoch 12/15\n",
      "19s - loss: 1.9163 - acc: 0.3228 - val_loss: 1.9182 - val_acc: 0.3148\n",
      "Epoch 13/15\n",
      "23s - loss: 1.8979 - acc: 0.3275 - val_loss: 1.9150 - val_acc: 0.3173\n",
      "Epoch 14/15\n",
      "18s - loss: 1.8917 - acc: 0.3337 - val_loss: 1.9131 - val_acc: 0.3199\n",
      "Epoch 15/15\n",
      "19s - loss: 1.8637 - acc: 0.3429 - val_loss: 1.9088 - val_acc: 0.3225\n",
      "logloss val 1.9088091854050782\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/15\n",
      "15s - loss: 2.4156 - acc: 0.1379 - val_loss: 2.3403 - val_acc: 0.1759\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3164 - acc: 0.1798 - val_loss: 2.2286 - val_acc: 0.2115\n",
      "Epoch 3/15\n",
      "11s - loss: 2.2315 - acc: 0.2090 - val_loss: 2.1455 - val_acc: 0.2634\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1571 - acc: 0.2399 - val_loss: 2.0751 - val_acc: 0.2831\n",
      "Epoch 5/15\n",
      "17s - loss: 2.0976 - acc: 0.2634 - val_loss: 2.0355 - val_acc: 0.2956\n",
      "Epoch 6/15\n",
      "10s - loss: 2.0590 - acc: 0.2765 - val_loss: 2.0019 - val_acc: 0.3033\n",
      "Epoch 7/15\n",
      "14s - loss: 2.0294 - acc: 0.2836 - val_loss: 1.9791 - val_acc: 0.3145\n",
      "Epoch 8/15\n",
      "10s - loss: 1.9996 - acc: 0.2941 - val_loss: 1.9664 - val_acc: 0.3162\n",
      "Epoch 9/15\n",
      "12s - loss: 1.9730 - acc: 0.3019 - val_loss: 1.9568 - val_acc: 0.3235\n",
      "Epoch 10/15\n",
      "13s - loss: 1.9580 - acc: 0.3089 - val_loss: 1.9505 - val_acc: 0.3209\n",
      "Epoch 11/15\n",
      "10s - loss: 1.9401 - acc: 0.3151 - val_loss: 1.9415 - val_acc: 0.3248\n",
      "Epoch 12/15\n",
      "10s - loss: 1.9140 - acc: 0.3243 - val_loss: 1.9393 - val_acc: 0.3265\n",
      "Epoch 13/15\n",
      "14s - loss: 1.9021 - acc: 0.3279 - val_loss: 1.9319 - val_acc: 0.3273\n",
      "Epoch 14/15\n",
      "10s - loss: 1.8836 - acc: 0.3362 - val_loss: 1.9311 - val_acc: 0.3200\n",
      "Epoch 15/15\n",
      "13s - loss: 1.8678 - acc: 0.3408 - val_loss: 1.9298 - val_acc: 0.3252\n",
      "logloss val 1.929815106827435\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/15\n",
      "23s - loss: 2.3961 - acc: 0.1496 - val_loss: 2.3005 - val_acc: 0.2027\n",
      "Epoch 2/15\n",
      "19s - loss: 2.2944 - acc: 0.1900 - val_loss: 2.1857 - val_acc: 0.2422\n",
      "Epoch 3/15\n",
      "21s - loss: 2.2013 - acc: 0.2240 - val_loss: 2.0809 - val_acc: 0.2976\n",
      "Epoch 4/15\n",
      "20s - loss: 2.1331 - acc: 0.2515 - val_loss: 2.0113 - val_acc: 0.3053\n",
      "Epoch 5/15\n",
      "20s - loss: 2.0803 - acc: 0.2665 - val_loss: 1.9527 - val_acc: 0.3280\n",
      "Epoch 6/15\n",
      "20s - loss: 2.0489 - acc: 0.2787 - val_loss: 1.9305 - val_acc: 0.3375\n",
      "Epoch 7/15\n",
      "21s - loss: 2.0166 - acc: 0.2878 - val_loss: 1.9105 - val_acc: 0.3340\n",
      "Epoch 8/15\n",
      "21s - loss: 1.9958 - acc: 0.2932 - val_loss: 1.8948 - val_acc: 0.3371\n",
      "Epoch 9/15\n",
      "23s - loss: 1.9774 - acc: 0.2987 - val_loss: 1.8862 - val_acc: 0.3435\n",
      "Epoch 10/15\n",
      "21s - loss: 1.9509 - acc: 0.3132 - val_loss: 1.8746 - val_acc: 0.3422\n",
      "Epoch 11/15\n",
      "51s - loss: 1.9323 - acc: 0.3176 - val_loss: 1.8711 - val_acc: 0.3413\n",
      "Epoch 12/15\n",
      "37s - loss: 1.9166 - acc: 0.3196 - val_loss: 1.8633 - val_acc: 0.3452\n",
      "Epoch 13/15\n",
      "52s - loss: 1.9000 - acc: 0.3274 - val_loss: 1.8583 - val_acc: 0.3431\n",
      "Epoch 14/15\n",
      "52s - loss: 1.8804 - acc: 0.3292 - val_loss: 1.8550 - val_acc: 0.3439\n",
      "Epoch 15/15\n",
      "44s - loss: 1.8660 - acc: 0.3415 - val_loss: 1.8516 - val_acc: 0.3495\n",
      "logloss val 1.8515822320661481\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/15\n",
      "112s - loss: 2.4031 - acc: 0.1430 - val_loss: 2.3167 - val_acc: 0.1997\n",
      "Epoch 2/15\n",
      "79s - loss: 2.3002 - acc: 0.1869 - val_loss: 2.1776 - val_acc: 0.2404\n",
      "Epoch 3/15\n",
      "43s - loss: 2.2109 - acc: 0.2191 - val_loss: 2.0756 - val_acc: 0.2885\n",
      "Epoch 4/15\n",
      "11s - loss: 2.1438 - acc: 0.2441 - val_loss: 2.0056 - val_acc: 0.2971\n",
      "Epoch 5/15\n",
      "11s - loss: 2.0858 - acc: 0.2643 - val_loss: 1.9695 - val_acc: 0.3023\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0526 - acc: 0.2781 - val_loss: 1.9384 - val_acc: 0.3177\n",
      "Epoch 7/15\n",
      "11s - loss: 2.0379 - acc: 0.2835 - val_loss: 1.9221 - val_acc: 0.3259\n",
      "Epoch 8/15\n",
      "11s - loss: 1.9973 - acc: 0.2989 - val_loss: 1.9065 - val_acc: 0.3315\n",
      "Epoch 9/15\n",
      "11s - loss: 1.9846 - acc: 0.2990 - val_loss: 1.8997 - val_acc: 0.3405\n",
      "Epoch 10/15\n",
      "11s - loss: 1.9580 - acc: 0.3116 - val_loss: 1.8843 - val_acc: 0.3383\n",
      "Epoch 11/15\n",
      "19s - loss: 1.9372 - acc: 0.3179 - val_loss: 1.8830 - val_acc: 0.3293\n",
      "Epoch 12/15\n",
      "28s - loss: 1.9267 - acc: 0.3198 - val_loss: 1.8721 - val_acc: 0.3358\n",
      "Epoch 13/15\n",
      "15s - loss: 1.9067 - acc: 0.3288 - val_loss: 1.8691 - val_acc: 0.3482\n",
      "Epoch 14/15\n",
      "22s - loss: 1.8797 - acc: 0.3309 - val_loss: 1.8645 - val_acc: 0.3392\n",
      "Epoch 15/15\n",
      "30s - loss: 1.8703 - acc: 0.3392 - val_loss: 1.8608 - val_acc: 0.3340\n",
      "logloss val 1.8608277279063068\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/15\n",
      "10s - loss: 2.4072 - acc: 0.1425 - val_loss: 2.3258 - val_acc: 0.1946\n",
      "Epoch 2/15\n",
      "10s - loss: 2.3050 - acc: 0.1869 - val_loss: 2.1946 - val_acc: 0.2393\n",
      "Epoch 3/15\n",
      "14s - loss: 2.2108 - acc: 0.2209 - val_loss: 2.0888 - val_acc: 0.2668\n",
      "Epoch 4/15\n",
      "8s - loss: 2.1446 - acc: 0.2440 - val_loss: 2.0201 - val_acc: 0.2942\n",
      "Epoch 5/15\n",
      "8s - loss: 2.0950 - acc: 0.2638 - val_loss: 1.9940 - val_acc: 0.2985\n",
      "Epoch 6/15\n",
      "8s - loss: 2.0554 - acc: 0.2766 - val_loss: 1.9656 - val_acc: 0.3046\n",
      "Epoch 7/15\n",
      "9s - loss: 2.0270 - acc: 0.2854 - val_loss: 1.9549 - val_acc: 0.3020\n",
      "Epoch 8/15\n",
      "9s - loss: 2.0000 - acc: 0.2972 - val_loss: 1.9448 - val_acc: 0.3136\n",
      "Epoch 9/15\n",
      "8s - loss: 1.9840 - acc: 0.3029 - val_loss: 1.9210 - val_acc: 0.3119\n",
      "Epoch 10/15\n",
      "8s - loss: 1.9609 - acc: 0.3077 - val_loss: 1.9147 - val_acc: 0.3174\n",
      "Epoch 11/15\n",
      "8s - loss: 1.9391 - acc: 0.3152 - val_loss: 1.9098 - val_acc: 0.3239\n",
      "Epoch 12/15\n",
      "8s - loss: 1.9188 - acc: 0.3237 - val_loss: 1.9012 - val_acc: 0.3235\n",
      "Epoch 13/15\n",
      "8s - loss: 1.9084 - acc: 0.3276 - val_loss: 1.8997 - val_acc: 0.3226\n",
      "Epoch 14/15\n",
      "8s - loss: 1.8766 - acc: 0.3341 - val_loss: 1.9086 - val_acc: 0.3209\n",
      "Epoch 15/15\n",
      "8s - loss: 1.8703 - acc: 0.3412 - val_loss: 1.8936 - val_acc: 0.3265\n",
      "logloss val 1.893629152897451\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/15\n",
      "71s - loss: 2.3990 - acc: 0.1455 - val_loss: 2.3275 - val_acc: 0.1909\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3095 - acc: 0.1800 - val_loss: 2.2272 - val_acc: 0.2141\n",
      "Epoch 3/15\n",
      "12s - loss: 2.2171 - acc: 0.2123 - val_loss: 2.1385 - val_acc: 0.2648\n",
      "Epoch 4/15\n",
      "12s - loss: 2.1455 - acc: 0.2398 - val_loss: 2.0729 - val_acc: 0.2794\n",
      "Epoch 5/15\n",
      "12s - loss: 2.0980 - acc: 0.2573 - val_loss: 2.0402 - val_acc: 0.2859\n",
      "Epoch 6/15\n",
      "11s - loss: 2.0533 - acc: 0.2768 - val_loss: 2.0255 - val_acc: 0.2941\n",
      "Epoch 7/15\n",
      "12s - loss: 2.0248 - acc: 0.2831 - val_loss: 2.0164 - val_acc: 0.2992\n",
      "Epoch 8/15\n",
      "12s - loss: 2.0014 - acc: 0.2928 - val_loss: 1.9899 - val_acc: 0.3005\n",
      "Epoch 9/15\n",
      "12s - loss: 1.9726 - acc: 0.3058 - val_loss: 1.9931 - val_acc: 0.2919\n",
      "Epoch 10/15\n",
      "20s - loss: 1.9547 - acc: 0.3113 - val_loss: 1.9765 - val_acc: 0.3052\n",
      "Epoch 11/15\n",
      "33s - loss: 1.9361 - acc: 0.3177 - val_loss: 1.9607 - val_acc: 0.3065\n",
      "Epoch 12/15\n",
      "38s - loss: 1.9154 - acc: 0.3213 - val_loss: 1.9608 - val_acc: 0.3061\n",
      "Epoch 13/15\n",
      "34s - loss: 1.9051 - acc: 0.3253 - val_loss: 1.9652 - val_acc: 0.3022\n",
      "Epoch 14/15\n",
      "37s - loss: 1.8727 - acc: 0.3339 - val_loss: 1.9875 - val_acc: 0.3044\n",
      "Epoch 15/15\n",
      "34s - loss: 1.8763 - acc: 0.3357 - val_loss: 1.9643 - val_acc: 0.3014\n",
      "logloss val 1.9642904727757362\n",
      "average logloss val 1.950919911797799\n",
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/15\n",
      "13s - loss: 2.4127 - acc: 0.1383 - val_loss: 2.3546 - val_acc: 0.1571\n",
      "Epoch 2/15\n",
      "13s - loss: 2.2983 - acc: 0.1881 - val_loss: 2.2893 - val_acc: 0.1875\n",
      "Epoch 3/15\n",
      "13s - loss: 2.1908 - acc: 0.2265 - val_loss: 2.2163 - val_acc: 0.2256\n",
      "Epoch 4/15\n",
      "13s - loss: 2.1210 - acc: 0.2536 - val_loss: 2.1760 - val_acc: 0.2337\n",
      "Epoch 5/15\n",
      "12s - loss: 2.0699 - acc: 0.2684 - val_loss: 2.1502 - val_acc: 0.2496\n",
      "Epoch 6/15\n",
      "76s - loss: 2.0352 - acc: 0.2843 - val_loss: 2.1438 - val_acc: 0.2479\n",
      "Epoch 7/15\n",
      "293s - loss: 2.0084 - acc: 0.2943 - val_loss: 2.1403 - val_acc: 0.2500\n",
      "Epoch 8/15\n",
      "303s - loss: 1.9745 - acc: 0.3045 - val_loss: 2.1267 - val_acc: 0.2620\n",
      "Epoch 9/15\n",
      "314s - loss: 1.9541 - acc: 0.3106 - val_loss: 2.1281 - val_acc: 0.2564\n",
      "Epoch 10/15\n",
      "301s - loss: 1.9373 - acc: 0.3184 - val_loss: 2.1145 - val_acc: 0.2646\n",
      "Epoch 11/15\n",
      "286s - loss: 1.9176 - acc: 0.3236 - val_loss: 2.1096 - val_acc: 0.2646\n",
      "Epoch 12/15\n",
      "297s - loss: 1.8970 - acc: 0.3347 - val_loss: 2.1141 - val_acc: 0.2607\n",
      "Epoch 13/15\n",
      "300s - loss: 1.8774 - acc: 0.3372 - val_loss: 2.1186 - val_acc: 0.2577\n",
      "Epoch 14/15\n",
      "302s - loss: 1.8651 - acc: 0.3390 - val_loss: 2.1092 - val_acc: 0.2624\n",
      "Epoch 15/15\n",
      "304s - loss: 1.8447 - acc: 0.3482 - val_loss: 2.1123 - val_acc: 0.2671\n",
      "logloss val 2.112255678748176\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-76d669875bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                              \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                              \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_with\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                              )\n\u001b[1;32m     35\u001b[0m         scores_val_with = model.predict_generator(generator=batch_generatorp(X_val_with, 512, False), \n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                                  verbose=0)\n\u001b[0m\u001b[1;32m   1477\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         return self._test_loop(f, ins,\n\u001b[1;32m   1140\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                                verbose=verbose)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;31m# do not slice the training phase flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mslice_X\u001b[0;34m(X, start, stop)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def with_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(200, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(150, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "\n",
    "dummy_y_with = np_utils.to_categorical(y_train_total_with)\n",
    "for i in range(8):\n",
    "    kf = StratifiedKFold(y_train_total_with,n_folds = 10,random_state = i)\n",
    "    score_list_with=[]\n",
    "    val_loss_list_with = []\n",
    "    for index,(train, test) in enumerate(kf):\n",
    "        X_train_with = X_train_total_with[train]\n",
    "        y_train_with = dummy_y_with[train]\n",
    "        X_val_with = X_train_total_with[test]\n",
    "        y_val_with = dummy_y_with[test]\n",
    "        #print(X_val.shape)\n",
    "        print('*****************************************************')\n",
    "        print('{}_fold'.format(index))\n",
    "        model=with_model(X_train_total_with.shape[1])\n",
    "        fit= model.fit_generator(generator=batch_generator(X_train_with, y_train_with, 512, True),\n",
    "                             nb_epoch=15,\n",
    "                             samples_per_epoch=23000,\n",
    "                             validation_data=(X_val_with.todense(), y_val_with), verbose=2\n",
    "                             )\n",
    "        scores_val_with = model.predict_generator(generator=batch_generatorp(X_val_with, 512, False), \n",
    "                                             val_samples=X_val_with.shape[0])\n",
    "        scores_with = model.predict_generator(generator=batch_generatorp(X_test_total_with, 512, False), \n",
    "                                         val_samples=X_test_total_with.shape[0])\n",
    "        score_list_with.append(scores_with)\n",
    "        val_loss = log_loss(y_val_with, scores_val_with)\n",
    "        val_loss_list_with.append(val_loss)\n",
    "        print('logloss val {}'.format(val_loss))\n",
    "\n",
    "    for index,i in enumerate(val_loss_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    val_loss_ave_with = sumi/len(val_loss_list_with)\n",
    "    print('average logloss val {}'.format(val_loss_ave_with))\n",
    "    for index,i in enumerate(score_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    score_ave_with = sumi/len(score_list_with)\n",
    "    pred_with = pd.DataFrame(score_ave_with, index = gender_age_test_with.index, columns=targetencoder.classes_)\n",
    "    pred_with.to_csv('nnet_with_200relu150relusoftmax{}.csv'.format(val_loss_ave_with))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.342307\ttest-merror:0.804376\n",
      "[1]\ttrain-merror:0.207808\ttest-merror:0.797941\n",
      "[2]\ttrain-merror:0.13466\ttest-merror:0.789575\n",
      "[3]\ttrain-merror:0.088218\ttest-merror:0.781424\n",
      "[4]\ttrain-merror:0.063281\ttest-merror:0.773059\n",
      "logloss val 2.3439024316809403\n"
     ]
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_with)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':100,'eta':0.1,'silent':1,'objective':'multi:softprob','nthread':2,'num_class':12}\n",
    "num_round = 5\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0180472176683\n",
      "newton-cg\n",
      "1.99455721395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_with)\n",
    "#lr grid search\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['newton-cg']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_without= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.0180472176683,multi_class='multinomial',solver='newton-cg')\n",
    "lr.fit(X_train_total_with,y_train_total_with)\n",
    "score_ave_with_lr = lr.predict_proba(X_test_total_with)\n",
    "pred_with_lr = pd.DataFrame(score_ave_with_lr, \n",
    "                            index = gender_age_test_with.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_with_lr.to_csv('lr_with_result{}.csv'.format(val_loss_ave_with))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset II: device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_total_without = targetencoder.transform(gender_age_train_without_temp.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Device without eventsI: Naive Bayes, Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204.50354026\n",
      "2.42330723892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#NB grid search\n",
    "nbc = MultinomialNB()\n",
    "alpha_value = np.logspace(-3,4,100)\n",
    "clf = GridSearchCV(estimator=nbc,param_grid = dict(alpha=alpha_value),scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.alpha)\n",
    "print(-clf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0744380301325\n",
      "lbfgs\n",
      "2.39019928895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#lr grid search\n",
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_without)\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['lbfgs']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_without= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_without)\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(C=0.02,multi_class='multinomial',solver='newton-cg')\n",
    "lr = LogisticRegression(C=0.0744380301325,multi_class='multinomial',solver='lbfgs')\n",
    "lr.fit(X_train_total_without,y_train_total_without)\n",
    "score_ave_without_lr = lr.predict_proba(X_test_total_without)\n",
    "pred_without_lr = pd.DataFrame(score_ave_without_lr, \n",
    "                            index = gender_age_test_without.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_without_lr.to_csv('lr_without_result{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\\nscore_list_without=[]\\nval_loss_list_without = []\\nfor index,(train, test) in enumerate(kf):\\n    X_train_without = X_train_total_without[train]\\n    y_train_without = y_train_total_without[train]\\n    X_val_without = X_train_total_without[test]\\n    y_val_without = y_train_total_without[test]\\n    print('*****************************************************')\\n    print('{}_fold'.format(index))\\n    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\\n    lr.fit(X_train_without,y_train_without)\\n    scores_val_without = lr.predict_proba(X_val_without)\\n    val_loss = log_loss(y_val_without, scores_val_without)\\n    val_loss_list_without.append(val_loss)\\n    print('logloss val {}'.format(val_loss))\\n    \\n    scores_without = lr.predict_proba(X_test_total_without)\\n    score_list_without.append(scores_without)\\n    \\nfor index,i in enumerate(val_loss_list_without):\\n    if(index==0):\\n        sumi = i\\n    else:\\n        sumi = i+sumi\\nval_loss_ave_without = sumi/len(score_list_without)\\nprint('average logloss val {}'.format(val_loss_ave_without))\\nfor index,i in enumerate(score_list_without):\\n    if(index==0):\\n        sumi = i\\n    else:\\n        sumi = i+sumi\\nscore_ave_without = sumi/len(score_list_without)\\npred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\n",
    "score_list_without=[]\n",
    "val_loss_list_without = []\n",
    "for index,(train, test) in enumerate(kf):\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = y_train_total_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = y_train_total_without[test]\n",
    "    print('*****************************************************')\n",
    "    print('{}_fold'.format(index))\n",
    "    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\n",
    "    lr.fit(X_train_without,y_train_without)\n",
    "    scores_val_without = lr.predict_proba(X_val_without)\n",
    "    val_loss = log_loss(y_val_without, scores_val_without)\n",
    "    val_loss_list_without.append(val_loss)\n",
    "    print('logloss val {}'.format(val_loss))\n",
    "    \n",
    "    scores_without = lr.predict_proba(X_test_total_without)\n",
    "    score_list_without.append(scores_without)\n",
    "    \n",
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(score_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without eventsII: Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "0_fold\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/keras/engine/training.py:1460: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 2.4629 - acc: 0.1261 - val_loss: 2.4279 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4256 - acc: 0.1298 - val_loss: 2.4264 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4268 - acc: 0.1271 - val_loss: 2.4253 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4219 - acc: 0.1285 - val_loss: 2.4250 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4209 - acc: 0.1289 - val_loss: 2.4248 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4194 - acc: 0.1308 - val_loss: 2.4247 - val_acc: 0.1293\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4163 - acc: 0.1341 - val_loss: 2.4246 - val_acc: 0.1342\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4120 - acc: 0.1401 - val_loss: 2.4236 - val_acc: 0.1407\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4066 - acc: 0.1465 - val_loss: 2.4183 - val_acc: 0.1399\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4017 - acc: 0.1440 - val_loss: 2.4161 - val_acc: 0.1390\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3980 - acc: 0.1443 - val_loss: 2.4128 - val_acc: 0.1402\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3968 - acc: 0.1431 - val_loss: 2.4130 - val_acc: 0.1431\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3945 - acc: 0.1450 - val_loss: 2.4107 - val_acc: 0.1453\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3915 - acc: 0.1491 - val_loss: 2.4097 - val_acc: 0.1513\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3920 - acc: 0.1489 - val_loss: 2.4081 - val_acc: 0.1512\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3887 - acc: 0.1519 - val_loss: 2.4084 - val_acc: 0.1494\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3877 - acc: 0.1501 - val_loss: 2.4071 - val_acc: 0.1504\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3863 - acc: 0.1521 - val_loss: 2.4079 - val_acc: 0.1512\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3848 - acc: 0.1529 - val_loss: 2.4072 - val_acc: 0.1474\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3841 - acc: 0.1529 - val_loss: 2.4065 - val_acc: 0.1505\n",
      "logloss val 2.406513364236188\n",
      "*****************************************************\n",
      "1_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4639 - acc: 0.1261 - val_loss: 2.4276 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4269 - acc: 0.1280 - val_loss: 2.4253 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4235 - acc: 0.1282 - val_loss: 2.4235 - val_acc: 0.1294\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4233 - acc: 0.1288 - val_loss: 2.4219 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4215 - acc: 0.1292 - val_loss: 2.4213 - val_acc: 0.1284\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4191 - acc: 0.1310 - val_loss: 2.4207 - val_acc: 0.1307\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4194 - acc: 0.1319 - val_loss: 2.4199 - val_acc: 0.1291\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4168 - acc: 0.1325 - val_loss: 2.4193 - val_acc: 0.1288\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4157 - acc: 0.1368 - val_loss: 2.4172 - val_acc: 0.1390\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4109 - acc: 0.1394 - val_loss: 2.4134 - val_acc: 0.1433\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4066 - acc: 0.1433 - val_loss: 2.4080 - val_acc: 0.1409\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4021 - acc: 0.1423 - val_loss: 2.4046 - val_acc: 0.1404\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3983 - acc: 0.1427 - val_loss: 2.4025 - val_acc: 0.1430\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3971 - acc: 0.1440 - val_loss: 2.4006 - val_acc: 0.1422\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3950 - acc: 0.1449 - val_loss: 2.3994 - val_acc: 0.1450\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3940 - acc: 0.1443 - val_loss: 2.3985 - val_acc: 0.1466\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3909 - acc: 0.1476 - val_loss: 2.3975 - val_acc: 0.1476\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3900 - acc: 0.1493 - val_loss: 2.3972 - val_acc: 0.1466\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3893 - acc: 0.1504 - val_loss: 2.3964 - val_acc: 0.1487\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3877 - acc: 0.1511 - val_loss: 2.3967 - val_acc: 0.1503\n",
      "logloss val 2.39665597203874\n",
      "*****************************************************\n",
      "2_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4605 - acc: 0.1268 - val_loss: 2.4274 - val_acc: 0.1288\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4270 - acc: 0.1277 - val_loss: 2.4252 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4254 - acc: 0.1285 - val_loss: 2.4232 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4227 - acc: 0.1284 - val_loss: 2.4213 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4207 - acc: 0.1298 - val_loss: 2.4198 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4200 - acc: 0.1318 - val_loss: 2.4190 - val_acc: 0.1303\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4186 - acc: 0.1370 - val_loss: 2.4176 - val_acc: 0.1375\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4135 - acc: 0.1423 - val_loss: 2.4145 - val_acc: 0.1420\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4095 - acc: 0.1416 - val_loss: 2.4083 - val_acc: 0.1405\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4025 - acc: 0.1427 - val_loss: 2.4046 - val_acc: 0.1442\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3983 - acc: 0.1449 - val_loss: 2.4027 - val_acc: 0.1428\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3971 - acc: 0.1445 - val_loss: 2.4010 - val_acc: 0.1445\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3941 - acc: 0.1463 - val_loss: 2.3999 - val_acc: 0.1469\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3943 - acc: 0.1479 - val_loss: 2.3990 - val_acc: 0.1493\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3914 - acc: 0.1476 - val_loss: 2.3987 - val_acc: 0.1537\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3908 - acc: 0.1482 - val_loss: 2.3983 - val_acc: 0.1568\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3881 - acc: 0.1507 - val_loss: 2.3975 - val_acc: 0.1578\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3862 - acc: 0.1529 - val_loss: 2.3976 - val_acc: 0.1578\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3870 - acc: 0.1520 - val_loss: 2.3976 - val_acc: 0.1537\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3850 - acc: 0.1533 - val_loss: 2.3979 - val_acc: 0.1543\n",
      "logloss val 2.3978786770719847\n",
      "*****************************************************\n",
      "3_fold\n",
      "Epoch 1/20\n",
      "3s - loss: 2.4695 - acc: 0.1253 - val_loss: 2.4306 - val_acc: 0.1298\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4272 - acc: 0.1294 - val_loss: 2.4265 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4256 - acc: 0.1278 - val_loss: 2.4249 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4236 - acc: 0.1291 - val_loss: 2.4235 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4209 - acc: 0.1278 - val_loss: 2.4225 - val_acc: 0.1354\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4202 - acc: 0.1300 - val_loss: 2.4214 - val_acc: 0.1302\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4191 - acc: 0.1320 - val_loss: 2.4209 - val_acc: 0.1302\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4157 - acc: 0.1355 - val_loss: 2.4198 - val_acc: 0.1343\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4154 - acc: 0.1396 - val_loss: 2.4179 - val_acc: 0.1382\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4121 - acc: 0.1412 - val_loss: 2.4136 - val_acc: 0.1433\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4045 - acc: 0.1431 - val_loss: 2.4093 - val_acc: 0.1370\n",
      "Epoch 12/20\n",
      "2s - loss: 2.3978 - acc: 0.1443 - val_loss: 2.4081 - val_acc: 0.1323\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3973 - acc: 0.1463 - val_loss: 2.4082 - val_acc: 0.1275\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3944 - acc: 0.1471 - val_loss: 2.4067 - val_acc: 0.1342\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3922 - acc: 0.1485 - val_loss: 2.4059 - val_acc: 0.1347\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3910 - acc: 0.1495 - val_loss: 2.4057 - val_acc: 0.1355\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3887 - acc: 0.1518 - val_loss: 2.4058 - val_acc: 0.1382\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3887 - acc: 0.1526 - val_loss: 2.4057 - val_acc: 0.1397\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3845 - acc: 0.1545 - val_loss: 2.4056 - val_acc: 0.1383\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3865 - acc: 0.1538 - val_loss: 2.4058 - val_acc: 0.1410\n",
      "logloss val 2.405777173219826\n",
      "*****************************************************\n",
      "4_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4660 - acc: 0.1281 - val_loss: 2.4280 - val_acc: 0.1287\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4262 - acc: 0.1278 - val_loss: 2.4261 - val_acc: 0.1270\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4251 - acc: 0.1281 - val_loss: 2.4245 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4228 - acc: 0.1299 - val_loss: 2.4232 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4211 - acc: 0.1281 - val_loss: 2.4222 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4194 - acc: 0.1286 - val_loss: 2.4213 - val_acc: 0.1364\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4178 - acc: 0.1333 - val_loss: 2.4198 - val_acc: 0.1369\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4164 - acc: 0.1384 - val_loss: 2.4167 - val_acc: 0.1406\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4099 - acc: 0.1414 - val_loss: 2.4104 - val_acc: 0.1424\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4027 - acc: 0.1438 - val_loss: 2.4057 - val_acc: 0.1467\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3989 - acc: 0.1431 - val_loss: 2.4043 - val_acc: 0.1501\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3962 - acc: 0.1471 - val_loss: 2.4031 - val_acc: 0.1477\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3942 - acc: 0.1477 - val_loss: 2.4019 - val_acc: 0.1460\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3923 - acc: 0.1501 - val_loss: 2.4016 - val_acc: 0.1449\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3907 - acc: 0.1509 - val_loss: 2.4010 - val_acc: 0.1408\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3876 - acc: 0.1527 - val_loss: 2.4011 - val_acc: 0.1436\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3891 - acc: 0.1512 - val_loss: 2.4011 - val_acc: 0.1447\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3846 - acc: 0.1537 - val_loss: 2.4009 - val_acc: 0.1428\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3855 - acc: 0.1526 - val_loss: 2.4004 - val_acc: 0.1426\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3835 - acc: 0.1537 - val_loss: 2.4002 - val_acc: 0.1449\n",
      "logloss val 2.400220066269058\n",
      "*****************************************************\n",
      "5_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4627 - acc: 0.1263 - val_loss: 2.4280 - val_acc: 0.1286\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4262 - acc: 0.1278 - val_loss: 2.4265 - val_acc: 0.1330\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4259 - acc: 0.1300 - val_loss: 2.4254 - val_acc: 0.1286\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4224 - acc: 0.1282 - val_loss: 2.4244 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4203 - acc: 0.1295 - val_loss: 2.4234 - val_acc: 0.1286\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4202 - acc: 0.1296 - val_loss: 2.4226 - val_acc: 0.1326\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4182 - acc: 0.1319 - val_loss: 2.4216 - val_acc: 0.1316\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4166 - acc: 0.1331 - val_loss: 2.4200 - val_acc: 0.1332\n",
      "Epoch 9/20\n",
      "2s - loss: 2.4145 - acc: 0.1366 - val_loss: 2.4177 - val_acc: 0.1353\n",
      "Epoch 10/20\n",
      "2s - loss: 2.4126 - acc: 0.1401 - val_loss: 2.4124 - val_acc: 0.1416\n",
      "Epoch 11/20\n",
      "2s - loss: 2.4049 - acc: 0.1425 - val_loss: 2.4045 - val_acc: 0.1462\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4004 - acc: 0.1436 - val_loss: 2.4011 - val_acc: 0.1454\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3983 - acc: 0.1440 - val_loss: 2.4000 - val_acc: 0.1448\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3951 - acc: 0.1456 - val_loss: 2.3995 - val_acc: 0.1456\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3935 - acc: 0.1477 - val_loss: 2.3990 - val_acc: 0.1459\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3922 - acc: 0.1485 - val_loss: 2.3986 - val_acc: 0.1509\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3908 - acc: 0.1492 - val_loss: 2.3987 - val_acc: 0.1515\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3884 - acc: 0.1523 - val_loss: 2.3984 - val_acc: 0.1521\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3886 - acc: 0.1518 - val_loss: 2.3983 - val_acc: 0.1530\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3856 - acc: 0.1518 - val_loss: 2.3984 - val_acc: 0.1530\n",
      "logloss val 2.398418695389394\n",
      "*****************************************************\n",
      "6_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4667 - acc: 0.1260 - val_loss: 2.4284 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4274 - acc: 0.1279 - val_loss: 2.4257 - val_acc: 0.1286\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4252 - acc: 0.1268 - val_loss: 2.4237 - val_acc: 0.1306\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4236 - acc: 0.1300 - val_loss: 2.4215 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4221 - acc: 0.1296 - val_loss: 2.4205 - val_acc: 0.1286\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4199 - acc: 0.1297 - val_loss: 2.4180 - val_acc: 0.1316\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4187 - acc: 0.1373 - val_loss: 2.4152 - val_acc: 0.1428\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4139 - acc: 0.1413 - val_loss: 2.4084 - val_acc: 0.1411\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4050 - acc: 0.1428 - val_loss: 2.4012 - val_acc: 0.1439\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4014 - acc: 0.1430 - val_loss: 2.3986 - val_acc: 0.1444\n",
      "Epoch 11/20\n",
      "1s - loss: 2.3983 - acc: 0.1446 - val_loss: 2.3979 - val_acc: 0.1451\n",
      "Epoch 12/20\n",
      "1s - loss: 2.3944 - acc: 0.1460 - val_loss: 2.3972 - val_acc: 0.1473\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3931 - acc: 0.1475 - val_loss: 2.3967 - val_acc: 0.1490\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3922 - acc: 0.1478 - val_loss: 2.3970 - val_acc: 0.1502\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3903 - acc: 0.1515 - val_loss: 2.3964 - val_acc: 0.1487\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3884 - acc: 0.1521 - val_loss: 2.3967 - val_acc: 0.1501\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3868 - acc: 0.1529 - val_loss: 2.3961 - val_acc: 0.1473\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3853 - acc: 0.1533 - val_loss: 2.3963 - val_acc: 0.1485\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3850 - acc: 0.1534 - val_loss: 2.3960 - val_acc: 0.1481\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3846 - acc: 0.1529 - val_loss: 2.3963 - val_acc: 0.1491\n",
      "logloss val 2.3963135852101947\n",
      "*****************************************************\n",
      "7_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4646 - acc: 0.1268 - val_loss: 2.4273 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4274 - acc: 0.1288 - val_loss: 2.4244 - val_acc: 0.1286\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4250 - acc: 0.1272 - val_loss: 2.4221 - val_acc: 0.1286\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4218 - acc: 0.1303 - val_loss: 2.4198 - val_acc: 0.1286\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4205 - acc: 0.1352 - val_loss: 2.4166 - val_acc: 0.1372\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4164 - acc: 0.1422 - val_loss: 2.4102 - val_acc: 0.1359\n",
      "Epoch 7/20\n",
      "2s - loss: 2.4077 - acc: 0.1419 - val_loss: 2.4014 - val_acc: 0.1367\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4040 - acc: 0.1425 - val_loss: 2.3988 - val_acc: 0.1403\n",
      "Epoch 9/20\n",
      "2s - loss: 2.3994 - acc: 0.1455 - val_loss: 2.3967 - val_acc: 0.1406\n",
      "Epoch 10/20\n",
      "2s - loss: 2.3976 - acc: 0.1469 - val_loss: 2.3962 - val_acc: 0.1431\n",
      "Epoch 11/20\n",
      "2s - loss: 2.3957 - acc: 0.1463 - val_loss: 2.3952 - val_acc: 0.1404\n",
      "Epoch 12/20\n",
      "2s - loss: 2.3943 - acc: 0.1479 - val_loss: 2.3951 - val_acc: 0.1446\n",
      "Epoch 13/20\n",
      "2s - loss: 2.3921 - acc: 0.1511 - val_loss: 2.3952 - val_acc: 0.1448\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3904 - acc: 0.1505 - val_loss: 2.3947 - val_acc: 0.1442\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3895 - acc: 0.1510 - val_loss: 2.3943 - val_acc: 0.1446\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3883 - acc: 0.1522 - val_loss: 2.3943 - val_acc: 0.1463\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3858 - acc: 0.1547 - val_loss: 2.3939 - val_acc: 0.1467\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3852 - acc: 0.1534 - val_loss: 2.3948 - val_acc: 0.1481\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3830 - acc: 0.1559 - val_loss: 2.3949 - val_acc: 0.1471\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3830 - acc: 0.1543 - val_loss: 2.3949 - val_acc: 0.1475\n",
      "logloss val 2.3949207724634225\n",
      "*****************************************************\n",
      "8_fold\n",
      "Epoch 1/20\n",
      "1s - loss: 2.4654 - acc: 0.1257 - val_loss: 2.4283 - val_acc: 0.1269\n",
      "Epoch 2/20\n",
      "1s - loss: 2.4258 - acc: 0.1290 - val_loss: 2.4266 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "1s - loss: 2.4268 - acc: 0.1284 - val_loss: 2.4251 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "1s - loss: 2.4225 - acc: 0.1292 - val_loss: 2.4240 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "1s - loss: 2.4223 - acc: 0.1281 - val_loss: 2.4225 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "1s - loss: 2.4212 - acc: 0.1283 - val_loss: 2.4218 - val_acc: 0.1287\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4190 - acc: 0.1306 - val_loss: 2.4202 - val_acc: 0.1308\n",
      "Epoch 8/20\n",
      "1s - loss: 2.4178 - acc: 0.1309 - val_loss: 2.4186 - val_acc: 0.1304\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4170 - acc: 0.1327 - val_loss: 2.4160 - val_acc: 0.1371\n",
      "Epoch 10/20\n",
      "1s - loss: 2.4110 - acc: 0.1419 - val_loss: 2.4107 - val_acc: 0.1446\n",
      "Epoch 11/20\n",
      "1s - loss: 2.4054 - acc: 0.1434 - val_loss: 2.4059 - val_acc: 0.1414\n",
      "Epoch 12/20\n",
      "1s - loss: 2.4018 - acc: 0.1428 - val_loss: 2.4030 - val_acc: 0.1416\n",
      "Epoch 13/20\n",
      "1s - loss: 2.3993 - acc: 0.1439 - val_loss: 2.4019 - val_acc: 0.1405\n",
      "Epoch 14/20\n",
      "1s - loss: 2.3954 - acc: 0.1453 - val_loss: 2.4019 - val_acc: 0.1410\n",
      "Epoch 15/20\n",
      "1s - loss: 2.3956 - acc: 0.1453 - val_loss: 2.4006 - val_acc: 0.1420\n",
      "Epoch 16/20\n",
      "1s - loss: 2.3932 - acc: 0.1473 - val_loss: 2.4004 - val_acc: 0.1424\n",
      "Epoch 17/20\n",
      "1s - loss: 2.3913 - acc: 0.1480 - val_loss: 2.4000 - val_acc: 0.1436\n",
      "Epoch 18/20\n",
      "1s - loss: 2.3889 - acc: 0.1502 - val_loss: 2.3986 - val_acc: 0.1445\n",
      "Epoch 19/20\n",
      "1s - loss: 2.3893 - acc: 0.1502 - val_loss: 2.3987 - val_acc: 0.1444\n",
      "Epoch 20/20\n",
      "1s - loss: 2.3866 - acc: 0.1522 - val_loss: 2.3976 - val_acc: 0.1424\n",
      "logloss val 2.397624038275701\n",
      "*****************************************************\n",
      "9_fold\n",
      "Epoch 1/20\n",
      "2s - loss: 2.4651 - acc: 0.1247 - val_loss: 2.4280 - val_acc: 0.1270\n",
      "Epoch 2/20\n",
      "2s - loss: 2.4280 - acc: 0.1284 - val_loss: 2.4263 - val_acc: 0.1287\n",
      "Epoch 3/20\n",
      "2s - loss: 2.4248 - acc: 0.1292 - val_loss: 2.4249 - val_acc: 0.1287\n",
      "Epoch 4/20\n",
      "2s - loss: 2.4241 - acc: 0.1270 - val_loss: 2.4235 - val_acc: 0.1287\n",
      "Epoch 5/20\n",
      "2s - loss: 2.4218 - acc: 0.1293 - val_loss: 2.4223 - val_acc: 0.1287\n",
      "Epoch 6/20\n",
      "2s - loss: 2.4205 - acc: 0.1286 - val_loss: 2.4211 - val_acc: 0.1287\n",
      "Epoch 7/20\n",
      "1s - loss: 2.4206 - acc: 0.1272 - val_loss: 2.4201 - val_acc: 0.1278\n",
      "Epoch 8/20\n",
      "2s - loss: 2.4179 - acc: 0.1278 - val_loss: 2.4190 - val_acc: 0.1287\n",
      "Epoch 9/20\n",
      "1s - loss: 2.4178 - acc: 0.1280 - val_loss: 2.4176 - val_acc: 0.1327\n",
      "Epoch 10/20\n",
      "3s - loss: 2.4161 - acc: 0.1289 - val_loss: 2.4160 - val_acc: 0.1358\n",
      "Epoch 11/20\n",
      "1s - loss: 2.4132 - acc: 0.1364 - val_loss: 2.4123 - val_acc: 0.1468\n",
      "Epoch 12/20\n",
      "2s - loss: 2.4085 - acc: 0.1420 - val_loss: 2.4044 - val_acc: 0.1476\n",
      "Epoch 13/20\n",
      "2s - loss: 2.4018 - acc: 0.1433 - val_loss: 2.3984 - val_acc: 0.1471\n",
      "Epoch 14/20\n",
      "2s - loss: 2.3971 - acc: 0.1451 - val_loss: 2.3963 - val_acc: 0.1471\n",
      "Epoch 15/20\n",
      "2s - loss: 2.3946 - acc: 0.1455 - val_loss: 2.3953 - val_acc: 0.1473\n",
      "Epoch 16/20\n",
      "2s - loss: 2.3926 - acc: 0.1484 - val_loss: 2.3941 - val_acc: 0.1499\n",
      "Epoch 17/20\n",
      "2s - loss: 2.3913 - acc: 0.1501 - val_loss: 2.3935 - val_acc: 0.1460\n",
      "Epoch 18/20\n",
      "2s - loss: 2.3894 - acc: 0.1513 - val_loss: 2.3930 - val_acc: 0.1496\n",
      "Epoch 19/20\n",
      "2s - loss: 2.3878 - acc: 0.1528 - val_loss: 2.3932 - val_acc: 0.1489\n",
      "Epoch 20/20\n",
      "2s - loss: 2.3862 - acc: 0.1520 - val_loss: 2.3923 - val_acc: 0.1493\n",
      "logloss val 2.392325430377301\n",
      "average logloss val 2.3986647774551813\n"
     ]
    }
   ],
   "source": [
    "# define baseline model\n",
    "def without_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "dummy_y_without = np_utils.to_categorical(y_train_total_without)\n",
    "kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\n",
    "score_list_without=[]\n",
    "val_loss_list_without = []\n",
    "for index,(train, test) in enumerate(kf):\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = dummy_y_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = dummy_y_without[test]\n",
    "    print('*****************************************************')\n",
    "    print('{}_fold'.format(index))\n",
    "    model=without_model(X_train_total_without.shape[1])\n",
    "    fit= model.fit_generator(generator=batch_generator(X_train_without, y_train_without, 512, True),\n",
    "                         nb_epoch=20,\n",
    "                         samples_per_epoch=80000,\n",
    "                         validation_data=(X_val_without.todense(), y_val_without), verbose=2\n",
    "                         )\n",
    "    scores_val_without = model.predict_generator(generator=batch_generatorp(X_val_without, 512, False), \n",
    "                                         val_samples=X_val_without.shape[0])\n",
    "    scores_without = model.predict_generator(generator=batch_generatorp(X_test_total_without, 512, False), \n",
    "                                     val_samples=X_test_total_without.shape[0])\n",
    "    score_list_without.append(scores_without)\n",
    "    \n",
    "    val_loss = log_loss(y_val_without, scores_val_without)\n",
    "    val_loss_list_without.append(val_loss)\n",
    "    print('logloss val {}'.format(val_loss))\n",
    "\n",
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(score_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_without.to_csv('nnt_without_result{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_ensemble = (score_ave_without+score_ave_without_lr)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without eventsIII: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.821016\ttest-merror:0.850703\n",
      "[1]\ttrain-merror:0.821\ttest-merror:0.85077\n",
      "[2]\ttrain-merror:0.82038\ttest-merror:0.850502\n",
      "[3]\ttrain-merror:0.819995\ttest-merror:0.850703\n",
      "[4]\ttrain-merror:0.819442\ttest-merror:0.849833\n",
      "logloss val 2.440388885505712\n"
     ]
    }
   ],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.2,\n",
    "                                                    stratify=y_train_total_without)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':100,'eta':0.1,'silent':1,'objective':'multi:softprob','nthread':2,'num_class':12}\n",
    "num_round = 5\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# putting together and save into final file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final score based on the percentage of testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with score:1.9392115926279074\n",
      "without score:2.3931157227003554\n",
      "final validation score:2.2505748160093315\n"
     ]
    }
   ],
   "source": [
    "#val_score_final = val_loss_ave_without*76877/112071+val_loss_ave_with*35194/112071\n",
    "val_score_final = (val_loss_ave_without*X_test_total_without.shape[0]+\n",
    "                   val_loss_ave_with*X_test_total_with.shape[0])/(X_test_total_without.shape[0]+X_test_total_with.shape[0])\n",
    "print('with score:{}'.format(val_loss_ave_with))\n",
    "print('without score:{}'.format(val_loss_ave_without))\n",
    "print('final validation score:{}'.format(val_score_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pd.concat((pred_with,pred_without))\n",
    "pred.to_csv('doublemodel_v6.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
