{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talking data demographic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from scipy.sparse import csr_matrix,hstack,vstack\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from input folder and print the format of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py35/lib/python3.5/site-packages/numpy/lib/arraysetops.py:395: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "events\n",
      "                   device_id            timestamp  longitude  latitude\n",
      "event_id                                                             \n",
      "1         29182687948017175  2016-05-01 00:55:25     121.38     31.24 \n",
      "\n",
      "\n",
      "app_event\n",
      "    event_id               app_id  is_installed  is_active\n",
      "0         2  5927333115845830913             1          1 \n",
      "\n",
      "\n",
      "label\n",
      "    label_id category\n",
      "0         1      NaN \n",
      "\n",
      "\n",
      "app_label\n",
      "                 app_id  label_id\n",
      "0  7324884708820027918       251 \n",
      "\n",
      "\n",
      "device\n",
      "                      phone_brand device_model\n",
      "device_id                                    \n",
      "-8890648629457979026          小米           红米 \n",
      "\n",
      "gender_age_train\n",
      "                      gender  age   group\n",
      "device_id                               \n",
      "-8076087639492063270      M   35  M32-38 \n",
      "\n",
      "\n",
      "gender_age_test\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [1002079943728939269]\n"
     ]
    }
   ],
   "source": [
    "# When a user uses TalkingData SDK, the event gets logged in this data. \n",
    "# Each event has an event id, location (lat/long), and the event \n",
    "# corresponds to a list of apps in app_events.\n",
    "events = pd.read_csv('input/events.csv',index_col='event_id')\n",
    "app_event = pd.read_csv('input/app_events.csv')\n",
    "print('\\nevents\\n',events.head(1), '\\n')\n",
    "print('\\napp_event\\n',app_event.head(1), '\\n')\n",
    "\n",
    "# Apps' labels and their categories in text\n",
    "label = pd.read_csv('input/label_categories.csv')\n",
    "print('\\nlabel\\n',label.head(1), '\\n')\n",
    "\n",
    "# Apps and their labels, the label_id's can be used to join with \n",
    "# label_categories\n",
    "app_label = pd.read_csv('input/app_labels.csv')\n",
    "print('\\napp_label\\n',app_label.head(1), '\\n')\n",
    "\n",
    "# Device ids, brand, and models\n",
    "device = pd.read_csv('input/phone_brand_device_model.csv')\n",
    "device = device.drop_duplicates('device_id').set_index('device_id')\n",
    "print('\\ndevice\\n',device.head(1), '\\n')\n",
    "\n",
    "# Training set\n",
    "gender_age_train = pd.read_csv('input/gender_age_train.csv',index_col = 'device_id')\n",
    "print('gender_age_train\\n',gender_age_train.head(1),'\\n')\n",
    "\n",
    "# Test set. Group: this is the target variable you are going to predict.\n",
    "gender_age_test = pd.read_csv('input/gender_age_test.csv',index_col = 'device_id')\n",
    "print('\\ngender_age_test\\n',gender_age_test.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of two set of devices: with events and without events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that about 70% of the data has no event information. This could come from the fact that the users disable the data sharing function or they are inactive users. If it is because of the first reason, treating the features as no active usage will clearly mislead the model. So we separated the data into two groups and built models for both sets of data. Test data were also separated into two groups and fed into the corresponding models, after which the output was combined into the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set without events:    51336\n",
      "Size of training set with events:       23309\n",
      "Total size of training set:             74645\n",
      "Size of testing set without events:     76877\n",
      "Size of training set with events:       35194\n",
      "Total size of training set:             112071\n"
     ]
    }
   ],
   "source": [
    "gender_age_train_with = gender_age_train.loc[gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "\n",
    "gender_age_train_without = gender_age_train.loc[~gender_age_train.index.isin(events.device_id.unique())].copy()\n",
    "\n",
    "gender_age_test_with = gender_age_test.loc[gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "\n",
    "gender_age_test_without = gender_age_test.loc[~gender_age_test.index.isin(events.device_id.unique())].copy()\n",
    "\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set without events:',gender_age_train_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_train_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_train.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of testing set without events:',gender_age_test_without.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Size of training set with events:',gender_age_test_with.shape[0]))\n",
    "print('{0:<40.40}{1:5}'.format('Total size of training set:',gender_age_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convinience of creating sparse matrix, we create another integer index for the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_age_train_with['int_index'] = np.arange(gender_age_train_with.shape[0])\n",
    "gender_age_test_with['int_index'] = np.arange(gender_age_test_with.shape[0])\n",
    "gender_age_train_without['int_index'] = np.arange(gender_age_train_without.shape[0])\n",
    "gender_age_test_without['int_index'] = np.arange(gender_age_test_without.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering I: phone brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the phone brand, and feed this as a feature into the training and testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 131 kinds of phone brands.\n"
     ]
    }
   ],
   "source": [
    "# Encode labels 'brand' with value between 0 and n_classes-1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(device.phone_brand)\n",
    "device['brand'] = encoder.transform(device.phone_brand)\n",
    "\n",
    "# The training and test sets share the same index col \n",
    "# with device data frame, so simply insert the encoded\n",
    "# brand number. \n",
    "gender_age_train_with['brand'] = device['brand']\n",
    "gender_age_test_with['brand'] = device['brand']\n",
    "gender_age_train_without['brand'] = device['brand']\n",
    "gender_age_test_without['brand'] = device['brand']\n",
    "\n",
    "brandnumber = len(encoder.classes_)\n",
    "print('There are {0} kinds of phone brands.'.format(brandnumber))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of zeros in the matrix. In order to improve efficiency, we created sparse matrix with each row representing one device and each column representing one brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 131)\n",
      "X_test_brand_with shape: (35194, 131)\n",
      "X_train_brand_without shape: (51336, 131)\n",
      "X_test_brand_without shape: (76877, 131)\n"
     ]
    }
   ],
   "source": [
    "# The sparse matrix satisfies the following condition:\n",
    "#     X_train_brand_with(gender_age_train_with.int_index[k], gender_age_train_with.brand) = 1\n",
    "X_train_brand_with = csr_matrix(arg1 = (np.ones(gender_age_train_with.shape[0]),\n",
    "                                        (gender_age_train_with.int_index,\n",
    "                                         gender_age_train_with.brand)),\n",
    "                                shape = (gender_age_train_with.shape[0],\n",
    "                                         brandnumber)\n",
    "                               )\n",
    "\n",
    "X_test_brand_with = csr_matrix(arg1 = (np.ones(gender_age_test_with.shape[0]),\n",
    "                                       (gender_age_test_with.int_index,\n",
    "                                        gender_age_test_with.brand)),\n",
    "                              shape = (gender_age_test_with.shape[0],\n",
    "                                       brandnumber))\n",
    "\n",
    "\n",
    "X_train_brand_without = csr_matrix(arg1 = (np.ones(gender_age_train_without.shape[0]),\n",
    "                                           (gender_age_train_without.int_index,\n",
    "                                            gender_age_train_without.brand)),\n",
    "                                  shape = (gender_age_train_without.shape[0],\n",
    "                                           brandnumber))\n",
    "\n",
    "X_test_brand_without = csr_matrix(arg1 = (np.ones(gender_age_test_without.shape[0]),\n",
    "                                          (gender_age_test_without.int_index,\n",
    "                                           gender_age_test_without.brand)),\n",
    "                                 shape = (gender_age_test_without.shape[0],\n",
    "                                          brandnumber))\n",
    "\n",
    "print('X_train_brand_with shape:',X_train_brand_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_brand_with.shape)\n",
    "print('X_train_brand_without shape:',X_train_brand_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_brand_without.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering II: phone device model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature not only contains the phone brand but also the model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1667 kinds of phone brand and model combination.\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the phone brand and model strings\n",
    "brand_model = device.phone_brand.str.cat(device.device_model)\n",
    "\n",
    "# Encode the feature\n",
    "encoder3 = LabelEncoder()\n",
    "encoder3.fit(brand_model)\n",
    "device['model'] = encoder3.transform(brand_model)\n",
    "\n",
    "gender_age_train_with['model'] = device['model']\n",
    "gender_age_test_with['model'] = device['model']\n",
    "gender_age_train_without['model'] = device['model']\n",
    "gender_age_test_without['model'] = device['model']\n",
    "\n",
    "modelnumber = len(encoder3.classes_)\n",
    "print('There are {0} kinds of phone brand and model combination.'.format(modelnumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_brand_with shape: (23309, 1667)\n",
      "X_test_brand_with shape: (35194, 1667)\n",
      "X_train_brand_without shape: (51336, 1667)\n",
      "X_test_brand_without shape: (76877, 1667)\n"
     ]
    }
   ],
   "source": [
    "# Create the sparse matrix as above.\n",
    "X_train_model_with = csr_matrix(arg1 = (np.ones(gender_age_train_with.shape[0]),\n",
    "                                        (gender_age_train_with.int_index,\n",
    "                                         gender_age_train_with.model)),\n",
    "                               shape = (gender_age_train_with.shape[0],\n",
    "                                        modelnumber))\n",
    "\n",
    "X_test_model_with = csr_matrix(arg1 = (np.ones(gender_age_test_with.shape[0]),\n",
    "                                       (gender_age_test_with.int_index,\n",
    "                                        gender_age_test_with.model)),\n",
    "                              shape = (gender_age_test_with.shape[0],\n",
    "                                       modelnumber))\n",
    "\n",
    "X_train_model_without = csr_matrix(arg1 = (np.ones(gender_age_train_without.shape[0]),\n",
    "                                           (gender_age_train_without.int_index,\n",
    "                                            gender_age_train_without.model)),\n",
    "                                  shape = (gender_age_train_without.shape[0],\n",
    "                                           modelnumber))\n",
    "\n",
    "X_test_model_without = csr_matrix(arg1 = (np.ones(gender_age_test_without.shape[0]),\n",
    "                                          (gender_age_test_without.int_index,\n",
    "                                           gender_age_test_without.model)),\n",
    "                                 shape = (gender_age_test_without.shape[0],\n",
    "                                          modelnumber))\n",
    "\n",
    "print('X_train_brand_with shape:',X_train_model_with.shape)\n",
    "print('X_test_brand_with shape:',X_test_model_with.shape)\n",
    "print('X_train_brand_without shape:',X_train_model_without.shape)\n",
    "print('X_test_brand_without shape:',X_test_model_without.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean the memory related to devices and brand model.\n",
    "del device,brand_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering III: Installed app\n",
    "From the mobile events, we extracted the apps installed and used that as a feature. Only the data set with events has such feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Encoding the app_id and store it into app column, and feed this \n",
    "#as a feature into the training and testing test.\n",
    "encoder2 = LabelEncoder()\n",
    "encoder2.fit(app_event.app_id)\n",
    "app_event['app'] = encoder2.transform(app_event.app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The events dataframe:\n",
      "                    device_id            timestamp  longitude  latitude\n",
      "event_id                                                               \n",
      "1           29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
      "2        -6401643145415154744  2016-05-01 00:54:12     103.65     30.97 \n",
      "\n",
      "The app_event dataframe:\n",
      "   event_id               app_id  is_installed  is_active    app\n",
      "0         2  5927333115845830913             1          1  15408\n",
      "1         2 -5720078949152207372             1          0   3384 \n",
      "\n",
      "             device_id  event_id    app  is_installed\n",
      "0 -6401643145415154744         2  15408             1\n",
      "1 -6401643145415154744         2   3384             1\n",
      "2 -6401643145415154744         2   7620             1\n",
      "3 -6401643145415154744         2   8902             1\n",
      "4 -6401643145415154744         2  18686             1 \n",
      "\n",
      "Consider the installation of 19237 apps. This will be    the number of features after encoding.\n"
     ]
    }
   ],
   "source": [
    "print('The events dataframe:')\n",
    "print(events.head(2),'\\n')\n",
    "print('The app_event dataframe:')\n",
    "print(app_event.head(2), '\\n')\n",
    "\n",
    "# Merge the events dataframe with the app_events data frame\n",
    "installed_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_installed']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "\n",
    "print(installed_app.head(), '\\n')\n",
    "\n",
    "appnumber = np.size(installed_app.app.unique())\n",
    "print('Consider the installation of {0} apps. This will be\\\n",
    "    the number of features after encoding.'.format(appnumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installed_app_grouped:\n",
      "                           installed\n",
      "device_id            app            \n",
      "-9222956879900151005 548        True\n",
      "                     1096       True\n",
      "                     1248       True\n",
      "                     1545       True\n",
      "                     1664       True \n",
      "\n",
      "installed_app_train:\n",
      "                           installed  int_index\n",
      "device_id            app                       \n",
      "-9222956879900151005 548        True       5145\n",
      "                     1096       True       5145\n",
      "                     1248       True       5145\n",
      "                     1545       True       5145\n",
      "                     1664       True       5145\n"
     ]
    }
   ],
   "source": [
    "# Use a new dataFrame installed_app_grouped to store the \n",
    "# installed column for each device,app index\n",
    "installed_app_grouped = pd.DataFrame()\n",
    "installed_app_grouped['installed'] = installed_app\\\n",
    "                                        .groupby(['device_id','app'])['app'].size()>0\n",
    "\n",
    "print('installed_app_grouped:')\n",
    "print(installed_app_grouped.head(), '\\n')\n",
    "installed_app_train_with = pd.merge(installed_app_grouped,\n",
    "                                    gender_age_train_with[['int_index']],\n",
    "                                    how = 'right',\n",
    "                                    right_index=True,\n",
    "                                    left_index=True)\n",
    "installed_app_test_with = pd.merge(installed_app_grouped,\n",
    "                                   gender_age_test_with[['int_index']],\n",
    "                                   how = 'right',\n",
    "                                   right_index=True,\n",
    "                                   left_index=True)\n",
    "print('installed_app_train:')\n",
    "print(installed_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set:\n",
      "             device_id   app  installed  int_index\n",
      "0 -9222956879900151005   548       True       5145\n",
      "1 -9222956879900151005  1096       True       5145\n",
      "2 -9222956879900151005  1248       True       5145\n",
      "3 -9222956879900151005  1545       True       5145\n",
      "4 -9222956879900151005  1664       True       5145\n",
      "The test set:\n",
      "             device_id    app  installed  int_index\n",
      "0 -9222661944218806987   1867       True       2851\n",
      "1 -9222661944218806987   7519       True       2851\n",
      "2 -9222661944218806987   7843       True       2851\n",
      "3 -9222661944218806987   8704       True       2851\n",
      "4 -9222661944218806987  10000       True       2851\n"
     ]
    }
   ],
   "source": [
    "installed_app_train_with = installed_app_train_with.reset_index()\n",
    "installed_app_test_with = installed_app_test_with.reset_index()\n",
    "\n",
    "# Make sure there is no NA in int_index column\n",
    "installed_app_train_with = installed_app_train_with.dropna(subset=['int_index'])\n",
    "installed_app_test_with = installed_app_test_with.dropna(subset=['int_index'])\n",
    "print('The training set:')\n",
    "print(installed_app_train_with.head())\n",
    "print('The test set:')\n",
    "print(installed_app_test_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed shape: (23309, 19237)\n",
      "X_test_installed shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "# Used the table above, we can create the sparse matrix that corresponds to the \n",
    "# app installation feature.\n",
    "X_train_installed_with = csr_matrix(arg1 = (np.ones(installed_app_train_with.shape[0]),\n",
    "                                            (installed_app_train_with.int_index,\n",
    "                                             installed_app_train_with.app)), \n",
    "                                   shape = (gender_age_train_with.shape[0],\n",
    "                                            appnumber))\n",
    "\n",
    "X_test_installed_with = csr_matrix(arg1 = (np.ones(installed_app_test_with.shape[0]),\n",
    "                                           (installed_app_test_with.int_index,\n",
    "                                            installed_app_test_with.app)),\n",
    "                                   shape = (gender_age_test_with.shape[0],\n",
    "                                            appnumber))\n",
    "\n",
    "print('X_train_installed shape:',X_train_installed_with.shape)\n",
    "print('X_test_installed shape:',X_test_installed_with.shape)\n",
    "\n",
    "del installed_app_test_with,installed_app_train_with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering IV: app label\n",
    "\n",
    "While knowing the installation of different individual apps might be useful, we also grouped the apps based on their types (label_id in the data). After this step, instead of the dichotomous features we had above, we will have numerical features. This set of feature essentially represent the total number usage of different types of apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two dataframe used:\n",
      "app_events:\n",
      "                 app_id  event_id\n",
      "0  5927333115845830913         2\n",
      "1 -5720078949152207372         2 \n",
      "\n",
      "app_label:\n",
      "                 app_id  label_id\n",
      "0  7324884708820027918       251\n",
      "1 -4494216993218550286       251 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The two dataframe used:')\n",
    "print('app_events:\\n',app_event[['app_id','event_id']].head(2),'\\n')\n",
    "print('app_label:\\n',app_label[['app_id','label_id']].head(2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of labels: 492\n",
      "app_label_new:\n",
      "                     app_id  label_id    app  label\n",
      "434376 -2600987541603275322         2   6493      0\n",
      "434377 -2600987541603275322         4   6493      1\n",
      "435078  3489720147367481003         5  13156      2\n",
      "435221 -3009285907035616624         5   6118      2\n",
      "418666 -1968479138889230354         6   7100      3\n"
     ]
    }
   ],
   "source": [
    "# Not every app in the app_label data frame shows up in the app_event.\n",
    "# So we use only the ones appear in the app_event to save memory.\n",
    "# This part need to be fixed for streaming data set. \n",
    "app_label_new = app_label.loc[app_label.app_id.isin(app_event.app_id.unique())].copy()\n",
    "\n",
    "# Make use of the encoder in Feature engineering II to get label of app.\n",
    "app_label_new['app'] = encoder2.transform(app_label_new.app_id)\n",
    "\n",
    "# Encode the labels into smaller range to save memory.\n",
    "encoder4 = LabelEncoder().fit(app_label_new.label_id)\n",
    "app_label_new['label'] = encoder4.transform(app_label_new.label_id)\n",
    "\n",
    "labelnumber = len(encoder4.classes_)\n",
    "\n",
    "print('Total number of labels:',labelnumber)\n",
    "print('app_label_new:')\n",
    "print(app_label_new.sort_values(by='label').head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before merging: installed_app_grouped:\n",
      "                           installed\n",
      "device_id            app            \n",
      "-9222956879900151005 548        True\n",
      "                     1096       True\n",
      "                     1248       True\n",
      "                     1545       True\n",
      "                     1664       True \n",
      "\n",
      "After merging: installed_label_grouped:\n",
      "             device_id  label  size\n",
      "0 -9222956879900151005    117     1\n",
      "1 -9222956879900151005    120     1\n",
      "2 -9222956879900151005    126     1\n",
      "3 -9222956879900151005    138     2\n",
      "4 -9222956879900151005    147     2\n"
     ]
    }
   ],
   "source": [
    "print('Before merging: installed_app_grouped:')\n",
    "print(installed_app_grouped.head(),'\\n')\n",
    "\n",
    "installed_label_grouped = (installed_app_grouped.reset_index()[['device_id','app']]\n",
    "                                                # merge with the app_label_new data frame\n",
    "                                                .merge(app_label_new[['app','label']])\n",
    "                                                .groupby(['device_id','label'])\n",
    "                           # calculate the size of different device_id, label pairs\n",
    "                          )['app'].agg(['size'])\\\n",
    "                          .reset_index()\n",
    "                          \n",
    "print('After merging: installed_label_grouped:')\n",
    "print(installed_label_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge the feature into the training and testing sets.\n",
    "label_app_train_with = pd.merge(installed_label_grouped,\n",
    "                                gender_age_train_with[['int_index']],\n",
    "                                how = 'right',\n",
    "                                right_index=True,\n",
    "                                left_on='device_id')\n",
    "\n",
    "label_app_test_with = pd.merge(installed_label_grouped,\n",
    "                               gender_age_test_with[['int_index']],\n",
    "                               how = 'right',\n",
    "                               right_index=True,\n",
    "                               left_on ='device_id' )\n",
    "\n",
    "# Make sure there is no NA value in the int_index and label since they will be used \n",
    "# as the indexes in the sparse matrix.\n",
    "label_app_train_with = label_app_train_with.dropna(subset= ['int_index','label'])\n",
    "\n",
    "label_app_test_with = label_app_test_with.dropna(subset= ['int_index','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_installed_with shape: (23309, 492)\n",
      "X_test_installed_with shape: (35194, 492)\n"
     ]
    }
   ],
   "source": [
    "# Dichotomous feature as to whether apps with such label was installed or not.\n",
    "'''X_train_label_with = csr_matrix(arg1 = (np.ones(label_app_train_with.shape[0]),\n",
    "                                            (label_app_train_with.int_index,\n",
    "                                             label_app_train_with.label)),\n",
    "                                   shape = (gender_age_train_with.shape[0],\n",
    "                                            labelnumber))\n",
    "                                            \n",
    "X_test_label_with = csr_matrix(arg1 = (np.ones(label_app_test_with.shape[0]),\n",
    "                                        (label_app_test_with.int_index,\n",
    "                                         label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],\n",
    "                                       labelnumber))'''\n",
    "\n",
    "# Numerical feature as to how many apps with such label was installed.\n",
    "X_train_label_with = csr_matrix(arg1 = (label_app_train_with['size'],\n",
    "                                         (label_app_train_with.int_index,\n",
    "                                          label_app_train_with.label)),\n",
    "                                shape = (gender_age_train_with.shape[0],\n",
    "                                         labelnumber))\n",
    "\n",
    "X_test_label_with = csr_matrix(arg1 = (label_app_test_with['size'],\n",
    "                                        (label_app_test_with.int_index,\n",
    "                                         label_app_test_with.label)),\n",
    "                              shape = (gender_age_test_with.shape[0],\n",
    "                                       labelnumber))\n",
    "\n",
    "print('X_train_installed_with shape:',X_train_label_with.shape)\n",
    "\n",
    "print('X_test_installed_with shape:',X_test_label_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del installed_app_grouped,label,app_label,app_label_new,\\\n",
    "    label_app_test_with,label_app_train_with,encoder4,installed_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering V: active app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  event_id    app  is_active\n",
      "0 -6401643145415154744         2  15408          1\n",
      "3 -6401643145415154744         2   8902          1\n",
      "4 -6401643145415154744         2  18686          1\n",
      "5 -6401643145415154744         2  14346          1\n",
      "9 -6401643145415154744         2  16908          1\n"
     ]
    }
   ],
   "source": [
    "# Merge the events dataframe with the app_events data frame\n",
    "active_app = pd.merge(events[['device_id']],app_event[['event_id','app','is_active']],\n",
    "                         how='right',right_on = 'event_id',left_index = True)\n",
    "\n",
    "# Select the active ones\n",
    "active_app = active_app.loc[active_app.is_active==1]\n",
    "\n",
    "print(active_app.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_app_grouped:\n",
      "                           size\n",
      "device_id            app       \n",
      "-9222956879900151005 548      4\n",
      "                     1248    15\n",
      "                     1545     2\n",
      "                     1848    31\n",
      "                     2236    17\n"
     ]
    }
   ],
   "source": [
    "# Group by (device_id, app) index and calculat the number of active usage\n",
    "active_app_grouped = active_app.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "\n",
    "print('active_app_grouped:')\n",
    "print(active_app_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_app_train_with:\n",
      "                           size  int_index\n",
      "device_id            app                  \n",
      "-9222956879900151005 548      4     5145.0\n",
      "                     1248    15     5145.0\n",
      "                     1545     2     5145.0\n",
      "                     1848    31     5145.0\n",
      "                     2236    17     5145.0\n"
     ]
    }
   ],
   "source": [
    "active_app_train_with = pd.merge(active_app_grouped,gender_age_train_with[['int_index']],\n",
    "                               how = 'left',right_index=True,left_index=True)\n",
    "\n",
    "active_app_test_with = pd.merge(active_app_grouped,gender_age_test_with[['int_index']],\n",
    "                              how = 'left',right_index=True,left_index=True)\n",
    "\n",
    "print('active_app_train_with:')\n",
    "print(active_app_train_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id   app  size  int_index\n",
      "0 -9222956879900151005   548     4     5145.0\n",
      "1 -9222956879900151005  1248    15     5145.0\n",
      "2 -9222956879900151005  1545     2     5145.0\n",
      "3 -9222956879900151005  1848    31     5145.0\n",
      "4 -9222956879900151005  2236    17     5145.0\n",
      "              device_id    app  size  int_index\n",
      "55 -9222661944218806987   1867     3     2851.0\n",
      "56 -9222661944218806987   7519     7     2851.0\n",
      "57 -9222661944218806987   7843     1     2851.0\n",
      "58 -9222661944218806987   8704     3     2851.0\n",
      "59 -9222661944218806987  10000     1     2851.0\n"
     ]
    }
   ],
   "source": [
    "# reset the indexes and make sure no NA in the int_index columns\n",
    "active_app_train_with = active_app_train_with.reset_index()\n",
    "active_app_test_with = active_app_test_with.reset_index()\n",
    "active_app_train_with = active_app_train_with.dropna(subset=['int_index'])\n",
    "active_app_test_with = active_app_test_with.dropna(subset=['int_index'])\n",
    "print(active_app_train_with.head())\n",
    "print(active_app_test_with.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_active shape: (23309, 19237)\n",
      "X_test_active shape: (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "# binary active map\n",
    "#X_train_active_with = csr_matrix((np.ones(active_app_train_with.shape[0]),\n",
    "#                            (active_app_train_with.int_index,active_app_train_with.app)), \n",
    "#                            shape = (gender_age_train_with.shape[0],appnumber))\n",
    "#X_test_active = csr_matrix((np.ones(active_app_test_with.shape[0]),\n",
    "#                            (active_app_test.int_index,active_app_test_with.app)),\n",
    "#                            shape = (gender_age_test_with.shape[0],appnumber))\n",
    "# count the number of active app\n",
    "X_train_active_with = csr_matrix(arg1 = (active_app_train_with['size'],\n",
    "                                         (active_app_train_with.int_index,\n",
    "                                          active_app_train_with.app)), \n",
    "                                 shape = (gender_age_train_with.shape[0],\n",
    "                                          appnumber))\n",
    "\n",
    "X_test_active_with = csr_matrix(arg1 = (active_app_test_with['size'],\n",
    "                                        (active_app_test_with.int_index,\n",
    "                                         active_app_test_with.app)),\n",
    "                                shape = (gender_age_test_with.shape[0],\n",
    "                                         appnumber))\n",
    "\n",
    "print('X_train_active shape:',X_train_active_with.shape)\n",
    "print('X_test_active shape:',X_test_active_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler(with_mean=False)\\nX_train_active_with = scaler.fit_transform(X_train_active_with)\\nX_test_active_with = scaler.transform(X_test_active_with)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardlizing the data\n",
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_active_with = scaler.fit_transform(X_train_active_with)\n",
    "X_test_active_with = scaler.transform(X_test_active_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering VI: active time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             device_id  time  times\n",
      "0 -9222956879900151005     7      2\n",
      "1 -9222956879900151005    11      7\n",
      "2 -9222956879900151005    12     13\n",
      "3 -9222956879900151005    13      3\n",
      "4 -9222956879900151005    14      5\n"
     ]
    }
   ],
   "source": [
    "# Use the hour number to represent the time, so there are 24 different values\n",
    "events_time = events[['device_id','timestamp']].copy()\n",
    "\n",
    "events_time['time']  = events_time['timestamp'].str[11:13].astype(int)\n",
    "\n",
    "events_time.drop(['timestamp'],axis=1,inplace=True)\n",
    "\n",
    "events_time = events_time.groupby(['device_id','time'])['time']\\\n",
    "            .agg(['count']).reset_index().rename(columns = {'count':'times'})\n",
    "\n",
    "\n",
    "timenumber= events_time.time.unique().shape[0]\n",
    "\n",
    "print(events_time.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_time_with shape: (23309, 24)\n",
      "X_test_time_with shape: (35194, 24)\n"
     ]
    }
   ],
   "source": [
    "time_train_with = pd.merge(events_time,gender_age_train_with[['int_index']],\n",
    "                               right_index=True,left_on='device_id')\n",
    "time_test_with = pd.merge(events_time,gender_age_test_with[['int_index']],\n",
    "                               right_index=True,left_on ='device_id' )\n",
    "#binary\n",
    "X_train_time_with = csr_matrix(arg1 = (np.ones(time_train_with.shape[0]),\n",
    "                                       (time_train_with.int_index,\n",
    "                                        time_train_with.time)), \n",
    "                               shape = (gender_age_train_with.shape[0],timenumber))\n",
    "X_test_time_with = csr_matrix((np.ones(time_test_with.shape[0]),\n",
    "                            (time_test_with.int_index,time_test_with.time)),\n",
    "                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "\n",
    "#number\n",
    "#X_train_time_with = csr_matrix((time_train_with['times'],\n",
    "#                            (time_train_with.int_index,time_train_with.time)), \n",
    "#                            shape = (gender_age_train_with.shape[0],timenumber))\n",
    "#X_test_time_with = csr_matrix((time_test_with['times'],\n",
    "#                            (time_test_with.int_index,time_test_with.time)),\n",
    "#                            shape = (gender_age_test_with.shape[0],timenumber))\n",
    "print('X_train_time_with shape:',X_train_time_with.shape)\n",
    "print('X_test_time_with shape:',X_test_time_with.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the time period count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler(with_mean=False)\\nX_train_time_with = scaler.fit_transform(X_train_time_with)\\nX_test_time_with = scaler.transform(X_test_time_with)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scaler = StandardScaler(with_mean=False)\n",
    "X_train_time_with = scaler.fit_transform(X_train_time_with)\n",
    "X_test_time_with = scaler.transform(X_test_time_with)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature join and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(74645, 1798)\n",
      "Testing shape:\n",
      "(76877, 1798)\n",
      "y shape:\n",
      "(74645, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_without = hstack((X_train_brand_without,X_train_model_without),format='csr')\n",
    "temp_train = hstack((X_train_brand_with,X_train_model_with),format='csr')\n",
    "X_test_total_without = hstack((X_test_brand_without,X_test_model_without),format='csr')\n",
    "\n",
    "X_train_total_without= vstack((X_train_total_without,temp_train),format = 'csr')\n",
    "gender_age_train_without_temp = pd.concat((gender_age_train_without,gender_age_train_with))\n",
    "\n",
    "print('Training shape:')\n",
    "print(X_train_total_without.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_without.shape)\n",
    "print('y shape:')\n",
    "print(gender_age_train_without_temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device with events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:\n",
      "(23309, 40788)\n",
      "Testing shape:\n",
      "(35194, 40788)\n"
     ]
    }
   ],
   "source": [
    "X_train_total_with = hstack((X_train_brand_with,X_train_model_with,\n",
    "                             X_train_active_with,\n",
    "                             X_train_time_with,\n",
    "                             X_train_installed_with,X_train_label_with),format='csr')\n",
    "X_test_total_with = hstack((X_test_brand_with,X_test_model_with,\n",
    "                            X_test_active_with,\n",
    "                            X_test_time_with,\n",
    "                           X_test_installed_with,X_test_label_with),format='csr')\n",
    "print('Training shape:')\n",
    "print(X_train_total_with.shape)\n",
    "print('Testing shape:')\n",
    "print(X_test_total_with.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentile selction\n",
    "#selector = SelectPercentile(f_classif, percentile=80)\n",
    "#selector.fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#X_val.shape\n",
    "\n",
    "# Selection using chi-square\n",
    "#selector = SelectKBest(chi2, k=15155).fit(X_train_total, y_train_total)\n",
    "#X_train_total = selector.transform(X_train_total)\n",
    "#X_test_total = selector.transform(X_test_total)\n",
    "#print('Training shape:')\n",
    "#print(X_train_total.shape)\n",
    "#print('Testing shape:')\n",
    "#print(X_test_total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear the memory before we do the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del app_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Start training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetencoder = LabelEncoder().fit(gender_age_train_with.group)\n",
    "nclasses = len(targetencoder.classes_)\n",
    "y_train_total_with = targetencoder.transform(gender_age_train_with.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset I: device with events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Device with events I: Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator \n",
    "    #(https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def with_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(50, input_dim=X_dim_input, init='normal', activation='tanh'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    model.add(Dense(50, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    #model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "\n",
    "dummy_y_with = np_utils.to_categorical(y_train_total_with)\n",
    "for i in range(8):\n",
    "    kf = StratifiedKFold(y_train_total_with,n_folds = 10,random_state = i)\n",
    "    score_list_with=[]\n",
    "    val_loss_list_with = []\n",
    "    for index,(train, test) in enumerate(kf):\n",
    "        X_train_with = X_train_total_with[train]\n",
    "        y_train_with = dummy_y_with[train]\n",
    "        X_val_with = X_train_total_with[test]\n",
    "        y_val_with = dummy_y_with[test]\n",
    "        #print(X_val.shape)\n",
    "        print('*****************************************************')\n",
    "        print('{}_fold'.format(index))\n",
    "        model=with_model(X_train_total_with.shape[1])\n",
    "        fit= model.fit_generator(generator=batch_generator(X_train_with, y_train_with, 32, True),\n",
    "                             nb_epoch=15,\n",
    "                             samples_per_epoch=30000,\n",
    "                             validation_data=(X_val_with.todense(), y_val_with), verbose=2\n",
    "                             )\n",
    "        scores_val_with = model.predict_generator(generator=batch_generatorp(X_val_with, 32, False), \n",
    "                                             val_samples=X_val_with.shape[0])\n",
    "        scores_with = model.predict_generator(generator=batch_generatorp(X_test_total_with, 32, False), \n",
    "                                         val_samples=X_test_total_with.shape[0])\n",
    "        score_list_with.append(scores_with)\n",
    "        val_loss = log_loss(y_val_with, scores_val_with)\n",
    "        val_loss_list_with.append(val_loss)\n",
    "        print('logloss val {}'.format(val_loss))\n",
    "\n",
    "    for index,i in enumerate(val_loss_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    val_loss_ave_with = sumi/len(val_loss_list_with)\n",
    "    print('average logloss val {}'.format(val_loss_ave_with))\n",
    "    for index,i in enumerate(score_list_with):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    score_ave_with = sumi/len(score_list_with)\n",
    "    pred_with = pd.DataFrame(score_ave_with, index = gender_age_test_with.index, columns=targetencoder.classes_)\n",
    "    pred_with.to_csv('nnet_with_all_feature_100relu_softmax{}.csv'.format(val_loss_ave_with))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Device with events II: XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_total_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.02,\n",
    "                                                    stratify=y_train_total_with)\n",
    "#grid search cv\n",
    "xgbclassifier = xgb.XGBClassifier(objective=\"multi:softprob\", nthread=1)\n",
    "\n",
    "clf = GridSearchCV(estimator=xgbclassifier,param_grid={\n",
    "        'max_depth': [ 6,7,8],\n",
    "        'learning_rate': [0.15,0.2,0.25],\n",
    "        'reg_lambda':[4,5],\n",
    "        'reg_alpha':[2,3,4]\n",
    "    },verbose=10,scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_estimator_\n",
    "val_loss_ave_with= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_with)\n",
    "del X_train,X_val,y_train,y_val\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.02,\n",
    "                                                    stratify=y_train_total_with,random_state=1)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':6,\n",
    "         'eta':0.1,\n",
    "         'silent':0,\n",
    "         'objective':'multi:softprob',\n",
    "         'nthread':2,\n",
    "         'num_class':12,\n",
    "         'eval_metric':'mlogloss',\n",
    "        'lambda':5,\n",
    "        'lambda_bias':0,\n",
    "        'alpha':1}\n",
    "num_round = 300\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the best parameters, we combined the training set with the development set and started the final training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(X_train_total_with,label = y_train_total_with)\n",
    "xg_test = xgb.DMatrix(X_test_total_with)\n",
    "bst = xgb.train(param,xg_train,num_round)\n",
    "yprob = bst.predict(xg_test).reshape(X_test_total_with.shape[0],12)\n",
    "pred_with_xgb = pd.DataFrame(yprob, \n",
    "                            index = gender_age_test_with.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_with_xgb.to_csv('xgb_with_result{}.csv'.format(val_loss))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  Device with events III: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_with,y_train_total_with,test_size=0.2,\n",
    "                                                    stratify=y_train_total_with)\n",
    "#lr grid search\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['lbfgs']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_with= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_with)\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.0180472176683,multi_class='multinomial',solver='lbfgs')\n",
    "lr.fit(X_train_total_with,y_train_total_with)\n",
    "score_ave_with_lr = lr.predict_proba(X_test_total_with)\n",
    "pred_with_lr = pd.DataFrame(score_ave_with_lr, \n",
    "                            index = gender_age_test_with.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_with_lr.to_csv('lr_with_result{}.csv'.format(val_loss_ave_with))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset II: device without events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_total_without = targetencoder.transform(gender_age_train_without_temp.group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Device without events I: Naive Bayes, Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NB grid search\n",
    "nbc = MultinomialNB()\n",
    "alpha_value = np.logspace(-3,4,100)\n",
    "clf = GridSearchCV(estimator=nbc,param_grid = dict(alpha=alpha_value),scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.alpha)\n",
    "print(-clf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lr grid search\n",
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.2,\n",
    "                                                    stratify=y_train_total_without)\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "solver_value = ['lbfgs']\n",
    "C_value = np.logspace(-2,0,40)\n",
    "clf = GridSearchCV(estimator=lr,param_grid = dict(C=C_value,solver=solver_value),\n",
    "                   scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.solver)\n",
    "val_loss_ave_without= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_without)\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the best parameters, we combined the training set with the development set and started the final training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(C=0.02,multi_class='multinomial',solver='newton-cg')\n",
    "lr = LogisticRegression(C=0.0744380301325,multi_class='multinomial',solver='lbfgs')\n",
    "lr.fit(X_train_total_without,y_train_total_without)\n",
    "score_ave_without_lr = lr.predict_proba(X_test_total_without)\n",
    "pred_without_lr = pd.DataFrame(score_ave_without_lr, \n",
    "                            index = gender_age_test_without.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_without_lr.to_csv('lr_without_result{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = 1)\n",
    "score_list_without=[]\n",
    "val_loss_list_without = []\n",
    "for index,(train, test) in enumerate(kf):\n",
    "    X_train_without = X_train_total_without[train]\n",
    "    y_train_without = y_train_total_without[train]\n",
    "    X_val_without = X_train_total_without[test]\n",
    "    y_val_without = y_train_total_without[test]\n",
    "    print('*****************************************************')\n",
    "    print('{}_fold'.format(index))\n",
    "    lr = LogisticRegression(C=0.0774263682681,multi_class='multinomial',solver='newton-cg')\n",
    "    lr.fit(X_train_without,y_train_without)\n",
    "    scores_val_without = lr.predict_proba(X_val_without)\n",
    "    val_loss = log_loss(y_val_without, scores_val_without)\n",
    "    val_loss_list_without.append(val_loss)\n",
    "    print('logloss val {}'.format(val_loss))\n",
    "    \n",
    "    scores_without = lr.predict_proba(X_test_total_without)\n",
    "    score_list_without.append(scores_without)\n",
    "    \n",
    "for index,i in enumerate(val_loss_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "val_loss_ave_without = sumi/len(score_list_without)\n",
    "print('average logloss val {}'.format(val_loss_ave_without))\n",
    "for index,i in enumerate(score_list_without):\n",
    "    if(index==0):\n",
    "        sumi = i\n",
    "    else:\n",
    "        sumi = i+sumi\n",
    "score_ave_without = sumi/len(score_list_without)\n",
    "pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without events II: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def without_model(X_dim_input):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(10, input_dim=X_train_total.shape[1], init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    #model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dense(40, input_dim=X_dim_input, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "dummy_y_without = np_utils.to_categorical(y_train_total_without)\n",
    "for i in range(8):\n",
    "    kf = StratifiedKFold(y_train_total_without,n_folds = 10,random_state = i*2)\n",
    "    score_list_without=[]\n",
    "    val_loss_list_without = []\n",
    "    for index,(train, test) in enumerate(kf):\n",
    "        X_train_without = X_train_total_without[train]\n",
    "        y_train_without = dummy_y_without[train]\n",
    "        X_val_without = X_train_total_without[test]\n",
    "        y_val_without = dummy_y_without[test]\n",
    "        print('*****************************************************')\n",
    "        print('{}_fold'.format(index))\n",
    "        model=without_model(X_train_total_without.shape[1])\n",
    "        fit= model.fit_generator(generator=batch_generator(X_train_without, y_train_without, 512, True),\n",
    "                             nb_epoch=20,\n",
    "                             samples_per_epoch=80000,\n",
    "                             validation_data=(X_val_without.todense(), y_val_without), verbose=2\n",
    "                             )\n",
    "        scores_val_without = model.predict_generator(generator=batch_generatorp(X_val_without, 512, False), \n",
    "                                             val_samples=X_val_without.shape[0])\n",
    "        scores_without = model.predict_generator(generator=batch_generatorp(X_test_total_without, 512, False), \n",
    "                                         val_samples=X_test_total_without.shape[0])\n",
    "        score_list_without.append(scores_without)\n",
    "\n",
    "        val_loss = log_loss(y_val_without, scores_val_without)\n",
    "        val_loss_list_without.append(val_loss)\n",
    "        print('logloss val {}'.format(val_loss))\n",
    "\n",
    "    for index,i in enumerate(val_loss_list_without):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    val_loss_ave_without = sumi/len(score_list_without)\n",
    "    print('average logloss val {}'.format(val_loss_ave_without))\n",
    "    for index,i in enumerate(score_list_without):\n",
    "        if(index==0):\n",
    "            sumi = i\n",
    "        else:\n",
    "            sumi = i+sumi\n",
    "    score_ave_without = sumi/len(score_list_without)\n",
    "    pred_without = pd.DataFrame(score_ave_without, index = gender_age_test_without.index, columns=targetencoder.classes_)\n",
    "    pred_without.to_csv('nnt_without_100_relu{}.csv'.format(val_loss_ave_without))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device without events III: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.02,\n",
    "                                                    stratify=y_train_total_without)\n",
    "#grid search cv\n",
    "xgbclassifier = xgb.XGBClassifier(objective=\"multi:softprob\", nthread=1)\n",
    "\n",
    "clf = GridSearchCV(estimator=xgbclassifier,param_grid={\n",
    "        'max_depth': [ 4,5,6,7,8,9,10],\n",
    "        'learning_rate': [0.01,0.02, 0.1, 0.2],\n",
    "    },verbose=10,scoring='log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "val_loss_ave_with= -clf.score(X_val,y_val)\n",
    "print(val_loss_ave_with)\n",
    "del X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train,X_val,y_train,y_val) = cv.train_test_split(X_train_total_without,y_train_total_without,test_size=0.02,\n",
    "                                                    stratify=y_train_total_without,random_state=1)\n",
    "xg_train = xgb.DMatrix(X_train,label = y_train)\n",
    "xg_test = xgb.DMatrix(X_val,label = y_val)\n",
    "param = {'max_depth':6,\n",
    "         'eta':0.1,\n",
    "         'silent':0,\n",
    "         'objective':'multi:softprob',\n",
    "         'nthread':2,\n",
    "         'num_class':12,\n",
    "         'eval_metric':'mlogloss',\n",
    "        'lambda':4,\n",
    "        'lambda_bias':0,\n",
    "        'alpha':0}\n",
    "num_round = 300\n",
    "watchlist = [(xg_train,'train'),(xg_test,'test')]\n",
    "bst = xgb.train(param,xg_train,num_round,watchlist)\n",
    "yprob = bst.predict(xg_test).reshape(y_val.shape[0],12)\n",
    "val_loss = log_loss(y_val, yprob)\n",
    "print('logloss val {}'.format(val_loss))\n",
    "del X_train,X_val,y_train,y_val\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the best parameters, we combined the training set with the development set and started the final training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(X_train_total_without,label = y_train_total_without)\n",
    "xg_test = xgb.DMatrix(X_test_total_without)\n",
    "bst = xgb.train(param,xg_train,num_round)\n",
    "yprob = bst.predict(xg_test).reshape(X_test_total_without.shape[0],12)\n",
    "pred_without_xgb = pd.DataFrame(yprob, \n",
    "                            index = gender_age_test_without.index, \n",
    "                            columns=targetencoder.classes_)\n",
    "pred_without_xgb.to_csv('xgb_without_result{}.csv'.format(val_loss))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result of one model into a file.\n",
    "### Note: Ensemble will be done in another notebook.\n",
    "Final score based on the percentage of testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#val_score_final = val_loss_ave_without*76877/112071+val_loss_ave_with*35194/112071\n",
    "val_score_final = (val_loss_ave_without*X_test_total_without.shape[0]+\n",
    "                   val_loss_ave_with*X_test_total_with.shape[0])/(X_test_total_without.shape[0]+X_test_total_with.shape[0])\n",
    "print('with score:{}'.format(val_loss_ave_with))\n",
    "print('without score:{}'.format(val_loss_ave_without))\n",
    "print('final validation score:{}'.format(val_score_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pd.concat((pred_with,pred_without))\n",
    "pred.to_csv('doublemodel_v6.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
